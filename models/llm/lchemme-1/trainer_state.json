{
  "best_metric": 0.0008444083505310118,
  "best_model_checkpoint": "/nemo/lab/johnsone/home/users/johnsoe/projects/abx-discovery-strategy/models/240513_zinc22-lteq300.smiles.tok=10000k.pre=0k.bart-base.20250626-092330/checkpoint-2420000",
  "epoch": 0.14047725743440764,
  "eval_steps": 10000,
  "global_step": 2500000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0,
      "eval_loss": 6.888973712921143,
      "eval_runtime": 20.0014,
      "eval_samples_per_second": 4999.645,
      "eval_steps_per_second": 78.144,
      "step": 0
    },
    {
      "epoch": 2.8095451486881533e-05,
      "grad_norm": 9.52749252319336,
      "learning_rate": 5e-06,
      "loss": 5.5913,
      "step": 500
    },
    {
      "epoch": 5.6190902973763066e-05,
      "grad_norm": 5.683294296264648,
      "learning_rate": 1e-05,
      "loss": 3.9867,
      "step": 1000
    },
    {
      "epoch": 8.428635446064459e-05,
      "grad_norm": 1.47303307056427,
      "learning_rate": 1.5e-05,
      "loss": 2.4234,
      "step": 1500
    },
    {
      "epoch": 0.00011238180594752613,
      "grad_norm": 1.81260085105896,
      "learning_rate": 2e-05,
      "loss": 1.7937,
      "step": 2000
    },
    {
      "epoch": 0.00014047725743440766,
      "grad_norm": 1.7195221185684204,
      "learning_rate": 2.5e-05,
      "loss": 1.5134,
      "step": 2500
    },
    {
      "epoch": 0.00016857270892128918,
      "grad_norm": 1.8142869472503662,
      "learning_rate": 3e-05,
      "loss": 1.2611,
      "step": 3000
    },
    {
      "epoch": 0.0001966681604081707,
      "grad_norm": 1.9706733226776123,
      "learning_rate": 3.5e-05,
      "loss": 1.0631,
      "step": 3500
    },
    {
      "epoch": 0.00022476361189505226,
      "grad_norm": 1.9715917110443115,
      "learning_rate": 4e-05,
      "loss": 0.8883,
      "step": 4000
    },
    {
      "epoch": 0.0002528590633819338,
      "grad_norm": 1.6210906505584717,
      "learning_rate": 4.5e-05,
      "loss": 0.7415,
      "step": 4500
    },
    {
      "epoch": 0.0002809545148688153,
      "grad_norm": 1.674557089805603,
      "learning_rate": 5e-05,
      "loss": 0.6261,
      "step": 5000
    },
    {
      "epoch": 0.00030904996635569684,
      "grad_norm": 1.6202915906906128,
      "learning_rate": 5.500000000000001e-05,
      "loss": 0.529,
      "step": 5500
    },
    {
      "epoch": 0.00033714541784257837,
      "grad_norm": 1.5549585819244385,
      "learning_rate": 6e-05,
      "loss": 0.4633,
      "step": 6000
    },
    {
      "epoch": 0.0003652408693294599,
      "grad_norm": 1.827823281288147,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.4046,
      "step": 6500
    },
    {
      "epoch": 0.0003933363208163414,
      "grad_norm": 1.5045859813690186,
      "learning_rate": 7e-05,
      "loss": 0.355,
      "step": 7000
    },
    {
      "epoch": 0.00042143177230322294,
      "grad_norm": 1.8253350257873535,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.3141,
      "step": 7500
    },
    {
      "epoch": 0.0004495272237901045,
      "grad_norm": 1.566271185874939,
      "learning_rate": 8e-05,
      "loss": 0.284,
      "step": 8000
    },
    {
      "epoch": 0.00047762267527698605,
      "grad_norm": 1.5734202861785889,
      "learning_rate": 8.5e-05,
      "loss": 0.2589,
      "step": 8500
    },
    {
      "epoch": 0.0005057181267638676,
      "grad_norm": 1.7977020740509033,
      "learning_rate": 9e-05,
      "loss": 0.2356,
      "step": 9000
    },
    {
      "epoch": 0.0005338135782507491,
      "grad_norm": 1.600699543952942,
      "learning_rate": 9.5e-05,
      "loss": 0.2159,
      "step": 9500
    },
    {
      "epoch": 0.0005619090297376306,
      "grad_norm": 1.4404313564300537,
      "learning_rate": 0.0001,
      "loss": 0.2036,
      "step": 10000
    },
    {
      "epoch": 0.0005619090297376306,
      "eval_loss": 0.14702193439006805,
      "eval_runtime": 18.5107,
      "eval_samples_per_second": 5402.291,
      "eval_steps_per_second": 84.438,
      "step": 10000
    },
    {
      "epoch": 0.0005900044812245122,
      "grad_norm": 1.2905168533325195,
      "learning_rate": 9.999718887525494e-05,
      "loss": 0.1882,
      "step": 10500
    },
    {
      "epoch": 0.0006180999327113937,
      "grad_norm": 1.1306967735290527,
      "learning_rate": 9.999437775050987e-05,
      "loss": 0.1754,
      "step": 11000
    },
    {
      "epoch": 0.0006461953841982752,
      "grad_norm": 1.2319446802139282,
      "learning_rate": 9.999156662576481e-05,
      "loss": 0.1608,
      "step": 11500
    },
    {
      "epoch": 0.0006742908356851567,
      "grad_norm": 1.140312671661377,
      "learning_rate": 9.998875550101974e-05,
      "loss": 0.1502,
      "step": 12000
    },
    {
      "epoch": 0.0007023862871720383,
      "grad_norm": 1.1852821111679077,
      "learning_rate": 9.998594437627468e-05,
      "loss": 0.1379,
      "step": 12500
    },
    {
      "epoch": 0.0007304817386589198,
      "grad_norm": 1.3787728548049927,
      "learning_rate": 9.998313325152961e-05,
      "loss": 0.1329,
      "step": 13000
    },
    {
      "epoch": 0.0007585771901458013,
      "grad_norm": 1.1058694124221802,
      "learning_rate": 9.998032212678454e-05,
      "loss": 0.1244,
      "step": 13500
    },
    {
      "epoch": 0.0007866726416326828,
      "grad_norm": 1.2622324228286743,
      "learning_rate": 9.997751100203948e-05,
      "loss": 0.1144,
      "step": 14000
    },
    {
      "epoch": 0.0008147680931195644,
      "grad_norm": 1.313084363937378,
      "learning_rate": 9.997469987729441e-05,
      "loss": 0.1119,
      "step": 14500
    },
    {
      "epoch": 0.0008428635446064459,
      "grad_norm": 1.250646710395813,
      "learning_rate": 9.997188875254935e-05,
      "loss": 0.1039,
      "step": 15000
    },
    {
      "epoch": 0.0008709589960933275,
      "grad_norm": 0.9558308720588684,
      "learning_rate": 9.996907762780428e-05,
      "loss": 0.0982,
      "step": 15500
    },
    {
      "epoch": 0.000899054447580209,
      "grad_norm": 1.2596808671951294,
      "learning_rate": 9.996626650305922e-05,
      "loss": 0.097,
      "step": 16000
    },
    {
      "epoch": 0.0009271498990670906,
      "grad_norm": 1.3296126127243042,
      "learning_rate": 9.996345537831414e-05,
      "loss": 0.0928,
      "step": 16500
    },
    {
      "epoch": 0.0009552453505539721,
      "grad_norm": 0.6561537384986877,
      "learning_rate": 9.996064425356908e-05,
      "loss": 0.088,
      "step": 17000
    },
    {
      "epoch": 0.0009833408020408535,
      "grad_norm": 0.9283692240715027,
      "learning_rate": 9.9957833128824e-05,
      "loss": 0.0848,
      "step": 17500
    },
    {
      "epoch": 0.0010114362535277352,
      "grad_norm": 0.8722237348556519,
      "learning_rate": 9.995502200407895e-05,
      "loss": 0.0813,
      "step": 18000
    },
    {
      "epoch": 0.0010395317050146166,
      "grad_norm": 0.7258023023605347,
      "learning_rate": 9.995221087933389e-05,
      "loss": 0.0807,
      "step": 18500
    },
    {
      "epoch": 0.0010676271565014982,
      "grad_norm": 0.8281840085983276,
      "learning_rate": 9.994939975458881e-05,
      "loss": 0.0795,
      "step": 19000
    },
    {
      "epoch": 0.0010957226079883796,
      "grad_norm": 0.8396459221839905,
      "learning_rate": 9.994658862984376e-05,
      "loss": 0.0749,
      "step": 19500
    },
    {
      "epoch": 0.0011238180594752613,
      "grad_norm": 1.389635443687439,
      "learning_rate": 9.994377750509868e-05,
      "loss": 0.0734,
      "step": 20000
    },
    {
      "epoch": 0.0011238180594752613,
      "eval_loss": 0.04576404020190239,
      "eval_runtime": 18.1822,
      "eval_samples_per_second": 5499.886,
      "eval_steps_per_second": 85.963,
      "step": 20000
    },
    {
      "epoch": 0.0011519135109621429,
      "grad_norm": 0.8494037389755249,
      "learning_rate": 9.994096638035362e-05,
      "loss": 0.0713,
      "step": 20500
    },
    {
      "epoch": 0.0011800089624490243,
      "grad_norm": 0.9077866077423096,
      "learning_rate": 9.993815525560854e-05,
      "loss": 0.0696,
      "step": 21000
    },
    {
      "epoch": 0.001208104413935906,
      "grad_norm": 0.9291486144065857,
      "learning_rate": 9.993534413086348e-05,
      "loss": 0.0685,
      "step": 21500
    },
    {
      "epoch": 0.0012361998654227874,
      "grad_norm": 1.2969390153884888,
      "learning_rate": 9.993253300611843e-05,
      "loss": 0.0676,
      "step": 22000
    },
    {
      "epoch": 0.001264295316909669,
      "grad_norm": 0.6826701760292053,
      "learning_rate": 9.992972188137335e-05,
      "loss": 0.0651,
      "step": 22500
    },
    {
      "epoch": 0.0012923907683965504,
      "grad_norm": 0.9706263542175293,
      "learning_rate": 9.99269107566283e-05,
      "loss": 0.0618,
      "step": 23000
    },
    {
      "epoch": 0.001320486219883432,
      "grad_norm": 1.0366356372833252,
      "learning_rate": 9.992409963188322e-05,
      "loss": 0.063,
      "step": 23500
    },
    {
      "epoch": 0.0013485816713703135,
      "grad_norm": 0.8215048909187317,
      "learning_rate": 9.992128850713815e-05,
      "loss": 0.0608,
      "step": 24000
    },
    {
      "epoch": 0.001376677122857195,
      "grad_norm": 0.6448115110397339,
      "learning_rate": 9.991847738239308e-05,
      "loss": 0.0587,
      "step": 24500
    },
    {
      "epoch": 0.0014047725743440765,
      "grad_norm": 0.8662883639335632,
      "learning_rate": 9.991566625764802e-05,
      "loss": 0.0592,
      "step": 25000
    },
    {
      "epoch": 0.0014328680258309582,
      "grad_norm": 0.8560326099395752,
      "learning_rate": 9.991285513290295e-05,
      "loss": 0.0574,
      "step": 25500
    },
    {
      "epoch": 0.0014609634773178396,
      "grad_norm": 1.1596152782440186,
      "learning_rate": 9.991004400815789e-05,
      "loss": 0.0566,
      "step": 26000
    },
    {
      "epoch": 0.0014890589288047212,
      "grad_norm": 0.8749603033065796,
      "learning_rate": 9.990723288341282e-05,
      "loss": 0.0569,
      "step": 26500
    },
    {
      "epoch": 0.0015171543802916026,
      "grad_norm": 0.6134244203567505,
      "learning_rate": 9.990442175866776e-05,
      "loss": 0.0562,
      "step": 27000
    },
    {
      "epoch": 0.0015452498317784843,
      "grad_norm": 0.5479117035865784,
      "learning_rate": 9.990161063392269e-05,
      "loss": 0.0536,
      "step": 27500
    },
    {
      "epoch": 0.0015733452832653657,
      "grad_norm": 0.6497676968574524,
      "learning_rate": 9.989879950917762e-05,
      "loss": 0.053,
      "step": 28000
    },
    {
      "epoch": 0.0016014407347522473,
      "grad_norm": 0.9195018410682678,
      "learning_rate": 9.989598838443256e-05,
      "loss": 0.0519,
      "step": 28500
    },
    {
      "epoch": 0.0016295361862391287,
      "grad_norm": 0.6710736751556396,
      "learning_rate": 9.989317725968749e-05,
      "loss": 0.0515,
      "step": 29000
    },
    {
      "epoch": 0.0016576316377260104,
      "grad_norm": 0.5078403353691101,
      "learning_rate": 9.989036613494243e-05,
      "loss": 0.0513,
      "step": 29500
    },
    {
      "epoch": 0.0016857270892128918,
      "grad_norm": 1.0730489492416382,
      "learning_rate": 9.988755501019736e-05,
      "loss": 0.0505,
      "step": 30000
    },
    {
      "epoch": 0.0016857270892128918,
      "eval_loss": 0.030066829174757004,
      "eval_runtime": 18.9734,
      "eval_samples_per_second": 5270.533,
      "eval_steps_per_second": 82.378,
      "step": 30000
    },
    {
      "epoch": 0.0017138225406997734,
      "grad_norm": 0.8571711778640747,
      "learning_rate": 9.98847438854523e-05,
      "loss": 0.0515,
      "step": 30500
    },
    {
      "epoch": 0.001741917992186655,
      "grad_norm": 0.8424220085144043,
      "learning_rate": 9.988193276070723e-05,
      "loss": 0.0492,
      "step": 31000
    },
    {
      "epoch": 0.0017700134436735365,
      "grad_norm": 0.5051856637001038,
      "learning_rate": 9.987912163596216e-05,
      "loss": 0.0476,
      "step": 31500
    },
    {
      "epoch": 0.001798108895160418,
      "grad_norm": 0.7879220247268677,
      "learning_rate": 9.98763105112171e-05,
      "loss": 0.0483,
      "step": 32000
    },
    {
      "epoch": 0.0018262043466472995,
      "grad_norm": 0.6877661943435669,
      "learning_rate": 9.987349938647202e-05,
      "loss": 0.0468,
      "step": 32500
    },
    {
      "epoch": 0.0018542997981341811,
      "grad_norm": 1.3433399200439453,
      "learning_rate": 9.987068826172697e-05,
      "loss": 0.046,
      "step": 33000
    },
    {
      "epoch": 0.0018823952496210626,
      "grad_norm": 1.1512418985366821,
      "learning_rate": 9.98678771369819e-05,
      "loss": 0.0475,
      "step": 33500
    },
    {
      "epoch": 0.0019104907011079442,
      "grad_norm": 0.7874218821525574,
      "learning_rate": 9.986506601223683e-05,
      "loss": 0.0466,
      "step": 34000
    },
    {
      "epoch": 0.0019385861525948256,
      "grad_norm": 0.4622892439365387,
      "learning_rate": 9.986225488749177e-05,
      "loss": 0.0451,
      "step": 34500
    },
    {
      "epoch": 0.001966681604081707,
      "grad_norm": 0.7995318174362183,
      "learning_rate": 9.985944376274669e-05,
      "loss": 0.0438,
      "step": 35000
    },
    {
      "epoch": 0.001994777055568589,
      "grad_norm": 0.7266024351119995,
      "learning_rate": 9.985663263800164e-05,
      "loss": 0.0434,
      "step": 35500
    },
    {
      "epoch": 0.0020228725070554703,
      "grad_norm": 1.0257182121276855,
      "learning_rate": 9.985382151325656e-05,
      "loss": 0.0444,
      "step": 36000
    },
    {
      "epoch": 0.0020509679585423517,
      "grad_norm": 0.6577097773551941,
      "learning_rate": 9.98510103885115e-05,
      "loss": 0.0448,
      "step": 36500
    },
    {
      "epoch": 0.002079063410029233,
      "grad_norm": 1.1803948879241943,
      "learning_rate": 9.984819926376643e-05,
      "loss": 0.0434,
      "step": 37000
    },
    {
      "epoch": 0.002107158861516115,
      "grad_norm": 1.0205532312393188,
      "learning_rate": 9.984538813902136e-05,
      "loss": 0.0422,
      "step": 37500
    },
    {
      "epoch": 0.0021352543130029964,
      "grad_norm": 0.6613999009132385,
      "learning_rate": 9.984257701427631e-05,
      "loss": 0.0418,
      "step": 38000
    },
    {
      "epoch": 0.002163349764489878,
      "grad_norm": 0.9836078882217407,
      "learning_rate": 9.983976588953123e-05,
      "loss": 0.0419,
      "step": 38500
    },
    {
      "epoch": 0.0021914452159767592,
      "grad_norm": 0.3417188823223114,
      "learning_rate": 9.983695476478618e-05,
      "loss": 0.0423,
      "step": 39000
    },
    {
      "epoch": 0.002219540667463641,
      "grad_norm": 0.612248957157135,
      "learning_rate": 9.98341436400411e-05,
      "loss": 0.0406,
      "step": 39500
    },
    {
      "epoch": 0.0022476361189505225,
      "grad_norm": 1.5238674879074097,
      "learning_rate": 9.983133251529603e-05,
      "loss": 0.0398,
      "step": 40000
    },
    {
      "epoch": 0.0022476361189505225,
      "eval_loss": 0.023284142836928368,
      "eval_runtime": 18.8857,
      "eval_samples_per_second": 5295.009,
      "eval_steps_per_second": 82.761,
      "step": 40000
    },
    {
      "epoch": 0.002275731570437404,
      "grad_norm": 0.6089794039726257,
      "learning_rate": 9.982852139055097e-05,
      "loss": 0.044,
      "step": 40500
    },
    {
      "epoch": 0.0023038270219242858,
      "grad_norm": 1.8763660192489624,
      "learning_rate": 9.98257102658059e-05,
      "loss": 0.0411,
      "step": 41000
    },
    {
      "epoch": 0.002331922473411167,
      "grad_norm": 1.1818456649780273,
      "learning_rate": 9.982289914106085e-05,
      "loss": 0.0403,
      "step": 41500
    },
    {
      "epoch": 0.0023600179248980486,
      "grad_norm": 0.5629445910453796,
      "learning_rate": 9.982008801631577e-05,
      "loss": 0.0394,
      "step": 42000
    },
    {
      "epoch": 0.00238811337638493,
      "grad_norm": 1.3461107015609741,
      "learning_rate": 9.98172768915707e-05,
      "loss": 0.0388,
      "step": 42500
    },
    {
      "epoch": 0.002416208827871812,
      "grad_norm": 1.1721110343933105,
      "learning_rate": 9.981446576682564e-05,
      "loss": 0.0398,
      "step": 43000
    },
    {
      "epoch": 0.0024443042793586933,
      "grad_norm": 0.7615990042686462,
      "learning_rate": 9.981165464208057e-05,
      "loss": 0.0399,
      "step": 43500
    },
    {
      "epoch": 0.0024723997308455747,
      "grad_norm": 0.7045332789421082,
      "learning_rate": 9.98088435173355e-05,
      "loss": 0.0389,
      "step": 44000
    },
    {
      "epoch": 0.002500495182332456,
      "grad_norm": 0.7201482057571411,
      "learning_rate": 9.980603239259044e-05,
      "loss": 0.038,
      "step": 44500
    },
    {
      "epoch": 0.002528590633819338,
      "grad_norm": 1.375400424003601,
      "learning_rate": 9.980322126784537e-05,
      "loss": 0.0378,
      "step": 45000
    },
    {
      "epoch": 0.0025566860853062194,
      "grad_norm": 0.6325462460517883,
      "learning_rate": 9.980041014310031e-05,
      "loss": 0.0385,
      "step": 45500
    },
    {
      "epoch": 0.002584781536793101,
      "grad_norm": 0.6291035413742065,
      "learning_rate": 9.979759901835524e-05,
      "loss": 0.0372,
      "step": 46000
    },
    {
      "epoch": 0.0026128769882799822,
      "grad_norm": 0.6382013559341431,
      "learning_rate": 9.979478789361018e-05,
      "loss": 0.0388,
      "step": 46500
    },
    {
      "epoch": 0.002640972439766864,
      "grad_norm": 0.7805687189102173,
      "learning_rate": 9.979197676886511e-05,
      "loss": 0.0369,
      "step": 47000
    },
    {
      "epoch": 0.0026690678912537455,
      "grad_norm": 0.969341516494751,
      "learning_rate": 9.978916564412005e-05,
      "loss": 0.038,
      "step": 47500
    },
    {
      "epoch": 0.002697163342740627,
      "grad_norm": 0.49888843297958374,
      "learning_rate": 9.978635451937498e-05,
      "loss": 0.0361,
      "step": 48000
    },
    {
      "epoch": 0.0027252587942275083,
      "grad_norm": 0.6919141411781311,
      "learning_rate": 9.978354339462991e-05,
      "loss": 0.0362,
      "step": 48500
    },
    {
      "epoch": 0.00275335424571439,
      "grad_norm": 0.8416576385498047,
      "learning_rate": 9.978073226988485e-05,
      "loss": 0.0355,
      "step": 49000
    },
    {
      "epoch": 0.0027814496972012716,
      "grad_norm": 0.9731914401054382,
      "learning_rate": 9.977792114513978e-05,
      "loss": 0.0381,
      "step": 49500
    },
    {
      "epoch": 0.002809545148688153,
      "grad_norm": 0.9866794943809509,
      "learning_rate": 9.977511002039472e-05,
      "loss": 0.0363,
      "step": 50000
    },
    {
      "epoch": 0.002809545148688153,
      "eval_loss": 0.02040158584713936,
      "eval_runtime": 19.2914,
      "eval_samples_per_second": 5183.66,
      "eval_steps_per_second": 81.021,
      "step": 50000
    },
    {
      "epoch": 0.0028376406001750345,
      "grad_norm": 1.0668045282363892,
      "learning_rate": 9.977229889564965e-05,
      "loss": 0.0364,
      "step": 50500
    },
    {
      "epoch": 0.0028657360516619163,
      "grad_norm": 0.7556014060974121,
      "learning_rate": 9.976948777090459e-05,
      "loss": 0.0362,
      "step": 51000
    },
    {
      "epoch": 0.0028938315031487977,
      "grad_norm": 0.6548024415969849,
      "learning_rate": 9.976667664615952e-05,
      "loss": 0.0361,
      "step": 51500
    },
    {
      "epoch": 0.002921926954635679,
      "grad_norm": 0.5828558206558228,
      "learning_rate": 9.976386552141444e-05,
      "loss": 0.0352,
      "step": 52000
    },
    {
      "epoch": 0.002950022406122561,
      "grad_norm": 0.5702027082443237,
      "learning_rate": 9.976105439666939e-05,
      "loss": 0.0358,
      "step": 52500
    },
    {
      "epoch": 0.0029781178576094424,
      "grad_norm": 0.5199528336524963,
      "learning_rate": 9.975824327192432e-05,
      "loss": 0.035,
      "step": 53000
    },
    {
      "epoch": 0.003006213309096324,
      "grad_norm": 0.8544569611549377,
      "learning_rate": 9.975543214717926e-05,
      "loss": 0.0353,
      "step": 53500
    },
    {
      "epoch": 0.0030343087605832052,
      "grad_norm": 0.45181533694267273,
      "learning_rate": 9.975262102243419e-05,
      "loss": 0.0346,
      "step": 54000
    },
    {
      "epoch": 0.003062404212070087,
      "grad_norm": 0.38237255811691284,
      "learning_rate": 9.974980989768911e-05,
      "loss": 0.0345,
      "step": 54500
    },
    {
      "epoch": 0.0030904996635569685,
      "grad_norm": 0.7664223909378052,
      "learning_rate": 9.974699877294406e-05,
      "loss": 0.0333,
      "step": 55000
    },
    {
      "epoch": 0.00311859511504385,
      "grad_norm": 0.985428512096405,
      "learning_rate": 9.974418764819898e-05,
      "loss": 0.0352,
      "step": 55500
    },
    {
      "epoch": 0.0031466905665307313,
      "grad_norm": 0.742965579032898,
      "learning_rate": 9.974137652345393e-05,
      "loss": 0.0344,
      "step": 56000
    },
    {
      "epoch": 0.003174786018017613,
      "grad_norm": 0.7054492831230164,
      "learning_rate": 9.973856539870885e-05,
      "loss": 0.0342,
      "step": 56500
    },
    {
      "epoch": 0.0032028814695044946,
      "grad_norm": 0.8087093830108643,
      "learning_rate": 9.973575427396378e-05,
      "loss": 0.0337,
      "step": 57000
    },
    {
      "epoch": 0.003230976920991376,
      "grad_norm": 0.4896996021270752,
      "learning_rate": 9.973294314921873e-05,
      "loss": 0.0342,
      "step": 57500
    },
    {
      "epoch": 0.0032590723724782574,
      "grad_norm": 0.6823828220367432,
      "learning_rate": 9.973013202447365e-05,
      "loss": 0.0339,
      "step": 58000
    },
    {
      "epoch": 0.0032871678239651393,
      "grad_norm": 0.37413862347602844,
      "learning_rate": 9.97273208997286e-05,
      "loss": 0.0331,
      "step": 58500
    },
    {
      "epoch": 0.0033152632754520207,
      "grad_norm": 0.692920446395874,
      "learning_rate": 9.972450977498352e-05,
      "loss": 0.0318,
      "step": 59000
    },
    {
      "epoch": 0.003343358726938902,
      "grad_norm": 0.6295745968818665,
      "learning_rate": 9.972169865023845e-05,
      "loss": 0.033,
      "step": 59500
    },
    {
      "epoch": 0.0033714541784257836,
      "grad_norm": 0.8600564002990723,
      "learning_rate": 9.971888752549339e-05,
      "loss": 0.0334,
      "step": 60000
    },
    {
      "epoch": 0.0033714541784257836,
      "eval_loss": 0.018730403855443,
      "eval_runtime": 19.3205,
      "eval_samples_per_second": 5175.857,
      "eval_steps_per_second": 80.899,
      "step": 60000
    },
    {
      "epoch": 0.0033995496299126654,
      "grad_norm": 0.6944662928581238,
      "learning_rate": 9.971607640074832e-05,
      "loss": 0.0327,
      "step": 60500
    },
    {
      "epoch": 0.003427645081399547,
      "grad_norm": 0.6732498407363892,
      "learning_rate": 9.971326527600327e-05,
      "loss": 0.0336,
      "step": 61000
    },
    {
      "epoch": 0.0034557405328864282,
      "grad_norm": 0.6432012319564819,
      "learning_rate": 9.971045415125819e-05,
      "loss": 0.0331,
      "step": 61500
    },
    {
      "epoch": 0.00348383598437331,
      "grad_norm": 0.6665238738059998,
      "learning_rate": 9.970764302651313e-05,
      "loss": 0.0314,
      "step": 62000
    },
    {
      "epoch": 0.0035119314358601915,
      "grad_norm": 0.4972612261772156,
      "learning_rate": 9.970483190176806e-05,
      "loss": 0.0315,
      "step": 62500
    },
    {
      "epoch": 0.003540026887347073,
      "grad_norm": 0.8431594967842102,
      "learning_rate": 9.9702020777023e-05,
      "loss": 0.0323,
      "step": 63000
    },
    {
      "epoch": 0.0035681223388339543,
      "grad_norm": 1.3515090942382812,
      "learning_rate": 9.969920965227793e-05,
      "loss": 0.0333,
      "step": 63500
    },
    {
      "epoch": 0.003596217790320836,
      "grad_norm": 0.6204644441604614,
      "learning_rate": 9.969639852753286e-05,
      "loss": 0.0308,
      "step": 64000
    },
    {
      "epoch": 0.0036243132418077176,
      "grad_norm": 0.29109063744544983,
      "learning_rate": 9.96935874027878e-05,
      "loss": 0.0315,
      "step": 64500
    },
    {
      "epoch": 0.003652408693294599,
      "grad_norm": 0.6215724945068359,
      "learning_rate": 9.969077627804273e-05,
      "loss": 0.0321,
      "step": 65000
    },
    {
      "epoch": 0.0036805041447814804,
      "grad_norm": 0.6022735834121704,
      "learning_rate": 9.968796515329767e-05,
      "loss": 0.032,
      "step": 65500
    },
    {
      "epoch": 0.0037085995962683623,
      "grad_norm": 0.5668925046920776,
      "learning_rate": 9.96851540285526e-05,
      "loss": 0.0319,
      "step": 66000
    },
    {
      "epoch": 0.0037366950477552437,
      "grad_norm": 0.8474335074424744,
      "learning_rate": 9.968234290380753e-05,
      "loss": 0.0304,
      "step": 66500
    },
    {
      "epoch": 0.003764790499242125,
      "grad_norm": 1.045271396636963,
      "learning_rate": 9.967953177906247e-05,
      "loss": 0.03,
      "step": 67000
    },
    {
      "epoch": 0.0037928859507290066,
      "grad_norm": 0.9918080568313599,
      "learning_rate": 9.96767206543174e-05,
      "loss": 0.0307,
      "step": 67500
    },
    {
      "epoch": 0.0038209814022158884,
      "grad_norm": 0.7427146434783936,
      "learning_rate": 9.967390952957232e-05,
      "loss": 0.0318,
      "step": 68000
    },
    {
      "epoch": 0.00384907685370277,
      "grad_norm": 1.7972368001937866,
      "learning_rate": 9.967109840482727e-05,
      "loss": 0.0316,
      "step": 68500
    },
    {
      "epoch": 0.0038771723051896512,
      "grad_norm": 0.6442151665687561,
      "learning_rate": 9.96682872800822e-05,
      "loss": 0.0308,
      "step": 69000
    },
    {
      "epoch": 0.0039052677566765327,
      "grad_norm": 0.6184986233711243,
      "learning_rate": 9.966547615533714e-05,
      "loss": 0.0311,
      "step": 69500
    },
    {
      "epoch": 0.003933363208163414,
      "grad_norm": 0.7093702554702759,
      "learning_rate": 9.966266503059207e-05,
      "loss": 0.0311,
      "step": 70000
    },
    {
      "epoch": 0.003933363208163414,
      "eval_loss": 0.016542645171284676,
      "eval_runtime": 19.25,
      "eval_samples_per_second": 5194.803,
      "eval_steps_per_second": 81.195,
      "step": 70000
    },
    {
      "epoch": 0.0039614586596502955,
      "grad_norm": 0.9510529637336731,
      "learning_rate": 9.9659853905847e-05,
      "loss": 0.0296,
      "step": 70500
    },
    {
      "epoch": 0.003989554111137178,
      "grad_norm": 0.9259635210037231,
      "learning_rate": 9.965704278110194e-05,
      "loss": 0.0297,
      "step": 71000
    },
    {
      "epoch": 0.004017649562624059,
      "grad_norm": 0.4703981876373291,
      "learning_rate": 9.965423165635686e-05,
      "loss": 0.0293,
      "step": 71500
    },
    {
      "epoch": 0.004045745014110941,
      "grad_norm": 0.49683600664138794,
      "learning_rate": 9.965142053161181e-05,
      "loss": 0.0299,
      "step": 72000
    },
    {
      "epoch": 0.004073840465597822,
      "grad_norm": 1.314475178718567,
      "learning_rate": 9.964860940686674e-05,
      "loss": 0.031,
      "step": 72500
    },
    {
      "epoch": 0.0041019359170847034,
      "grad_norm": 1.245545744895935,
      "learning_rate": 9.964579828212167e-05,
      "loss": 0.0292,
      "step": 73000
    },
    {
      "epoch": 0.004130031368571585,
      "grad_norm": 0.6221644282341003,
      "learning_rate": 9.964298715737661e-05,
      "loss": 0.0302,
      "step": 73500
    },
    {
      "epoch": 0.004158126820058466,
      "grad_norm": 0.4022747874259949,
      "learning_rate": 9.964017603263153e-05,
      "loss": 0.0303,
      "step": 74000
    },
    {
      "epoch": 0.004186222271545349,
      "grad_norm": 0.671560525894165,
      "learning_rate": 9.963736490788648e-05,
      "loss": 0.0288,
      "step": 74500
    },
    {
      "epoch": 0.00421431772303223,
      "grad_norm": 1.1679952144622803,
      "learning_rate": 9.96345537831414e-05,
      "loss": 0.03,
      "step": 75000
    },
    {
      "epoch": 0.004242413174519111,
      "grad_norm": 0.4935213625431061,
      "learning_rate": 9.963174265839634e-05,
      "loss": 0.0292,
      "step": 75500
    },
    {
      "epoch": 0.004270508626005993,
      "grad_norm": 0.47310125827789307,
      "learning_rate": 9.962893153365128e-05,
      "loss": 0.0299,
      "step": 76000
    },
    {
      "epoch": 0.004298604077492874,
      "grad_norm": 0.496614545583725,
      "learning_rate": 9.96261204089062e-05,
      "loss": 0.0275,
      "step": 76500
    },
    {
      "epoch": 0.004326699528979756,
      "grad_norm": 0.6645877361297607,
      "learning_rate": 9.962330928416115e-05,
      "loss": 0.0289,
      "step": 77000
    },
    {
      "epoch": 0.004354794980466637,
      "grad_norm": 0.7337088584899902,
      "learning_rate": 9.962049815941607e-05,
      "loss": 0.0302,
      "step": 77500
    },
    {
      "epoch": 0.0043828904319535185,
      "grad_norm": 0.626189649105072,
      "learning_rate": 9.961768703467101e-05,
      "loss": 0.0305,
      "step": 78000
    },
    {
      "epoch": 0.004410985883440401,
      "grad_norm": 1.180782437324524,
      "learning_rate": 9.961487590992594e-05,
      "loss": 0.0289,
      "step": 78500
    },
    {
      "epoch": 0.004439081334927282,
      "grad_norm": 1.0060704946517944,
      "learning_rate": 9.961206478518088e-05,
      "loss": 0.0298,
      "step": 79000
    },
    {
      "epoch": 0.004467176786414164,
      "grad_norm": 1.5304850339889526,
      "learning_rate": 9.960925366043581e-05,
      "loss": 0.0294,
      "step": 79500
    },
    {
      "epoch": 0.004495272237901045,
      "grad_norm": 0.6861567497253418,
      "learning_rate": 9.960644253569074e-05,
      "loss": 0.028,
      "step": 80000
    },
    {
      "epoch": 0.004495272237901045,
      "eval_loss": 0.015485999174416065,
      "eval_runtime": 19.0579,
      "eval_samples_per_second": 5247.168,
      "eval_steps_per_second": 82.013,
      "step": 80000
    },
    {
      "epoch": 0.0045233676893879264,
      "grad_norm": 0.5370750427246094,
      "learning_rate": 9.960363141094569e-05,
      "loss": 0.0286,
      "step": 80500
    },
    {
      "epoch": 0.004551463140874808,
      "grad_norm": 1.0562478303909302,
      "learning_rate": 9.960082028620061e-05,
      "loss": 0.0283,
      "step": 81000
    },
    {
      "epoch": 0.004579558592361689,
      "grad_norm": 0.2803689241409302,
      "learning_rate": 9.959800916145555e-05,
      "loss": 0.0276,
      "step": 81500
    },
    {
      "epoch": 0.0046076540438485716,
      "grad_norm": 0.5591460466384888,
      "learning_rate": 9.959519803671048e-05,
      "loss": 0.0282,
      "step": 82000
    },
    {
      "epoch": 0.004635749495335453,
      "grad_norm": 0.4431484043598175,
      "learning_rate": 9.959238691196542e-05,
      "loss": 0.0285,
      "step": 82500
    },
    {
      "epoch": 0.004663844946822334,
      "grad_norm": 0.5534304976463318,
      "learning_rate": 9.958957578722035e-05,
      "loss": 0.0284,
      "step": 83000
    },
    {
      "epoch": 0.004691940398309216,
      "grad_norm": 0.5193730592727661,
      "learning_rate": 9.958676466247528e-05,
      "loss": 0.0276,
      "step": 83500
    },
    {
      "epoch": 0.004720035849796097,
      "grad_norm": 1.2389048337936401,
      "learning_rate": 9.958395353773022e-05,
      "loss": 0.0274,
      "step": 84000
    },
    {
      "epoch": 0.004748131301282979,
      "grad_norm": 0.6568717360496521,
      "learning_rate": 9.958114241298515e-05,
      "loss": 0.0271,
      "step": 84500
    },
    {
      "epoch": 0.00477622675276986,
      "grad_norm": 1.3748931884765625,
      "learning_rate": 9.957833128824009e-05,
      "loss": 0.0287,
      "step": 85000
    },
    {
      "epoch": 0.0048043222042567415,
      "grad_norm": 0.40599724650382996,
      "learning_rate": 9.957552016349502e-05,
      "loss": 0.0275,
      "step": 85500
    },
    {
      "epoch": 0.004832417655743624,
      "grad_norm": 0.510735034942627,
      "learning_rate": 9.957270903874996e-05,
      "loss": 0.028,
      "step": 86000
    },
    {
      "epoch": 0.004860513107230505,
      "grad_norm": 0.6451039910316467,
      "learning_rate": 9.956989791400489e-05,
      "loss": 0.0266,
      "step": 86500
    },
    {
      "epoch": 0.004888608558717387,
      "grad_norm": 0.9604875445365906,
      "learning_rate": 9.956708678925982e-05,
      "loss": 0.0277,
      "step": 87000
    },
    {
      "epoch": 0.004916704010204268,
      "grad_norm": 0.6776757836341858,
      "learning_rate": 9.956427566451474e-05,
      "loss": 0.0277,
      "step": 87500
    },
    {
      "epoch": 0.0049447994616911494,
      "grad_norm": 1.1531879901885986,
      "learning_rate": 9.956146453976969e-05,
      "loss": 0.0281,
      "step": 88000
    },
    {
      "epoch": 0.004972894913178031,
      "grad_norm": 0.5976983904838562,
      "learning_rate": 9.955865341502463e-05,
      "loss": 0.0279,
      "step": 88500
    },
    {
      "epoch": 0.005000990364664912,
      "grad_norm": 0.6951443552970886,
      "learning_rate": 9.955584229027956e-05,
      "loss": 0.0271,
      "step": 89000
    },
    {
      "epoch": 0.005029085816151794,
      "grad_norm": 0.5498329401016235,
      "learning_rate": 9.95530311655345e-05,
      "loss": 0.0287,
      "step": 89500
    },
    {
      "epoch": 0.005057181267638676,
      "grad_norm": 0.9546435475349426,
      "learning_rate": 9.955022004078942e-05,
      "loss": 0.0266,
      "step": 90000
    },
    {
      "epoch": 0.005057181267638676,
      "eval_loss": 0.01398326363414526,
      "eval_runtime": 18.766,
      "eval_samples_per_second": 5328.782,
      "eval_steps_per_second": 83.289,
      "step": 90000
    },
    {
      "epoch": 0.005085276719125557,
      "grad_norm": 0.4493773281574249,
      "learning_rate": 9.954740891604436e-05,
      "loss": 0.0279,
      "step": 90500
    },
    {
      "epoch": 0.005113372170612439,
      "grad_norm": 0.6571084856987,
      "learning_rate": 9.954459779129928e-05,
      "loss": 0.0259,
      "step": 91000
    },
    {
      "epoch": 0.00514146762209932,
      "grad_norm": 0.6624218821525574,
      "learning_rate": 9.954178666655423e-05,
      "loss": 0.0272,
      "step": 91500
    },
    {
      "epoch": 0.005169563073586202,
      "grad_norm": 0.5167191624641418,
      "learning_rate": 9.953897554180917e-05,
      "loss": 0.0267,
      "step": 92000
    },
    {
      "epoch": 0.005197658525073083,
      "grad_norm": 0.7379711866378784,
      "learning_rate": 9.953616441706409e-05,
      "loss": 0.0261,
      "step": 92500
    },
    {
      "epoch": 0.0052257539765599645,
      "grad_norm": 0.7112360596656799,
      "learning_rate": 9.953335329231904e-05,
      "loss": 0.0272,
      "step": 93000
    },
    {
      "epoch": 0.005253849428046847,
      "grad_norm": 0.6707677841186523,
      "learning_rate": 9.953054216757396e-05,
      "loss": 0.027,
      "step": 93500
    },
    {
      "epoch": 0.005281944879533728,
      "grad_norm": 0.9781812429428101,
      "learning_rate": 9.95277310428289e-05,
      "loss": 0.0272,
      "step": 94000
    },
    {
      "epoch": 0.00531004033102061,
      "grad_norm": 0.6173732280731201,
      "learning_rate": 9.952491991808382e-05,
      "loss": 0.0261,
      "step": 94500
    },
    {
      "epoch": 0.005338135782507491,
      "grad_norm": 0.7282496094703674,
      "learning_rate": 9.952210879333876e-05,
      "loss": 0.0266,
      "step": 95000
    },
    {
      "epoch": 0.0053662312339943724,
      "grad_norm": 0.8274973630905151,
      "learning_rate": 9.95192976685937e-05,
      "loss": 0.0278,
      "step": 95500
    },
    {
      "epoch": 0.005394326685481254,
      "grad_norm": 0.2780550718307495,
      "learning_rate": 9.951648654384863e-05,
      "loss": 0.0256,
      "step": 96000
    },
    {
      "epoch": 0.005422422136968135,
      "grad_norm": 0.6013314723968506,
      "learning_rate": 9.951367541910357e-05,
      "loss": 0.026,
      "step": 96500
    },
    {
      "epoch": 0.005450517588455017,
      "grad_norm": 0.7421242594718933,
      "learning_rate": 9.95108642943585e-05,
      "loss": 0.0268,
      "step": 97000
    },
    {
      "epoch": 0.005478613039941899,
      "grad_norm": 0.5446153879165649,
      "learning_rate": 9.950805316961343e-05,
      "loss": 0.0257,
      "step": 97500
    },
    {
      "epoch": 0.00550670849142878,
      "grad_norm": 0.55085289478302,
      "learning_rate": 9.950524204486836e-05,
      "loss": 0.0259,
      "step": 98000
    },
    {
      "epoch": 0.005534803942915662,
      "grad_norm": 0.2618267238140106,
      "learning_rate": 9.95024309201233e-05,
      "loss": 0.0258,
      "step": 98500
    },
    {
      "epoch": 0.005562899394402543,
      "grad_norm": 0.8586559891700745,
      "learning_rate": 9.949961979537823e-05,
      "loss": 0.0263,
      "step": 99000
    },
    {
      "epoch": 0.005590994845889425,
      "grad_norm": 0.4170944094657898,
      "learning_rate": 9.949680867063317e-05,
      "loss": 0.0257,
      "step": 99500
    },
    {
      "epoch": 0.005619090297376306,
      "grad_norm": 0.4155482351779938,
      "learning_rate": 9.94939975458881e-05,
      "loss": 0.0263,
      "step": 100000
    },
    {
      "epoch": 0.005619090297376306,
      "eval_loss": 0.014447582885622978,
      "eval_runtime": 18.885,
      "eval_samples_per_second": 5295.204,
      "eval_steps_per_second": 82.764,
      "step": 100000
    },
    {
      "epoch": 0.0056471857488631875,
      "grad_norm": 0.5490061640739441,
      "learning_rate": 9.949118642114304e-05,
      "loss": 0.0264,
      "step": 100500
    },
    {
      "epoch": 0.005675281200350069,
      "grad_norm": 0.4762502610683441,
      "learning_rate": 9.948837529639797e-05,
      "loss": 0.0255,
      "step": 101000
    },
    {
      "epoch": 0.005703376651836951,
      "grad_norm": 0.3665883541107178,
      "learning_rate": 9.94855641716529e-05,
      "loss": 0.0268,
      "step": 101500
    },
    {
      "epoch": 0.005731472103323833,
      "grad_norm": 0.9273629784584045,
      "learning_rate": 9.948275304690784e-05,
      "loss": 0.0252,
      "step": 102000
    },
    {
      "epoch": 0.005759567554810714,
      "grad_norm": 0.6369949579238892,
      "learning_rate": 9.947994192216277e-05,
      "loss": 0.0251,
      "step": 102500
    },
    {
      "epoch": 0.0057876630062975954,
      "grad_norm": 0.7485786080360413,
      "learning_rate": 9.94771307974177e-05,
      "loss": 0.0254,
      "step": 103000
    },
    {
      "epoch": 0.005815758457784477,
      "grad_norm": 1.8874928951263428,
      "learning_rate": 9.947431967267264e-05,
      "loss": 0.0264,
      "step": 103500
    },
    {
      "epoch": 0.005843853909271358,
      "grad_norm": 0.7037925124168396,
      "learning_rate": 9.947150854792757e-05,
      "loss": 0.0256,
      "step": 104000
    },
    {
      "epoch": 0.00587194936075824,
      "grad_norm": 0.7097001671791077,
      "learning_rate": 9.946869742318251e-05,
      "loss": 0.0252,
      "step": 104500
    },
    {
      "epoch": 0.005900044812245122,
      "grad_norm": 0.7609269022941589,
      "learning_rate": 9.946588629843744e-05,
      "loss": 0.024,
      "step": 105000
    },
    {
      "epoch": 0.005928140263732003,
      "grad_norm": 1.2152695655822754,
      "learning_rate": 9.946307517369238e-05,
      "loss": 0.0266,
      "step": 105500
    },
    {
      "epoch": 0.005956235715218885,
      "grad_norm": 0.5068541765213013,
      "learning_rate": 9.94602640489473e-05,
      "loss": 0.0247,
      "step": 106000
    },
    {
      "epoch": 0.005984331166705766,
      "grad_norm": 0.5479680299758911,
      "learning_rate": 9.945745292420225e-05,
      "loss": 0.0253,
      "step": 106500
    },
    {
      "epoch": 0.006012426618192648,
      "grad_norm": 0.6898829936981201,
      "learning_rate": 9.945464179945717e-05,
      "loss": 0.026,
      "step": 107000
    },
    {
      "epoch": 0.006040522069679529,
      "grad_norm": 0.6801425218582153,
      "learning_rate": 9.945183067471211e-05,
      "loss": 0.0258,
      "step": 107500
    },
    {
      "epoch": 0.0060686175211664105,
      "grad_norm": 0.84214848279953,
      "learning_rate": 9.944901954996705e-05,
      "loss": 0.024,
      "step": 108000
    },
    {
      "epoch": 0.006096712972653292,
      "grad_norm": 0.7912098169326782,
      "learning_rate": 9.944620842522197e-05,
      "loss": 0.0252,
      "step": 108500
    },
    {
      "epoch": 0.006124808424140174,
      "grad_norm": 0.9437082409858704,
      "learning_rate": 9.944339730047692e-05,
      "loss": 0.0264,
      "step": 109000
    },
    {
      "epoch": 0.006152903875627056,
      "grad_norm": 0.9737704396247864,
      "learning_rate": 9.944058617573184e-05,
      "loss": 0.0243,
      "step": 109500
    },
    {
      "epoch": 0.006180999327113937,
      "grad_norm": 0.5967629551887512,
      "learning_rate": 9.943777505098679e-05,
      "loss": 0.0252,
      "step": 110000
    },
    {
      "epoch": 0.006180999327113937,
      "eval_loss": 0.012133277021348476,
      "eval_runtime": 19.0562,
      "eval_samples_per_second": 5247.632,
      "eval_steps_per_second": 82.02,
      "step": 110000
    },
    {
      "epoch": 0.0062090947786008184,
      "grad_norm": 0.5103573203086853,
      "learning_rate": 9.94349639262417e-05,
      "loss": 0.0237,
      "step": 110500
    },
    {
      "epoch": 0.0062371902300877,
      "grad_norm": 0.9100476503372192,
      "learning_rate": 9.943215280149664e-05,
      "loss": 0.0248,
      "step": 111000
    },
    {
      "epoch": 0.006265285681574581,
      "grad_norm": 0.6580165028572083,
      "learning_rate": 9.942934167675159e-05,
      "loss": 0.025,
      "step": 111500
    },
    {
      "epoch": 0.006293381133061463,
      "grad_norm": 0.4358986020088196,
      "learning_rate": 9.942653055200651e-05,
      "loss": 0.0255,
      "step": 112000
    },
    {
      "epoch": 0.006321476584548345,
      "grad_norm": 0.5521385073661804,
      "learning_rate": 9.942371942726146e-05,
      "loss": 0.0246,
      "step": 112500
    },
    {
      "epoch": 0.006349572036035226,
      "grad_norm": 0.38539907336235046,
      "learning_rate": 9.942090830251638e-05,
      "loss": 0.0248,
      "step": 113000
    },
    {
      "epoch": 0.006377667487522108,
      "grad_norm": 1.058937668800354,
      "learning_rate": 9.941809717777131e-05,
      "loss": 0.0248,
      "step": 113500
    },
    {
      "epoch": 0.006405762939008989,
      "grad_norm": 0.7541336417198181,
      "learning_rate": 9.941528605302625e-05,
      "loss": 0.0241,
      "step": 114000
    },
    {
      "epoch": 0.006433858390495871,
      "grad_norm": 0.4427940249443054,
      "learning_rate": 9.941247492828118e-05,
      "loss": 0.0254,
      "step": 114500
    },
    {
      "epoch": 0.006461953841982752,
      "grad_norm": 0.3224238157272339,
      "learning_rate": 9.940966380353613e-05,
      "loss": 0.0252,
      "step": 115000
    },
    {
      "epoch": 0.0064900492934696335,
      "grad_norm": 0.4065735936164856,
      "learning_rate": 9.940685267879105e-05,
      "loss": 0.0239,
      "step": 115500
    },
    {
      "epoch": 0.006518144744956515,
      "grad_norm": 0.6716532707214355,
      "learning_rate": 9.9404041554046e-05,
      "loss": 0.0242,
      "step": 116000
    },
    {
      "epoch": 0.006546240196443397,
      "grad_norm": 0.936443567276001,
      "learning_rate": 9.940123042930092e-05,
      "loss": 0.0246,
      "step": 116500
    },
    {
      "epoch": 0.006574335647930279,
      "grad_norm": 0.6127439737319946,
      "learning_rate": 9.939841930455585e-05,
      "loss": 0.0235,
      "step": 117000
    },
    {
      "epoch": 0.00660243109941716,
      "grad_norm": 0.43631306290626526,
      "learning_rate": 9.939560817981079e-05,
      "loss": 0.0248,
      "step": 117500
    },
    {
      "epoch": 0.0066305265509040414,
      "grad_norm": 1.2664657831192017,
      "learning_rate": 9.939279705506572e-05,
      "loss": 0.0246,
      "step": 118000
    },
    {
      "epoch": 0.006658622002390923,
      "grad_norm": 0.6419003009796143,
      "learning_rate": 9.938998593032065e-05,
      "loss": 0.0229,
      "step": 118500
    },
    {
      "epoch": 0.006686717453877804,
      "grad_norm": 1.0790367126464844,
      "learning_rate": 9.938717480557559e-05,
      "loss": 0.0244,
      "step": 119000
    },
    {
      "epoch": 0.006714812905364686,
      "grad_norm": 0.6293129324913025,
      "learning_rate": 9.938436368083052e-05,
      "loss": 0.0245,
      "step": 119500
    },
    {
      "epoch": 0.006742908356851567,
      "grad_norm": 0.6374635696411133,
      "learning_rate": 9.938155255608546e-05,
      "loss": 0.0236,
      "step": 120000
    },
    {
      "epoch": 0.006742908356851567,
      "eval_loss": 0.012192350812256336,
      "eval_runtime": 18.4642,
      "eval_samples_per_second": 5415.877,
      "eval_steps_per_second": 84.65,
      "step": 120000
    },
    {
      "epoch": 0.006771003808338449,
      "grad_norm": 0.28802385926246643,
      "learning_rate": 9.937874143134039e-05,
      "loss": 0.0251,
      "step": 120500
    },
    {
      "epoch": 0.006799099259825331,
      "grad_norm": 0.3661339282989502,
      "learning_rate": 9.937593030659533e-05,
      "loss": 0.0232,
      "step": 121000
    },
    {
      "epoch": 0.006827194711312212,
      "grad_norm": 0.368255078792572,
      "learning_rate": 9.937311918185026e-05,
      "loss": 0.0238,
      "step": 121500
    },
    {
      "epoch": 0.006855290162799094,
      "grad_norm": 1.426461100578308,
      "learning_rate": 9.93703080571052e-05,
      "loss": 0.0248,
      "step": 122000
    },
    {
      "epoch": 0.006883385614285975,
      "grad_norm": 0.6076269745826721,
      "learning_rate": 9.936749693236013e-05,
      "loss": 0.0241,
      "step": 122500
    },
    {
      "epoch": 0.0069114810657728565,
      "grad_norm": 0.8755596876144409,
      "learning_rate": 9.936468580761506e-05,
      "loss": 0.0233,
      "step": 123000
    },
    {
      "epoch": 0.006939576517259738,
      "grad_norm": 0.43755027651786804,
      "learning_rate": 9.936187468287e-05,
      "loss": 0.0234,
      "step": 123500
    },
    {
      "epoch": 0.00696767196874662,
      "grad_norm": 0.6863389015197754,
      "learning_rate": 9.935906355812493e-05,
      "loss": 0.0235,
      "step": 124000
    },
    {
      "epoch": 0.006995767420233502,
      "grad_norm": 0.7160234451293945,
      "learning_rate": 9.935625243337987e-05,
      "loss": 0.0236,
      "step": 124500
    },
    {
      "epoch": 0.007023862871720383,
      "grad_norm": 0.2964171767234802,
      "learning_rate": 9.93534413086348e-05,
      "loss": 0.0238,
      "step": 125000
    },
    {
      "epoch": 0.0070519583232072644,
      "grad_norm": 0.804300844669342,
      "learning_rate": 9.935063018388972e-05,
      "loss": 0.0236,
      "step": 125500
    },
    {
      "epoch": 0.007080053774694146,
      "grad_norm": 0.6932108998298645,
      "learning_rate": 9.934781905914467e-05,
      "loss": 0.0232,
      "step": 126000
    },
    {
      "epoch": 0.007108149226181027,
      "grad_norm": 0.6126430630683899,
      "learning_rate": 9.93450079343996e-05,
      "loss": 0.0234,
      "step": 126500
    },
    {
      "epoch": 0.007136244677667909,
      "grad_norm": 1.111369252204895,
      "learning_rate": 9.934219680965454e-05,
      "loss": 0.0237,
      "step": 127000
    },
    {
      "epoch": 0.00716434012915479,
      "grad_norm": 0.5315598249435425,
      "learning_rate": 9.933938568490947e-05,
      "loss": 0.024,
      "step": 127500
    },
    {
      "epoch": 0.007192435580641672,
      "grad_norm": 0.6639930009841919,
      "learning_rate": 9.933657456016439e-05,
      "loss": 0.0241,
      "step": 128000
    },
    {
      "epoch": 0.007220531032128554,
      "grad_norm": 0.49413490295410156,
      "learning_rate": 9.933376343541934e-05,
      "loss": 0.0225,
      "step": 128500
    },
    {
      "epoch": 0.007248626483615435,
      "grad_norm": 1.0716702938079834,
      "learning_rate": 9.933095231067426e-05,
      "loss": 0.0231,
      "step": 129000
    },
    {
      "epoch": 0.007276721935102317,
      "grad_norm": 0.7296008467674255,
      "learning_rate": 9.932814118592921e-05,
      "loss": 0.0221,
      "step": 129500
    },
    {
      "epoch": 0.007304817386589198,
      "grad_norm": 0.5837460160255432,
      "learning_rate": 9.932533006118413e-05,
      "loss": 0.023,
      "step": 130000
    },
    {
      "epoch": 0.007304817386589198,
      "eval_loss": 0.012012001127004623,
      "eval_runtime": 19.0917,
      "eval_samples_per_second": 5237.877,
      "eval_steps_per_second": 81.868,
      "step": 130000
    },
    {
      "epoch": 0.0073329128380760795,
      "grad_norm": 0.6428576111793518,
      "learning_rate": 9.932251893643906e-05,
      "loss": 0.0232,
      "step": 130500
    },
    {
      "epoch": 0.007361008289562961,
      "grad_norm": 0.7243213057518005,
      "learning_rate": 9.931970781169401e-05,
      "loss": 0.0227,
      "step": 131000
    },
    {
      "epoch": 0.007389103741049842,
      "grad_norm": 0.7374753952026367,
      "learning_rate": 9.931689668694893e-05,
      "loss": 0.0233,
      "step": 131500
    },
    {
      "epoch": 0.007417199192536725,
      "grad_norm": 1.0093932151794434,
      "learning_rate": 9.931408556220388e-05,
      "loss": 0.0225,
      "step": 132000
    },
    {
      "epoch": 0.007445294644023606,
      "grad_norm": 0.5923150181770325,
      "learning_rate": 9.93112744374588e-05,
      "loss": 0.0224,
      "step": 132500
    },
    {
      "epoch": 0.0074733900955104874,
      "grad_norm": 0.832309901714325,
      "learning_rate": 9.930846331271373e-05,
      "loss": 0.023,
      "step": 133000
    },
    {
      "epoch": 0.007501485546997369,
      "grad_norm": 0.42341306805610657,
      "learning_rate": 9.930565218796867e-05,
      "loss": 0.023,
      "step": 133500
    },
    {
      "epoch": 0.00752958099848425,
      "grad_norm": 0.5673015117645264,
      "learning_rate": 9.93028410632236e-05,
      "loss": 0.0219,
      "step": 134000
    },
    {
      "epoch": 0.007557676449971132,
      "grad_norm": 0.5600834488868713,
      "learning_rate": 9.930002993847855e-05,
      "loss": 0.0226,
      "step": 134500
    },
    {
      "epoch": 0.007585771901458013,
      "grad_norm": 0.5786458253860474,
      "learning_rate": 9.929721881373347e-05,
      "loss": 0.0225,
      "step": 135000
    },
    {
      "epoch": 0.007613867352944895,
      "grad_norm": 0.6069884896278381,
      "learning_rate": 9.92944076889884e-05,
      "loss": 0.0228,
      "step": 135500
    },
    {
      "epoch": 0.007641962804431777,
      "grad_norm": 0.5175036787986755,
      "learning_rate": 9.929159656424334e-05,
      "loss": 0.023,
      "step": 136000
    },
    {
      "epoch": 0.007670058255918658,
      "grad_norm": 0.5384681224822998,
      "learning_rate": 9.928878543949827e-05,
      "loss": 0.0228,
      "step": 136500
    },
    {
      "epoch": 0.00769815370740554,
      "grad_norm": 0.39034590125083923,
      "learning_rate": 9.928597431475321e-05,
      "loss": 0.0232,
      "step": 137000
    },
    {
      "epoch": 0.007726249158892421,
      "grad_norm": 0.5922384858131409,
      "learning_rate": 9.928316319000814e-05,
      "loss": 0.0229,
      "step": 137500
    },
    {
      "epoch": 0.0077543446103793025,
      "grad_norm": 0.6710036993026733,
      "learning_rate": 9.928035206526308e-05,
      "loss": 0.0226,
      "step": 138000
    },
    {
      "epoch": 0.007782440061866184,
      "grad_norm": 0.8601182699203491,
      "learning_rate": 9.927754094051801e-05,
      "loss": 0.0227,
      "step": 138500
    },
    {
      "epoch": 0.007810535513353065,
      "grad_norm": 0.48436209559440613,
      "learning_rate": 9.927472981577294e-05,
      "loss": 0.0223,
      "step": 139000
    },
    {
      "epoch": 0.007838630964839947,
      "grad_norm": 0.9830897450447083,
      "learning_rate": 9.927191869102788e-05,
      "loss": 0.0217,
      "step": 139500
    },
    {
      "epoch": 0.007866726416326828,
      "grad_norm": 0.9000312685966492,
      "learning_rate": 9.926910756628281e-05,
      "loss": 0.0221,
      "step": 140000
    },
    {
      "epoch": 0.007866726416326828,
      "eval_loss": 0.010976091958582401,
      "eval_runtime": 18.4148,
      "eval_samples_per_second": 5430.416,
      "eval_steps_per_second": 84.877,
      "step": 140000
    },
    {
      "epoch": 0.00789482186781371,
      "grad_norm": 0.5844916105270386,
      "learning_rate": 9.926629644153775e-05,
      "loss": 0.0226,
      "step": 140500
    },
    {
      "epoch": 0.007922917319300591,
      "grad_norm": 0.8096144795417786,
      "learning_rate": 9.926348531679268e-05,
      "loss": 0.0229,
      "step": 141000
    },
    {
      "epoch": 0.007951012770787474,
      "grad_norm": 0.31872618198394775,
      "learning_rate": 9.92606741920476e-05,
      "loss": 0.0224,
      "step": 141500
    },
    {
      "epoch": 0.007979108222274356,
      "grad_norm": 1.0229254961013794,
      "learning_rate": 9.925786306730255e-05,
      "loss": 0.0217,
      "step": 142000
    },
    {
      "epoch": 0.008007203673761237,
      "grad_norm": 0.3348972499370575,
      "learning_rate": 9.925505194255748e-05,
      "loss": 0.0211,
      "step": 142500
    },
    {
      "epoch": 0.008035299125248118,
      "grad_norm": 0.4189039170742035,
      "learning_rate": 9.925224081781242e-05,
      "loss": 0.0217,
      "step": 143000
    },
    {
      "epoch": 0.008063394576735,
      "grad_norm": 0.791426420211792,
      "learning_rate": 9.924942969306735e-05,
      "loss": 0.022,
      "step": 143500
    },
    {
      "epoch": 0.008091490028221881,
      "grad_norm": 0.3401518166065216,
      "learning_rate": 9.924661856832227e-05,
      "loss": 0.0208,
      "step": 144000
    },
    {
      "epoch": 0.008119585479708763,
      "grad_norm": 1.011383056640625,
      "learning_rate": 9.924380744357722e-05,
      "loss": 0.0211,
      "step": 144500
    },
    {
      "epoch": 0.008147680931195644,
      "grad_norm": 0.9253689050674438,
      "learning_rate": 9.924099631883214e-05,
      "loss": 0.0221,
      "step": 145000
    },
    {
      "epoch": 0.008175776382682525,
      "grad_norm": 0.4171708822250366,
      "learning_rate": 9.923818519408709e-05,
      "loss": 0.0229,
      "step": 145500
    },
    {
      "epoch": 0.008203871834169407,
      "grad_norm": 0.6407692432403564,
      "learning_rate": 9.923537406934202e-05,
      "loss": 0.0218,
      "step": 146000
    },
    {
      "epoch": 0.008231967285656288,
      "grad_norm": 2.083143949508667,
      "learning_rate": 9.923256294459695e-05,
      "loss": 0.0222,
      "step": 146500
    },
    {
      "epoch": 0.00826006273714317,
      "grad_norm": 0.5380130410194397,
      "learning_rate": 9.922975181985189e-05,
      "loss": 0.0212,
      "step": 147000
    },
    {
      "epoch": 0.008288158188630051,
      "grad_norm": 0.6426936388015747,
      "learning_rate": 9.922694069510681e-05,
      "loss": 0.0213,
      "step": 147500
    },
    {
      "epoch": 0.008316253640116933,
      "grad_norm": 0.9963617920875549,
      "learning_rate": 9.922412957036176e-05,
      "loss": 0.0218,
      "step": 148000
    },
    {
      "epoch": 0.008344349091603814,
      "grad_norm": 0.4228992760181427,
      "learning_rate": 9.922131844561668e-05,
      "loss": 0.0216,
      "step": 148500
    },
    {
      "epoch": 0.008372444543090697,
      "grad_norm": 0.5192162394523621,
      "learning_rate": 9.921850732087163e-05,
      "loss": 0.0211,
      "step": 149000
    },
    {
      "epoch": 0.008400539994577579,
      "grad_norm": 0.6786049008369446,
      "learning_rate": 9.921569619612655e-05,
      "loss": 0.0204,
      "step": 149500
    },
    {
      "epoch": 0.00842863544606446,
      "grad_norm": 0.5530043840408325,
      "learning_rate": 9.921288507138148e-05,
      "loss": 0.022,
      "step": 150000
    },
    {
      "epoch": 0.00842863544606446,
      "eval_loss": 0.010809710249304771,
      "eval_runtime": 19.2512,
      "eval_samples_per_second": 5194.47,
      "eval_steps_per_second": 81.19,
      "step": 150000
    },
    {
      "epoch": 0.008456730897551341,
      "grad_norm": 0.6009419560432434,
      "learning_rate": 9.921007394663643e-05,
      "loss": 0.0221,
      "step": 150500
    },
    {
      "epoch": 0.008484826349038223,
      "grad_norm": 0.5608759522438049,
      "learning_rate": 9.920726282189135e-05,
      "loss": 0.0231,
      "step": 151000
    },
    {
      "epoch": 0.008512921800525104,
      "grad_norm": 0.5778579115867615,
      "learning_rate": 9.92044516971463e-05,
      "loss": 0.0221,
      "step": 151500
    },
    {
      "epoch": 0.008541017252011986,
      "grad_norm": 0.437195748090744,
      "learning_rate": 9.920164057240122e-05,
      "loss": 0.0219,
      "step": 152000
    },
    {
      "epoch": 0.008569112703498867,
      "grad_norm": 0.5045691728591919,
      "learning_rate": 9.919882944765616e-05,
      "loss": 0.0206,
      "step": 152500
    },
    {
      "epoch": 0.008597208154985748,
      "grad_norm": 0.2847050130367279,
      "learning_rate": 9.919601832291109e-05,
      "loss": 0.021,
      "step": 153000
    },
    {
      "epoch": 0.00862530360647263,
      "grad_norm": 0.9893535375595093,
      "learning_rate": 9.919320719816602e-05,
      "loss": 0.0209,
      "step": 153500
    },
    {
      "epoch": 0.008653399057959511,
      "grad_norm": 0.5837205052375793,
      "learning_rate": 9.919039607342097e-05,
      "loss": 0.0214,
      "step": 154000
    },
    {
      "epoch": 0.008681494509446393,
      "grad_norm": 0.5020848512649536,
      "learning_rate": 9.918758494867589e-05,
      "loss": 0.0208,
      "step": 154500
    },
    {
      "epoch": 0.008709589960933274,
      "grad_norm": 0.5893449783325195,
      "learning_rate": 9.918477382393083e-05,
      "loss": 0.0209,
      "step": 155000
    },
    {
      "epoch": 0.008737685412420156,
      "grad_norm": 0.49874037504196167,
      "learning_rate": 9.918196269918576e-05,
      "loss": 0.0218,
      "step": 155500
    },
    {
      "epoch": 0.008765780863907037,
      "grad_norm": 0.8705244064331055,
      "learning_rate": 9.91791515744407e-05,
      "loss": 0.0206,
      "step": 156000
    },
    {
      "epoch": 0.00879387631539392,
      "grad_norm": 0.525691568851471,
      "learning_rate": 9.917634044969563e-05,
      "loss": 0.02,
      "step": 156500
    },
    {
      "epoch": 0.008821971766880802,
      "grad_norm": 0.6237220764160156,
      "learning_rate": 9.917352932495056e-05,
      "loss": 0.0215,
      "step": 157000
    },
    {
      "epoch": 0.008850067218367683,
      "grad_norm": 0.6427828669548035,
      "learning_rate": 9.91707182002055e-05,
      "loss": 0.0214,
      "step": 157500
    },
    {
      "epoch": 0.008878162669854564,
      "grad_norm": 0.8829165101051331,
      "learning_rate": 9.916790707546043e-05,
      "loss": 0.0208,
      "step": 158000
    },
    {
      "epoch": 0.008906258121341446,
      "grad_norm": 0.6863264441490173,
      "learning_rate": 9.916509595071537e-05,
      "loss": 0.0218,
      "step": 158500
    },
    {
      "epoch": 0.008934353572828327,
      "grad_norm": 0.556310772895813,
      "learning_rate": 9.91622848259703e-05,
      "loss": 0.0204,
      "step": 159000
    },
    {
      "epoch": 0.008962449024315209,
      "grad_norm": 0.26555341482162476,
      "learning_rate": 9.915947370122524e-05,
      "loss": 0.0207,
      "step": 159500
    },
    {
      "epoch": 0.00899054447580209,
      "grad_norm": 0.2942919433116913,
      "learning_rate": 9.915666257648017e-05,
      "loss": 0.0214,
      "step": 160000
    },
    {
      "epoch": 0.00899054447580209,
      "eval_loss": 0.010982096195220947,
      "eval_runtime": 18.7127,
      "eval_samples_per_second": 5343.959,
      "eval_steps_per_second": 83.526,
      "step": 160000
    },
    {
      "epoch": 0.009018639927288971,
      "grad_norm": 0.5460048913955688,
      "learning_rate": 9.91538514517351e-05,
      "loss": 0.0219,
      "step": 160500
    },
    {
      "epoch": 0.009046735378775853,
      "grad_norm": 0.4782920777797699,
      "learning_rate": 9.915104032699002e-05,
      "loss": 0.0213,
      "step": 161000
    },
    {
      "epoch": 0.009074830830262734,
      "grad_norm": 0.49256646633148193,
      "learning_rate": 9.914822920224497e-05,
      "loss": 0.0208,
      "step": 161500
    },
    {
      "epoch": 0.009102926281749616,
      "grad_norm": 0.28647375106811523,
      "learning_rate": 9.91454180774999e-05,
      "loss": 0.0204,
      "step": 162000
    },
    {
      "epoch": 0.009131021733236497,
      "grad_norm": 0.4104774594306946,
      "learning_rate": 9.914260695275484e-05,
      "loss": 0.0208,
      "step": 162500
    },
    {
      "epoch": 0.009159117184723379,
      "grad_norm": 0.29945802688598633,
      "learning_rate": 9.913979582800978e-05,
      "loss": 0.0196,
      "step": 163000
    },
    {
      "epoch": 0.00918721263621026,
      "grad_norm": 0.6749097108840942,
      "learning_rate": 9.91369847032647e-05,
      "loss": 0.0214,
      "step": 163500
    },
    {
      "epoch": 0.009215308087697143,
      "grad_norm": 0.3119262456893921,
      "learning_rate": 9.913417357851964e-05,
      "loss": 0.0207,
      "step": 164000
    },
    {
      "epoch": 0.009243403539184025,
      "grad_norm": 0.8357768654823303,
      "learning_rate": 9.913136245377456e-05,
      "loss": 0.0202,
      "step": 164500
    },
    {
      "epoch": 0.009271498990670906,
      "grad_norm": 0.6733993887901306,
      "learning_rate": 9.912855132902951e-05,
      "loss": 0.0212,
      "step": 165000
    },
    {
      "epoch": 0.009299594442157787,
      "grad_norm": 1.4815974235534668,
      "learning_rate": 9.912574020428445e-05,
      "loss": 0.0206,
      "step": 165500
    },
    {
      "epoch": 0.009327689893644669,
      "grad_norm": 0.4072015583515167,
      "learning_rate": 9.912292907953937e-05,
      "loss": 0.0214,
      "step": 166000
    },
    {
      "epoch": 0.00935578534513155,
      "grad_norm": 0.29057765007019043,
      "learning_rate": 9.912011795479431e-05,
      "loss": 0.0202,
      "step": 166500
    },
    {
      "epoch": 0.009383880796618432,
      "grad_norm": 0.41328275203704834,
      "learning_rate": 9.911730683004924e-05,
      "loss": 0.0207,
      "step": 167000
    },
    {
      "epoch": 0.009411976248105313,
      "grad_norm": 0.41458866000175476,
      "learning_rate": 9.911449570530418e-05,
      "loss": 0.0204,
      "step": 167500
    },
    {
      "epoch": 0.009440071699592194,
      "grad_norm": 0.9216137528419495,
      "learning_rate": 9.91116845805591e-05,
      "loss": 0.0204,
      "step": 168000
    },
    {
      "epoch": 0.009468167151079076,
      "grad_norm": 0.715486466884613,
      "learning_rate": 9.910887345581404e-05,
      "loss": 0.0208,
      "step": 168500
    },
    {
      "epoch": 0.009496262602565957,
      "grad_norm": 0.8938928842544556,
      "learning_rate": 9.910606233106897e-05,
      "loss": 0.0208,
      "step": 169000
    },
    {
      "epoch": 0.009524358054052839,
      "grad_norm": 1.6448153257369995,
      "learning_rate": 9.910325120632391e-05,
      "loss": 0.02,
      "step": 169500
    },
    {
      "epoch": 0.00955245350553972,
      "grad_norm": 0.4668855667114258,
      "learning_rate": 9.910044008157885e-05,
      "loss": 0.0208,
      "step": 170000
    },
    {
      "epoch": 0.00955245350553972,
      "eval_loss": 0.010404354892671108,
      "eval_runtime": 18.9763,
      "eval_samples_per_second": 5269.72,
      "eval_steps_per_second": 82.366,
      "step": 170000
    },
    {
      "epoch": 0.009580548957026602,
      "grad_norm": 0.5463786721229553,
      "learning_rate": 9.909762895683378e-05,
      "loss": 0.0204,
      "step": 170500
    },
    {
      "epoch": 0.009608644408513483,
      "grad_norm": 0.648205041885376,
      "learning_rate": 9.909481783208871e-05,
      "loss": 0.0197,
      "step": 171000
    },
    {
      "epoch": 0.009636739860000364,
      "grad_norm": 0.861804187297821,
      "learning_rate": 9.909200670734364e-05,
      "loss": 0.02,
      "step": 171500
    },
    {
      "epoch": 0.009664835311487248,
      "grad_norm": 0.4861721992492676,
      "learning_rate": 9.908919558259858e-05,
      "loss": 0.0207,
      "step": 172000
    },
    {
      "epoch": 0.009692930762974129,
      "grad_norm": 0.7309359312057495,
      "learning_rate": 9.908638445785351e-05,
      "loss": 0.0192,
      "step": 172500
    },
    {
      "epoch": 0.00972102621446101,
      "grad_norm": 0.4787294864654541,
      "learning_rate": 9.908357333310845e-05,
      "loss": 0.0201,
      "step": 173000
    },
    {
      "epoch": 0.009749121665947892,
      "grad_norm": 1.41818368434906,
      "learning_rate": 9.908076220836338e-05,
      "loss": 0.0199,
      "step": 173500
    },
    {
      "epoch": 0.009777217117434773,
      "grad_norm": 0.9498695135116577,
      "learning_rate": 9.907795108361832e-05,
      "loss": 0.0205,
      "step": 174000
    },
    {
      "epoch": 0.009805312568921655,
      "grad_norm": 1.0245543718338013,
      "learning_rate": 9.907513995887325e-05,
      "loss": 0.0199,
      "step": 174500
    },
    {
      "epoch": 0.009833408020408536,
      "grad_norm": 0.6575708985328674,
      "learning_rate": 9.907232883412818e-05,
      "loss": 0.0215,
      "step": 175000
    },
    {
      "epoch": 0.009861503471895417,
      "grad_norm": 0.4056185781955719,
      "learning_rate": 9.906951770938312e-05,
      "loss": 0.0199,
      "step": 175500
    },
    {
      "epoch": 0.009889598923382299,
      "grad_norm": 0.4503178894519806,
      "learning_rate": 9.906670658463805e-05,
      "loss": 0.0195,
      "step": 176000
    },
    {
      "epoch": 0.00991769437486918,
      "grad_norm": 0.6791141033172607,
      "learning_rate": 9.906389545989299e-05,
      "loss": 0.0206,
      "step": 176500
    },
    {
      "epoch": 0.009945789826356062,
      "grad_norm": 0.37500956654548645,
      "learning_rate": 9.906108433514792e-05,
      "loss": 0.0198,
      "step": 177000
    },
    {
      "epoch": 0.009973885277842943,
      "grad_norm": 0.27753961086273193,
      "learning_rate": 9.905827321040285e-05,
      "loss": 0.0199,
      "step": 177500
    },
    {
      "epoch": 0.010001980729329825,
      "grad_norm": 0.6152690052986145,
      "learning_rate": 9.905546208565779e-05,
      "loss": 0.0204,
      "step": 178000
    },
    {
      "epoch": 0.010030076180816706,
      "grad_norm": 0.36511173844337463,
      "learning_rate": 9.905265096091272e-05,
      "loss": 0.0191,
      "step": 178500
    },
    {
      "epoch": 0.010058171632303587,
      "grad_norm": 0.33662688732147217,
      "learning_rate": 9.904983983616766e-05,
      "loss": 0.0203,
      "step": 179000
    },
    {
      "epoch": 0.01008626708379047,
      "grad_norm": 0.2945351302623749,
      "learning_rate": 9.904702871142258e-05,
      "loss": 0.0199,
      "step": 179500
    },
    {
      "epoch": 0.010114362535277352,
      "grad_norm": 0.41735774278640747,
      "learning_rate": 9.904421758667753e-05,
      "loss": 0.0201,
      "step": 180000
    },
    {
      "epoch": 0.010114362535277352,
      "eval_loss": 0.009707009419798851,
      "eval_runtime": 19.6732,
      "eval_samples_per_second": 5083.056,
      "eval_steps_per_second": 79.448,
      "step": 180000
    },
    {
      "epoch": 0.010142457986764233,
      "grad_norm": 0.38405707478523254,
      "learning_rate": 9.904140646193245e-05,
      "loss": 0.0192,
      "step": 180500
    },
    {
      "epoch": 0.010170553438251115,
      "grad_norm": 0.3260100781917572,
      "learning_rate": 9.90385953371874e-05,
      "loss": 0.0196,
      "step": 181000
    },
    {
      "epoch": 0.010198648889737996,
      "grad_norm": 0.28608593344688416,
      "learning_rate": 9.903578421244233e-05,
      "loss": 0.02,
      "step": 181500
    },
    {
      "epoch": 0.010226744341224878,
      "grad_norm": 1.0256189107894897,
      "learning_rate": 9.903297308769725e-05,
      "loss": 0.0201,
      "step": 182000
    },
    {
      "epoch": 0.010254839792711759,
      "grad_norm": 0.4437403082847595,
      "learning_rate": 9.90301619629522e-05,
      "loss": 0.0192,
      "step": 182500
    },
    {
      "epoch": 0.01028293524419864,
      "grad_norm": 0.4689243733882904,
      "learning_rate": 9.902735083820712e-05,
      "loss": 0.021,
      "step": 183000
    },
    {
      "epoch": 0.010311030695685522,
      "grad_norm": 0.4313191771507263,
      "learning_rate": 9.902453971346207e-05,
      "loss": 0.0191,
      "step": 183500
    },
    {
      "epoch": 0.010339126147172403,
      "grad_norm": 1.4244210720062256,
      "learning_rate": 9.902172858871699e-05,
      "loss": 0.0189,
      "step": 184000
    },
    {
      "epoch": 0.010367221598659285,
      "grad_norm": 0.2982521057128906,
      "learning_rate": 9.901891746397193e-05,
      "loss": 0.02,
      "step": 184500
    },
    {
      "epoch": 0.010395317050146166,
      "grad_norm": 0.45575347542762756,
      "learning_rate": 9.901610633922687e-05,
      "loss": 0.0195,
      "step": 185000
    },
    {
      "epoch": 0.010423412501633048,
      "grad_norm": 1.2016103267669678,
      "learning_rate": 9.901329521448179e-05,
      "loss": 0.0186,
      "step": 185500
    },
    {
      "epoch": 0.010451507953119929,
      "grad_norm": 0.77830970287323,
      "learning_rate": 9.901048408973674e-05,
      "loss": 0.0198,
      "step": 186000
    },
    {
      "epoch": 0.01047960340460681,
      "grad_norm": 0.8929855823516846,
      "learning_rate": 9.900767296499166e-05,
      "loss": 0.0202,
      "step": 186500
    },
    {
      "epoch": 0.010507698856093694,
      "grad_norm": 0.5177837610244751,
      "learning_rate": 9.90048618402466e-05,
      "loss": 0.02,
      "step": 187000
    },
    {
      "epoch": 0.010535794307580575,
      "grad_norm": 0.11409644782543182,
      "learning_rate": 9.900205071550153e-05,
      "loss": 0.0188,
      "step": 187500
    },
    {
      "epoch": 0.010563889759067456,
      "grad_norm": 0.41213372349739075,
      "learning_rate": 9.899923959075646e-05,
      "loss": 0.019,
      "step": 188000
    },
    {
      "epoch": 0.010591985210554338,
      "grad_norm": 0.527448296546936,
      "learning_rate": 9.89964284660114e-05,
      "loss": 0.0191,
      "step": 188500
    },
    {
      "epoch": 0.01062008066204122,
      "grad_norm": 0.7762627601623535,
      "learning_rate": 9.899361734126633e-05,
      "loss": 0.0191,
      "step": 189000
    },
    {
      "epoch": 0.0106481761135281,
      "grad_norm": 0.8252434730529785,
      "learning_rate": 9.899080621652128e-05,
      "loss": 0.0182,
      "step": 189500
    },
    {
      "epoch": 0.010676271565014982,
      "grad_norm": 0.32005032896995544,
      "learning_rate": 9.89879950917762e-05,
      "loss": 0.0194,
      "step": 190000
    },
    {
      "epoch": 0.010676271565014982,
      "eval_loss": 0.009520676918327808,
      "eval_runtime": 18.6573,
      "eval_samples_per_second": 5359.823,
      "eval_steps_per_second": 83.774,
      "step": 190000
    },
    {
      "epoch": 0.010704367016501863,
      "grad_norm": 0.5413611531257629,
      "learning_rate": 9.898518396703113e-05,
      "loss": 0.019,
      "step": 190500
    },
    {
      "epoch": 0.010732462467988745,
      "grad_norm": 0.589913010597229,
      "learning_rate": 9.898237284228607e-05,
      "loss": 0.0196,
      "step": 191000
    },
    {
      "epoch": 0.010760557919475626,
      "grad_norm": 1.00969660282135,
      "learning_rate": 9.8979561717541e-05,
      "loss": 0.019,
      "step": 191500
    },
    {
      "epoch": 0.010788653370962508,
      "grad_norm": 0.43692150712013245,
      "learning_rate": 9.897675059279593e-05,
      "loss": 0.0194,
      "step": 192000
    },
    {
      "epoch": 0.01081674882244939,
      "grad_norm": 0.43486085534095764,
      "learning_rate": 9.897393946805087e-05,
      "loss": 0.02,
      "step": 192500
    },
    {
      "epoch": 0.01084484427393627,
      "grad_norm": 0.41427722573280334,
      "learning_rate": 9.89711283433058e-05,
      "loss": 0.0198,
      "step": 193000
    },
    {
      "epoch": 0.010872939725423152,
      "grad_norm": 0.26080647110939026,
      "learning_rate": 9.896831721856074e-05,
      "loss": 0.0191,
      "step": 193500
    },
    {
      "epoch": 0.010901035176910033,
      "grad_norm": 0.22921739518642426,
      "learning_rate": 9.896550609381567e-05,
      "loss": 0.019,
      "step": 194000
    },
    {
      "epoch": 0.010929130628396917,
      "grad_norm": 0.6009637117385864,
      "learning_rate": 9.89626949690706e-05,
      "loss": 0.018,
      "step": 194500
    },
    {
      "epoch": 0.010957226079883798,
      "grad_norm": 0.2982064485549927,
      "learning_rate": 9.895988384432554e-05,
      "loss": 0.019,
      "step": 195000
    },
    {
      "epoch": 0.01098532153137068,
      "grad_norm": 1.4973069429397583,
      "learning_rate": 9.895707271958047e-05,
      "loss": 0.0188,
      "step": 195500
    },
    {
      "epoch": 0.01101341698285756,
      "grad_norm": 0.598974883556366,
      "learning_rate": 9.895426159483541e-05,
      "loss": 0.0191,
      "step": 196000
    },
    {
      "epoch": 0.011041512434344442,
      "grad_norm": 0.6232970952987671,
      "learning_rate": 9.895145047009034e-05,
      "loss": 0.019,
      "step": 196500
    },
    {
      "epoch": 0.011069607885831324,
      "grad_norm": 0.535892128944397,
      "learning_rate": 9.894863934534528e-05,
      "loss": 0.0212,
      "step": 197000
    },
    {
      "epoch": 0.011097703337318205,
      "grad_norm": 0.4725837707519531,
      "learning_rate": 9.894582822060021e-05,
      "loss": 0.018,
      "step": 197500
    },
    {
      "epoch": 0.011125798788805086,
      "grad_norm": 0.5100841522216797,
      "learning_rate": 9.894301709585515e-05,
      "loss": 0.0192,
      "step": 198000
    },
    {
      "epoch": 0.011153894240291968,
      "grad_norm": 1.0653387308120728,
      "learning_rate": 9.894020597111008e-05,
      "loss": 0.0189,
      "step": 198500
    },
    {
      "epoch": 0.01118198969177885,
      "grad_norm": 0.36304742097854614,
      "learning_rate": 9.8937394846365e-05,
      "loss": 0.0189,
      "step": 199000
    },
    {
      "epoch": 0.01121008514326573,
      "grad_norm": 0.6526703238487244,
      "learning_rate": 9.893458372161995e-05,
      "loss": 0.0183,
      "step": 199500
    },
    {
      "epoch": 0.011238180594752612,
      "grad_norm": 0.6586011648178101,
      "learning_rate": 9.893177259687487e-05,
      "loss": 0.0193,
      "step": 200000
    },
    {
      "epoch": 0.011238180594752612,
      "eval_loss": 0.009309160523116589,
      "eval_runtime": 18.7639,
      "eval_samples_per_second": 5329.396,
      "eval_steps_per_second": 83.298,
      "step": 200000
    },
    {
      "epoch": 0.011266276046239494,
      "grad_norm": 0.9930192828178406,
      "learning_rate": 9.892896147212982e-05,
      "loss": 0.0188,
      "step": 200500
    },
    {
      "epoch": 0.011294371497726375,
      "grad_norm": 0.28738903999328613,
      "learning_rate": 9.892615034738475e-05,
      "loss": 0.0193,
      "step": 201000
    },
    {
      "epoch": 0.011322466949213256,
      "grad_norm": 0.35908326506614685,
      "learning_rate": 9.892333922263967e-05,
      "loss": 0.0183,
      "step": 201500
    },
    {
      "epoch": 0.011350562400700138,
      "grad_norm": 0.2599450647830963,
      "learning_rate": 9.892052809789462e-05,
      "loss": 0.0186,
      "step": 202000
    },
    {
      "epoch": 0.011378657852187021,
      "grad_norm": 0.7080351114273071,
      "learning_rate": 9.891771697314954e-05,
      "loss": 0.0188,
      "step": 202500
    },
    {
      "epoch": 0.011406753303673902,
      "grad_norm": 0.36172059178352356,
      "learning_rate": 9.891490584840449e-05,
      "loss": 0.0194,
      "step": 203000
    },
    {
      "epoch": 0.011434848755160784,
      "grad_norm": 0.5002048015594482,
      "learning_rate": 9.891209472365941e-05,
      "loss": 0.0183,
      "step": 203500
    },
    {
      "epoch": 0.011462944206647665,
      "grad_norm": 0.8733323216438293,
      "learning_rate": 9.890928359891434e-05,
      "loss": 0.0193,
      "step": 204000
    },
    {
      "epoch": 0.011491039658134547,
      "grad_norm": 0.2602192461490631,
      "learning_rate": 9.890647247416929e-05,
      "loss": 0.0201,
      "step": 204500
    },
    {
      "epoch": 0.011519135109621428,
      "grad_norm": 0.552394449710846,
      "learning_rate": 9.890366134942421e-05,
      "loss": 0.0183,
      "step": 205000
    },
    {
      "epoch": 0.01154723056110831,
      "grad_norm": 0.9295070767402649,
      "learning_rate": 9.890085022467916e-05,
      "loss": 0.0186,
      "step": 205500
    },
    {
      "epoch": 0.011575326012595191,
      "grad_norm": 0.45718076825141907,
      "learning_rate": 9.889803909993408e-05,
      "loss": 0.0183,
      "step": 206000
    },
    {
      "epoch": 0.011603421464082072,
      "grad_norm": 0.7913313508033752,
      "learning_rate": 9.889522797518901e-05,
      "loss": 0.0185,
      "step": 206500
    },
    {
      "epoch": 0.011631516915568954,
      "grad_norm": 0.6400220394134521,
      "learning_rate": 9.889241685044395e-05,
      "loss": 0.0194,
      "step": 207000
    },
    {
      "epoch": 0.011659612367055835,
      "grad_norm": 1.0921614170074463,
      "learning_rate": 9.888960572569888e-05,
      "loss": 0.0182,
      "step": 207500
    },
    {
      "epoch": 0.011687707818542717,
      "grad_norm": 1.3244868516921997,
      "learning_rate": 9.888679460095383e-05,
      "loss": 0.0185,
      "step": 208000
    },
    {
      "epoch": 0.011715803270029598,
      "grad_norm": 0.49307817220687866,
      "learning_rate": 9.888398347620875e-05,
      "loss": 0.0187,
      "step": 208500
    },
    {
      "epoch": 0.01174389872151648,
      "grad_norm": 0.23157566785812378,
      "learning_rate": 9.888117235146369e-05,
      "loss": 0.0181,
      "step": 209000
    },
    {
      "epoch": 0.01177199417300336,
      "grad_norm": 0.6016632914543152,
      "learning_rate": 9.887836122671862e-05,
      "loss": 0.0186,
      "step": 209500
    },
    {
      "epoch": 0.011800089624490244,
      "grad_norm": 0.6974902749061584,
      "learning_rate": 9.887555010197355e-05,
      "loss": 0.0186,
      "step": 210000
    },
    {
      "epoch": 0.011800089624490244,
      "eval_loss": 0.008942986838519573,
      "eval_runtime": 18.5475,
      "eval_samples_per_second": 5391.556,
      "eval_steps_per_second": 84.27,
      "step": 210000
    },
    {
      "epoch": 0.011828185075977125,
      "grad_norm": 0.6204833388328552,
      "learning_rate": 9.887273897722849e-05,
      "loss": 0.0185,
      "step": 210500
    },
    {
      "epoch": 0.011856280527464007,
      "grad_norm": 0.5232461094856262,
      "learning_rate": 9.886992785248342e-05,
      "loss": 0.019,
      "step": 211000
    },
    {
      "epoch": 0.011884375978950888,
      "grad_norm": 0.598020613193512,
      "learning_rate": 9.886711672773836e-05,
      "loss": 0.0185,
      "step": 211500
    },
    {
      "epoch": 0.01191247143043777,
      "grad_norm": 0.5243792533874512,
      "learning_rate": 9.886430560299329e-05,
      "loss": 0.0182,
      "step": 212000
    },
    {
      "epoch": 0.011940566881924651,
      "grad_norm": 0.7392913103103638,
      "learning_rate": 9.886149447824822e-05,
      "loss": 0.018,
      "step": 212500
    },
    {
      "epoch": 0.011968662333411532,
      "grad_norm": 0.6001286506652832,
      "learning_rate": 9.885868335350316e-05,
      "loss": 0.0179,
      "step": 213000
    },
    {
      "epoch": 0.011996757784898414,
      "grad_norm": 0.33171993494033813,
      "learning_rate": 9.885587222875809e-05,
      "loss": 0.018,
      "step": 213500
    },
    {
      "epoch": 0.012024853236385295,
      "grad_norm": 0.36668750643730164,
      "learning_rate": 9.885306110401303e-05,
      "loss": 0.0179,
      "step": 214000
    },
    {
      "epoch": 0.012052948687872177,
      "grad_norm": 0.444654643535614,
      "learning_rate": 9.885024997926796e-05,
      "loss": 0.0183,
      "step": 214500
    },
    {
      "epoch": 0.012081044139359058,
      "grad_norm": 0.35414454340934753,
      "learning_rate": 9.884743885452288e-05,
      "loss": 0.0188,
      "step": 215000
    },
    {
      "epoch": 0.01210913959084594,
      "grad_norm": 0.24553389847278595,
      "learning_rate": 9.884462772977783e-05,
      "loss": 0.0184,
      "step": 215500
    },
    {
      "epoch": 0.012137235042332821,
      "grad_norm": 0.5879337191581726,
      "learning_rate": 9.884181660503276e-05,
      "loss": 0.0182,
      "step": 216000
    },
    {
      "epoch": 0.012165330493819702,
      "grad_norm": 0.6197173595428467,
      "learning_rate": 9.88390054802877e-05,
      "loss": 0.0182,
      "step": 216500
    },
    {
      "epoch": 0.012193425945306584,
      "grad_norm": 0.651223361492157,
      "learning_rate": 9.883619435554263e-05,
      "loss": 0.0182,
      "step": 217000
    },
    {
      "epoch": 0.012221521396793467,
      "grad_norm": 1.1157289743423462,
      "learning_rate": 9.883338323079757e-05,
      "loss": 0.0183,
      "step": 217500
    },
    {
      "epoch": 0.012249616848280348,
      "grad_norm": 0.35704824328422546,
      "learning_rate": 9.88305721060525e-05,
      "loss": 0.0181,
      "step": 218000
    },
    {
      "epoch": 0.01227771229976723,
      "grad_norm": 0.7132351398468018,
      "learning_rate": 9.882776098130742e-05,
      "loss": 0.018,
      "step": 218500
    },
    {
      "epoch": 0.012305807751254111,
      "grad_norm": 0.27425631880760193,
      "learning_rate": 9.882494985656237e-05,
      "loss": 0.0168,
      "step": 219000
    },
    {
      "epoch": 0.012333903202740993,
      "grad_norm": 0.7046167254447937,
      "learning_rate": 9.882213873181729e-05,
      "loss": 0.0175,
      "step": 219500
    },
    {
      "epoch": 0.012361998654227874,
      "grad_norm": 0.6964855194091797,
      "learning_rate": 9.881932760707224e-05,
      "loss": 0.0189,
      "step": 220000
    },
    {
      "epoch": 0.012361998654227874,
      "eval_loss": 0.009282019920647144,
      "eval_runtime": 19.2082,
      "eval_samples_per_second": 5206.111,
      "eval_steps_per_second": 81.372,
      "step": 220000
    },
    {
      "epoch": 0.012390094105714755,
      "grad_norm": 1.1668189764022827,
      "learning_rate": 9.881651648232717e-05,
      "loss": 0.0176,
      "step": 220500
    },
    {
      "epoch": 0.012418189557201637,
      "grad_norm": 0.44370877742767334,
      "learning_rate": 9.88137053575821e-05,
      "loss": 0.0178,
      "step": 221000
    },
    {
      "epoch": 0.012446285008688518,
      "grad_norm": 0.2473619431257248,
      "learning_rate": 9.881089423283704e-05,
      "loss": 0.0176,
      "step": 221500
    },
    {
      "epoch": 0.0124743804601754,
      "grad_norm": 4.17043924331665,
      "learning_rate": 9.880808310809196e-05,
      "loss": 0.0176,
      "step": 222000
    },
    {
      "epoch": 0.012502475911662281,
      "grad_norm": 0.5467270016670227,
      "learning_rate": 9.880527198334691e-05,
      "loss": 0.018,
      "step": 222500
    },
    {
      "epoch": 0.012530571363149163,
      "grad_norm": 0.490038126707077,
      "learning_rate": 9.880246085860183e-05,
      "loss": 0.018,
      "step": 223000
    },
    {
      "epoch": 0.012558666814636044,
      "grad_norm": 0.5768824815750122,
      "learning_rate": 9.879964973385676e-05,
      "loss": 0.017,
      "step": 223500
    },
    {
      "epoch": 0.012586762266122925,
      "grad_norm": 0.3669991195201874,
      "learning_rate": 9.879683860911171e-05,
      "loss": 0.0176,
      "step": 224000
    },
    {
      "epoch": 0.012614857717609807,
      "grad_norm": 0.3789229691028595,
      "learning_rate": 9.879402748436663e-05,
      "loss": 0.0171,
      "step": 224500
    },
    {
      "epoch": 0.01264295316909669,
      "grad_norm": 1.0541253089904785,
      "learning_rate": 9.879121635962158e-05,
      "loss": 0.0182,
      "step": 225000
    },
    {
      "epoch": 0.012671048620583571,
      "grad_norm": 0.6217306852340698,
      "learning_rate": 9.87884052348765e-05,
      "loss": 0.0179,
      "step": 225500
    },
    {
      "epoch": 0.012699144072070453,
      "grad_norm": 0.17201943695545197,
      "learning_rate": 9.878559411013144e-05,
      "loss": 0.0175,
      "step": 226000
    },
    {
      "epoch": 0.012727239523557334,
      "grad_norm": 0.4926697015762329,
      "learning_rate": 9.878278298538637e-05,
      "loss": 0.0174,
      "step": 226500
    },
    {
      "epoch": 0.012755334975044216,
      "grad_norm": 0.626548707485199,
      "learning_rate": 9.87799718606413e-05,
      "loss": 0.0178,
      "step": 227000
    },
    {
      "epoch": 0.012783430426531097,
      "grad_norm": 0.4851466119289398,
      "learning_rate": 9.877716073589625e-05,
      "loss": 0.0176,
      "step": 227500
    },
    {
      "epoch": 0.012811525878017978,
      "grad_norm": 0.7407012581825256,
      "learning_rate": 9.877434961115117e-05,
      "loss": 0.0183,
      "step": 228000
    },
    {
      "epoch": 0.01283962132950486,
      "grad_norm": 0.3307691514492035,
      "learning_rate": 9.877153848640611e-05,
      "loss": 0.018,
      "step": 228500
    },
    {
      "epoch": 0.012867716780991741,
      "grad_norm": 0.2780846357345581,
      "learning_rate": 9.876872736166104e-05,
      "loss": 0.018,
      "step": 229000
    },
    {
      "epoch": 0.012895812232478623,
      "grad_norm": 0.34851858019828796,
      "learning_rate": 9.876591623691598e-05,
      "loss": 0.0169,
      "step": 229500
    },
    {
      "epoch": 0.012923907683965504,
      "grad_norm": 0.186121866106987,
      "learning_rate": 9.876310511217091e-05,
      "loss": 0.0173,
      "step": 230000
    },
    {
      "epoch": 0.012923907683965504,
      "eval_loss": 0.008574179373681545,
      "eval_runtime": 18.7172,
      "eval_samples_per_second": 5342.683,
      "eval_steps_per_second": 83.506,
      "step": 230000
    },
    {
      "epoch": 0.012952003135452386,
      "grad_norm": 0.3276934325695038,
      "learning_rate": 9.876029398742584e-05,
      "loss": 0.0175,
      "step": 230500
    },
    {
      "epoch": 0.012980098586939267,
      "grad_norm": 0.5951675772666931,
      "learning_rate": 9.875748286268078e-05,
      "loss": 0.0177,
      "step": 231000
    },
    {
      "epoch": 0.013008194038426148,
      "grad_norm": 0.4932069778442383,
      "learning_rate": 9.875467173793571e-05,
      "loss": 0.0169,
      "step": 231500
    },
    {
      "epoch": 0.01303628948991303,
      "grad_norm": 0.4758877754211426,
      "learning_rate": 9.875186061319065e-05,
      "loss": 0.0169,
      "step": 232000
    },
    {
      "epoch": 0.013064384941399911,
      "grad_norm": 0.5250113606452942,
      "learning_rate": 9.874904948844558e-05,
      "loss": 0.0176,
      "step": 232500
    },
    {
      "epoch": 0.013092480392886794,
      "grad_norm": 0.5302578210830688,
      "learning_rate": 9.874623836370052e-05,
      "loss": 0.0183,
      "step": 233000
    },
    {
      "epoch": 0.013120575844373676,
      "grad_norm": 0.3792286217212677,
      "learning_rate": 9.874342723895545e-05,
      "loss": 0.0165,
      "step": 233500
    },
    {
      "epoch": 0.013148671295860557,
      "grad_norm": 0.6750426888465881,
      "learning_rate": 9.874061611421038e-05,
      "loss": 0.0173,
      "step": 234000
    },
    {
      "epoch": 0.013176766747347439,
      "grad_norm": 0.35452014207839966,
      "learning_rate": 9.87378049894653e-05,
      "loss": 0.0168,
      "step": 234500
    },
    {
      "epoch": 0.01320486219883432,
      "grad_norm": 3.5882561206817627,
      "learning_rate": 9.873499386472025e-05,
      "loss": 0.0183,
      "step": 235000
    },
    {
      "epoch": 0.013232957650321201,
      "grad_norm": 0.36751893162727356,
      "learning_rate": 9.873218273997519e-05,
      "loss": 0.0177,
      "step": 235500
    },
    {
      "epoch": 0.013261053101808083,
      "grad_norm": 0.48825204372406006,
      "learning_rate": 9.872937161523012e-05,
      "loss": 0.0175,
      "step": 236000
    },
    {
      "epoch": 0.013289148553294964,
      "grad_norm": 0.6559988856315613,
      "learning_rate": 9.872656049048505e-05,
      "loss": 0.0177,
      "step": 236500
    },
    {
      "epoch": 0.013317244004781846,
      "grad_norm": 0.5938155055046082,
      "learning_rate": 9.872374936573998e-05,
      "loss": 0.0172,
      "step": 237000
    },
    {
      "epoch": 0.013345339456268727,
      "grad_norm": 0.5792304873466492,
      "learning_rate": 9.872093824099492e-05,
      "loss": 0.018,
      "step": 237500
    },
    {
      "epoch": 0.013373434907755609,
      "grad_norm": 0.6799984574317932,
      "learning_rate": 9.871812711624984e-05,
      "loss": 0.017,
      "step": 238000
    },
    {
      "epoch": 0.01340153035924249,
      "grad_norm": 0.451350599527359,
      "learning_rate": 9.871531599150479e-05,
      "loss": 0.0169,
      "step": 238500
    },
    {
      "epoch": 0.013429625810729371,
      "grad_norm": 0.6767572164535522,
      "learning_rate": 9.871250486675971e-05,
      "loss": 0.0178,
      "step": 239000
    },
    {
      "epoch": 0.013457721262216253,
      "grad_norm": 0.4431097209453583,
      "learning_rate": 9.870969374201465e-05,
      "loss": 0.0168,
      "step": 239500
    },
    {
      "epoch": 0.013485816713703134,
      "grad_norm": 0.25124603509902954,
      "learning_rate": 9.87068826172696e-05,
      "loss": 0.0167,
      "step": 240000
    },
    {
      "epoch": 0.013485816713703134,
      "eval_loss": 0.008476830087602139,
      "eval_runtime": 18.9985,
      "eval_samples_per_second": 5263.579,
      "eval_steps_per_second": 82.27,
      "step": 240000
    },
    {
      "epoch": 0.013513912165190017,
      "grad_norm": 1.2377352714538574,
      "learning_rate": 9.870407149252452e-05,
      "loss": 0.0176,
      "step": 240500
    },
    {
      "epoch": 0.013542007616676899,
      "grad_norm": 0.46619707345962524,
      "learning_rate": 9.870126036777946e-05,
      "loss": 0.0166,
      "step": 241000
    },
    {
      "epoch": 0.01357010306816378,
      "grad_norm": 0.27912867069244385,
      "learning_rate": 9.869844924303438e-05,
      "loss": 0.0167,
      "step": 241500
    },
    {
      "epoch": 0.013598198519650662,
      "grad_norm": 0.3280809819698334,
      "learning_rate": 9.869563811828932e-05,
      "loss": 0.0174,
      "step": 242000
    },
    {
      "epoch": 0.013626293971137543,
      "grad_norm": 0.6433950662612915,
      "learning_rate": 9.869282699354425e-05,
      "loss": 0.0169,
      "step": 242500
    },
    {
      "epoch": 0.013654389422624424,
      "grad_norm": 0.6389753222465515,
      "learning_rate": 9.869001586879919e-05,
      "loss": 0.0171,
      "step": 243000
    },
    {
      "epoch": 0.013682484874111306,
      "grad_norm": 0.7572235465049744,
      "learning_rate": 9.868720474405413e-05,
      "loss": 0.0177,
      "step": 243500
    },
    {
      "epoch": 0.013710580325598187,
      "grad_norm": 0.4562583267688751,
      "learning_rate": 9.868439361930906e-05,
      "loss": 0.0173,
      "step": 244000
    },
    {
      "epoch": 0.013738675777085069,
      "grad_norm": 1.4747250080108643,
      "learning_rate": 9.868158249456399e-05,
      "loss": 0.0178,
      "step": 244500
    },
    {
      "epoch": 0.01376677122857195,
      "grad_norm": 0.5082557201385498,
      "learning_rate": 9.867877136981892e-05,
      "loss": 0.0165,
      "step": 245000
    },
    {
      "epoch": 0.013794866680058832,
      "grad_norm": 0.16707009077072144,
      "learning_rate": 9.867596024507386e-05,
      "loss": 0.0165,
      "step": 245500
    },
    {
      "epoch": 0.013822962131545713,
      "grad_norm": 0.6214559674263,
      "learning_rate": 9.867314912032879e-05,
      "loss": 0.0172,
      "step": 246000
    },
    {
      "epoch": 0.013851057583032594,
      "grad_norm": 0.687592089176178,
      "learning_rate": 9.867033799558373e-05,
      "loss": 0.0165,
      "step": 246500
    },
    {
      "epoch": 0.013879153034519476,
      "grad_norm": 0.6140646934509277,
      "learning_rate": 9.866752687083866e-05,
      "loss": 0.0165,
      "step": 247000
    },
    {
      "epoch": 0.013907248486006357,
      "grad_norm": 0.1035384014248848,
      "learning_rate": 9.86647157460936e-05,
      "loss": 0.0173,
      "step": 247500
    },
    {
      "epoch": 0.01393534393749324,
      "grad_norm": 0.5800098180770874,
      "learning_rate": 9.866190462134853e-05,
      "loss": 0.0168,
      "step": 248000
    },
    {
      "epoch": 0.013963439388980122,
      "grad_norm": 0.5864430069923401,
      "learning_rate": 9.865909349660346e-05,
      "loss": 0.0167,
      "step": 248500
    },
    {
      "epoch": 0.013991534840467003,
      "grad_norm": 0.3139672577381134,
      "learning_rate": 9.86562823718584e-05,
      "loss": 0.0162,
      "step": 249000
    },
    {
      "epoch": 0.014019630291953885,
      "grad_norm": 0.7083836793899536,
      "learning_rate": 9.865347124711333e-05,
      "loss": 0.0167,
      "step": 249500
    },
    {
      "epoch": 0.014047725743440766,
      "grad_norm": 0.21317562460899353,
      "learning_rate": 9.865066012236827e-05,
      "loss": 0.017,
      "step": 250000
    },
    {
      "epoch": 0.014047725743440766,
      "eval_loss": 0.008234957233071327,
      "eval_runtime": 18.8571,
      "eval_samples_per_second": 5303.043,
      "eval_steps_per_second": 82.887,
      "step": 250000
    },
    {
      "epoch": 0.014075821194927647,
      "grad_norm": 0.28550609946250916,
      "learning_rate": 9.86478489976232e-05,
      "loss": 0.0163,
      "step": 250500
    },
    {
      "epoch": 0.014103916646414529,
      "grad_norm": 0.340408056974411,
      "learning_rate": 9.864503787287813e-05,
      "loss": 0.0167,
      "step": 251000
    },
    {
      "epoch": 0.01413201209790141,
      "grad_norm": 0.8278250694274902,
      "learning_rate": 9.864222674813307e-05,
      "loss": 0.0165,
      "step": 251500
    },
    {
      "epoch": 0.014160107549388292,
      "grad_norm": 0.7703796029090881,
      "learning_rate": 9.8639415623388e-05,
      "loss": 0.0167,
      "step": 252000
    },
    {
      "epoch": 0.014188203000875173,
      "grad_norm": 0.5172754526138306,
      "learning_rate": 9.863660449864294e-05,
      "loss": 0.0169,
      "step": 252500
    },
    {
      "epoch": 0.014216298452362055,
      "grad_norm": 0.45950058102607727,
      "learning_rate": 9.863379337389787e-05,
      "loss": 0.0172,
      "step": 253000
    },
    {
      "epoch": 0.014244393903848936,
      "grad_norm": 0.773688554763794,
      "learning_rate": 9.86309822491528e-05,
      "loss": 0.0169,
      "step": 253500
    },
    {
      "epoch": 0.014272489355335817,
      "grad_norm": 0.13639673590660095,
      "learning_rate": 9.862817112440773e-05,
      "loss": 0.016,
      "step": 254000
    },
    {
      "epoch": 0.014300584806822699,
      "grad_norm": 0.3087548315525055,
      "learning_rate": 9.862535999966267e-05,
      "loss": 0.0155,
      "step": 254500
    },
    {
      "epoch": 0.01432868025830958,
      "grad_norm": 1.8101898431777954,
      "learning_rate": 9.862254887491761e-05,
      "loss": 0.0165,
      "step": 255000
    },
    {
      "epoch": 0.014356775709796463,
      "grad_norm": 0.454734742641449,
      "learning_rate": 9.861973775017254e-05,
      "loss": 0.0162,
      "step": 255500
    },
    {
      "epoch": 0.014384871161283345,
      "grad_norm": 0.44234177470207214,
      "learning_rate": 9.861692662542748e-05,
      "loss": 0.0171,
      "step": 256000
    },
    {
      "epoch": 0.014412966612770226,
      "grad_norm": 0.5395411849021912,
      "learning_rate": 9.86141155006824e-05,
      "loss": 0.0167,
      "step": 256500
    },
    {
      "epoch": 0.014441062064257108,
      "grad_norm": 0.2908221483230591,
      "learning_rate": 9.861130437593735e-05,
      "loss": 0.0167,
      "step": 257000
    },
    {
      "epoch": 0.014469157515743989,
      "grad_norm": 0.6442658305168152,
      "learning_rate": 9.860849325119227e-05,
      "loss": 0.0166,
      "step": 257500
    },
    {
      "epoch": 0.01449725296723087,
      "grad_norm": 0.41649550199508667,
      "learning_rate": 9.860568212644721e-05,
      "loss": 0.0163,
      "step": 258000
    },
    {
      "epoch": 0.014525348418717752,
      "grad_norm": 0.20960120856761932,
      "learning_rate": 9.860287100170215e-05,
      "loss": 0.0155,
      "step": 258500
    },
    {
      "epoch": 0.014553443870204633,
      "grad_norm": 0.7131113409996033,
      "learning_rate": 9.860005987695707e-05,
      "loss": 0.017,
      "step": 259000
    },
    {
      "epoch": 0.014581539321691515,
      "grad_norm": 0.44170811772346497,
      "learning_rate": 9.859724875221202e-05,
      "loss": 0.016,
      "step": 259500
    },
    {
      "epoch": 0.014609634773178396,
      "grad_norm": 0.6710616946220398,
      "learning_rate": 9.859443762746694e-05,
      "loss": 0.0168,
      "step": 260000
    },
    {
      "epoch": 0.014609634773178396,
      "eval_loss": 0.008320016786456108,
      "eval_runtime": 19.7786,
      "eval_samples_per_second": 5055.982,
      "eval_steps_per_second": 79.025,
      "step": 260000
    },
    {
      "epoch": 0.014637730224665278,
      "grad_norm": 0.7879049777984619,
      "learning_rate": 9.859162650272189e-05,
      "loss": 0.0166,
      "step": 260500
    },
    {
      "epoch": 0.014665825676152159,
      "grad_norm": 0.4116862714290619,
      "learning_rate": 9.85888153779768e-05,
      "loss": 0.0163,
      "step": 261000
    },
    {
      "epoch": 0.01469392112763904,
      "grad_norm": 0.6443643569946289,
      "learning_rate": 9.858600425323174e-05,
      "loss": 0.0162,
      "step": 261500
    },
    {
      "epoch": 0.014722016579125922,
      "grad_norm": 0.4508487582206726,
      "learning_rate": 9.858319312848667e-05,
      "loss": 0.016,
      "step": 262000
    },
    {
      "epoch": 0.014750112030612803,
      "grad_norm": 0.7326563000679016,
      "learning_rate": 9.858038200374161e-05,
      "loss": 0.0167,
      "step": 262500
    },
    {
      "epoch": 0.014778207482099685,
      "grad_norm": 0.28291434049606323,
      "learning_rate": 9.857757087899656e-05,
      "loss": 0.0162,
      "step": 263000
    },
    {
      "epoch": 0.014806302933586568,
      "grad_norm": 0.5793440341949463,
      "learning_rate": 9.857475975425148e-05,
      "loss": 0.0166,
      "step": 263500
    },
    {
      "epoch": 0.01483439838507345,
      "grad_norm": 0.35821422934532166,
      "learning_rate": 9.857194862950641e-05,
      "loss": 0.0166,
      "step": 264000
    },
    {
      "epoch": 0.01486249383656033,
      "grad_norm": 0.5984551906585693,
      "learning_rate": 9.856913750476135e-05,
      "loss": 0.0159,
      "step": 264500
    },
    {
      "epoch": 0.014890589288047212,
      "grad_norm": 2.021782875061035,
      "learning_rate": 9.856632638001628e-05,
      "loss": 0.0162,
      "step": 265000
    },
    {
      "epoch": 0.014918684739534093,
      "grad_norm": 1.6493958234786987,
      "learning_rate": 9.856351525527121e-05,
      "loss": 0.0168,
      "step": 265500
    },
    {
      "epoch": 0.014946780191020975,
      "grad_norm": 0.36428865790367126,
      "learning_rate": 9.856070413052615e-05,
      "loss": 0.0159,
      "step": 266000
    },
    {
      "epoch": 0.014974875642507856,
      "grad_norm": 0.3281286060810089,
      "learning_rate": 9.855789300578108e-05,
      "loss": 0.016,
      "step": 266500
    },
    {
      "epoch": 0.015002971093994738,
      "grad_norm": 0.2683238089084625,
      "learning_rate": 9.855508188103602e-05,
      "loss": 0.0157,
      "step": 267000
    },
    {
      "epoch": 0.015031066545481619,
      "grad_norm": 0.6156920790672302,
      "learning_rate": 9.855227075629095e-05,
      "loss": 0.0162,
      "step": 267500
    },
    {
      "epoch": 0.0150591619969685,
      "grad_norm": 0.442991703748703,
      "learning_rate": 9.854945963154589e-05,
      "loss": 0.0158,
      "step": 268000
    },
    {
      "epoch": 0.015087257448455382,
      "grad_norm": 0.7703702449798584,
      "learning_rate": 9.854664850680082e-05,
      "loss": 0.0161,
      "step": 268500
    },
    {
      "epoch": 0.015115352899942263,
      "grad_norm": 0.6967585682868958,
      "learning_rate": 9.854383738205575e-05,
      "loss": 0.0158,
      "step": 269000
    },
    {
      "epoch": 0.015143448351429145,
      "grad_norm": 0.712132453918457,
      "learning_rate": 9.854102625731069e-05,
      "loss": 0.0162,
      "step": 269500
    },
    {
      "epoch": 0.015171543802916026,
      "grad_norm": 0.37408971786499023,
      "learning_rate": 9.853821513256561e-05,
      "loss": 0.0167,
      "step": 270000
    },
    {
      "epoch": 0.015171543802916026,
      "eval_loss": 0.007587958127260208,
      "eval_runtime": 18.6063,
      "eval_samples_per_second": 5374.535,
      "eval_steps_per_second": 84.004,
      "step": 270000
    },
    {
      "epoch": 0.015199639254402908,
      "grad_norm": 0.3620031177997589,
      "learning_rate": 9.853540400782056e-05,
      "loss": 0.0163,
      "step": 270500
    },
    {
      "epoch": 0.01522773470588979,
      "grad_norm": 0.6007280349731445,
      "learning_rate": 9.853259288307549e-05,
      "loss": 0.0167,
      "step": 271000
    },
    {
      "epoch": 0.015255830157376672,
      "grad_norm": 0.31732800602912903,
      "learning_rate": 9.852978175833042e-05,
      "loss": 0.0157,
      "step": 271500
    },
    {
      "epoch": 0.015283925608863554,
      "grad_norm": 0.6301318407058716,
      "learning_rate": 9.852697063358536e-05,
      "loss": 0.0154,
      "step": 272000
    },
    {
      "epoch": 0.015312021060350435,
      "grad_norm": 0.4912616014480591,
      "learning_rate": 9.852415950884028e-05,
      "loss": 0.0158,
      "step": 272500
    },
    {
      "epoch": 0.015340116511837316,
      "grad_norm": 0.3140382766723633,
      "learning_rate": 9.852134838409523e-05,
      "loss": 0.0159,
      "step": 273000
    },
    {
      "epoch": 0.015368211963324198,
      "grad_norm": 0.43585360050201416,
      "learning_rate": 9.851853725935015e-05,
      "loss": 0.0155,
      "step": 273500
    },
    {
      "epoch": 0.01539630741481108,
      "grad_norm": 0.15575209259986877,
      "learning_rate": 9.85157261346051e-05,
      "loss": 0.0163,
      "step": 274000
    },
    {
      "epoch": 0.01542440286629796,
      "grad_norm": 0.4168897271156311,
      "learning_rate": 9.851291500986003e-05,
      "loss": 0.0153,
      "step": 274500
    },
    {
      "epoch": 0.015452498317784842,
      "grad_norm": 0.3953695297241211,
      "learning_rate": 9.851010388511495e-05,
      "loss": 0.0158,
      "step": 275000
    },
    {
      "epoch": 0.015480593769271724,
      "grad_norm": 1.1610009670257568,
      "learning_rate": 9.85072927603699e-05,
      "loss": 0.0157,
      "step": 275500
    },
    {
      "epoch": 0.015508689220758605,
      "grad_norm": 0.3139486610889435,
      "learning_rate": 9.850448163562482e-05,
      "loss": 0.0159,
      "step": 276000
    },
    {
      "epoch": 0.015536784672245486,
      "grad_norm": 1.2356152534484863,
      "learning_rate": 9.850167051087977e-05,
      "loss": 0.0163,
      "step": 276500
    },
    {
      "epoch": 0.015564880123732368,
      "grad_norm": 0.5104894638061523,
      "learning_rate": 9.849885938613469e-05,
      "loss": 0.0154,
      "step": 277000
    },
    {
      "epoch": 0.01559297557521925,
      "grad_norm": 0.4091249406337738,
      "learning_rate": 9.849604826138962e-05,
      "loss": 0.0168,
      "step": 277500
    },
    {
      "epoch": 0.01562107102670613,
      "grad_norm": 0.6003503799438477,
      "learning_rate": 9.849323713664457e-05,
      "loss": 0.0164,
      "step": 278000
    },
    {
      "epoch": 0.015649166478193012,
      "grad_norm": 0.19052156805992126,
      "learning_rate": 9.849042601189949e-05,
      "loss": 0.0163,
      "step": 278500
    },
    {
      "epoch": 0.015677261929679893,
      "grad_norm": 0.20464366674423218,
      "learning_rate": 9.848761488715444e-05,
      "loss": 0.016,
      "step": 279000
    },
    {
      "epoch": 0.015705357381166775,
      "grad_norm": 0.7550371885299683,
      "learning_rate": 9.848480376240936e-05,
      "loss": 0.0155,
      "step": 279500
    },
    {
      "epoch": 0.015733452832653656,
      "grad_norm": 0.3016967177391052,
      "learning_rate": 9.84819926376643e-05,
      "loss": 0.0161,
      "step": 280000
    },
    {
      "epoch": 0.015733452832653656,
      "eval_loss": 0.007829619571566582,
      "eval_runtime": 18.7496,
      "eval_samples_per_second": 5333.45,
      "eval_steps_per_second": 83.362,
      "step": 280000
    },
    {
      "epoch": 0.015761548284140538,
      "grad_norm": 0.547448456287384,
      "learning_rate": 9.847918151291923e-05,
      "loss": 0.0154,
      "step": 280500
    },
    {
      "epoch": 0.01578964373562742,
      "grad_norm": 0.2750471532344818,
      "learning_rate": 9.847637038817416e-05,
      "loss": 0.0155,
      "step": 281000
    },
    {
      "epoch": 0.0158177391871143,
      "grad_norm": 1.226569414138794,
      "learning_rate": 9.84735592634291e-05,
      "loss": 0.0164,
      "step": 281500
    },
    {
      "epoch": 0.015845834638601182,
      "grad_norm": 3.551999092102051,
      "learning_rate": 9.847074813868403e-05,
      "loss": 0.0149,
      "step": 282000
    },
    {
      "epoch": 0.015873930090088067,
      "grad_norm": 0.6003472805023193,
      "learning_rate": 9.846793701393896e-05,
      "loss": 0.016,
      "step": 282500
    },
    {
      "epoch": 0.01590202554157495,
      "grad_norm": 0.5711688995361328,
      "learning_rate": 9.84651258891939e-05,
      "loss": 0.016,
      "step": 283000
    },
    {
      "epoch": 0.01593012099306183,
      "grad_norm": 0.2098074108362198,
      "learning_rate": 9.846231476444883e-05,
      "loss": 0.016,
      "step": 283500
    },
    {
      "epoch": 0.01595821644454871,
      "grad_norm": 0.4152434766292572,
      "learning_rate": 9.845950363970377e-05,
      "loss": 0.0153,
      "step": 284000
    },
    {
      "epoch": 0.015986311896035593,
      "grad_norm": 0.5540562868118286,
      "learning_rate": 9.84566925149587e-05,
      "loss": 0.0154,
      "step": 284500
    },
    {
      "epoch": 0.016014407347522474,
      "grad_norm": 0.3706552982330322,
      "learning_rate": 9.845388139021364e-05,
      "loss": 0.0148,
      "step": 285000
    },
    {
      "epoch": 0.016042502799009355,
      "grad_norm": 0.8216433525085449,
      "learning_rate": 9.845107026546857e-05,
      "loss": 0.016,
      "step": 285500
    },
    {
      "epoch": 0.016070598250496237,
      "grad_norm": 0.6140445470809937,
      "learning_rate": 9.84482591407235e-05,
      "loss": 0.0156,
      "step": 286000
    },
    {
      "epoch": 0.016098693701983118,
      "grad_norm": 0.08394131809473038,
      "learning_rate": 9.844544801597844e-05,
      "loss": 0.015,
      "step": 286500
    },
    {
      "epoch": 0.01612678915347,
      "grad_norm": 0.22054485976696014,
      "learning_rate": 9.844263689123337e-05,
      "loss": 0.0158,
      "step": 287000
    },
    {
      "epoch": 0.01615488460495688,
      "grad_norm": 0.9096868634223938,
      "learning_rate": 9.843982576648831e-05,
      "loss": 0.017,
      "step": 287500
    },
    {
      "epoch": 0.016182980056443762,
      "grad_norm": 0.5767183303833008,
      "learning_rate": 9.843701464174324e-05,
      "loss": 0.0141,
      "step": 288000
    },
    {
      "epoch": 0.016211075507930644,
      "grad_norm": 0.38890907168388367,
      "learning_rate": 9.843420351699818e-05,
      "loss": 0.0151,
      "step": 288500
    },
    {
      "epoch": 0.016239170959417525,
      "grad_norm": 0.6375842690467834,
      "learning_rate": 9.843139239225311e-05,
      "loss": 0.0156,
      "step": 289000
    },
    {
      "epoch": 0.016267266410904407,
      "grad_norm": 0.7393246293067932,
      "learning_rate": 9.842858126750804e-05,
      "loss": 0.0162,
      "step": 289500
    },
    {
      "epoch": 0.016295361862391288,
      "grad_norm": 0.6710322499275208,
      "learning_rate": 9.842577014276298e-05,
      "loss": 0.0158,
      "step": 290000
    },
    {
      "epoch": 0.016295361862391288,
      "eval_loss": 0.007814363576471806,
      "eval_runtime": 19.4345,
      "eval_samples_per_second": 5145.5,
      "eval_steps_per_second": 80.424,
      "step": 290000
    },
    {
      "epoch": 0.01632345731387817,
      "grad_norm": 0.6573466658592224,
      "learning_rate": 9.842295901801791e-05,
      "loss": 0.0154,
      "step": 290500
    },
    {
      "epoch": 0.01635155276536505,
      "grad_norm": 0.6639581918716431,
      "learning_rate": 9.842014789327285e-05,
      "loss": 0.016,
      "step": 291000
    },
    {
      "epoch": 0.016379648216851932,
      "grad_norm": 0.4403160512447357,
      "learning_rate": 9.841733676852778e-05,
      "loss": 0.0158,
      "step": 291500
    },
    {
      "epoch": 0.016407743668338814,
      "grad_norm": 0.11711228638887405,
      "learning_rate": 9.84145256437827e-05,
      "loss": 0.0147,
      "step": 292000
    },
    {
      "epoch": 0.016435839119825695,
      "grad_norm": 0.23567253351211548,
      "learning_rate": 9.841171451903765e-05,
      "loss": 0.0154,
      "step": 292500
    },
    {
      "epoch": 0.016463934571312577,
      "grad_norm": 0.8765954375267029,
      "learning_rate": 9.840890339429257e-05,
      "loss": 0.0158,
      "step": 293000
    },
    {
      "epoch": 0.016492030022799458,
      "grad_norm": 0.42050883173942566,
      "learning_rate": 9.840609226954752e-05,
      "loss": 0.0148,
      "step": 293500
    },
    {
      "epoch": 0.01652012547428634,
      "grad_norm": 1.3343311548233032,
      "learning_rate": 9.840328114480245e-05,
      "loss": 0.0149,
      "step": 294000
    },
    {
      "epoch": 0.01654822092577322,
      "grad_norm": 0.22939741611480713,
      "learning_rate": 9.840047002005737e-05,
      "loss": 0.0152,
      "step": 294500
    },
    {
      "epoch": 0.016576316377260102,
      "grad_norm": 0.35279393196105957,
      "learning_rate": 9.839765889531232e-05,
      "loss": 0.0158,
      "step": 295000
    },
    {
      "epoch": 0.016604411828746984,
      "grad_norm": 0.3775445520877838,
      "learning_rate": 9.839484777056724e-05,
      "loss": 0.0156,
      "step": 295500
    },
    {
      "epoch": 0.016632507280233865,
      "grad_norm": 0.21708913147449493,
      "learning_rate": 9.839203664582219e-05,
      "loss": 0.0158,
      "step": 296000
    },
    {
      "epoch": 0.016660602731720747,
      "grad_norm": 0.809931218624115,
      "learning_rate": 9.838922552107711e-05,
      "loss": 0.0157,
      "step": 296500
    },
    {
      "epoch": 0.016688698183207628,
      "grad_norm": 0.5278391242027283,
      "learning_rate": 9.838641439633204e-05,
      "loss": 0.0159,
      "step": 297000
    },
    {
      "epoch": 0.016716793634694513,
      "grad_norm": 0.6930294632911682,
      "learning_rate": 9.838360327158699e-05,
      "loss": 0.0149,
      "step": 297500
    },
    {
      "epoch": 0.016744889086181394,
      "grad_norm": 0.40331241488456726,
      "learning_rate": 9.838079214684191e-05,
      "loss": 0.0148,
      "step": 298000
    },
    {
      "epoch": 0.016772984537668276,
      "grad_norm": 0.25592198967933655,
      "learning_rate": 9.837798102209686e-05,
      "loss": 0.0147,
      "step": 298500
    },
    {
      "epoch": 0.016801079989155157,
      "grad_norm": 0.27715763449668884,
      "learning_rate": 9.837516989735178e-05,
      "loss": 0.0151,
      "step": 299000
    },
    {
      "epoch": 0.01682917544064204,
      "grad_norm": 0.7184957265853882,
      "learning_rate": 9.837235877260672e-05,
      "loss": 0.0157,
      "step": 299500
    },
    {
      "epoch": 0.01685727089212892,
      "grad_norm": 0.2931360602378845,
      "learning_rate": 9.836954764786165e-05,
      "loss": 0.015,
      "step": 300000
    },
    {
      "epoch": 0.01685727089212892,
      "eval_loss": 0.00794436689466238,
      "eval_runtime": 18.2151,
      "eval_samples_per_second": 5489.962,
      "eval_steps_per_second": 85.808,
      "step": 300000
    },
    {
      "epoch": 0.0168853663436158,
      "grad_norm": 0.35207071900367737,
      "learning_rate": 9.836673652311658e-05,
      "loss": 0.0154,
      "step": 300500
    },
    {
      "epoch": 0.016913461795102683,
      "grad_norm": 0.2933228015899658,
      "learning_rate": 9.836392539837152e-05,
      "loss": 0.0153,
      "step": 301000
    },
    {
      "epoch": 0.016941557246589564,
      "grad_norm": 0.2796812057495117,
      "learning_rate": 9.836111427362645e-05,
      "loss": 0.0155,
      "step": 301500
    },
    {
      "epoch": 0.016969652698076446,
      "grad_norm": 0.3283675014972687,
      "learning_rate": 9.835830314888139e-05,
      "loss": 0.0151,
      "step": 302000
    },
    {
      "epoch": 0.016997748149563327,
      "grad_norm": 0.9333537220954895,
      "learning_rate": 9.835549202413632e-05,
      "loss": 0.015,
      "step": 302500
    },
    {
      "epoch": 0.01702584360105021,
      "grad_norm": 0.3687163293361664,
      "learning_rate": 9.835268089939126e-05,
      "loss": 0.0149,
      "step": 303000
    },
    {
      "epoch": 0.01705393905253709,
      "grad_norm": 0.44760021567344666,
      "learning_rate": 9.834986977464619e-05,
      "loss": 0.0151,
      "step": 303500
    },
    {
      "epoch": 0.01708203450402397,
      "grad_norm": 0.6980685591697693,
      "learning_rate": 9.834705864990112e-05,
      "loss": 0.0155,
      "step": 304000
    },
    {
      "epoch": 0.017110129955510853,
      "grad_norm": 0.45135533809661865,
      "learning_rate": 9.834424752515606e-05,
      "loss": 0.0148,
      "step": 304500
    },
    {
      "epoch": 0.017138225406997734,
      "grad_norm": 0.42845338582992554,
      "learning_rate": 9.834143640041099e-05,
      "loss": 0.015,
      "step": 305000
    },
    {
      "epoch": 0.017166320858484616,
      "grad_norm": 0.5244550704956055,
      "learning_rate": 9.833862527566593e-05,
      "loss": 0.0144,
      "step": 305500
    },
    {
      "epoch": 0.017194416309971497,
      "grad_norm": 0.8827624320983887,
      "learning_rate": 9.833581415092086e-05,
      "loss": 0.0147,
      "step": 306000
    },
    {
      "epoch": 0.01722251176145838,
      "grad_norm": 0.4645797908306122,
      "learning_rate": 9.83330030261758e-05,
      "loss": 0.0156,
      "step": 306500
    },
    {
      "epoch": 0.01725060721294526,
      "grad_norm": 0.5482994914054871,
      "learning_rate": 9.833019190143073e-05,
      "loss": 0.0153,
      "step": 307000
    },
    {
      "epoch": 0.01727870266443214,
      "grad_norm": 0.8867300152778625,
      "learning_rate": 9.832738077668566e-05,
      "loss": 0.0153,
      "step": 307500
    },
    {
      "epoch": 0.017306798115919023,
      "grad_norm": 0.5734395384788513,
      "learning_rate": 9.832456965194058e-05,
      "loss": 0.0154,
      "step": 308000
    },
    {
      "epoch": 0.017334893567405904,
      "grad_norm": 0.6458438634872437,
      "learning_rate": 9.832175852719553e-05,
      "loss": 0.0148,
      "step": 308500
    },
    {
      "epoch": 0.017362989018892785,
      "grad_norm": 0.6995040774345398,
      "learning_rate": 9.831894740245047e-05,
      "loss": 0.0149,
      "step": 309000
    },
    {
      "epoch": 0.017391084470379667,
      "grad_norm": 0.5715248584747314,
      "learning_rate": 9.83161362777054e-05,
      "loss": 0.0153,
      "step": 309500
    },
    {
      "epoch": 0.01741917992186655,
      "grad_norm": 0.2590680718421936,
      "learning_rate": 9.831332515296033e-05,
      "loss": 0.0154,
      "step": 310000
    },
    {
      "epoch": 0.01741917992186655,
      "eval_loss": 0.007786944042891264,
      "eval_runtime": 19.4373,
      "eval_samples_per_second": 5144.735,
      "eval_steps_per_second": 80.412,
      "step": 310000
    },
    {
      "epoch": 0.01744727537335343,
      "grad_norm": 0.42675918340682983,
      "learning_rate": 9.831051402821526e-05,
      "loss": 0.015,
      "step": 310500
    },
    {
      "epoch": 0.01747537082484031,
      "grad_norm": 0.65916508436203,
      "learning_rate": 9.83077029034702e-05,
      "loss": 0.0152,
      "step": 311000
    },
    {
      "epoch": 0.017503466276327193,
      "grad_norm": 0.7312374114990234,
      "learning_rate": 9.830489177872512e-05,
      "loss": 0.015,
      "step": 311500
    },
    {
      "epoch": 0.017531561727814074,
      "grad_norm": 0.28443530201911926,
      "learning_rate": 9.830208065398007e-05,
      "loss": 0.0152,
      "step": 312000
    },
    {
      "epoch": 0.017559657179300955,
      "grad_norm": 0.4120645821094513,
      "learning_rate": 9.829926952923499e-05,
      "loss": 0.0148,
      "step": 312500
    },
    {
      "epoch": 0.01758775263078784,
      "grad_norm": 0.17809395492076874,
      "learning_rate": 9.829645840448993e-05,
      "loss": 0.015,
      "step": 313000
    },
    {
      "epoch": 0.01761584808227472,
      "grad_norm": 0.3291025459766388,
      "learning_rate": 9.829364727974487e-05,
      "loss": 0.0145,
      "step": 313500
    },
    {
      "epoch": 0.017643943533761603,
      "grad_norm": 0.3347111940383911,
      "learning_rate": 9.82908361549998e-05,
      "loss": 0.0149,
      "step": 314000
    },
    {
      "epoch": 0.017672038985248485,
      "grad_norm": 0.13740763068199158,
      "learning_rate": 9.828802503025474e-05,
      "loss": 0.0143,
      "step": 314500
    },
    {
      "epoch": 0.017700134436735366,
      "grad_norm": 0.6767564415931702,
      "learning_rate": 9.828521390550966e-05,
      "loss": 0.0146,
      "step": 315000
    },
    {
      "epoch": 0.017728229888222247,
      "grad_norm": 0.3452836573123932,
      "learning_rate": 9.82824027807646e-05,
      "loss": 0.0145,
      "step": 315500
    },
    {
      "epoch": 0.01775632533970913,
      "grad_norm": 0.6014510989189148,
      "learning_rate": 9.827959165601953e-05,
      "loss": 0.0157,
      "step": 316000
    },
    {
      "epoch": 0.01778442079119601,
      "grad_norm": 0.1410292536020279,
      "learning_rate": 9.827678053127447e-05,
      "loss": 0.0143,
      "step": 316500
    },
    {
      "epoch": 0.01781251624268289,
      "grad_norm": 0.6620088815689087,
      "learning_rate": 9.827396940652941e-05,
      "loss": 0.0156,
      "step": 317000
    },
    {
      "epoch": 0.017840611694169773,
      "grad_norm": 0.35765597224235535,
      "learning_rate": 9.827115828178433e-05,
      "loss": 0.0148,
      "step": 317500
    },
    {
      "epoch": 0.017868707145656654,
      "grad_norm": 0.6672362685203552,
      "learning_rate": 9.826834715703927e-05,
      "loss": 0.0152,
      "step": 318000
    },
    {
      "epoch": 0.017896802597143536,
      "grad_norm": 0.6332268714904785,
      "learning_rate": 9.82655360322942e-05,
      "loss": 0.0139,
      "step": 318500
    },
    {
      "epoch": 0.017924898048630417,
      "grad_norm": 0.24690954387187958,
      "learning_rate": 9.826272490754914e-05,
      "loss": 0.0147,
      "step": 319000
    },
    {
      "epoch": 0.0179529935001173,
      "grad_norm": 0.7615674138069153,
      "learning_rate": 9.825991378280407e-05,
      "loss": 0.0145,
      "step": 319500
    },
    {
      "epoch": 0.01798108895160418,
      "grad_norm": 0.12635166943073273,
      "learning_rate": 9.8257102658059e-05,
      "loss": 0.0149,
      "step": 320000
    },
    {
      "epoch": 0.01798108895160418,
      "eval_loss": 0.007236349396407604,
      "eval_runtime": 18.7017,
      "eval_samples_per_second": 5347.106,
      "eval_steps_per_second": 83.575,
      "step": 320000
    },
    {
      "epoch": 0.01800918440309106,
      "grad_norm": 0.2463577687740326,
      "learning_rate": 9.825429153331394e-05,
      "loss": 0.014,
      "step": 320500
    },
    {
      "epoch": 0.018037279854577943,
      "grad_norm": 0.37954872846603394,
      "learning_rate": 9.825148040856887e-05,
      "loss": 0.0152,
      "step": 321000
    },
    {
      "epoch": 0.018065375306064824,
      "grad_norm": 0.4405539035797119,
      "learning_rate": 9.824866928382381e-05,
      "loss": 0.0144,
      "step": 321500
    },
    {
      "epoch": 0.018093470757551706,
      "grad_norm": 1.2160053253173828,
      "learning_rate": 9.824585815907874e-05,
      "loss": 0.014,
      "step": 322000
    },
    {
      "epoch": 0.018121566209038587,
      "grad_norm": 0.6997607946395874,
      "learning_rate": 9.824304703433368e-05,
      "loss": 0.0149,
      "step": 322500
    },
    {
      "epoch": 0.01814966166052547,
      "grad_norm": 0.44360673427581787,
      "learning_rate": 9.824023590958861e-05,
      "loss": 0.014,
      "step": 323000
    },
    {
      "epoch": 0.01817775711201235,
      "grad_norm": 0.2707040011882782,
      "learning_rate": 9.823742478484355e-05,
      "loss": 0.0142,
      "step": 323500
    },
    {
      "epoch": 0.01820585256349923,
      "grad_norm": 0.3727486729621887,
      "learning_rate": 9.823461366009848e-05,
      "loss": 0.0147,
      "step": 324000
    },
    {
      "epoch": 0.018233948014986113,
      "grad_norm": 1.094238042831421,
      "learning_rate": 9.823180253535341e-05,
      "loss": 0.015,
      "step": 324500
    },
    {
      "epoch": 0.018262043466472994,
      "grad_norm": 0.6172130703926086,
      "learning_rate": 9.822899141060835e-05,
      "loss": 0.0146,
      "step": 325000
    },
    {
      "epoch": 0.018290138917959876,
      "grad_norm": 0.7307929992675781,
      "learning_rate": 9.822618028586328e-05,
      "loss": 0.015,
      "step": 325500
    },
    {
      "epoch": 0.018318234369446757,
      "grad_norm": 0.33413785696029663,
      "learning_rate": 9.822336916111822e-05,
      "loss": 0.0139,
      "step": 326000
    },
    {
      "epoch": 0.01834632982093364,
      "grad_norm": 0.35439154505729675,
      "learning_rate": 9.822055803637315e-05,
      "loss": 0.0149,
      "step": 326500
    },
    {
      "epoch": 0.01837442527242052,
      "grad_norm": 0.5203521847724915,
      "learning_rate": 9.821774691162809e-05,
      "loss": 0.014,
      "step": 327000
    },
    {
      "epoch": 0.0184025207239074,
      "grad_norm": 0.2198539823293686,
      "learning_rate": 9.8214935786883e-05,
      "loss": 0.0145,
      "step": 327500
    },
    {
      "epoch": 0.018430616175394286,
      "grad_norm": 0.17686566710472107,
      "learning_rate": 9.821212466213795e-05,
      "loss": 0.014,
      "step": 328000
    },
    {
      "epoch": 0.018458711626881168,
      "grad_norm": 0.44087985157966614,
      "learning_rate": 9.820931353739289e-05,
      "loss": 0.0149,
      "step": 328500
    },
    {
      "epoch": 0.01848680707836805,
      "grad_norm": 0.8490753173828125,
      "learning_rate": 9.820650241264782e-05,
      "loss": 0.0151,
      "step": 329000
    },
    {
      "epoch": 0.01851490252985493,
      "grad_norm": 0.5492969751358032,
      "learning_rate": 9.820369128790276e-05,
      "loss": 0.0143,
      "step": 329500
    },
    {
      "epoch": 0.018542997981341812,
      "grad_norm": 0.4405359625816345,
      "learning_rate": 9.820088016315768e-05,
      "loss": 0.015,
      "step": 330000
    },
    {
      "epoch": 0.018542997981341812,
      "eval_loss": 0.007393309846520424,
      "eval_runtime": 18.9151,
      "eval_samples_per_second": 5286.795,
      "eval_steps_per_second": 82.633,
      "step": 330000
    },
    {
      "epoch": 0.018571093432828693,
      "grad_norm": 0.3140644133090973,
      "learning_rate": 9.819806903841263e-05,
      "loss": 0.0144,
      "step": 330500
    },
    {
      "epoch": 0.018599188884315575,
      "grad_norm": 0.27285730838775635,
      "learning_rate": 9.819525791366755e-05,
      "loss": 0.015,
      "step": 331000
    },
    {
      "epoch": 0.018627284335802456,
      "grad_norm": 0.8629260063171387,
      "learning_rate": 9.81924467889225e-05,
      "loss": 0.0148,
      "step": 331500
    },
    {
      "epoch": 0.018655379787289338,
      "grad_norm": 0.2176041454076767,
      "learning_rate": 9.818963566417741e-05,
      "loss": 0.0143,
      "step": 332000
    },
    {
      "epoch": 0.01868347523877622,
      "grad_norm": 0.35624316334724426,
      "learning_rate": 9.818682453943235e-05,
      "loss": 0.0145,
      "step": 332500
    },
    {
      "epoch": 0.0187115706902631,
      "grad_norm": 0.28347671031951904,
      "learning_rate": 9.81840134146873e-05,
      "loss": 0.0144,
      "step": 333000
    },
    {
      "epoch": 0.018739666141749982,
      "grad_norm": 0.2884323000907898,
      "learning_rate": 9.818120228994222e-05,
      "loss": 0.0142,
      "step": 333500
    },
    {
      "epoch": 0.018767761593236863,
      "grad_norm": 0.6790107488632202,
      "learning_rate": 9.817839116519716e-05,
      "loss": 0.014,
      "step": 334000
    },
    {
      "epoch": 0.018795857044723745,
      "grad_norm": 0.19639626145362854,
      "learning_rate": 9.817558004045209e-05,
      "loss": 0.0141,
      "step": 334500
    },
    {
      "epoch": 0.018823952496210626,
      "grad_norm": 0.6060466170310974,
      "learning_rate": 9.817276891570702e-05,
      "loss": 0.014,
      "step": 335000
    },
    {
      "epoch": 0.018852047947697508,
      "grad_norm": 1.4249602556228638,
      "learning_rate": 9.816995779096195e-05,
      "loss": 0.0138,
      "step": 335500
    },
    {
      "epoch": 0.01888014339918439,
      "grad_norm": 0.41361185908317566,
      "learning_rate": 9.816714666621689e-05,
      "loss": 0.0147,
      "step": 336000
    },
    {
      "epoch": 0.01890823885067127,
      "grad_norm": 3.2120461463928223,
      "learning_rate": 9.816433554147184e-05,
      "loss": 0.0149,
      "step": 336500
    },
    {
      "epoch": 0.018936334302158152,
      "grad_norm": 0.27891239523887634,
      "learning_rate": 9.816152441672676e-05,
      "loss": 0.0147,
      "step": 337000
    },
    {
      "epoch": 0.018964429753645033,
      "grad_norm": 0.16715498268604279,
      "learning_rate": 9.815871329198169e-05,
      "loss": 0.0147,
      "step": 337500
    },
    {
      "epoch": 0.018992525205131915,
      "grad_norm": 0.5610492825508118,
      "learning_rate": 9.815590216723663e-05,
      "loss": 0.0137,
      "step": 338000
    },
    {
      "epoch": 0.019020620656618796,
      "grad_norm": 0.429900199174881,
      "learning_rate": 9.815309104249156e-05,
      "loss": 0.0145,
      "step": 338500
    },
    {
      "epoch": 0.019048716108105677,
      "grad_norm": 0.4574965238571167,
      "learning_rate": 9.81502799177465e-05,
      "loss": 0.0151,
      "step": 339000
    },
    {
      "epoch": 0.01907681155959256,
      "grad_norm": 0.5456498265266418,
      "learning_rate": 9.814746879300143e-05,
      "loss": 0.0143,
      "step": 339500
    },
    {
      "epoch": 0.01910490701107944,
      "grad_norm": 0.31968092918395996,
      "learning_rate": 9.814465766825636e-05,
      "loss": 0.0145,
      "step": 340000
    },
    {
      "epoch": 0.01910490701107944,
      "eval_loss": 0.0071706632152199745,
      "eval_runtime": 18.727,
      "eval_samples_per_second": 5339.889,
      "eval_steps_per_second": 83.462,
      "step": 340000
    },
    {
      "epoch": 0.01913300246256632,
      "grad_norm": 0.6408776044845581,
      "learning_rate": 9.81418465435113e-05,
      "loss": 0.014,
      "step": 340500
    },
    {
      "epoch": 0.019161097914053203,
      "grad_norm": 0.5670737624168396,
      "learning_rate": 9.813903541876623e-05,
      "loss": 0.014,
      "step": 341000
    },
    {
      "epoch": 0.019189193365540085,
      "grad_norm": 0.37051305174827576,
      "learning_rate": 9.813622429402116e-05,
      "loss": 0.0136,
      "step": 341500
    },
    {
      "epoch": 0.019217288817026966,
      "grad_norm": 0.8176578879356384,
      "learning_rate": 9.81334131692761e-05,
      "loss": 0.0137,
      "step": 342000
    },
    {
      "epoch": 0.019245384268513847,
      "grad_norm": 0.14371083676815033,
      "learning_rate": 9.813060204453103e-05,
      "loss": 0.0138,
      "step": 342500
    },
    {
      "epoch": 0.01927347972000073,
      "grad_norm": 0.3983425199985504,
      "learning_rate": 9.812779091978597e-05,
      "loss": 0.0144,
      "step": 343000
    },
    {
      "epoch": 0.019301575171487614,
      "grad_norm": 0.5509483218193054,
      "learning_rate": 9.812497979504089e-05,
      "loss": 0.014,
      "step": 343500
    },
    {
      "epoch": 0.019329670622974495,
      "grad_norm": 0.3992050290107727,
      "learning_rate": 9.812216867029584e-05,
      "loss": 0.0141,
      "step": 344000
    },
    {
      "epoch": 0.019357766074461377,
      "grad_norm": 0.2465938776731491,
      "learning_rate": 9.811935754555077e-05,
      "loss": 0.0138,
      "step": 344500
    },
    {
      "epoch": 0.019385861525948258,
      "grad_norm": 0.4336896240711212,
      "learning_rate": 9.81165464208057e-05,
      "loss": 0.0134,
      "step": 345000
    },
    {
      "epoch": 0.01941395697743514,
      "grad_norm": 0.5806129574775696,
      "learning_rate": 9.811373529606064e-05,
      "loss": 0.0145,
      "step": 345500
    },
    {
      "epoch": 0.01944205242892202,
      "grad_norm": 0.18066373467445374,
      "learning_rate": 9.811092417131556e-05,
      "loss": 0.0148,
      "step": 346000
    },
    {
      "epoch": 0.019470147880408902,
      "grad_norm": 0.2745896875858307,
      "learning_rate": 9.810811304657051e-05,
      "loss": 0.0141,
      "step": 346500
    },
    {
      "epoch": 0.019498243331895784,
      "grad_norm": 0.41119641065597534,
      "learning_rate": 9.810530192182543e-05,
      "loss": 0.0136,
      "step": 347000
    },
    {
      "epoch": 0.019526338783382665,
      "grad_norm": 0.31052058935165405,
      "learning_rate": 9.810249079708038e-05,
      "loss": 0.0139,
      "step": 347500
    },
    {
      "epoch": 0.019554434234869546,
      "grad_norm": 0.5447463989257812,
      "learning_rate": 9.809967967233531e-05,
      "loss": 0.0141,
      "step": 348000
    },
    {
      "epoch": 0.019582529686356428,
      "grad_norm": 0.14716020226478577,
      "learning_rate": 9.809686854759023e-05,
      "loss": 0.0143,
      "step": 348500
    },
    {
      "epoch": 0.01961062513784331,
      "grad_norm": 0.3224150538444519,
      "learning_rate": 9.809405742284518e-05,
      "loss": 0.0145,
      "step": 349000
    },
    {
      "epoch": 0.01963872058933019,
      "grad_norm": 0.34978288412094116,
      "learning_rate": 9.80912462981001e-05,
      "loss": 0.0151,
      "step": 349500
    },
    {
      "epoch": 0.019666816040817072,
      "grad_norm": 0.5163747072219849,
      "learning_rate": 9.808843517335505e-05,
      "loss": 0.0142,
      "step": 350000
    },
    {
      "epoch": 0.019666816040817072,
      "eval_loss": 0.007311064284294844,
      "eval_runtime": 18.7108,
      "eval_samples_per_second": 5344.518,
      "eval_steps_per_second": 83.535,
      "step": 350000
    },
    {
      "epoch": 0.019694911492303954,
      "grad_norm": 0.25497445464134216,
      "learning_rate": 9.808562404860997e-05,
      "loss": 0.0143,
      "step": 350500
    },
    {
      "epoch": 0.019723006943790835,
      "grad_norm": 0.728572428226471,
      "learning_rate": 9.80828129238649e-05,
      "loss": 0.0134,
      "step": 351000
    },
    {
      "epoch": 0.019751102395277716,
      "grad_norm": 0.6397882699966431,
      "learning_rate": 9.808000179911984e-05,
      "loss": 0.0139,
      "step": 351500
    },
    {
      "epoch": 0.019779197846764598,
      "grad_norm": 0.3090519309043884,
      "learning_rate": 9.807719067437477e-05,
      "loss": 0.0137,
      "step": 352000
    },
    {
      "epoch": 0.01980729329825148,
      "grad_norm": 0.7426418662071228,
      "learning_rate": 9.807437954962972e-05,
      "loss": 0.0151,
      "step": 352500
    },
    {
      "epoch": 0.01983538874973836,
      "grad_norm": 0.9457556009292603,
      "learning_rate": 9.807156842488464e-05,
      "loss": 0.0139,
      "step": 353000
    },
    {
      "epoch": 0.019863484201225242,
      "grad_norm": 0.5456348061561584,
      "learning_rate": 9.806875730013957e-05,
      "loss": 0.0135,
      "step": 353500
    },
    {
      "epoch": 0.019891579652712123,
      "grad_norm": 0.36445167660713196,
      "learning_rate": 9.806594617539451e-05,
      "loss": 0.0144,
      "step": 354000
    },
    {
      "epoch": 0.019919675104199005,
      "grad_norm": 0.5012747645378113,
      "learning_rate": 9.806313505064944e-05,
      "loss": 0.0138,
      "step": 354500
    },
    {
      "epoch": 0.019947770555685886,
      "grad_norm": 0.3388526439666748,
      "learning_rate": 9.806032392590438e-05,
      "loss": 0.0142,
      "step": 355000
    },
    {
      "epoch": 0.019975866007172768,
      "grad_norm": 1.1962660551071167,
      "learning_rate": 9.805751280115931e-05,
      "loss": 0.0137,
      "step": 355500
    },
    {
      "epoch": 0.02000396145865965,
      "grad_norm": 0.4031824469566345,
      "learning_rate": 9.805470167641424e-05,
      "loss": 0.014,
      "step": 356000
    },
    {
      "epoch": 0.02003205691014653,
      "grad_norm": 0.2719019651412964,
      "learning_rate": 9.805189055166918e-05,
      "loss": 0.0144,
      "step": 356500
    },
    {
      "epoch": 0.020060152361633412,
      "grad_norm": 0.39935609698295593,
      "learning_rate": 9.804907942692411e-05,
      "loss": 0.0142,
      "step": 357000
    },
    {
      "epoch": 0.020088247813120293,
      "grad_norm": 0.42525365948677063,
      "learning_rate": 9.804626830217905e-05,
      "loss": 0.0146,
      "step": 357500
    },
    {
      "epoch": 0.020116343264607175,
      "grad_norm": 0.15211574733257294,
      "learning_rate": 9.804345717743398e-05,
      "loss": 0.0134,
      "step": 358000
    },
    {
      "epoch": 0.02014443871609406,
      "grad_norm": 0.12074899673461914,
      "learning_rate": 9.804064605268892e-05,
      "loss": 0.0133,
      "step": 358500
    },
    {
      "epoch": 0.02017253416758094,
      "grad_norm": 0.23889324069023132,
      "learning_rate": 9.803783492794385e-05,
      "loss": 0.0139,
      "step": 359000
    },
    {
      "epoch": 0.020200629619067823,
      "grad_norm": 0.5391647219657898,
      "learning_rate": 9.803502380319878e-05,
      "loss": 0.0135,
      "step": 359500
    },
    {
      "epoch": 0.020228725070554704,
      "grad_norm": 0.2815723717212677,
      "learning_rate": 9.803221267845372e-05,
      "loss": 0.0141,
      "step": 360000
    },
    {
      "epoch": 0.020228725070554704,
      "eval_loss": 0.00708660576492548,
      "eval_runtime": 19.4166,
      "eval_samples_per_second": 5150.224,
      "eval_steps_per_second": 80.498,
      "step": 360000
    },
    {
      "epoch": 0.020256820522041585,
      "grad_norm": 0.783308207988739,
      "learning_rate": 9.802940155370865e-05,
      "loss": 0.0134,
      "step": 360500
    },
    {
      "epoch": 0.020284915973528467,
      "grad_norm": 0.2735559344291687,
      "learning_rate": 9.802659042896359e-05,
      "loss": 0.0135,
      "step": 361000
    },
    {
      "epoch": 0.020313011425015348,
      "grad_norm": 0.6033392548561096,
      "learning_rate": 9.802377930421852e-05,
      "loss": 0.0135,
      "step": 361500
    },
    {
      "epoch": 0.02034110687650223,
      "grad_norm": 0.6569308638572693,
      "learning_rate": 9.802096817947346e-05,
      "loss": 0.0137,
      "step": 362000
    },
    {
      "epoch": 0.02036920232798911,
      "grad_norm": 0.10660820454359055,
      "learning_rate": 9.801815705472839e-05,
      "loss": 0.0134,
      "step": 362500
    },
    {
      "epoch": 0.020397297779475992,
      "grad_norm": 0.22208087146282196,
      "learning_rate": 9.801534592998331e-05,
      "loss": 0.0138,
      "step": 363000
    },
    {
      "epoch": 0.020425393230962874,
      "grad_norm": 0.588617742061615,
      "learning_rate": 9.801253480523826e-05,
      "loss": 0.0134,
      "step": 363500
    },
    {
      "epoch": 0.020453488682449755,
      "grad_norm": 0.44282880425453186,
      "learning_rate": 9.800972368049319e-05,
      "loss": 0.0134,
      "step": 364000
    },
    {
      "epoch": 0.020481584133936637,
      "grad_norm": 0.41146188974380493,
      "learning_rate": 9.800691255574813e-05,
      "loss": 0.0137,
      "step": 364500
    },
    {
      "epoch": 0.020509679585423518,
      "grad_norm": 0.8718388676643372,
      "learning_rate": 9.800410143100306e-05,
      "loss": 0.0143,
      "step": 365000
    },
    {
      "epoch": 0.0205377750369104,
      "grad_norm": 0.146742045879364,
      "learning_rate": 9.800129030625798e-05,
      "loss": 0.0136,
      "step": 365500
    },
    {
      "epoch": 0.02056587048839728,
      "grad_norm": 0.7999879717826843,
      "learning_rate": 9.799847918151293e-05,
      "loss": 0.0135,
      "step": 366000
    },
    {
      "epoch": 0.020593965939884162,
      "grad_norm": 0.35721713304519653,
      "learning_rate": 9.799566805676785e-05,
      "loss": 0.0133,
      "step": 366500
    },
    {
      "epoch": 0.020622061391371044,
      "grad_norm": 0.4856230318546295,
      "learning_rate": 9.79928569320228e-05,
      "loss": 0.0148,
      "step": 367000
    },
    {
      "epoch": 0.020650156842857925,
      "grad_norm": 0.23079267144203186,
      "learning_rate": 9.799004580727773e-05,
      "loss": 0.0139,
      "step": 367500
    },
    {
      "epoch": 0.020678252294344807,
      "grad_norm": 0.8440527319908142,
      "learning_rate": 9.798723468253265e-05,
      "loss": 0.0135,
      "step": 368000
    },
    {
      "epoch": 0.020706347745831688,
      "grad_norm": 0.4957386553287506,
      "learning_rate": 9.79844235577876e-05,
      "loss": 0.014,
      "step": 368500
    },
    {
      "epoch": 0.02073444319731857,
      "grad_norm": 1.3705438375473022,
      "learning_rate": 9.798161243304252e-05,
      "loss": 0.0134,
      "step": 369000
    },
    {
      "epoch": 0.02076253864880545,
      "grad_norm": 0.3222070634365082,
      "learning_rate": 9.797880130829747e-05,
      "loss": 0.0134,
      "step": 369500
    },
    {
      "epoch": 0.020790634100292332,
      "grad_norm": 0.9846035838127136,
      "learning_rate": 9.797599018355239e-05,
      "loss": 0.0133,
      "step": 370000
    },
    {
      "epoch": 0.020790634100292332,
      "eval_loss": 0.007193480618298054,
      "eval_runtime": 18.6474,
      "eval_samples_per_second": 5362.673,
      "eval_steps_per_second": 83.819,
      "step": 370000
    },
    {
      "epoch": 0.020818729551779214,
      "grad_norm": 0.5804412961006165,
      "learning_rate": 9.797317905880732e-05,
      "loss": 0.0137,
      "step": 370500
    },
    {
      "epoch": 0.020846825003266095,
      "grad_norm": 0.44620129466056824,
      "learning_rate": 9.797036793406227e-05,
      "loss": 0.0137,
      "step": 371000
    },
    {
      "epoch": 0.020874920454752977,
      "grad_norm": 0.19805823266506195,
      "learning_rate": 9.796755680931719e-05,
      "loss": 0.0129,
      "step": 371500
    },
    {
      "epoch": 0.020903015906239858,
      "grad_norm": 0.08582660555839539,
      "learning_rate": 9.796474568457214e-05,
      "loss": 0.0137,
      "step": 372000
    },
    {
      "epoch": 0.02093111135772674,
      "grad_norm": 0.6742361187934875,
      "learning_rate": 9.796193455982706e-05,
      "loss": 0.0145,
      "step": 372500
    },
    {
      "epoch": 0.02095920680921362,
      "grad_norm": 0.6540464162826538,
      "learning_rate": 9.7959123435082e-05,
      "loss": 0.0139,
      "step": 373000
    },
    {
      "epoch": 0.020987302260700502,
      "grad_norm": 0.4097542464733124,
      "learning_rate": 9.795631231033693e-05,
      "loss": 0.0131,
      "step": 373500
    },
    {
      "epoch": 0.021015397712187387,
      "grad_norm": 0.23173324763774872,
      "learning_rate": 9.795350118559186e-05,
      "loss": 0.0133,
      "step": 374000
    },
    {
      "epoch": 0.02104349316367427,
      "grad_norm": 0.576994001865387,
      "learning_rate": 9.79506900608468e-05,
      "loss": 0.014,
      "step": 374500
    },
    {
      "epoch": 0.02107158861516115,
      "grad_norm": 0.31771931052207947,
      "learning_rate": 9.794787893610173e-05,
      "loss": 0.0136,
      "step": 375000
    },
    {
      "epoch": 0.02109968406664803,
      "grad_norm": 0.48230355978012085,
      "learning_rate": 9.794506781135667e-05,
      "loss": 0.014,
      "step": 375500
    },
    {
      "epoch": 0.021127779518134913,
      "grad_norm": 0.7080682516098022,
      "learning_rate": 9.79422566866116e-05,
      "loss": 0.0133,
      "step": 376000
    },
    {
      "epoch": 0.021155874969621794,
      "grad_norm": 0.3576468527317047,
      "learning_rate": 9.793944556186653e-05,
      "loss": 0.0134,
      "step": 376500
    },
    {
      "epoch": 0.021183970421108676,
      "grad_norm": 0.09283844381570816,
      "learning_rate": 9.793663443712147e-05,
      "loss": 0.0132,
      "step": 377000
    },
    {
      "epoch": 0.021212065872595557,
      "grad_norm": 0.32057392597198486,
      "learning_rate": 9.79338233123764e-05,
      "loss": 0.0138,
      "step": 377500
    },
    {
      "epoch": 0.02124016132408244,
      "grad_norm": 1.2008708715438843,
      "learning_rate": 9.793101218763134e-05,
      "loss": 0.0143,
      "step": 378000
    },
    {
      "epoch": 0.02126825677556932,
      "grad_norm": 0.1363142430782318,
      "learning_rate": 9.792820106288627e-05,
      "loss": 0.0129,
      "step": 378500
    },
    {
      "epoch": 0.0212963522270562,
      "grad_norm": 0.36150333285331726,
      "learning_rate": 9.79253899381412e-05,
      "loss": 0.0142,
      "step": 379000
    },
    {
      "epoch": 0.021324447678543083,
      "grad_norm": 0.27614161372184753,
      "learning_rate": 9.792257881339614e-05,
      "loss": 0.0134,
      "step": 379500
    },
    {
      "epoch": 0.021352543130029964,
      "grad_norm": 0.1963164359331131,
      "learning_rate": 9.791976768865107e-05,
      "loss": 0.0132,
      "step": 380000
    },
    {
      "epoch": 0.021352543130029964,
      "eval_loss": 0.00725132692605257,
      "eval_runtime": 19.2408,
      "eval_samples_per_second": 5197.292,
      "eval_steps_per_second": 81.234,
      "step": 380000
    },
    {
      "epoch": 0.021380638581516846,
      "grad_norm": 0.1303676962852478,
      "learning_rate": 9.791695656390601e-05,
      "loss": 0.014,
      "step": 380500
    },
    {
      "epoch": 0.021408734033003727,
      "grad_norm": 0.6230373978614807,
      "learning_rate": 9.791414543916094e-05,
      "loss": 0.0136,
      "step": 381000
    },
    {
      "epoch": 0.02143682948449061,
      "grad_norm": 0.5324074625968933,
      "learning_rate": 9.791133431441586e-05,
      "loss": 0.0134,
      "step": 381500
    },
    {
      "epoch": 0.02146492493597749,
      "grad_norm": 0.8955931663513184,
      "learning_rate": 9.790852318967081e-05,
      "loss": 0.0134,
      "step": 382000
    },
    {
      "epoch": 0.02149302038746437,
      "grad_norm": 0.9236654043197632,
      "learning_rate": 9.790571206492573e-05,
      "loss": 0.0137,
      "step": 382500
    },
    {
      "epoch": 0.021521115838951253,
      "grad_norm": 1.1771705150604248,
      "learning_rate": 9.790290094018068e-05,
      "loss": 0.0132,
      "step": 383000
    },
    {
      "epoch": 0.021549211290438134,
      "grad_norm": 0.476746529340744,
      "learning_rate": 9.790008981543561e-05,
      "loss": 0.0132,
      "step": 383500
    },
    {
      "epoch": 0.021577306741925015,
      "grad_norm": 0.10952511429786682,
      "learning_rate": 9.789727869069054e-05,
      "loss": 0.0126,
      "step": 384000
    },
    {
      "epoch": 0.021605402193411897,
      "grad_norm": 0.3164037764072418,
      "learning_rate": 9.789446756594548e-05,
      "loss": 0.014,
      "step": 384500
    },
    {
      "epoch": 0.02163349764489878,
      "grad_norm": 0.31799250841140747,
      "learning_rate": 9.78916564412004e-05,
      "loss": 0.0134,
      "step": 385000
    },
    {
      "epoch": 0.02166159309638566,
      "grad_norm": 0.6404954195022583,
      "learning_rate": 9.788884531645535e-05,
      "loss": 0.0134,
      "step": 385500
    },
    {
      "epoch": 0.02168968854787254,
      "grad_norm": 0.7982852458953857,
      "learning_rate": 9.788603419171027e-05,
      "loss": 0.0138,
      "step": 386000
    },
    {
      "epoch": 0.021717783999359423,
      "grad_norm": 0.20917227864265442,
      "learning_rate": 9.78832230669652e-05,
      "loss": 0.0132,
      "step": 386500
    },
    {
      "epoch": 0.021745879450846304,
      "grad_norm": 0.30594247579574585,
      "learning_rate": 9.788041194222015e-05,
      "loss": 0.013,
      "step": 387000
    },
    {
      "epoch": 0.021773974902333185,
      "grad_norm": 0.3450610339641571,
      "learning_rate": 9.787760081747507e-05,
      "loss": 0.0135,
      "step": 387500
    },
    {
      "epoch": 0.021802070353820067,
      "grad_norm": 0.20757225155830383,
      "learning_rate": 9.787478969273002e-05,
      "loss": 0.0126,
      "step": 388000
    },
    {
      "epoch": 0.021830165805306948,
      "grad_norm": 0.15095262229442596,
      "learning_rate": 9.787197856798494e-05,
      "loss": 0.0137,
      "step": 388500
    },
    {
      "epoch": 0.021858261256793833,
      "grad_norm": 0.6392836570739746,
      "learning_rate": 9.786916744323988e-05,
      "loss": 0.0128,
      "step": 389000
    },
    {
      "epoch": 0.021886356708280715,
      "grad_norm": 0.34819671511650085,
      "learning_rate": 9.786635631849481e-05,
      "loss": 0.0134,
      "step": 389500
    },
    {
      "epoch": 0.021914452159767596,
      "grad_norm": 0.4149271845817566,
      "learning_rate": 9.786354519374975e-05,
      "loss": 0.0139,
      "step": 390000
    },
    {
      "epoch": 0.021914452159767596,
      "eval_loss": 0.007193064317107201,
      "eval_runtime": 18.723,
      "eval_samples_per_second": 5341.02,
      "eval_steps_per_second": 83.48,
      "step": 390000
    },
    {
      "epoch": 0.021942547611254477,
      "grad_norm": 0.20511053502559662,
      "learning_rate": 9.78607340690047e-05,
      "loss": 0.0133,
      "step": 390500
    },
    {
      "epoch": 0.02197064306274136,
      "grad_norm": 0.25780773162841797,
      "learning_rate": 9.785792294425961e-05,
      "loss": 0.0138,
      "step": 391000
    },
    {
      "epoch": 0.02199873851422824,
      "grad_norm": 0.11284694820642471,
      "learning_rate": 9.785511181951456e-05,
      "loss": 0.0132,
      "step": 391500
    },
    {
      "epoch": 0.02202683396571512,
      "grad_norm": 0.08159232139587402,
      "learning_rate": 9.785230069476948e-05,
      "loss": 0.0126,
      "step": 392000
    },
    {
      "epoch": 0.022054929417202003,
      "grad_norm": 0.625684916973114,
      "learning_rate": 9.784948957002442e-05,
      "loss": 0.0127,
      "step": 392500
    },
    {
      "epoch": 0.022083024868688884,
      "grad_norm": 0.06536667048931122,
      "learning_rate": 9.784667844527935e-05,
      "loss": 0.0135,
      "step": 393000
    },
    {
      "epoch": 0.022111120320175766,
      "grad_norm": 0.5743341445922852,
      "learning_rate": 9.784386732053429e-05,
      "loss": 0.0129,
      "step": 393500
    },
    {
      "epoch": 0.022139215771662647,
      "grad_norm": 0.47161000967025757,
      "learning_rate": 9.784105619578922e-05,
      "loss": 0.0126,
      "step": 394000
    },
    {
      "epoch": 0.02216731122314953,
      "grad_norm": 0.3436099588871002,
      "learning_rate": 9.783824507104415e-05,
      "loss": 0.0133,
      "step": 394500
    },
    {
      "epoch": 0.02219540667463641,
      "grad_norm": 0.7981424331665039,
      "learning_rate": 9.783543394629909e-05,
      "loss": 0.0134,
      "step": 395000
    },
    {
      "epoch": 0.02222350212612329,
      "grad_norm": 0.4504792094230652,
      "learning_rate": 9.783262282155402e-05,
      "loss": 0.0133,
      "step": 395500
    },
    {
      "epoch": 0.022251597577610173,
      "grad_norm": 0.4785001575946808,
      "learning_rate": 9.782981169680896e-05,
      "loss": 0.0133,
      "step": 396000
    },
    {
      "epoch": 0.022279693029097054,
      "grad_norm": 0.2413908839225769,
      "learning_rate": 9.782700057206389e-05,
      "loss": 0.0133,
      "step": 396500
    },
    {
      "epoch": 0.022307788480583936,
      "grad_norm": 0.6845047473907471,
      "learning_rate": 9.782418944731883e-05,
      "loss": 0.0133,
      "step": 397000
    },
    {
      "epoch": 0.022335883932070817,
      "grad_norm": 0.2604016661643982,
      "learning_rate": 9.782137832257376e-05,
      "loss": 0.0128,
      "step": 397500
    },
    {
      "epoch": 0.0223639793835577,
      "grad_norm": 0.6292726993560791,
      "learning_rate": 9.78185671978287e-05,
      "loss": 0.0131,
      "step": 398000
    },
    {
      "epoch": 0.02239207483504458,
      "grad_norm": 0.20582608878612518,
      "learning_rate": 9.781575607308363e-05,
      "loss": 0.0128,
      "step": 398500
    },
    {
      "epoch": 0.02242017028653146,
      "grad_norm": 0.49700862169265747,
      "learning_rate": 9.781294494833856e-05,
      "loss": 0.0126,
      "step": 399000
    },
    {
      "epoch": 0.022448265738018343,
      "grad_norm": 0.21827974915504456,
      "learning_rate": 9.78101338235935e-05,
      "loss": 0.013,
      "step": 399500
    },
    {
      "epoch": 0.022476361189505224,
      "grad_norm": 0.6358104348182678,
      "learning_rate": 9.780732269884843e-05,
      "loss": 0.0133,
      "step": 400000
    },
    {
      "epoch": 0.022476361189505224,
      "eval_loss": 0.006582159548997879,
      "eval_runtime": 18.3611,
      "eval_samples_per_second": 5446.301,
      "eval_steps_per_second": 85.126,
      "step": 400000
    },
    {
      "epoch": 0.022504456640992106,
      "grad_norm": 0.5309126973152161,
      "learning_rate": 9.780451157410337e-05,
      "loss": 0.0129,
      "step": 400500
    },
    {
      "epoch": 0.022532552092478987,
      "grad_norm": 0.2550283372402191,
      "learning_rate": 9.780170044935829e-05,
      "loss": 0.0127,
      "step": 401000
    },
    {
      "epoch": 0.02256064754396587,
      "grad_norm": 0.2618975043296814,
      "learning_rate": 9.779888932461323e-05,
      "loss": 0.0138,
      "step": 401500
    },
    {
      "epoch": 0.02258874299545275,
      "grad_norm": 0.4468163251876831,
      "learning_rate": 9.779607819986815e-05,
      "loss": 0.0132,
      "step": 402000
    },
    {
      "epoch": 0.02261683844693963,
      "grad_norm": 0.7020946145057678,
      "learning_rate": 9.77932670751231e-05,
      "loss": 0.0127,
      "step": 402500
    },
    {
      "epoch": 0.022644933898426513,
      "grad_norm": 0.5403339862823486,
      "learning_rate": 9.779045595037804e-05,
      "loss": 0.0137,
      "step": 403000
    },
    {
      "epoch": 0.022673029349913394,
      "grad_norm": 0.21393291652202606,
      "learning_rate": 9.778764482563296e-05,
      "loss": 0.0136,
      "step": 403500
    },
    {
      "epoch": 0.022701124801400276,
      "grad_norm": 0.5073421597480774,
      "learning_rate": 9.77848337008879e-05,
      "loss": 0.0126,
      "step": 404000
    },
    {
      "epoch": 0.02272922025288716,
      "grad_norm": 0.5401400327682495,
      "learning_rate": 9.778202257614283e-05,
      "loss": 0.0129,
      "step": 404500
    },
    {
      "epoch": 0.022757315704374042,
      "grad_norm": 0.9660219550132751,
      "learning_rate": 9.777921145139777e-05,
      "loss": 0.0135,
      "step": 405000
    },
    {
      "epoch": 0.022785411155860923,
      "grad_norm": 0.4859282672405243,
      "learning_rate": 9.77764003266527e-05,
      "loss": 0.0138,
      "step": 405500
    },
    {
      "epoch": 0.022813506607347805,
      "grad_norm": 0.252189964056015,
      "learning_rate": 9.777358920190763e-05,
      "loss": 0.013,
      "step": 406000
    },
    {
      "epoch": 0.022841602058834686,
      "grad_norm": 0.40716737508773804,
      "learning_rate": 9.777077807716258e-05,
      "loss": 0.0125,
      "step": 406500
    },
    {
      "epoch": 0.022869697510321568,
      "grad_norm": 0.34095412492752075,
      "learning_rate": 9.77679669524175e-05,
      "loss": 0.0126,
      "step": 407000
    },
    {
      "epoch": 0.02289779296180845,
      "grad_norm": 0.2458161562681198,
      "learning_rate": 9.776515582767244e-05,
      "loss": 0.0128,
      "step": 407500
    },
    {
      "epoch": 0.02292588841329533,
      "grad_norm": 0.5974273681640625,
      "learning_rate": 9.776234470292737e-05,
      "loss": 0.0131,
      "step": 408000
    },
    {
      "epoch": 0.022953983864782212,
      "grad_norm": 0.4457134008407593,
      "learning_rate": 9.77595335781823e-05,
      "loss": 0.0129,
      "step": 408500
    },
    {
      "epoch": 0.022982079316269093,
      "grad_norm": 0.2545663118362427,
      "learning_rate": 9.775672245343723e-05,
      "loss": 0.0125,
      "step": 409000
    },
    {
      "epoch": 0.023010174767755975,
      "grad_norm": 0.8608212471008301,
      "learning_rate": 9.775391132869217e-05,
      "loss": 0.0133,
      "step": 409500
    },
    {
      "epoch": 0.023038270219242856,
      "grad_norm": 0.2606578469276428,
      "learning_rate": 9.775110020394712e-05,
      "loss": 0.0134,
      "step": 410000
    },
    {
      "epoch": 0.023038270219242856,
      "eval_loss": 0.006915245670825243,
      "eval_runtime": 18.7576,
      "eval_samples_per_second": 5331.164,
      "eval_steps_per_second": 83.326,
      "step": 410000
    },
    {
      "epoch": 0.023066365670729738,
      "grad_norm": 0.12277929484844208,
      "learning_rate": 9.774828907920204e-05,
      "loss": 0.0134,
      "step": 410500
    },
    {
      "epoch": 0.02309446112221662,
      "grad_norm": 0.4838726818561554,
      "learning_rate": 9.774547795445697e-05,
      "loss": 0.0131,
      "step": 411000
    },
    {
      "epoch": 0.0231225565737035,
      "grad_norm": 0.33473092317581177,
      "learning_rate": 9.77426668297119e-05,
      "loss": 0.0126,
      "step": 411500
    },
    {
      "epoch": 0.023150652025190382,
      "grad_norm": 0.15277187526226044,
      "learning_rate": 9.773985570496684e-05,
      "loss": 0.0133,
      "step": 412000
    },
    {
      "epoch": 0.023178747476677263,
      "grad_norm": 0.3640172779560089,
      "learning_rate": 9.773704458022177e-05,
      "loss": 0.0128,
      "step": 412500
    },
    {
      "epoch": 0.023206842928164145,
      "grad_norm": 0.7625461220741272,
      "learning_rate": 9.773423345547671e-05,
      "loss": 0.0127,
      "step": 413000
    },
    {
      "epoch": 0.023234938379651026,
      "grad_norm": 0.4899637997150421,
      "learning_rate": 9.773142233073164e-05,
      "loss": 0.0129,
      "step": 413500
    },
    {
      "epoch": 0.023263033831137907,
      "grad_norm": 0.6876718401908875,
      "learning_rate": 9.772861120598658e-05,
      "loss": 0.0132,
      "step": 414000
    },
    {
      "epoch": 0.02329112928262479,
      "grad_norm": 0.5197399854660034,
      "learning_rate": 9.772580008124151e-05,
      "loss": 0.0129,
      "step": 414500
    },
    {
      "epoch": 0.02331922473411167,
      "grad_norm": 1.0062683820724487,
      "learning_rate": 9.772298895649644e-05,
      "loss": 0.0124,
      "step": 415000
    },
    {
      "epoch": 0.02334732018559855,
      "grad_norm": 0.514835774898529,
      "learning_rate": 9.772017783175138e-05,
      "loss": 0.0127,
      "step": 415500
    },
    {
      "epoch": 0.023375415637085433,
      "grad_norm": 0.28499525785446167,
      "learning_rate": 9.771736670700631e-05,
      "loss": 0.0123,
      "step": 416000
    },
    {
      "epoch": 0.023403511088572315,
      "grad_norm": 0.13584095239639282,
      "learning_rate": 9.771455558226125e-05,
      "loss": 0.0126,
      "step": 416500
    },
    {
      "epoch": 0.023431606540059196,
      "grad_norm": 0.11486556380987167,
      "learning_rate": 9.771174445751617e-05,
      "loss": 0.0131,
      "step": 417000
    },
    {
      "epoch": 0.023459701991546077,
      "grad_norm": 0.8755265474319458,
      "learning_rate": 9.770893333277112e-05,
      "loss": 0.0131,
      "step": 417500
    },
    {
      "epoch": 0.02348779744303296,
      "grad_norm": 0.11670374870300293,
      "learning_rate": 9.770612220802605e-05,
      "loss": 0.013,
      "step": 418000
    },
    {
      "epoch": 0.02351589289451984,
      "grad_norm": 0.31769895553588867,
      "learning_rate": 9.770331108328098e-05,
      "loss": 0.0124,
      "step": 418500
    },
    {
      "epoch": 0.02354398834600672,
      "grad_norm": 0.199913889169693,
      "learning_rate": 9.770049995853592e-05,
      "loss": 0.0135,
      "step": 419000
    },
    {
      "epoch": 0.023572083797493606,
      "grad_norm": 0.2725765109062195,
      "learning_rate": 9.769768883379084e-05,
      "loss": 0.0132,
      "step": 419500
    },
    {
      "epoch": 0.023600179248980488,
      "grad_norm": 0.21584340929985046,
      "learning_rate": 9.769487770904579e-05,
      "loss": 0.013,
      "step": 420000
    },
    {
      "epoch": 0.023600179248980488,
      "eval_loss": 0.006669978611171246,
      "eval_runtime": 18.9303,
      "eval_samples_per_second": 5282.523,
      "eval_steps_per_second": 82.566,
      "step": 420000
    },
    {
      "epoch": 0.02362827470046737,
      "grad_norm": 0.5533322095870972,
      "learning_rate": 9.769206658430071e-05,
      "loss": 0.0122,
      "step": 420500
    },
    {
      "epoch": 0.02365637015195425,
      "grad_norm": 0.15355059504508972,
      "learning_rate": 9.768925545955566e-05,
      "loss": 0.0132,
      "step": 421000
    },
    {
      "epoch": 0.023684465603441132,
      "grad_norm": 0.1266605108976364,
      "learning_rate": 9.768644433481059e-05,
      "loss": 0.0133,
      "step": 421500
    },
    {
      "epoch": 0.023712561054928014,
      "grad_norm": 0.7176119685173035,
      "learning_rate": 9.768363321006551e-05,
      "loss": 0.0125,
      "step": 422000
    },
    {
      "epoch": 0.023740656506414895,
      "grad_norm": 0.18284910917282104,
      "learning_rate": 9.768082208532046e-05,
      "loss": 0.0122,
      "step": 422500
    },
    {
      "epoch": 0.023768751957901776,
      "grad_norm": 0.5508572459220886,
      "learning_rate": 9.767801096057538e-05,
      "loss": 0.0127,
      "step": 423000
    },
    {
      "epoch": 0.023796847409388658,
      "grad_norm": 1.3148412704467773,
      "learning_rate": 9.767519983583033e-05,
      "loss": 0.0124,
      "step": 423500
    },
    {
      "epoch": 0.02382494286087554,
      "grad_norm": 0.12531723082065582,
      "learning_rate": 9.767238871108525e-05,
      "loss": 0.0131,
      "step": 424000
    },
    {
      "epoch": 0.02385303831236242,
      "grad_norm": 0.22128477692604065,
      "learning_rate": 9.766957758634018e-05,
      "loss": 0.013,
      "step": 424500
    },
    {
      "epoch": 0.023881133763849302,
      "grad_norm": 0.38853397965431213,
      "learning_rate": 9.766676646159512e-05,
      "loss": 0.0131,
      "step": 425000
    },
    {
      "epoch": 0.023909229215336184,
      "grad_norm": 0.16750019788742065,
      "learning_rate": 9.766395533685005e-05,
      "loss": 0.0127,
      "step": 425500
    },
    {
      "epoch": 0.023937324666823065,
      "grad_norm": 0.6360704302787781,
      "learning_rate": 9.7661144212105e-05,
      "loss": 0.0129,
      "step": 426000
    },
    {
      "epoch": 0.023965420118309946,
      "grad_norm": 0.7439746260643005,
      "learning_rate": 9.765833308735992e-05,
      "loss": 0.013,
      "step": 426500
    },
    {
      "epoch": 0.023993515569796828,
      "grad_norm": 0.6728466749191284,
      "learning_rate": 9.765552196261487e-05,
      "loss": 0.0125,
      "step": 427000
    },
    {
      "epoch": 0.02402161102128371,
      "grad_norm": 0.5793729424476624,
      "learning_rate": 9.765271083786979e-05,
      "loss": 0.0118,
      "step": 427500
    },
    {
      "epoch": 0.02404970647277059,
      "grad_norm": 0.6231518387794495,
      "learning_rate": 9.764989971312472e-05,
      "loss": 0.0117,
      "step": 428000
    },
    {
      "epoch": 0.024077801924257472,
      "grad_norm": 0.4197641611099243,
      "learning_rate": 9.764708858837966e-05,
      "loss": 0.0124,
      "step": 428500
    },
    {
      "epoch": 0.024105897375744353,
      "grad_norm": 0.21408358216285706,
      "learning_rate": 9.764427746363459e-05,
      "loss": 0.0129,
      "step": 429000
    },
    {
      "epoch": 0.024133992827231235,
      "grad_norm": 0.10889995098114014,
      "learning_rate": 9.764146633888954e-05,
      "loss": 0.0128,
      "step": 429500
    },
    {
      "epoch": 0.024162088278718116,
      "grad_norm": 0.7812238335609436,
      "learning_rate": 9.763865521414446e-05,
      "loss": 0.0124,
      "step": 430000
    },
    {
      "epoch": 0.024162088278718116,
      "eval_loss": 0.006840534508228302,
      "eval_runtime": 18.9199,
      "eval_samples_per_second": 5285.45,
      "eval_steps_per_second": 82.612,
      "step": 430000
    },
    {
      "epoch": 0.024190183730204998,
      "grad_norm": 0.3705257177352905,
      "learning_rate": 9.763584408939939e-05,
      "loss": 0.013,
      "step": 430500
    },
    {
      "epoch": 0.02421827918169188,
      "grad_norm": 0.5398535132408142,
      "learning_rate": 9.763303296465433e-05,
      "loss": 0.0129,
      "step": 431000
    },
    {
      "epoch": 0.02424637463317876,
      "grad_norm": 0.33035483956336975,
      "learning_rate": 9.763022183990926e-05,
      "loss": 0.0131,
      "step": 431500
    },
    {
      "epoch": 0.024274470084665642,
      "grad_norm": 0.24138252437114716,
      "learning_rate": 9.76274107151642e-05,
      "loss": 0.0125,
      "step": 432000
    },
    {
      "epoch": 0.024302565536152523,
      "grad_norm": 0.48454028367996216,
      "learning_rate": 9.762459959041913e-05,
      "loss": 0.0124,
      "step": 432500
    },
    {
      "epoch": 0.024330660987639405,
      "grad_norm": 0.31129008531570435,
      "learning_rate": 9.762178846567406e-05,
      "loss": 0.0123,
      "step": 433000
    },
    {
      "epoch": 0.024358756439126286,
      "grad_norm": 0.21895509958267212,
      "learning_rate": 9.7618977340929e-05,
      "loss": 0.0132,
      "step": 433500
    },
    {
      "epoch": 0.024386851890613168,
      "grad_norm": 0.3733038306236267,
      "learning_rate": 9.761616621618393e-05,
      "loss": 0.0123,
      "step": 434000
    },
    {
      "epoch": 0.02441494734210005,
      "grad_norm": 0.43303728103637695,
      "learning_rate": 9.761335509143887e-05,
      "loss": 0.0132,
      "step": 434500
    },
    {
      "epoch": 0.024443042793586934,
      "grad_norm": 0.4812220633029938,
      "learning_rate": 9.76105439666938e-05,
      "loss": 0.0129,
      "step": 435000
    },
    {
      "epoch": 0.024471138245073815,
      "grad_norm": 0.13160662353038788,
      "learning_rate": 9.760773284194874e-05,
      "loss": 0.0125,
      "step": 435500
    },
    {
      "epoch": 0.024499233696560697,
      "grad_norm": 0.2745435833930969,
      "learning_rate": 9.760492171720367e-05,
      "loss": 0.0133,
      "step": 436000
    },
    {
      "epoch": 0.024527329148047578,
      "grad_norm": 0.2797413170337677,
      "learning_rate": 9.760211059245859e-05,
      "loss": 0.0126,
      "step": 436500
    },
    {
      "epoch": 0.02455542459953446,
      "grad_norm": 0.30401530861854553,
      "learning_rate": 9.759929946771354e-05,
      "loss": 0.0126,
      "step": 437000
    },
    {
      "epoch": 0.02458352005102134,
      "grad_norm": 0.16983355581760406,
      "learning_rate": 9.759648834296847e-05,
      "loss": 0.0128,
      "step": 437500
    },
    {
      "epoch": 0.024611615502508222,
      "grad_norm": 0.8953491449356079,
      "learning_rate": 9.75936772182234e-05,
      "loss": 0.013,
      "step": 438000
    },
    {
      "epoch": 0.024639710953995104,
      "grad_norm": 0.1746322214603424,
      "learning_rate": 9.759086609347834e-05,
      "loss": 0.0128,
      "step": 438500
    },
    {
      "epoch": 0.024667806405481985,
      "grad_norm": 0.24703934788703918,
      "learning_rate": 9.758805496873326e-05,
      "loss": 0.0124,
      "step": 439000
    },
    {
      "epoch": 0.024695901856968867,
      "grad_norm": 0.8379140496253967,
      "learning_rate": 9.758524384398821e-05,
      "loss": 0.0126,
      "step": 439500
    },
    {
      "epoch": 0.024723997308455748,
      "grad_norm": 0.297138512134552,
      "learning_rate": 9.758243271924313e-05,
      "loss": 0.0123,
      "step": 440000
    },
    {
      "epoch": 0.024723997308455748,
      "eval_loss": 0.006498600356280804,
      "eval_runtime": 18.5561,
      "eval_samples_per_second": 5389.069,
      "eval_steps_per_second": 84.231,
      "step": 440000
    },
    {
      "epoch": 0.02475209275994263,
      "grad_norm": 0.42209097743034363,
      "learning_rate": 9.757962159449808e-05,
      "loss": 0.0124,
      "step": 440500
    },
    {
      "epoch": 0.02478018821142951,
      "grad_norm": 0.39988577365875244,
      "learning_rate": 9.757681046975301e-05,
      "loss": 0.0122,
      "step": 441000
    },
    {
      "epoch": 0.024808283662916392,
      "grad_norm": 0.7987575531005859,
      "learning_rate": 9.757399934500793e-05,
      "loss": 0.0119,
      "step": 441500
    },
    {
      "epoch": 0.024836379114403274,
      "grad_norm": 0.8574027419090271,
      "learning_rate": 9.757118822026288e-05,
      "loss": 0.0119,
      "step": 442000
    },
    {
      "epoch": 0.024864474565890155,
      "grad_norm": 0.7398255467414856,
      "learning_rate": 9.75683770955178e-05,
      "loss": 0.0123,
      "step": 442500
    },
    {
      "epoch": 0.024892570017377037,
      "grad_norm": 0.8204388618469238,
      "learning_rate": 9.756556597077275e-05,
      "loss": 0.0122,
      "step": 443000
    },
    {
      "epoch": 0.024920665468863918,
      "grad_norm": 0.17322511970996857,
      "learning_rate": 9.756275484602767e-05,
      "loss": 0.0124,
      "step": 443500
    },
    {
      "epoch": 0.0249487609203508,
      "grad_norm": 0.5980262756347656,
      "learning_rate": 9.75599437212826e-05,
      "loss": 0.012,
      "step": 444000
    },
    {
      "epoch": 0.02497685637183768,
      "grad_norm": 0.584019660949707,
      "learning_rate": 9.755713259653754e-05,
      "loss": 0.0123,
      "step": 444500
    },
    {
      "epoch": 0.025004951823324562,
      "grad_norm": 0.30270394682884216,
      "learning_rate": 9.755432147179247e-05,
      "loss": 0.0128,
      "step": 445000
    },
    {
      "epoch": 0.025033047274811444,
      "grad_norm": 0.21216242015361786,
      "learning_rate": 9.755151034704742e-05,
      "loss": 0.0127,
      "step": 445500
    },
    {
      "epoch": 0.025061142726298325,
      "grad_norm": 0.42239490151405334,
      "learning_rate": 9.754869922230234e-05,
      "loss": 0.0118,
      "step": 446000
    },
    {
      "epoch": 0.025089238177785207,
      "grad_norm": 0.26764628291130066,
      "learning_rate": 9.754588809755727e-05,
      "loss": 0.0123,
      "step": 446500
    },
    {
      "epoch": 0.025117333629272088,
      "grad_norm": 0.48938119411468506,
      "learning_rate": 9.754307697281221e-05,
      "loss": 0.0127,
      "step": 447000
    },
    {
      "epoch": 0.02514542908075897,
      "grad_norm": 0.40680480003356934,
      "learning_rate": 9.754026584806714e-05,
      "loss": 0.0124,
      "step": 447500
    },
    {
      "epoch": 0.02517352453224585,
      "grad_norm": 0.25481903553009033,
      "learning_rate": 9.753745472332208e-05,
      "loss": 0.0128,
      "step": 448000
    },
    {
      "epoch": 0.025201619983732732,
      "grad_norm": 0.7841607332229614,
      "learning_rate": 9.753464359857701e-05,
      "loss": 0.0119,
      "step": 448500
    },
    {
      "epoch": 0.025229715435219614,
      "grad_norm": 0.528932511806488,
      "learning_rate": 9.753183247383195e-05,
      "loss": 0.0118,
      "step": 449000
    },
    {
      "epoch": 0.025257810886706495,
      "grad_norm": 0.3166006803512573,
      "learning_rate": 9.752902134908688e-05,
      "loss": 0.012,
      "step": 449500
    },
    {
      "epoch": 0.02528590633819338,
      "grad_norm": 0.27596941590309143,
      "learning_rate": 9.752621022434181e-05,
      "loss": 0.0118,
      "step": 450000
    },
    {
      "epoch": 0.02528590633819338,
      "eval_loss": 0.006681800354272127,
      "eval_runtime": 19.4623,
      "eval_samples_per_second": 5138.15,
      "eval_steps_per_second": 80.309,
      "step": 450000
    },
    {
      "epoch": 0.02531400178968026,
      "grad_norm": 0.33546924591064453,
      "learning_rate": 9.752339909959675e-05,
      "loss": 0.0127,
      "step": 450500
    },
    {
      "epoch": 0.025342097241167143,
      "grad_norm": 0.5605536103248596,
      "learning_rate": 9.752058797485168e-05,
      "loss": 0.0122,
      "step": 451000
    },
    {
      "epoch": 0.025370192692654024,
      "grad_norm": 0.1829218715429306,
      "learning_rate": 9.751777685010662e-05,
      "loss": 0.0126,
      "step": 451500
    },
    {
      "epoch": 0.025398288144140906,
      "grad_norm": 0.3176310360431671,
      "learning_rate": 9.751496572536155e-05,
      "loss": 0.0126,
      "step": 452000
    },
    {
      "epoch": 0.025426383595627787,
      "grad_norm": 0.25795218348503113,
      "learning_rate": 9.751215460061647e-05,
      "loss": 0.0121,
      "step": 452500
    },
    {
      "epoch": 0.02545447904711467,
      "grad_norm": 0.4627133309841156,
      "learning_rate": 9.750934347587142e-05,
      "loss": 0.0125,
      "step": 453000
    },
    {
      "epoch": 0.02548257449860155,
      "grad_norm": 0.2366759330034256,
      "learning_rate": 9.750653235112635e-05,
      "loss": 0.0123,
      "step": 453500
    },
    {
      "epoch": 0.02551066995008843,
      "grad_norm": 0.2546842098236084,
      "learning_rate": 9.750372122638129e-05,
      "loss": 0.0117,
      "step": 454000
    },
    {
      "epoch": 0.025538765401575313,
      "grad_norm": 0.41133323311805725,
      "learning_rate": 9.750091010163622e-05,
      "loss": 0.0119,
      "step": 454500
    },
    {
      "epoch": 0.025566860853062194,
      "grad_norm": 0.9228731393814087,
      "learning_rate": 9.749809897689114e-05,
      "loss": 0.0123,
      "step": 455000
    },
    {
      "epoch": 0.025594956304549075,
      "grad_norm": 0.3966595530509949,
      "learning_rate": 9.749528785214609e-05,
      "loss": 0.0119,
      "step": 455500
    },
    {
      "epoch": 0.025623051756035957,
      "grad_norm": 0.6685185432434082,
      "learning_rate": 9.749247672740101e-05,
      "loss": 0.0132,
      "step": 456000
    },
    {
      "epoch": 0.02565114720752284,
      "grad_norm": 0.11811944842338562,
      "learning_rate": 9.748966560265596e-05,
      "loss": 0.0126,
      "step": 456500
    },
    {
      "epoch": 0.02567924265900972,
      "grad_norm": 0.34374523162841797,
      "learning_rate": 9.74868544779109e-05,
      "loss": 0.0121,
      "step": 457000
    },
    {
      "epoch": 0.0257073381104966,
      "grad_norm": 0.32307976484298706,
      "learning_rate": 9.748404335316581e-05,
      "loss": 0.0125,
      "step": 457500
    },
    {
      "epoch": 0.025735433561983483,
      "grad_norm": 0.6434653997421265,
      "learning_rate": 9.748123222842076e-05,
      "loss": 0.0129,
      "step": 458000
    },
    {
      "epoch": 0.025763529013470364,
      "grad_norm": 0.1231471449136734,
      "learning_rate": 9.747842110367568e-05,
      "loss": 0.0126,
      "step": 458500
    },
    {
      "epoch": 0.025791624464957245,
      "grad_norm": 0.2996654510498047,
      "learning_rate": 9.747560997893063e-05,
      "loss": 0.0122,
      "step": 459000
    },
    {
      "epoch": 0.025819719916444127,
      "grad_norm": 0.6753466129302979,
      "learning_rate": 9.747279885418555e-05,
      "loss": 0.0123,
      "step": 459500
    },
    {
      "epoch": 0.025847815367931008,
      "grad_norm": 2.174626111984253,
      "learning_rate": 9.74699877294405e-05,
      "loss": 0.0119,
      "step": 460000
    },
    {
      "epoch": 0.025847815367931008,
      "eval_loss": 0.0064561329782009125,
      "eval_runtime": 19.5762,
      "eval_samples_per_second": 5108.252,
      "eval_steps_per_second": 79.842,
      "step": 460000
    },
    {
      "epoch": 0.02587591081941789,
      "grad_norm": 0.2921956479549408,
      "learning_rate": 9.746717660469543e-05,
      "loss": 0.0124,
      "step": 460500
    },
    {
      "epoch": 0.02590400627090477,
      "grad_norm": 0.3701619505882263,
      "learning_rate": 9.746436547995035e-05,
      "loss": 0.0125,
      "step": 461000
    },
    {
      "epoch": 0.025932101722391653,
      "grad_norm": 0.4678509831428528,
      "learning_rate": 9.74615543552053e-05,
      "loss": 0.0122,
      "step": 461500
    },
    {
      "epoch": 0.025960197173878534,
      "grad_norm": 0.3679974675178528,
      "learning_rate": 9.745874323046022e-05,
      "loss": 0.0126,
      "step": 462000
    },
    {
      "epoch": 0.025988292625365415,
      "grad_norm": 0.4447646737098694,
      "learning_rate": 9.745593210571517e-05,
      "loss": 0.0118,
      "step": 462500
    },
    {
      "epoch": 0.026016388076852297,
      "grad_norm": 0.3912498652935028,
      "learning_rate": 9.745312098097009e-05,
      "loss": 0.0126,
      "step": 463000
    },
    {
      "epoch": 0.026044483528339178,
      "grad_norm": 0.3890945315361023,
      "learning_rate": 9.745030985622503e-05,
      "loss": 0.0123,
      "step": 463500
    },
    {
      "epoch": 0.02607257897982606,
      "grad_norm": 0.6364971995353699,
      "learning_rate": 9.744749873147996e-05,
      "loss": 0.0119,
      "step": 464000
    },
    {
      "epoch": 0.02610067443131294,
      "grad_norm": 0.3153020441532135,
      "learning_rate": 9.74446876067349e-05,
      "loss": 0.0127,
      "step": 464500
    },
    {
      "epoch": 0.026128769882799822,
      "grad_norm": 0.41715842485427856,
      "learning_rate": 9.744187648198984e-05,
      "loss": 0.0118,
      "step": 465000
    },
    {
      "epoch": 0.026156865334286707,
      "grad_norm": 0.14592580497264862,
      "learning_rate": 9.743906535724476e-05,
      "loss": 0.012,
      "step": 465500
    },
    {
      "epoch": 0.02618496078577359,
      "grad_norm": 0.1871623396873474,
      "learning_rate": 9.74362542324997e-05,
      "loss": 0.0119,
      "step": 466000
    },
    {
      "epoch": 0.02621305623726047,
      "grad_norm": 0.3082323372364044,
      "learning_rate": 9.743344310775463e-05,
      "loss": 0.0127,
      "step": 466500
    },
    {
      "epoch": 0.02624115168874735,
      "grad_norm": 0.38995441794395447,
      "learning_rate": 9.743063198300957e-05,
      "loss": 0.0119,
      "step": 467000
    },
    {
      "epoch": 0.026269247140234233,
      "grad_norm": 0.625164270401001,
      "learning_rate": 9.74278208582645e-05,
      "loss": 0.012,
      "step": 467500
    },
    {
      "epoch": 0.026297342591721114,
      "grad_norm": 0.5196816921234131,
      "learning_rate": 9.742500973351943e-05,
      "loss": 0.0119,
      "step": 468000
    },
    {
      "epoch": 0.026325438043207996,
      "grad_norm": 0.6608692407608032,
      "learning_rate": 9.742219860877437e-05,
      "loss": 0.0116,
      "step": 468500
    },
    {
      "epoch": 0.026353533494694877,
      "grad_norm": 0.644168496131897,
      "learning_rate": 9.74193874840293e-05,
      "loss": 0.0122,
      "step": 469000
    },
    {
      "epoch": 0.02638162894618176,
      "grad_norm": 0.3851991295814514,
      "learning_rate": 9.741657635928424e-05,
      "loss": 0.0128,
      "step": 469500
    },
    {
      "epoch": 0.02640972439766864,
      "grad_norm": 0.596378743648529,
      "learning_rate": 9.741376523453917e-05,
      "loss": 0.0117,
      "step": 470000
    },
    {
      "epoch": 0.02640972439766864,
      "eval_loss": 0.006708650384098291,
      "eval_runtime": 18.8561,
      "eval_samples_per_second": 5303.334,
      "eval_steps_per_second": 82.891,
      "step": 470000
    },
    {
      "epoch": 0.02643781984915552,
      "grad_norm": 0.29963138699531555,
      "learning_rate": 9.74109541097941e-05,
      "loss": 0.0124,
      "step": 470500
    },
    {
      "epoch": 0.026465915300642403,
      "grad_norm": 0.7396432757377625,
      "learning_rate": 9.740814298504904e-05,
      "loss": 0.012,
      "step": 471000
    },
    {
      "epoch": 0.026494010752129284,
      "grad_norm": 0.06161506474018097,
      "learning_rate": 9.740533186030397e-05,
      "loss": 0.012,
      "step": 471500
    },
    {
      "epoch": 0.026522106203616166,
      "grad_norm": 0.35353022813796997,
      "learning_rate": 9.740252073555891e-05,
      "loss": 0.0121,
      "step": 472000
    },
    {
      "epoch": 0.026550201655103047,
      "grad_norm": 0.734293520450592,
      "learning_rate": 9.739970961081384e-05,
      "loss": 0.0113,
      "step": 472500
    },
    {
      "epoch": 0.02657829710658993,
      "grad_norm": 0.5307350158691406,
      "learning_rate": 9.739689848606878e-05,
      "loss": 0.012,
      "step": 473000
    },
    {
      "epoch": 0.02660639255807681,
      "grad_norm": 0.8804522156715393,
      "learning_rate": 9.739408736132371e-05,
      "loss": 0.0118,
      "step": 473500
    },
    {
      "epoch": 0.02663448800956369,
      "grad_norm": 0.3044167757034302,
      "learning_rate": 9.739127623657864e-05,
      "loss": 0.0126,
      "step": 474000
    },
    {
      "epoch": 0.026662583461050573,
      "grad_norm": 0.757149338722229,
      "learning_rate": 9.738846511183357e-05,
      "loss": 0.0123,
      "step": 474500
    },
    {
      "epoch": 0.026690678912537454,
      "grad_norm": 0.30725327134132385,
      "learning_rate": 9.738565398708851e-05,
      "loss": 0.0115,
      "step": 475000
    },
    {
      "epoch": 0.026718774364024336,
      "grad_norm": 0.5085268616676331,
      "learning_rate": 9.738284286234343e-05,
      "loss": 0.0116,
      "step": 475500
    },
    {
      "epoch": 0.026746869815511217,
      "grad_norm": 0.056462209671735764,
      "learning_rate": 9.738003173759838e-05,
      "loss": 0.0122,
      "step": 476000
    },
    {
      "epoch": 0.0267749652669981,
      "grad_norm": 0.3376822769641876,
      "learning_rate": 9.737722061285332e-05,
      "loss": 0.0115,
      "step": 476500
    },
    {
      "epoch": 0.02680306071848498,
      "grad_norm": 0.496234267950058,
      "learning_rate": 9.737440948810824e-05,
      "loss": 0.0121,
      "step": 477000
    },
    {
      "epoch": 0.02683115616997186,
      "grad_norm": 0.2950417101383209,
      "learning_rate": 9.737159836336318e-05,
      "loss": 0.0117,
      "step": 477500
    },
    {
      "epoch": 0.026859251621458743,
      "grad_norm": 0.04880478233098984,
      "learning_rate": 9.73687872386181e-05,
      "loss": 0.0117,
      "step": 478000
    },
    {
      "epoch": 0.026887347072945624,
      "grad_norm": 0.639693021774292,
      "learning_rate": 9.736597611387305e-05,
      "loss": 0.0121,
      "step": 478500
    },
    {
      "epoch": 0.026915442524432506,
      "grad_norm": 0.2806378901004791,
      "learning_rate": 9.736316498912797e-05,
      "loss": 0.0123,
      "step": 479000
    },
    {
      "epoch": 0.026943537975919387,
      "grad_norm": 1.1801836490631104,
      "learning_rate": 9.736035386438291e-05,
      "loss": 0.0119,
      "step": 479500
    },
    {
      "epoch": 0.02697163342740627,
      "grad_norm": 0.2734300494194031,
      "learning_rate": 9.735754273963786e-05,
      "loss": 0.0113,
      "step": 480000
    },
    {
      "epoch": 0.02697163342740627,
      "eval_loss": 0.006378451827913523,
      "eval_runtime": 19.0931,
      "eval_samples_per_second": 5237.49,
      "eval_steps_per_second": 81.862,
      "step": 480000
    },
    {
      "epoch": 0.026999728878893153,
      "grad_norm": 0.6657348871231079,
      "learning_rate": 9.735473161489278e-05,
      "loss": 0.0116,
      "step": 480500
    },
    {
      "epoch": 0.027027824330380035,
      "grad_norm": 0.36404454708099365,
      "learning_rate": 9.735192049014772e-05,
      "loss": 0.0126,
      "step": 481000
    },
    {
      "epoch": 0.027055919781866916,
      "grad_norm": 0.3901594877243042,
      "learning_rate": 9.734910936540264e-05,
      "loss": 0.0127,
      "step": 481500
    },
    {
      "epoch": 0.027084015233353798,
      "grad_norm": 0.7407589554786682,
      "learning_rate": 9.734629824065758e-05,
      "loss": 0.0116,
      "step": 482000
    },
    {
      "epoch": 0.02711211068484068,
      "grad_norm": 0.4376415014266968,
      "learning_rate": 9.734348711591251e-05,
      "loss": 0.0116,
      "step": 482500
    },
    {
      "epoch": 0.02714020613632756,
      "grad_norm": 0.43185245990753174,
      "learning_rate": 9.734067599116745e-05,
      "loss": 0.0114,
      "step": 483000
    },
    {
      "epoch": 0.027168301587814442,
      "grad_norm": 0.07931684702634811,
      "learning_rate": 9.733786486642238e-05,
      "loss": 0.0121,
      "step": 483500
    },
    {
      "epoch": 0.027196397039301323,
      "grad_norm": 0.8967832326889038,
      "learning_rate": 9.733505374167732e-05,
      "loss": 0.0118,
      "step": 484000
    },
    {
      "epoch": 0.027224492490788205,
      "grad_norm": 0.38455358147621155,
      "learning_rate": 9.733224261693225e-05,
      "loss": 0.0116,
      "step": 484500
    },
    {
      "epoch": 0.027252587942275086,
      "grad_norm": 0.19598501920700073,
      "learning_rate": 9.732943149218718e-05,
      "loss": 0.0122,
      "step": 485000
    },
    {
      "epoch": 0.027280683393761967,
      "grad_norm": 0.3429715931415558,
      "learning_rate": 9.732662036744212e-05,
      "loss": 0.0119,
      "step": 485500
    },
    {
      "epoch": 0.02730877884524885,
      "grad_norm": 0.19033637642860413,
      "learning_rate": 9.732380924269705e-05,
      "loss": 0.0125,
      "step": 486000
    },
    {
      "epoch": 0.02733687429673573,
      "grad_norm": 0.4905616343021393,
      "learning_rate": 9.732099811795199e-05,
      "loss": 0.0114,
      "step": 486500
    },
    {
      "epoch": 0.027364969748222612,
      "grad_norm": 0.16416701674461365,
      "learning_rate": 9.731818699320692e-05,
      "loss": 0.0121,
      "step": 487000
    },
    {
      "epoch": 0.027393065199709493,
      "grad_norm": 0.6149224638938904,
      "learning_rate": 9.731537586846186e-05,
      "loss": 0.0119,
      "step": 487500
    },
    {
      "epoch": 0.027421160651196375,
      "grad_norm": 0.03897770494222641,
      "learning_rate": 9.731256474371679e-05,
      "loss": 0.0126,
      "step": 488000
    },
    {
      "epoch": 0.027449256102683256,
      "grad_norm": 0.10507778823375702,
      "learning_rate": 9.730975361897172e-05,
      "loss": 0.0116,
      "step": 488500
    },
    {
      "epoch": 0.027477351554170137,
      "grad_norm": 0.10932054370641708,
      "learning_rate": 9.730694249422666e-05,
      "loss": 0.0115,
      "step": 489000
    },
    {
      "epoch": 0.02750544700565702,
      "grad_norm": 0.18206289410591125,
      "learning_rate": 9.730413136948159e-05,
      "loss": 0.0112,
      "step": 489500
    },
    {
      "epoch": 0.0275335424571439,
      "grad_norm": 0.36620840430259705,
      "learning_rate": 9.730132024473653e-05,
      "loss": 0.0114,
      "step": 490000
    },
    {
      "epoch": 0.0275335424571439,
      "eval_loss": 0.00640550022944808,
      "eval_runtime": 18.3917,
      "eval_samples_per_second": 5437.234,
      "eval_steps_per_second": 84.984,
      "step": 490000
    },
    {
      "epoch": 0.02756163790863078,
      "grad_norm": 0.1657595932483673,
      "learning_rate": 9.729850911999145e-05,
      "loss": 0.0126,
      "step": 490500
    },
    {
      "epoch": 0.027589733360117663,
      "grad_norm": 0.28971225023269653,
      "learning_rate": 9.72956979952464e-05,
      "loss": 0.0125,
      "step": 491000
    },
    {
      "epoch": 0.027617828811604545,
      "grad_norm": 0.5355511903762817,
      "learning_rate": 9.729288687050133e-05,
      "loss": 0.0122,
      "step": 491500
    },
    {
      "epoch": 0.027645924263091426,
      "grad_norm": 0.6967254281044006,
      "learning_rate": 9.729007574575626e-05,
      "loss": 0.0122,
      "step": 492000
    },
    {
      "epoch": 0.027674019714578307,
      "grad_norm": 0.2252027690410614,
      "learning_rate": 9.72872646210112e-05,
      "loss": 0.0115,
      "step": 492500
    },
    {
      "epoch": 0.02770211516606519,
      "grad_norm": 0.09515063464641571,
      "learning_rate": 9.728445349626613e-05,
      "loss": 0.0117,
      "step": 493000
    },
    {
      "epoch": 0.02773021061755207,
      "grad_norm": 0.9232158064842224,
      "learning_rate": 9.728164237152107e-05,
      "loss": 0.0119,
      "step": 493500
    },
    {
      "epoch": 0.02775830606903895,
      "grad_norm": 0.1689729541540146,
      "learning_rate": 9.727883124677599e-05,
      "loss": 0.0118,
      "step": 494000
    },
    {
      "epoch": 0.027786401520525833,
      "grad_norm": 0.9463116526603699,
      "learning_rate": 9.727602012203094e-05,
      "loss": 0.0119,
      "step": 494500
    },
    {
      "epoch": 0.027814496972012714,
      "grad_norm": 0.309862345457077,
      "learning_rate": 9.727320899728586e-05,
      "loss": 0.012,
      "step": 495000
    },
    {
      "epoch": 0.027842592423499596,
      "grad_norm": 0.5645830631256104,
      "learning_rate": 9.72703978725408e-05,
      "loss": 0.0118,
      "step": 495500
    },
    {
      "epoch": 0.02787068787498648,
      "grad_norm": 0.10649652034044266,
      "learning_rate": 9.726758674779574e-05,
      "loss": 0.0115,
      "step": 496000
    },
    {
      "epoch": 0.027898783326473362,
      "grad_norm": 0.1341196596622467,
      "learning_rate": 9.726477562305066e-05,
      "loss": 0.0119,
      "step": 496500
    },
    {
      "epoch": 0.027926878777960244,
      "grad_norm": 0.4472888708114624,
      "learning_rate": 9.72619644983056e-05,
      "loss": 0.012,
      "step": 497000
    },
    {
      "epoch": 0.027954974229447125,
      "grad_norm": 0.09666258096694946,
      "learning_rate": 9.725915337356053e-05,
      "loss": 0.0115,
      "step": 497500
    },
    {
      "epoch": 0.027983069680934006,
      "grad_norm": 0.21121954917907715,
      "learning_rate": 9.725634224881548e-05,
      "loss": 0.012,
      "step": 498000
    },
    {
      "epoch": 0.028011165132420888,
      "grad_norm": 0.057506635785102844,
      "learning_rate": 9.72535311240704e-05,
      "loss": 0.0118,
      "step": 498500
    },
    {
      "epoch": 0.02803926058390777,
      "grad_norm": 0.4226726293563843,
      "learning_rate": 9.725071999932533e-05,
      "loss": 0.0118,
      "step": 499000
    },
    {
      "epoch": 0.02806735603539465,
      "grad_norm": 0.3342919945716858,
      "learning_rate": 9.724790887458028e-05,
      "loss": 0.0117,
      "step": 499500
    },
    {
      "epoch": 0.028095451486881532,
      "grad_norm": 0.3062766194343567,
      "learning_rate": 9.72450977498352e-05,
      "loss": 0.0114,
      "step": 500000
    },
    {
      "epoch": 0.028095451486881532,
      "eval_loss": 0.006390406284481287,
      "eval_runtime": 18.8161,
      "eval_samples_per_second": 5314.602,
      "eval_steps_per_second": 83.067,
      "step": 500000
    },
    {
      "epoch": 0.028123546938368413,
      "grad_norm": 0.6499149799346924,
      "learning_rate": 9.724228662509015e-05,
      "loss": 0.0124,
      "step": 500500
    },
    {
      "epoch": 0.028151642389855295,
      "grad_norm": 0.7021749019622803,
      "learning_rate": 9.723947550034507e-05,
      "loss": 0.012,
      "step": 501000
    },
    {
      "epoch": 0.028179737841342176,
      "grad_norm": 0.4053070843219757,
      "learning_rate": 9.72366643756e-05,
      "loss": 0.012,
      "step": 501500
    },
    {
      "epoch": 0.028207833292829058,
      "grad_norm": 0.5927961468696594,
      "learning_rate": 9.723385325085494e-05,
      "loss": 0.0122,
      "step": 502000
    },
    {
      "epoch": 0.02823592874431594,
      "grad_norm": 0.3165886104106903,
      "learning_rate": 9.723104212610987e-05,
      "loss": 0.0117,
      "step": 502500
    },
    {
      "epoch": 0.02826402419580282,
      "grad_norm": 0.666223406791687,
      "learning_rate": 9.722823100136482e-05,
      "loss": 0.0115,
      "step": 503000
    },
    {
      "epoch": 0.028292119647289702,
      "grad_norm": 0.5255927443504333,
      "learning_rate": 9.722541987661974e-05,
      "loss": 0.011,
      "step": 503500
    },
    {
      "epoch": 0.028320215098776583,
      "grad_norm": 0.6501134037971497,
      "learning_rate": 9.722260875187467e-05,
      "loss": 0.0115,
      "step": 504000
    },
    {
      "epoch": 0.028348310550263465,
      "grad_norm": 0.8278947472572327,
      "learning_rate": 9.72197976271296e-05,
      "loss": 0.0118,
      "step": 504500
    },
    {
      "epoch": 0.028376406001750346,
      "grad_norm": 0.0827355608344078,
      "learning_rate": 9.721698650238454e-05,
      "loss": 0.0115,
      "step": 505000
    },
    {
      "epoch": 0.028404501453237228,
      "grad_norm": 0.35495227575302124,
      "learning_rate": 9.721417537763948e-05,
      "loss": 0.0112,
      "step": 505500
    },
    {
      "epoch": 0.02843259690472411,
      "grad_norm": 0.4294947683811188,
      "learning_rate": 9.721136425289441e-05,
      "loss": 0.0113,
      "step": 506000
    },
    {
      "epoch": 0.02846069235621099,
      "grad_norm": 0.8964625000953674,
      "learning_rate": 9.720855312814934e-05,
      "loss": 0.0118,
      "step": 506500
    },
    {
      "epoch": 0.028488787807697872,
      "grad_norm": 0.3812432885169983,
      "learning_rate": 9.720574200340428e-05,
      "loss": 0.0117,
      "step": 507000
    },
    {
      "epoch": 0.028516883259184753,
      "grad_norm": 1.0551683902740479,
      "learning_rate": 9.720293087865921e-05,
      "loss": 0.0113,
      "step": 507500
    },
    {
      "epoch": 0.028544978710671635,
      "grad_norm": 0.790922224521637,
      "learning_rate": 9.720011975391415e-05,
      "loss": 0.012,
      "step": 508000
    },
    {
      "epoch": 0.028573074162158516,
      "grad_norm": 1.0549900531768799,
      "learning_rate": 9.719730862916908e-05,
      "loss": 0.0113,
      "step": 508500
    },
    {
      "epoch": 0.028601169613645398,
      "grad_norm": 0.8514739274978638,
      "learning_rate": 9.719449750442401e-05,
      "loss": 0.0119,
      "step": 509000
    },
    {
      "epoch": 0.02862926506513228,
      "grad_norm": 0.40794113278388977,
      "learning_rate": 9.719168637967895e-05,
      "loss": 0.0118,
      "step": 509500
    },
    {
      "epoch": 0.02865736051661916,
      "grad_norm": 0.63272625207901,
      "learning_rate": 9.718887525493387e-05,
      "loss": 0.0112,
      "step": 510000
    },
    {
      "epoch": 0.02865736051661916,
      "eval_loss": 0.006216038949787617,
      "eval_runtime": 19.3446,
      "eval_samples_per_second": 5169.403,
      "eval_steps_per_second": 80.798,
      "step": 510000
    },
    {
      "epoch": 0.028685455968106042,
      "grad_norm": 0.3423255383968353,
      "learning_rate": 9.718606413018882e-05,
      "loss": 0.012,
      "step": 510500
    },
    {
      "epoch": 0.028713551419592927,
      "grad_norm": 2.3064754009246826,
      "learning_rate": 9.718325300544375e-05,
      "loss": 0.0119,
      "step": 511000
    },
    {
      "epoch": 0.028741646871079808,
      "grad_norm": 0.0879511684179306,
      "learning_rate": 9.718044188069869e-05,
      "loss": 0.0114,
      "step": 511500
    },
    {
      "epoch": 0.02876974232256669,
      "grad_norm": 0.5073251724243164,
      "learning_rate": 9.717763075595362e-05,
      "loss": 0.0115,
      "step": 512000
    },
    {
      "epoch": 0.02879783777405357,
      "grad_norm": 0.848915696144104,
      "learning_rate": 9.717481963120854e-05,
      "loss": 0.012,
      "step": 512500
    },
    {
      "epoch": 0.028825933225540452,
      "grad_norm": 0.5823558568954468,
      "learning_rate": 9.717200850646349e-05,
      "loss": 0.0122,
      "step": 513000
    },
    {
      "epoch": 0.028854028677027334,
      "grad_norm": 0.4793594777584076,
      "learning_rate": 9.716919738171841e-05,
      "loss": 0.0115,
      "step": 513500
    },
    {
      "epoch": 0.028882124128514215,
      "grad_norm": 0.19947804510593414,
      "learning_rate": 9.716638625697336e-05,
      "loss": 0.012,
      "step": 514000
    },
    {
      "epoch": 0.028910219580001097,
      "grad_norm": 0.270412415266037,
      "learning_rate": 9.716357513222828e-05,
      "loss": 0.011,
      "step": 514500
    },
    {
      "epoch": 0.028938315031487978,
      "grad_norm": 0.40860873460769653,
      "learning_rate": 9.716076400748321e-05,
      "loss": 0.0117,
      "step": 515000
    },
    {
      "epoch": 0.02896641048297486,
      "grad_norm": 0.2806835174560547,
      "learning_rate": 9.715795288273816e-05,
      "loss": 0.0111,
      "step": 515500
    },
    {
      "epoch": 0.02899450593446174,
      "grad_norm": 0.5554071068763733,
      "learning_rate": 9.715514175799308e-05,
      "loss": 0.0115,
      "step": 516000
    },
    {
      "epoch": 0.029022601385948622,
      "grad_norm": 0.4270631968975067,
      "learning_rate": 9.715233063324803e-05,
      "loss": 0.0123,
      "step": 516500
    },
    {
      "epoch": 0.029050696837435504,
      "grad_norm": 0.10946045070886612,
      "learning_rate": 9.714951950850295e-05,
      "loss": 0.0121,
      "step": 517000
    },
    {
      "epoch": 0.029078792288922385,
      "grad_norm": 0.39465445280075073,
      "learning_rate": 9.714670838375788e-05,
      "loss": 0.0119,
      "step": 517500
    },
    {
      "epoch": 0.029106887740409267,
      "grad_norm": 0.14776597917079926,
      "learning_rate": 9.714389725901282e-05,
      "loss": 0.0108,
      "step": 518000
    },
    {
      "epoch": 0.029134983191896148,
      "grad_norm": 0.11681540310382843,
      "learning_rate": 9.714108613426775e-05,
      "loss": 0.0121,
      "step": 518500
    },
    {
      "epoch": 0.02916307864338303,
      "grad_norm": 0.0765526294708252,
      "learning_rate": 9.71382750095227e-05,
      "loss": 0.0112,
      "step": 519000
    },
    {
      "epoch": 0.02919117409486991,
      "grad_norm": 0.5108997225761414,
      "learning_rate": 9.713546388477762e-05,
      "loss": 0.0121,
      "step": 519500
    },
    {
      "epoch": 0.029219269546356792,
      "grad_norm": 0.5977979898452759,
      "learning_rate": 9.713265276003255e-05,
      "loss": 0.012,
      "step": 520000
    },
    {
      "epoch": 0.029219269546356792,
      "eval_loss": 0.0062965392135083675,
      "eval_runtime": 18.8649,
      "eval_samples_per_second": 5300.858,
      "eval_steps_per_second": 82.852,
      "step": 520000
    },
    {
      "epoch": 0.029247364997843674,
      "grad_norm": 0.41748523712158203,
      "learning_rate": 9.712984163528749e-05,
      "loss": 0.0115,
      "step": 520500
    },
    {
      "epoch": 0.029275460449330555,
      "grad_norm": 0.12229342013597488,
      "learning_rate": 9.712703051054242e-05,
      "loss": 0.0113,
      "step": 521000
    },
    {
      "epoch": 0.029303555900817436,
      "grad_norm": 0.17274564504623413,
      "learning_rate": 9.712421938579736e-05,
      "loss": 0.0116,
      "step": 521500
    },
    {
      "epoch": 0.029331651352304318,
      "grad_norm": 0.479086697101593,
      "learning_rate": 9.712140826105229e-05,
      "loss": 0.0107,
      "step": 522000
    },
    {
      "epoch": 0.0293597468037912,
      "grad_norm": 0.08285436779260635,
      "learning_rate": 9.711859713630723e-05,
      "loss": 0.0115,
      "step": 522500
    },
    {
      "epoch": 0.02938784225527808,
      "grad_norm": 0.7799371480941772,
      "learning_rate": 9.711578601156216e-05,
      "loss": 0.0113,
      "step": 523000
    },
    {
      "epoch": 0.029415937706764962,
      "grad_norm": 0.4074203670024872,
      "learning_rate": 9.71129748868171e-05,
      "loss": 0.0118,
      "step": 523500
    },
    {
      "epoch": 0.029444033158251844,
      "grad_norm": 0.1275954395532608,
      "learning_rate": 9.711016376207203e-05,
      "loss": 0.012,
      "step": 524000
    },
    {
      "epoch": 0.029472128609738725,
      "grad_norm": 0.19583888351917267,
      "learning_rate": 9.710735263732696e-05,
      "loss": 0.0118,
      "step": 524500
    },
    {
      "epoch": 0.029500224061225606,
      "grad_norm": 0.1119794026017189,
      "learning_rate": 9.71045415125819e-05,
      "loss": 0.0113,
      "step": 525000
    },
    {
      "epoch": 0.029528319512712488,
      "grad_norm": 0.23058997094631195,
      "learning_rate": 9.710173038783683e-05,
      "loss": 0.0114,
      "step": 525500
    },
    {
      "epoch": 0.02955641496419937,
      "grad_norm": 0.4211817979812622,
      "learning_rate": 9.709891926309175e-05,
      "loss": 0.0113,
      "step": 526000
    },
    {
      "epoch": 0.029584510415686254,
      "grad_norm": 0.40642526745796204,
      "learning_rate": 9.70961081383467e-05,
      "loss": 0.0109,
      "step": 526500
    },
    {
      "epoch": 0.029612605867173136,
      "grad_norm": 0.44750604033470154,
      "learning_rate": 9.709329701360163e-05,
      "loss": 0.0112,
      "step": 527000
    },
    {
      "epoch": 0.029640701318660017,
      "grad_norm": 0.049607615917921066,
      "learning_rate": 9.709048588885657e-05,
      "loss": 0.0105,
      "step": 527500
    },
    {
      "epoch": 0.0296687967701469,
      "grad_norm": 0.07758203893899918,
      "learning_rate": 9.70876747641115e-05,
      "loss": 0.0111,
      "step": 528000
    },
    {
      "epoch": 0.02969689222163378,
      "grad_norm": 1.021450161933899,
      "learning_rate": 9.708486363936644e-05,
      "loss": 0.0117,
      "step": 528500
    },
    {
      "epoch": 0.02972498767312066,
      "grad_norm": 0.43800684809684753,
      "learning_rate": 9.708205251462137e-05,
      "loss": 0.0119,
      "step": 529000
    },
    {
      "epoch": 0.029753083124607543,
      "grad_norm": 0.5605775713920593,
      "learning_rate": 9.707924138987629e-05,
      "loss": 0.0116,
      "step": 529500
    },
    {
      "epoch": 0.029781178576094424,
      "grad_norm": 0.37565669417381287,
      "learning_rate": 9.707643026513124e-05,
      "loss": 0.0115,
      "step": 530000
    },
    {
      "epoch": 0.029781178576094424,
      "eval_loss": 0.006182672921568155,
      "eval_runtime": 18.615,
      "eval_samples_per_second": 5372.014,
      "eval_steps_per_second": 83.965,
      "step": 530000
    },
    {
      "epoch": 0.029809274027581305,
      "grad_norm": 0.38043633103370667,
      "learning_rate": 9.707361914038617e-05,
      "loss": 0.0114,
      "step": 530500
    },
    {
      "epoch": 0.029837369479068187,
      "grad_norm": 0.3070763945579529,
      "learning_rate": 9.707080801564111e-05,
      "loss": 0.0112,
      "step": 531000
    },
    {
      "epoch": 0.02986546493055507,
      "grad_norm": 0.28402507305145264,
      "learning_rate": 9.706799689089604e-05,
      "loss": 0.0113,
      "step": 531500
    },
    {
      "epoch": 0.02989356038204195,
      "grad_norm": 0.3440755605697632,
      "learning_rate": 9.706518576615096e-05,
      "loss": 0.0111,
      "step": 532000
    },
    {
      "epoch": 0.02992165583352883,
      "grad_norm": 0.26858898997306824,
      "learning_rate": 9.706237464140591e-05,
      "loss": 0.0117,
      "step": 532500
    },
    {
      "epoch": 0.029949751285015713,
      "grad_norm": 0.9539679288864136,
      "learning_rate": 9.705956351666083e-05,
      "loss": 0.012,
      "step": 533000
    },
    {
      "epoch": 0.029977846736502594,
      "grad_norm": 0.5699421167373657,
      "learning_rate": 9.705675239191578e-05,
      "loss": 0.0118,
      "step": 533500
    },
    {
      "epoch": 0.030005942187989475,
      "grad_norm": 0.44063931703567505,
      "learning_rate": 9.70539412671707e-05,
      "loss": 0.0114,
      "step": 534000
    },
    {
      "epoch": 0.030034037639476357,
      "grad_norm": 0.3159170150756836,
      "learning_rate": 9.705113014242563e-05,
      "loss": 0.0111,
      "step": 534500
    },
    {
      "epoch": 0.030062133090963238,
      "grad_norm": 0.32939475774765015,
      "learning_rate": 9.704831901768058e-05,
      "loss": 0.0112,
      "step": 535000
    },
    {
      "epoch": 0.03009022854245012,
      "grad_norm": 0.7877300977706909,
      "learning_rate": 9.70455078929355e-05,
      "loss": 0.0114,
      "step": 535500
    },
    {
      "epoch": 0.030118323993937,
      "grad_norm": 0.2619049847126007,
      "learning_rate": 9.704269676819045e-05,
      "loss": 0.0112,
      "step": 536000
    },
    {
      "epoch": 0.030146419445423882,
      "grad_norm": 0.10544268786907196,
      "learning_rate": 9.703988564344537e-05,
      "loss": 0.0117,
      "step": 536500
    },
    {
      "epoch": 0.030174514896910764,
      "grad_norm": 0.48340490460395813,
      "learning_rate": 9.70370745187003e-05,
      "loss": 0.0124,
      "step": 537000
    },
    {
      "epoch": 0.030202610348397645,
      "grad_norm": 0.24996191263198853,
      "learning_rate": 9.703426339395524e-05,
      "loss": 0.0115,
      "step": 537500
    },
    {
      "epoch": 0.030230705799884527,
      "grad_norm": 0.5205747485160828,
      "learning_rate": 9.703145226921017e-05,
      "loss": 0.0117,
      "step": 538000
    },
    {
      "epoch": 0.030258801251371408,
      "grad_norm": 0.3250220715999603,
      "learning_rate": 9.702864114446512e-05,
      "loss": 0.0114,
      "step": 538500
    },
    {
      "epoch": 0.03028689670285829,
      "grad_norm": 0.7055532336235046,
      "learning_rate": 9.702583001972004e-05,
      "loss": 0.0112,
      "step": 539000
    },
    {
      "epoch": 0.03031499215434517,
      "grad_norm": 0.11598887294530869,
      "learning_rate": 9.702301889497498e-05,
      "loss": 0.0114,
      "step": 539500
    },
    {
      "epoch": 0.030343087605832052,
      "grad_norm": 0.055381253361701965,
      "learning_rate": 9.702020777022991e-05,
      "loss": 0.0114,
      "step": 540000
    },
    {
      "epoch": 0.030343087605832052,
      "eval_loss": 0.006181562319397926,
      "eval_runtime": 20.0362,
      "eval_samples_per_second": 4990.972,
      "eval_steps_per_second": 78.009,
      "step": 540000
    },
    {
      "epoch": 0.030371183057318934,
      "grad_norm": 0.3677043616771698,
      "learning_rate": 9.701739664548485e-05,
      "loss": 0.0112,
      "step": 540500
    },
    {
      "epoch": 0.030399278508805815,
      "grad_norm": 0.30779144167900085,
      "learning_rate": 9.701458552073978e-05,
      "loss": 0.0111,
      "step": 541000
    },
    {
      "epoch": 0.0304273739602927,
      "grad_norm": 0.6316295266151428,
      "learning_rate": 9.701177439599471e-05,
      "loss": 0.0113,
      "step": 541500
    },
    {
      "epoch": 0.03045546941177958,
      "grad_norm": 0.41708385944366455,
      "learning_rate": 9.700896327124965e-05,
      "loss": 0.011,
      "step": 542000
    },
    {
      "epoch": 0.030483564863266463,
      "grad_norm": 0.22671717405319214,
      "learning_rate": 9.700615214650458e-05,
      "loss": 0.0113,
      "step": 542500
    },
    {
      "epoch": 0.030511660314753344,
      "grad_norm": 5.239217758178711,
      "learning_rate": 9.700334102175952e-05,
      "loss": 0.0115,
      "step": 543000
    },
    {
      "epoch": 0.030539755766240226,
      "grad_norm": 0.0838475301861763,
      "learning_rate": 9.700052989701445e-05,
      "loss": 0.0116,
      "step": 543500
    },
    {
      "epoch": 0.030567851217727107,
      "grad_norm": 0.35827502608299255,
      "learning_rate": 9.699771877226938e-05,
      "loss": 0.0112,
      "step": 544000
    },
    {
      "epoch": 0.03059594666921399,
      "grad_norm": 0.19229495525360107,
      "learning_rate": 9.699490764752432e-05,
      "loss": 0.0113,
      "step": 544500
    },
    {
      "epoch": 0.03062404212070087,
      "grad_norm": 0.10885893553495407,
      "learning_rate": 9.699209652277925e-05,
      "loss": 0.0119,
      "step": 545000
    },
    {
      "epoch": 0.03065213757218775,
      "grad_norm": 0.6548859477043152,
      "learning_rate": 9.698928539803417e-05,
      "loss": 0.0116,
      "step": 545500
    },
    {
      "epoch": 0.030680233023674633,
      "grad_norm": 0.36823245882987976,
      "learning_rate": 9.698647427328912e-05,
      "loss": 0.0111,
      "step": 546000
    },
    {
      "epoch": 0.030708328475161514,
      "grad_norm": 0.23643261194229126,
      "learning_rate": 9.698366314854406e-05,
      "loss": 0.0114,
      "step": 546500
    },
    {
      "epoch": 0.030736423926648396,
      "grad_norm": 0.43348827958106995,
      "learning_rate": 9.698085202379899e-05,
      "loss": 0.0107,
      "step": 547000
    },
    {
      "epoch": 0.030764519378135277,
      "grad_norm": 0.46278247237205505,
      "learning_rate": 9.697804089905392e-05,
      "loss": 0.0115,
      "step": 547500
    },
    {
      "epoch": 0.03079261482962216,
      "grad_norm": 0.5761275291442871,
      "learning_rate": 9.697522977430885e-05,
      "loss": 0.0116,
      "step": 548000
    },
    {
      "epoch": 0.03082071028110904,
      "grad_norm": 0.10683590918779373,
      "learning_rate": 9.697241864956379e-05,
      "loss": 0.0113,
      "step": 548500
    },
    {
      "epoch": 0.03084880573259592,
      "grad_norm": 0.22342456877231598,
      "learning_rate": 9.696960752481871e-05,
      "loss": 0.0109,
      "step": 549000
    },
    {
      "epoch": 0.030876901184082803,
      "grad_norm": 0.2364841103553772,
      "learning_rate": 9.696679640007366e-05,
      "loss": 0.0111,
      "step": 549500
    },
    {
      "epoch": 0.030904996635569684,
      "grad_norm": 0.28056785464286804,
      "learning_rate": 9.69639852753286e-05,
      "loss": 0.0112,
      "step": 550000
    },
    {
      "epoch": 0.030904996635569684,
      "eval_loss": 0.005982937756925821,
      "eval_runtime": 20.5568,
      "eval_samples_per_second": 4864.574,
      "eval_steps_per_second": 76.033,
      "step": 550000
    },
    {
      "epoch": 0.030933092087056566,
      "grad_norm": 0.6580504179000854,
      "learning_rate": 9.696117415058352e-05,
      "loss": 0.0117,
      "step": 550500
    },
    {
      "epoch": 0.030961187538543447,
      "grad_norm": 0.500797688961029,
      "learning_rate": 9.695836302583846e-05,
      "loss": 0.0109,
      "step": 551000
    },
    {
      "epoch": 0.03098928299003033,
      "grad_norm": 0.5587705373764038,
      "learning_rate": 9.695555190109338e-05,
      "loss": 0.0119,
      "step": 551500
    },
    {
      "epoch": 0.03101737844151721,
      "grad_norm": 1.2246109247207642,
      "learning_rate": 9.695274077634833e-05,
      "loss": 0.0109,
      "step": 552000
    },
    {
      "epoch": 0.03104547389300409,
      "grad_norm": 0.4561747908592224,
      "learning_rate": 9.694992965160325e-05,
      "loss": 0.0111,
      "step": 552500
    },
    {
      "epoch": 0.031073569344490973,
      "grad_norm": 0.08744759857654572,
      "learning_rate": 9.694711852685819e-05,
      "loss": 0.0113,
      "step": 553000
    },
    {
      "epoch": 0.031101664795977854,
      "grad_norm": 0.5227572321891785,
      "learning_rate": 9.694430740211314e-05,
      "loss": 0.0114,
      "step": 553500
    },
    {
      "epoch": 0.031129760247464736,
      "grad_norm": 0.15860366821289062,
      "learning_rate": 9.694149627736806e-05,
      "loss": 0.0109,
      "step": 554000
    },
    {
      "epoch": 0.031157855698951617,
      "grad_norm": 0.4986821115016937,
      "learning_rate": 9.6938685152623e-05,
      "loss": 0.0113,
      "step": 554500
    },
    {
      "epoch": 0.0311859511504385,
      "grad_norm": 0.3528510630130768,
      "learning_rate": 9.693587402787792e-05,
      "loss": 0.0117,
      "step": 555000
    },
    {
      "epoch": 0.03121404660192538,
      "grad_norm": 0.4510123133659363,
      "learning_rate": 9.693306290313286e-05,
      "loss": 0.0112,
      "step": 555500
    },
    {
      "epoch": 0.03124214205341226,
      "grad_norm": 0.1584884375333786,
      "learning_rate": 9.693025177838779e-05,
      "loss": 0.0113,
      "step": 556000
    },
    {
      "epoch": 0.03127023750489914,
      "grad_norm": 0.4338979423046112,
      "learning_rate": 9.692744065364273e-05,
      "loss": 0.0107,
      "step": 556500
    },
    {
      "epoch": 0.031298332956386024,
      "grad_norm": 0.5121985077857971,
      "learning_rate": 9.692462952889766e-05,
      "loss": 0.0109,
      "step": 557000
    },
    {
      "epoch": 0.031326428407872906,
      "grad_norm": 0.4900038540363312,
      "learning_rate": 9.69218184041526e-05,
      "loss": 0.0119,
      "step": 557500
    },
    {
      "epoch": 0.03135452385935979,
      "grad_norm": 0.032788414508104324,
      "learning_rate": 9.691900727940753e-05,
      "loss": 0.0107,
      "step": 558000
    },
    {
      "epoch": 0.03138261931084667,
      "grad_norm": 0.30592674016952515,
      "learning_rate": 9.691619615466246e-05,
      "loss": 0.0113,
      "step": 558500
    },
    {
      "epoch": 0.03141071476233355,
      "grad_norm": 0.24386833608150482,
      "learning_rate": 9.69133850299174e-05,
      "loss": 0.0115,
      "step": 559000
    },
    {
      "epoch": 0.03143881021382043,
      "grad_norm": 0.6053903102874756,
      "learning_rate": 9.691057390517233e-05,
      "loss": 0.0113,
      "step": 559500
    },
    {
      "epoch": 0.03146690566530731,
      "grad_norm": 0.5151149034500122,
      "learning_rate": 9.690776278042727e-05,
      "loss": 0.0112,
      "step": 560000
    },
    {
      "epoch": 0.03146690566530731,
      "eval_loss": 0.00598317151889205,
      "eval_runtime": 19.3461,
      "eval_samples_per_second": 5169.009,
      "eval_steps_per_second": 80.792,
      "step": 560000
    },
    {
      "epoch": 0.031495001116794194,
      "grad_norm": 0.9975929260253906,
      "learning_rate": 9.69049516556822e-05,
      "loss": 0.0113,
      "step": 560500
    },
    {
      "epoch": 0.031523096568281075,
      "grad_norm": 0.32577088475227356,
      "learning_rate": 9.690214053093714e-05,
      "loss": 0.0111,
      "step": 561000
    },
    {
      "epoch": 0.03155119201976796,
      "grad_norm": 0.15062826871871948,
      "learning_rate": 9.689932940619207e-05,
      "loss": 0.0114,
      "step": 561500
    },
    {
      "epoch": 0.03157928747125484,
      "grad_norm": 0.5948595404624939,
      "learning_rate": 9.6896518281447e-05,
      "loss": 0.0105,
      "step": 562000
    },
    {
      "epoch": 0.03160738292274172,
      "grad_norm": 1.0905530452728271,
      "learning_rate": 9.689370715670194e-05,
      "loss": 0.0109,
      "step": 562500
    },
    {
      "epoch": 0.0316354783742286,
      "grad_norm": 0.25888127088546753,
      "learning_rate": 9.689089603195687e-05,
      "loss": 0.0112,
      "step": 563000
    },
    {
      "epoch": 0.03166357382571548,
      "grad_norm": 0.31374356150627136,
      "learning_rate": 9.688808490721181e-05,
      "loss": 0.0109,
      "step": 563500
    },
    {
      "epoch": 0.031691669277202364,
      "grad_norm": 0.28272193670272827,
      "learning_rate": 9.688527378246674e-05,
      "loss": 0.0115,
      "step": 564000
    },
    {
      "epoch": 0.03171976472868925,
      "grad_norm": 0.36120155453681946,
      "learning_rate": 9.688246265772168e-05,
      "loss": 0.0111,
      "step": 564500
    },
    {
      "epoch": 0.031747860180176134,
      "grad_norm": 0.4157930612564087,
      "learning_rate": 9.68796515329766e-05,
      "loss": 0.0111,
      "step": 565000
    },
    {
      "epoch": 0.031775955631663015,
      "grad_norm": 0.5248309969902039,
      "learning_rate": 9.687684040823154e-05,
      "loss": 0.0111,
      "step": 565500
    },
    {
      "epoch": 0.0318040510831499,
      "grad_norm": 0.655518114566803,
      "learning_rate": 9.687402928348648e-05,
      "loss": 0.011,
      "step": 566000
    },
    {
      "epoch": 0.03183214653463678,
      "grad_norm": 0.5725305080413818,
      "learning_rate": 9.687121815874141e-05,
      "loss": 0.0108,
      "step": 566500
    },
    {
      "epoch": 0.03186024198612366,
      "grad_norm": 0.5223643183708191,
      "learning_rate": 9.686840703399635e-05,
      "loss": 0.0109,
      "step": 567000
    },
    {
      "epoch": 0.03188833743761054,
      "grad_norm": 1.156038522720337,
      "learning_rate": 9.686559590925127e-05,
      "loss": 0.0111,
      "step": 567500
    },
    {
      "epoch": 0.03191643288909742,
      "grad_norm": 0.06592261046171188,
      "learning_rate": 9.686278478450622e-05,
      "loss": 0.0112,
      "step": 568000
    },
    {
      "epoch": 0.031944528340584304,
      "grad_norm": 0.4270872175693512,
      "learning_rate": 9.685997365976114e-05,
      "loss": 0.0108,
      "step": 568500
    },
    {
      "epoch": 0.031972623792071185,
      "grad_norm": 0.2032531350851059,
      "learning_rate": 9.685716253501608e-05,
      "loss": 0.0113,
      "step": 569000
    },
    {
      "epoch": 0.032000719243558066,
      "grad_norm": 0.1694176197052002,
      "learning_rate": 9.685435141027102e-05,
      "loss": 0.011,
      "step": 569500
    },
    {
      "epoch": 0.03202881469504495,
      "grad_norm": 0.15483447909355164,
      "learning_rate": 9.685154028552594e-05,
      "loss": 0.0107,
      "step": 570000
    },
    {
      "epoch": 0.03202881469504495,
      "eval_loss": 0.006207565777003765,
      "eval_runtime": 18.5941,
      "eval_samples_per_second": 5378.047,
      "eval_steps_per_second": 84.059,
      "step": 570000
    },
    {
      "epoch": 0.03205691014653183,
      "grad_norm": 0.3343627154827118,
      "learning_rate": 9.684872916078089e-05,
      "loss": 0.0104,
      "step": 570500
    },
    {
      "epoch": 0.03208500559801871,
      "grad_norm": 0.5795565843582153,
      "learning_rate": 9.684591803603581e-05,
      "loss": 0.011,
      "step": 571000
    },
    {
      "epoch": 0.03211310104950559,
      "grad_norm": 0.4458058178424835,
      "learning_rate": 9.684310691129075e-05,
      "loss": 0.011,
      "step": 571500
    },
    {
      "epoch": 0.032141196500992474,
      "grad_norm": 0.1055859699845314,
      "learning_rate": 9.684029578654568e-05,
      "loss": 0.0116,
      "step": 572000
    },
    {
      "epoch": 0.032169291952479355,
      "grad_norm": 0.08400570601224899,
      "learning_rate": 9.683748466180061e-05,
      "loss": 0.0113,
      "step": 572500
    },
    {
      "epoch": 0.032197387403966236,
      "grad_norm": 0.3627428412437439,
      "learning_rate": 9.683467353705556e-05,
      "loss": 0.0111,
      "step": 573000
    },
    {
      "epoch": 0.03222548285545312,
      "grad_norm": 0.08634141832590103,
      "learning_rate": 9.683186241231048e-05,
      "loss": 0.0109,
      "step": 573500
    },
    {
      "epoch": 0.03225357830694,
      "grad_norm": 0.412311851978302,
      "learning_rate": 9.682905128756543e-05,
      "loss": 0.0113,
      "step": 574000
    },
    {
      "epoch": 0.03228167375842688,
      "grad_norm": 0.0827632024884224,
      "learning_rate": 9.682624016282035e-05,
      "loss": 0.0113,
      "step": 574500
    },
    {
      "epoch": 0.03230976920991376,
      "grad_norm": 2.773427963256836,
      "learning_rate": 9.682342903807528e-05,
      "loss": 0.0109,
      "step": 575000
    },
    {
      "epoch": 0.032337864661400643,
      "grad_norm": 0.4015938639640808,
      "learning_rate": 9.682061791333022e-05,
      "loss": 0.0104,
      "step": 575500
    },
    {
      "epoch": 0.032365960112887525,
      "grad_norm": 0.570549488067627,
      "learning_rate": 9.681780678858515e-05,
      "loss": 0.0106,
      "step": 576000
    },
    {
      "epoch": 0.032394055564374406,
      "grad_norm": 0.1123131588101387,
      "learning_rate": 9.681499566384008e-05,
      "loss": 0.0111,
      "step": 576500
    },
    {
      "epoch": 0.03242215101586129,
      "grad_norm": 0.8664669394493103,
      "learning_rate": 9.681218453909502e-05,
      "loss": 0.0106,
      "step": 577000
    },
    {
      "epoch": 0.03245024646734817,
      "grad_norm": 0.6452949047088623,
      "learning_rate": 9.680937341434995e-05,
      "loss": 0.012,
      "step": 577500
    },
    {
      "epoch": 0.03247834191883505,
      "grad_norm": 0.3859676122665405,
      "learning_rate": 9.680656228960489e-05,
      "loss": 0.0106,
      "step": 578000
    },
    {
      "epoch": 0.03250643737032193,
      "grad_norm": 0.36694440245628357,
      "learning_rate": 9.680375116485982e-05,
      "loss": 0.0108,
      "step": 578500
    },
    {
      "epoch": 0.03253453282180881,
      "grad_norm": 0.3239990472793579,
      "learning_rate": 9.680094004011475e-05,
      "loss": 0.0115,
      "step": 579000
    },
    {
      "epoch": 0.032562628273295695,
      "grad_norm": 0.2699403464794159,
      "learning_rate": 9.679812891536969e-05,
      "loss": 0.0106,
      "step": 579500
    },
    {
      "epoch": 0.032590723724782576,
      "grad_norm": 0.38508206605911255,
      "learning_rate": 9.679531779062462e-05,
      "loss": 0.0115,
      "step": 580000
    },
    {
      "epoch": 0.032590723724782576,
      "eval_loss": 0.0058703250251710415,
      "eval_runtime": 19.1512,
      "eval_samples_per_second": 5221.604,
      "eval_steps_per_second": 81.614,
      "step": 580000
    },
    {
      "epoch": 0.03261881917626946,
      "grad_norm": 0.08405345678329468,
      "learning_rate": 9.679250666587956e-05,
      "loss": 0.0106,
      "step": 580500
    },
    {
      "epoch": 0.03264691462775634,
      "grad_norm": 0.3818919360637665,
      "learning_rate": 9.678969554113449e-05,
      "loss": 0.0112,
      "step": 581000
    },
    {
      "epoch": 0.03267501007924322,
      "grad_norm": 0.40729275345802307,
      "learning_rate": 9.678688441638943e-05,
      "loss": 0.0111,
      "step": 581500
    },
    {
      "epoch": 0.0327031055307301,
      "grad_norm": 0.35556551814079285,
      "learning_rate": 9.678407329164436e-05,
      "loss": 0.0108,
      "step": 582000
    },
    {
      "epoch": 0.03273120098221698,
      "grad_norm": 0.37216687202453613,
      "learning_rate": 9.67812621668993e-05,
      "loss": 0.0108,
      "step": 582500
    },
    {
      "epoch": 0.032759296433703865,
      "grad_norm": 0.37617573142051697,
      "learning_rate": 9.677845104215423e-05,
      "loss": 0.0108,
      "step": 583000
    },
    {
      "epoch": 0.032787391885190746,
      "grad_norm": 0.29566314816474915,
      "learning_rate": 9.677563991740915e-05,
      "loss": 0.0107,
      "step": 583500
    },
    {
      "epoch": 0.03281548733667763,
      "grad_norm": 0.14153212308883667,
      "learning_rate": 9.67728287926641e-05,
      "loss": 0.0109,
      "step": 584000
    },
    {
      "epoch": 0.03284358278816451,
      "grad_norm": 0.40414783358573914,
      "learning_rate": 9.677001766791903e-05,
      "loss": 0.0108,
      "step": 584500
    },
    {
      "epoch": 0.03287167823965139,
      "grad_norm": 0.07411383092403412,
      "learning_rate": 9.676720654317397e-05,
      "loss": 0.0114,
      "step": 585000
    },
    {
      "epoch": 0.03289977369113827,
      "grad_norm": 0.16027629375457764,
      "learning_rate": 9.67643954184289e-05,
      "loss": 0.0111,
      "step": 585500
    },
    {
      "epoch": 0.03292786914262515,
      "grad_norm": 0.07429331541061401,
      "learning_rate": 9.676158429368382e-05,
      "loss": 0.011,
      "step": 586000
    },
    {
      "epoch": 0.032955964594112035,
      "grad_norm": 0.20519517362117767,
      "learning_rate": 9.675877316893877e-05,
      "loss": 0.0108,
      "step": 586500
    },
    {
      "epoch": 0.032984060045598916,
      "grad_norm": 0.2982245683670044,
      "learning_rate": 9.675596204419369e-05,
      "loss": 0.0112,
      "step": 587000
    },
    {
      "epoch": 0.0330121554970858,
      "grad_norm": 0.052826620638370514,
      "learning_rate": 9.675315091944864e-05,
      "loss": 0.0106,
      "step": 587500
    },
    {
      "epoch": 0.03304025094857268,
      "grad_norm": 0.6495950818061829,
      "learning_rate": 9.675033979470356e-05,
      "loss": 0.0112,
      "step": 588000
    },
    {
      "epoch": 0.03306834640005956,
      "grad_norm": 0.5613300204277039,
      "learning_rate": 9.674752866995849e-05,
      "loss": 0.0102,
      "step": 588500
    },
    {
      "epoch": 0.03309644185154644,
      "grad_norm": 0.5322198271751404,
      "learning_rate": 9.674471754521344e-05,
      "loss": 0.0109,
      "step": 589000
    },
    {
      "epoch": 0.03312453730303332,
      "grad_norm": 0.47724682092666626,
      "learning_rate": 9.674190642046836e-05,
      "loss": 0.0107,
      "step": 589500
    },
    {
      "epoch": 0.033152632754520205,
      "grad_norm": 0.601229190826416,
      "learning_rate": 9.673909529572331e-05,
      "loss": 0.0114,
      "step": 590000
    },
    {
      "epoch": 0.033152632754520205,
      "eval_loss": 0.005951932165771723,
      "eval_runtime": 19.2646,
      "eval_samples_per_second": 5190.868,
      "eval_steps_per_second": 81.133,
      "step": 590000
    },
    {
      "epoch": 0.033180728206007086,
      "grad_norm": 0.2980733811855316,
      "learning_rate": 9.673628417097823e-05,
      "loss": 0.0103,
      "step": 590500
    },
    {
      "epoch": 0.03320882365749397,
      "grad_norm": 0.13629065454006195,
      "learning_rate": 9.673347304623316e-05,
      "loss": 0.0111,
      "step": 591000
    },
    {
      "epoch": 0.03323691910898085,
      "grad_norm": 0.35060396790504456,
      "learning_rate": 9.67306619214881e-05,
      "loss": 0.011,
      "step": 591500
    },
    {
      "epoch": 0.03326501456046773,
      "grad_norm": 0.5072975754737854,
      "learning_rate": 9.672785079674303e-05,
      "loss": 0.0105,
      "step": 592000
    },
    {
      "epoch": 0.03329311001195461,
      "grad_norm": 0.3131972849369049,
      "learning_rate": 9.672503967199798e-05,
      "loss": 0.0109,
      "step": 592500
    },
    {
      "epoch": 0.03332120546344149,
      "grad_norm": 0.3762055039405823,
      "learning_rate": 9.67222285472529e-05,
      "loss": 0.0105,
      "step": 593000
    },
    {
      "epoch": 0.033349300914928375,
      "grad_norm": 0.2790994942188263,
      "learning_rate": 9.671941742250783e-05,
      "loss": 0.0107,
      "step": 593500
    },
    {
      "epoch": 0.033377396366415256,
      "grad_norm": 0.3512658178806305,
      "learning_rate": 9.671660629776277e-05,
      "loss": 0.0105,
      "step": 594000
    },
    {
      "epoch": 0.03340549181790214,
      "grad_norm": 0.24964773654937744,
      "learning_rate": 9.67137951730177e-05,
      "loss": 0.0108,
      "step": 594500
    },
    {
      "epoch": 0.033433587269389026,
      "grad_norm": 0.1573631912469864,
      "learning_rate": 9.671098404827264e-05,
      "loss": 0.0105,
      "step": 595000
    },
    {
      "epoch": 0.03346168272087591,
      "grad_norm": 0.09202548116445541,
      "learning_rate": 9.670817292352757e-05,
      "loss": 0.0109,
      "step": 595500
    },
    {
      "epoch": 0.03348977817236279,
      "grad_norm": 0.14001421630382538,
      "learning_rate": 9.67053617987825e-05,
      "loss": 0.0107,
      "step": 596000
    },
    {
      "epoch": 0.03351787362384967,
      "grad_norm": 0.1042180135846138,
      "learning_rate": 9.670255067403744e-05,
      "loss": 0.0104,
      "step": 596500
    },
    {
      "epoch": 0.03354596907533655,
      "grad_norm": 0.47939741611480713,
      "learning_rate": 9.669973954929237e-05,
      "loss": 0.0108,
      "step": 597000
    },
    {
      "epoch": 0.03357406452682343,
      "grad_norm": 0.19359706342220306,
      "learning_rate": 9.669692842454731e-05,
      "loss": 0.0109,
      "step": 597500
    },
    {
      "epoch": 0.033602159978310314,
      "grad_norm": 0.4077487885951996,
      "learning_rate": 9.669411729980224e-05,
      "loss": 0.0111,
      "step": 598000
    },
    {
      "epoch": 0.033630255429797196,
      "grad_norm": 0.34191474318504333,
      "learning_rate": 9.669130617505718e-05,
      "loss": 0.0109,
      "step": 598500
    },
    {
      "epoch": 0.03365835088128408,
      "grad_norm": 0.3512324392795563,
      "learning_rate": 9.668849505031211e-05,
      "loss": 0.0104,
      "step": 599000
    },
    {
      "epoch": 0.03368644633277096,
      "grad_norm": 0.20930862426757812,
      "learning_rate": 9.668568392556705e-05,
      "loss": 0.011,
      "step": 599500
    },
    {
      "epoch": 0.03371454178425784,
      "grad_norm": 0.48825424909591675,
      "learning_rate": 9.668287280082198e-05,
      "loss": 0.0105,
      "step": 600000
    },
    {
      "epoch": 0.03371454178425784,
      "eval_loss": 0.006003146059811115,
      "eval_runtime": 18.6553,
      "eval_samples_per_second": 5360.407,
      "eval_steps_per_second": 83.783,
      "step": 600000
    },
    {
      "epoch": 0.03374263723574472,
      "grad_norm": 0.46616876125335693,
      "learning_rate": 9.668006167607691e-05,
      "loss": 0.0108,
      "step": 600500
    },
    {
      "epoch": 0.0337707326872316,
      "grad_norm": 0.6378139853477478,
      "learning_rate": 9.667725055133185e-05,
      "loss": 0.0106,
      "step": 601000
    },
    {
      "epoch": 0.033798828138718484,
      "grad_norm": 0.495353102684021,
      "learning_rate": 9.667443942658678e-05,
      "loss": 0.0101,
      "step": 601500
    },
    {
      "epoch": 0.033826923590205366,
      "grad_norm": 0.07774470746517181,
      "learning_rate": 9.667162830184172e-05,
      "loss": 0.0114,
      "step": 602000
    },
    {
      "epoch": 0.03385501904169225,
      "grad_norm": 0.41767072677612305,
      "learning_rate": 9.666881717709665e-05,
      "loss": 0.0107,
      "step": 602500
    },
    {
      "epoch": 0.03388311449317913,
      "grad_norm": 0.7517557144165039,
      "learning_rate": 9.666600605235157e-05,
      "loss": 0.0105,
      "step": 603000
    },
    {
      "epoch": 0.03391120994466601,
      "grad_norm": 0.3763370215892792,
      "learning_rate": 9.666319492760652e-05,
      "loss": 0.0107,
      "step": 603500
    },
    {
      "epoch": 0.03393930539615289,
      "grad_norm": 0.7912824153900146,
      "learning_rate": 9.666038380286145e-05,
      "loss": 0.011,
      "step": 604000
    },
    {
      "epoch": 0.03396740084763977,
      "grad_norm": 0.6730977296829224,
      "learning_rate": 9.665757267811639e-05,
      "loss": 0.0109,
      "step": 604500
    },
    {
      "epoch": 0.033995496299126654,
      "grad_norm": 0.2436911165714264,
      "learning_rate": 9.665476155337132e-05,
      "loss": 0.0119,
      "step": 605000
    },
    {
      "epoch": 0.034023591750613535,
      "grad_norm": 0.3624734878540039,
      "learning_rate": 9.665195042862624e-05,
      "loss": 0.0106,
      "step": 605500
    },
    {
      "epoch": 0.03405168720210042,
      "grad_norm": 0.6979221105575562,
      "learning_rate": 9.664913930388119e-05,
      "loss": 0.0111,
      "step": 606000
    },
    {
      "epoch": 0.0340797826535873,
      "grad_norm": 0.3563697934150696,
      "learning_rate": 9.664632817913611e-05,
      "loss": 0.0111,
      "step": 606500
    },
    {
      "epoch": 0.03410787810507418,
      "grad_norm": 0.6747722029685974,
      "learning_rate": 9.664351705439106e-05,
      "loss": 0.0107,
      "step": 607000
    },
    {
      "epoch": 0.03413597355656106,
      "grad_norm": 0.08478164672851562,
      "learning_rate": 9.664070592964598e-05,
      "loss": 0.0108,
      "step": 607500
    },
    {
      "epoch": 0.03416406900804794,
      "grad_norm": 0.43230584263801575,
      "learning_rate": 9.663789480490091e-05,
      "loss": 0.0109,
      "step": 608000
    },
    {
      "epoch": 0.034192164459534824,
      "grad_norm": 0.3555333912372589,
      "learning_rate": 9.663508368015586e-05,
      "loss": 0.0116,
      "step": 608500
    },
    {
      "epoch": 0.034220259911021705,
      "grad_norm": 0.457415908575058,
      "learning_rate": 9.663227255541078e-05,
      "loss": 0.0105,
      "step": 609000
    },
    {
      "epoch": 0.03424835536250859,
      "grad_norm": 0.3676947355270386,
      "learning_rate": 9.662946143066573e-05,
      "loss": 0.011,
      "step": 609500
    },
    {
      "epoch": 0.03427645081399547,
      "grad_norm": 0.5312399864196777,
      "learning_rate": 9.662665030592065e-05,
      "loss": 0.0103,
      "step": 610000
    },
    {
      "epoch": 0.03427645081399547,
      "eval_loss": 0.005901414901018143,
      "eval_runtime": 18.7116,
      "eval_samples_per_second": 5344.28,
      "eval_steps_per_second": 83.531,
      "step": 610000
    },
    {
      "epoch": 0.03430454626548235,
      "grad_norm": 0.16272099316120148,
      "learning_rate": 9.662383918117559e-05,
      "loss": 0.0105,
      "step": 610500
    },
    {
      "epoch": 0.03433264171696923,
      "grad_norm": 0.1537352055311203,
      "learning_rate": 9.662102805643052e-05,
      "loss": 0.011,
      "step": 611000
    },
    {
      "epoch": 0.03436073716845611,
      "grad_norm": 0.24457405507564545,
      "learning_rate": 9.661821693168545e-05,
      "loss": 0.0113,
      "step": 611500
    },
    {
      "epoch": 0.034388832619942994,
      "grad_norm": 0.956107497215271,
      "learning_rate": 9.66154058069404e-05,
      "loss": 0.0107,
      "step": 612000
    },
    {
      "epoch": 0.034416928071429875,
      "grad_norm": 0.02696198970079422,
      "learning_rate": 9.661259468219532e-05,
      "loss": 0.0108,
      "step": 612500
    },
    {
      "epoch": 0.03444502352291676,
      "grad_norm": 0.5180732607841492,
      "learning_rate": 9.660978355745026e-05,
      "loss": 0.0105,
      "step": 613000
    },
    {
      "epoch": 0.03447311897440364,
      "grad_norm": 0.31058207154273987,
      "learning_rate": 9.660697243270519e-05,
      "loss": 0.0107,
      "step": 613500
    },
    {
      "epoch": 0.03450121442589052,
      "grad_norm": 0.7315548658370972,
      "learning_rate": 9.660416130796012e-05,
      "loss": 0.0104,
      "step": 614000
    },
    {
      "epoch": 0.0345293098773774,
      "grad_norm": 0.029359884560108185,
      "learning_rate": 9.660135018321506e-05,
      "loss": 0.0104,
      "step": 614500
    },
    {
      "epoch": 0.03455740532886428,
      "grad_norm": 0.32212740182876587,
      "learning_rate": 9.659853905847e-05,
      "loss": 0.0108,
      "step": 615000
    },
    {
      "epoch": 0.034585500780351164,
      "grad_norm": 0.0899205282330513,
      "learning_rate": 9.659572793372493e-05,
      "loss": 0.0111,
      "step": 615500
    },
    {
      "epoch": 0.034613596231838045,
      "grad_norm": 0.3276538848876953,
      "learning_rate": 9.659291680897986e-05,
      "loss": 0.0106,
      "step": 616000
    },
    {
      "epoch": 0.03464169168332493,
      "grad_norm": 0.45506465435028076,
      "learning_rate": 9.65901056842348e-05,
      "loss": 0.0104,
      "step": 616500
    },
    {
      "epoch": 0.03466978713481181,
      "grad_norm": 0.16132216155529022,
      "learning_rate": 9.658729455948973e-05,
      "loss": 0.0108,
      "step": 617000
    },
    {
      "epoch": 0.03469788258629869,
      "grad_norm": 0.5378542542457581,
      "learning_rate": 9.658448343474466e-05,
      "loss": 0.0109,
      "step": 617500
    },
    {
      "epoch": 0.03472597803778557,
      "grad_norm": 0.17841722071170807,
      "learning_rate": 9.65816723099996e-05,
      "loss": 0.0105,
      "step": 618000
    },
    {
      "epoch": 0.03475407348927245,
      "grad_norm": 0.23830066621303558,
      "learning_rate": 9.657886118525453e-05,
      "loss": 0.0105,
      "step": 618500
    },
    {
      "epoch": 0.034782168940759334,
      "grad_norm": 0.15117330849170685,
      "learning_rate": 9.657605006050945e-05,
      "loss": 0.0106,
      "step": 619000
    },
    {
      "epoch": 0.034810264392246215,
      "grad_norm": 0.4489680826663971,
      "learning_rate": 9.65732389357644e-05,
      "loss": 0.0106,
      "step": 619500
    },
    {
      "epoch": 0.0348383598437331,
      "grad_norm": 0.2518180310726166,
      "learning_rate": 9.657042781101934e-05,
      "loss": 0.0106,
      "step": 620000
    },
    {
      "epoch": 0.0348383598437331,
      "eval_loss": 0.005807733163237572,
      "eval_runtime": 19.2139,
      "eval_samples_per_second": 5204.576,
      "eval_steps_per_second": 81.348,
      "step": 620000
    },
    {
      "epoch": 0.03486645529521998,
      "grad_norm": 0.7465360164642334,
      "learning_rate": 9.656761668627427e-05,
      "loss": 0.0109,
      "step": 620500
    },
    {
      "epoch": 0.03489455074670686,
      "grad_norm": 0.396929532289505,
      "learning_rate": 9.65648055615292e-05,
      "loss": 0.0108,
      "step": 621000
    },
    {
      "epoch": 0.03492264619819374,
      "grad_norm": 0.47967731952667236,
      "learning_rate": 9.656199443678412e-05,
      "loss": 0.0107,
      "step": 621500
    },
    {
      "epoch": 0.03495074164968062,
      "grad_norm": 0.0880035012960434,
      "learning_rate": 9.655918331203907e-05,
      "loss": 0.0104,
      "step": 622000
    },
    {
      "epoch": 0.034978837101167504,
      "grad_norm": 0.3737051486968994,
      "learning_rate": 9.6556372187294e-05,
      "loss": 0.0109,
      "step": 622500
    },
    {
      "epoch": 0.035006932552654385,
      "grad_norm": 0.07556519657373428,
      "learning_rate": 9.655356106254894e-05,
      "loss": 0.0104,
      "step": 623000
    },
    {
      "epoch": 0.035035028004141266,
      "grad_norm": 0.783458411693573,
      "learning_rate": 9.655074993780388e-05,
      "loss": 0.0101,
      "step": 623500
    },
    {
      "epoch": 0.03506312345562815,
      "grad_norm": 0.4798116683959961,
      "learning_rate": 9.65479388130588e-05,
      "loss": 0.0105,
      "step": 624000
    },
    {
      "epoch": 0.03509121890711503,
      "grad_norm": 0.7819056510925293,
      "learning_rate": 9.654512768831374e-05,
      "loss": 0.0106,
      "step": 624500
    },
    {
      "epoch": 0.03511931435860191,
      "grad_norm": 0.517107367515564,
      "learning_rate": 9.654231656356866e-05,
      "loss": 0.0108,
      "step": 625000
    },
    {
      "epoch": 0.0351474098100888,
      "grad_norm": 0.348347932100296,
      "learning_rate": 9.653950543882361e-05,
      "loss": 0.0112,
      "step": 625500
    },
    {
      "epoch": 0.03517550526157568,
      "grad_norm": 0.1394297331571579,
      "learning_rate": 9.653669431407853e-05,
      "loss": 0.0103,
      "step": 626000
    },
    {
      "epoch": 0.03520360071306256,
      "grad_norm": 0.41403666138648987,
      "learning_rate": 9.653388318933347e-05,
      "loss": 0.0104,
      "step": 626500
    },
    {
      "epoch": 0.03523169616454944,
      "grad_norm": 0.37789440155029297,
      "learning_rate": 9.65310720645884e-05,
      "loss": 0.0105,
      "step": 627000
    },
    {
      "epoch": 0.035259791616036325,
      "grad_norm": 1.243255615234375,
      "learning_rate": 9.652826093984334e-05,
      "loss": 0.0099,
      "step": 627500
    },
    {
      "epoch": 0.035287887067523206,
      "grad_norm": 0.822909414768219,
      "learning_rate": 9.652544981509828e-05,
      "loss": 0.0105,
      "step": 628000
    },
    {
      "epoch": 0.03531598251901009,
      "grad_norm": 0.07245057076215744,
      "learning_rate": 9.65226386903532e-05,
      "loss": 0.0109,
      "step": 628500
    },
    {
      "epoch": 0.03534407797049697,
      "grad_norm": 0.2983707785606384,
      "learning_rate": 9.651982756560814e-05,
      "loss": 0.0102,
      "step": 629000
    },
    {
      "epoch": 0.03537217342198385,
      "grad_norm": 0.06564455479383469,
      "learning_rate": 9.651701644086307e-05,
      "loss": 0.0103,
      "step": 629500
    },
    {
      "epoch": 0.03540026887347073,
      "grad_norm": 0.9008161425590515,
      "learning_rate": 9.651420531611801e-05,
      "loss": 0.0105,
      "step": 630000
    },
    {
      "epoch": 0.03540026887347073,
      "eval_loss": 0.005716219544410706,
      "eval_runtime": 20.4977,
      "eval_samples_per_second": 4878.6,
      "eval_steps_per_second": 76.253,
      "step": 630000
    },
    {
      "epoch": 0.03542836432495761,
      "grad_norm": 0.07127736508846283,
      "learning_rate": 9.651139419137294e-05,
      "loss": 0.0108,
      "step": 630500
    },
    {
      "epoch": 0.035456459776444495,
      "grad_norm": 0.16095301508903503,
      "learning_rate": 9.650858306662788e-05,
      "loss": 0.0106,
      "step": 631000
    },
    {
      "epoch": 0.035484555227931376,
      "grad_norm": 0.3989807665348053,
      "learning_rate": 9.650577194188281e-05,
      "loss": 0.011,
      "step": 631500
    },
    {
      "epoch": 0.03551265067941826,
      "grad_norm": 0.20693263411521912,
      "learning_rate": 9.650296081713774e-05,
      "loss": 0.0107,
      "step": 632000
    },
    {
      "epoch": 0.03554074613090514,
      "grad_norm": 0.2122601568698883,
      "learning_rate": 9.650014969239268e-05,
      "loss": 0.0102,
      "step": 632500
    },
    {
      "epoch": 0.03556884158239202,
      "grad_norm": 0.07577106356620789,
      "learning_rate": 9.649733856764761e-05,
      "loss": 0.0103,
      "step": 633000
    },
    {
      "epoch": 0.0355969370338789,
      "grad_norm": 0.2965242564678192,
      "learning_rate": 9.649452744290255e-05,
      "loss": 0.0105,
      "step": 633500
    },
    {
      "epoch": 0.03562503248536578,
      "grad_norm": 0.11199742555618286,
      "learning_rate": 9.649171631815748e-05,
      "loss": 0.0108,
      "step": 634000
    },
    {
      "epoch": 0.035653127936852665,
      "grad_norm": 0.292388916015625,
      "learning_rate": 9.648890519341242e-05,
      "loss": 0.0105,
      "step": 634500
    },
    {
      "epoch": 0.035681223388339546,
      "grad_norm": 0.6288355588912964,
      "learning_rate": 9.648609406866735e-05,
      "loss": 0.0106,
      "step": 635000
    },
    {
      "epoch": 0.03570931883982643,
      "grad_norm": 0.6371080279350281,
      "learning_rate": 9.648328294392228e-05,
      "loss": 0.0105,
      "step": 635500
    },
    {
      "epoch": 0.03573741429131331,
      "grad_norm": 0.9240890741348267,
      "learning_rate": 9.648047181917722e-05,
      "loss": 0.0102,
      "step": 636000
    },
    {
      "epoch": 0.03576550974280019,
      "grad_norm": 0.29145318269729614,
      "learning_rate": 9.647766069443215e-05,
      "loss": 0.0108,
      "step": 636500
    },
    {
      "epoch": 0.03579360519428707,
      "grad_norm": 0.20893429219722748,
      "learning_rate": 9.647484956968709e-05,
      "loss": 0.011,
      "step": 637000
    },
    {
      "epoch": 0.03582170064577395,
      "grad_norm": 0.23515067994594574,
      "learning_rate": 9.647203844494202e-05,
      "loss": 0.0104,
      "step": 637500
    },
    {
      "epoch": 0.035849796097260835,
      "grad_norm": 0.397445946931839,
      "learning_rate": 9.646922732019696e-05,
      "loss": 0.0112,
      "step": 638000
    },
    {
      "epoch": 0.035877891548747716,
      "grad_norm": 0.8271249532699585,
      "learning_rate": 9.646641619545188e-05,
      "loss": 0.0107,
      "step": 638500
    },
    {
      "epoch": 0.0359059870002346,
      "grad_norm": 0.17016708850860596,
      "learning_rate": 9.646360507070682e-05,
      "loss": 0.0105,
      "step": 639000
    },
    {
      "epoch": 0.03593408245172148,
      "grad_norm": 0.21487641334533691,
      "learning_rate": 9.646079394596176e-05,
      "loss": 0.0103,
      "step": 639500
    },
    {
      "epoch": 0.03596217790320836,
      "grad_norm": 0.12098662555217743,
      "learning_rate": 9.645798282121669e-05,
      "loss": 0.0099,
      "step": 640000
    },
    {
      "epoch": 0.03596217790320836,
      "eval_loss": 0.0057366653345525265,
      "eval_runtime": 18.794,
      "eval_samples_per_second": 5320.847,
      "eval_steps_per_second": 83.165,
      "step": 640000
    },
    {
      "epoch": 0.03599027335469524,
      "grad_norm": 0.6894363760948181,
      "learning_rate": 9.645517169647163e-05,
      "loss": 0.0102,
      "step": 640500
    },
    {
      "epoch": 0.03601836880618212,
      "grad_norm": 0.11914936453104019,
      "learning_rate": 9.645236057172655e-05,
      "loss": 0.0102,
      "step": 641000
    },
    {
      "epoch": 0.036046464257669004,
      "grad_norm": 0.1425171196460724,
      "learning_rate": 9.64495494469815e-05,
      "loss": 0.0098,
      "step": 641500
    },
    {
      "epoch": 0.036074559709155886,
      "grad_norm": 0.2696870267391205,
      "learning_rate": 9.644673832223642e-05,
      "loss": 0.0103,
      "step": 642000
    },
    {
      "epoch": 0.03610265516064277,
      "grad_norm": 0.3685436248779297,
      "learning_rate": 9.644392719749136e-05,
      "loss": 0.01,
      "step": 642500
    },
    {
      "epoch": 0.03613075061212965,
      "grad_norm": 0.4672562777996063,
      "learning_rate": 9.64411160727463e-05,
      "loss": 0.0108,
      "step": 643000
    },
    {
      "epoch": 0.03615884606361653,
      "grad_norm": 0.2938706874847412,
      "learning_rate": 9.643830494800122e-05,
      "loss": 0.0103,
      "step": 643500
    },
    {
      "epoch": 0.03618694151510341,
      "grad_norm": 0.6154657602310181,
      "learning_rate": 9.643549382325617e-05,
      "loss": 0.0103,
      "step": 644000
    },
    {
      "epoch": 0.03621503696659029,
      "grad_norm": 0.08689044415950775,
      "learning_rate": 9.643268269851109e-05,
      "loss": 0.0105,
      "step": 644500
    },
    {
      "epoch": 0.036243132418077174,
      "grad_norm": 0.17121641337871552,
      "learning_rate": 9.642987157376603e-05,
      "loss": 0.0109,
      "step": 645000
    },
    {
      "epoch": 0.036271227869564056,
      "grad_norm": 0.1960376799106598,
      "learning_rate": 9.642706044902096e-05,
      "loss": 0.0108,
      "step": 645500
    },
    {
      "epoch": 0.03629932332105094,
      "grad_norm": 0.25509071350097656,
      "learning_rate": 9.642424932427589e-05,
      "loss": 0.0102,
      "step": 646000
    },
    {
      "epoch": 0.03632741877253782,
      "grad_norm": 0.47544780373573303,
      "learning_rate": 9.642143819953082e-05,
      "loss": 0.0106,
      "step": 646500
    },
    {
      "epoch": 0.0363555142240247,
      "grad_norm": 0.013014242984354496,
      "learning_rate": 9.641862707478576e-05,
      "loss": 0.0102,
      "step": 647000
    },
    {
      "epoch": 0.03638360967551158,
      "grad_norm": 0.10731974244117737,
      "learning_rate": 9.64158159500407e-05,
      "loss": 0.0104,
      "step": 647500
    },
    {
      "epoch": 0.03641170512699846,
      "grad_norm": 2.1380231380462646,
      "learning_rate": 9.641300482529563e-05,
      "loss": 0.0096,
      "step": 648000
    },
    {
      "epoch": 0.036439800578485344,
      "grad_norm": 0.1563372164964676,
      "learning_rate": 9.641019370055056e-05,
      "loss": 0.0105,
      "step": 648500
    },
    {
      "epoch": 0.036467896029972226,
      "grad_norm": 0.3083561360836029,
      "learning_rate": 9.64073825758055e-05,
      "loss": 0.0103,
      "step": 649000
    },
    {
      "epoch": 0.03649599148145911,
      "grad_norm": 0.6153504252433777,
      "learning_rate": 9.640457145106043e-05,
      "loss": 0.0101,
      "step": 649500
    },
    {
      "epoch": 0.03652408693294599,
      "grad_norm": 0.6598836183547974,
      "learning_rate": 9.640176032631536e-05,
      "loss": 0.0099,
      "step": 650000
    },
    {
      "epoch": 0.03652408693294599,
      "eval_loss": 0.005789713468402624,
      "eval_runtime": 19.5005,
      "eval_samples_per_second": 5128.077,
      "eval_steps_per_second": 80.152,
      "step": 650000
    },
    {
      "epoch": 0.03655218238443287,
      "grad_norm": 0.3270878493785858,
      "learning_rate": 9.63989492015703e-05,
      "loss": 0.0102,
      "step": 650500
    },
    {
      "epoch": 0.03658027783591975,
      "grad_norm": 0.6122785210609436,
      "learning_rate": 9.639613807682523e-05,
      "loss": 0.0104,
      "step": 651000
    },
    {
      "epoch": 0.03660837328740663,
      "grad_norm": 0.9697695970535278,
      "learning_rate": 9.639332695208017e-05,
      "loss": 0.0105,
      "step": 651500
    },
    {
      "epoch": 0.036636468738893514,
      "grad_norm": 0.09604355692863464,
      "learning_rate": 9.63905158273351e-05,
      "loss": 0.0109,
      "step": 652000
    },
    {
      "epoch": 0.036664564190380396,
      "grad_norm": 0.2159813791513443,
      "learning_rate": 9.638770470259003e-05,
      "loss": 0.01,
      "step": 652500
    },
    {
      "epoch": 0.03669265964186728,
      "grad_norm": 0.5723518133163452,
      "learning_rate": 9.638489357784497e-05,
      "loss": 0.011,
      "step": 653000
    },
    {
      "epoch": 0.03672075509335416,
      "grad_norm": 0.45263394713401794,
      "learning_rate": 9.63820824530999e-05,
      "loss": 0.0104,
      "step": 653500
    },
    {
      "epoch": 0.03674885054484104,
      "grad_norm": 0.23969875276088715,
      "learning_rate": 9.637927132835484e-05,
      "loss": 0.0099,
      "step": 654000
    },
    {
      "epoch": 0.03677694599632792,
      "grad_norm": 0.33698830008506775,
      "learning_rate": 9.637646020360977e-05,
      "loss": 0.0103,
      "step": 654500
    },
    {
      "epoch": 0.0368050414478148,
      "grad_norm": 0.14774121344089508,
      "learning_rate": 9.63736490788647e-05,
      "loss": 0.0107,
      "step": 655000
    },
    {
      "epoch": 0.036833136899301684,
      "grad_norm": 0.23815321922302246,
      "learning_rate": 9.637083795411964e-05,
      "loss": 0.0108,
      "step": 655500
    },
    {
      "epoch": 0.03686123235078857,
      "grad_norm": 0.05448777601122856,
      "learning_rate": 9.636802682937457e-05,
      "loss": 0.0105,
      "step": 656000
    },
    {
      "epoch": 0.036889327802275454,
      "grad_norm": 0.3568180203437805,
      "learning_rate": 9.636521570462951e-05,
      "loss": 0.0102,
      "step": 656500
    },
    {
      "epoch": 0.036917423253762335,
      "grad_norm": 0.24823853373527527,
      "learning_rate": 9.636240457988443e-05,
      "loss": 0.0104,
      "step": 657000
    },
    {
      "epoch": 0.03694551870524922,
      "grad_norm": 0.11209660023450851,
      "learning_rate": 9.635959345513938e-05,
      "loss": 0.0101,
      "step": 657500
    },
    {
      "epoch": 0.0369736141567361,
      "grad_norm": 0.11450112611055374,
      "learning_rate": 9.63567823303943e-05,
      "loss": 0.0109,
      "step": 658000
    },
    {
      "epoch": 0.03700170960822298,
      "grad_norm": 0.2033972144126892,
      "learning_rate": 9.635397120564925e-05,
      "loss": 0.0109,
      "step": 658500
    },
    {
      "epoch": 0.03702980505970986,
      "grad_norm": 0.33852189779281616,
      "learning_rate": 9.635116008090418e-05,
      "loss": 0.01,
      "step": 659000
    },
    {
      "epoch": 0.03705790051119674,
      "grad_norm": 0.3083723485469818,
      "learning_rate": 9.63483489561591e-05,
      "loss": 0.0104,
      "step": 659500
    },
    {
      "epoch": 0.037085995962683624,
      "grad_norm": 0.4955124855041504,
      "learning_rate": 9.634553783141405e-05,
      "loss": 0.0106,
      "step": 660000
    },
    {
      "epoch": 0.037085995962683624,
      "eval_loss": 0.00567674683406949,
      "eval_runtime": 18.9926,
      "eval_samples_per_second": 5265.221,
      "eval_steps_per_second": 82.295,
      "step": 660000
    },
    {
      "epoch": 0.037114091414170505,
      "grad_norm": 0.055359043180942535,
      "learning_rate": 9.634272670666897e-05,
      "loss": 0.0106,
      "step": 660500
    },
    {
      "epoch": 0.03714218686565739,
      "grad_norm": 0.07772095501422882,
      "learning_rate": 9.633991558192392e-05,
      "loss": 0.0102,
      "step": 661000
    },
    {
      "epoch": 0.03717028231714427,
      "grad_norm": 0.512215256690979,
      "learning_rate": 9.633710445717884e-05,
      "loss": 0.0098,
      "step": 661500
    },
    {
      "epoch": 0.03719837776863115,
      "grad_norm": 0.5376361012458801,
      "learning_rate": 9.633429333243377e-05,
      "loss": 0.0103,
      "step": 662000
    },
    {
      "epoch": 0.03722647322011803,
      "grad_norm": 0.9270104765892029,
      "learning_rate": 9.633148220768872e-05,
      "loss": 0.0101,
      "step": 662500
    },
    {
      "epoch": 0.03725456867160491,
      "grad_norm": 1.267326831817627,
      "learning_rate": 9.632867108294364e-05,
      "loss": 0.0106,
      "step": 663000
    },
    {
      "epoch": 0.037282664123091794,
      "grad_norm": 0.211044043302536,
      "learning_rate": 9.632585995819859e-05,
      "loss": 0.0098,
      "step": 663500
    },
    {
      "epoch": 0.037310759574578675,
      "grad_norm": 0.40142887830734253,
      "learning_rate": 9.632304883345351e-05,
      "loss": 0.01,
      "step": 664000
    },
    {
      "epoch": 0.03733885502606556,
      "grad_norm": 2.1509344577789307,
      "learning_rate": 9.632023770870844e-05,
      "loss": 0.0105,
      "step": 664500
    },
    {
      "epoch": 0.03736695047755244,
      "grad_norm": 0.25348445773124695,
      "learning_rate": 9.631742658396338e-05,
      "loss": 0.0109,
      "step": 665000
    },
    {
      "epoch": 0.03739504592903932,
      "grad_norm": 0.5545433759689331,
      "learning_rate": 9.631461545921831e-05,
      "loss": 0.0102,
      "step": 665500
    },
    {
      "epoch": 0.0374231413805262,
      "grad_norm": 0.5068938136100769,
      "learning_rate": 9.631180433447326e-05,
      "loss": 0.0102,
      "step": 666000
    },
    {
      "epoch": 0.03745123683201308,
      "grad_norm": 0.240300714969635,
      "learning_rate": 9.630899320972818e-05,
      "loss": 0.0102,
      "step": 666500
    },
    {
      "epoch": 0.037479332283499964,
      "grad_norm": 0.1422615945339203,
      "learning_rate": 9.630618208498311e-05,
      "loss": 0.0107,
      "step": 667000
    },
    {
      "epoch": 0.037507427734986845,
      "grad_norm": 0.3538837432861328,
      "learning_rate": 9.630337096023805e-05,
      "loss": 0.011,
      "step": 667500
    },
    {
      "epoch": 0.03753552318647373,
      "grad_norm": 0.2513439655303955,
      "learning_rate": 9.630055983549298e-05,
      "loss": 0.0101,
      "step": 668000
    },
    {
      "epoch": 0.03756361863796061,
      "grad_norm": 0.5560499429702759,
      "learning_rate": 9.629774871074792e-05,
      "loss": 0.01,
      "step": 668500
    },
    {
      "epoch": 0.03759171408944749,
      "grad_norm": 0.17691393196582794,
      "learning_rate": 9.629493758600285e-05,
      "loss": 0.01,
      "step": 669000
    },
    {
      "epoch": 0.03761980954093437,
      "grad_norm": 0.46621251106262207,
      "learning_rate": 9.629212646125779e-05,
      "loss": 0.01,
      "step": 669500
    },
    {
      "epoch": 0.03764790499242125,
      "grad_norm": 0.8527337312698364,
      "learning_rate": 9.628931533651272e-05,
      "loss": 0.0103,
      "step": 670000
    },
    {
      "epoch": 0.03764790499242125,
      "eval_loss": 0.00575348362326622,
      "eval_runtime": 18.6158,
      "eval_samples_per_second": 5371.792,
      "eval_steps_per_second": 83.961,
      "step": 670000
    },
    {
      "epoch": 0.037676000443908134,
      "grad_norm": 0.6720250248908997,
      "learning_rate": 9.628650421176765e-05,
      "loss": 0.01,
      "step": 670500
    },
    {
      "epoch": 0.037704095895395015,
      "grad_norm": 0.21211887896060944,
      "learning_rate": 9.628369308702259e-05,
      "loss": 0.0106,
      "step": 671000
    },
    {
      "epoch": 0.037732191346881896,
      "grad_norm": 0.13360555469989777,
      "learning_rate": 9.628088196227752e-05,
      "loss": 0.0109,
      "step": 671500
    },
    {
      "epoch": 0.03776028679836878,
      "grad_norm": 0.08587860316038132,
      "learning_rate": 9.627807083753246e-05,
      "loss": 0.0099,
      "step": 672000
    },
    {
      "epoch": 0.03778838224985566,
      "grad_norm": 0.12664014101028442,
      "learning_rate": 9.627525971278739e-05,
      "loss": 0.0103,
      "step": 672500
    },
    {
      "epoch": 0.03781647770134254,
      "grad_norm": 0.10747763514518738,
      "learning_rate": 9.627244858804233e-05,
      "loss": 0.0096,
      "step": 673000
    },
    {
      "epoch": 0.03784457315282942,
      "grad_norm": 0.18073579668998718,
      "learning_rate": 9.626963746329726e-05,
      "loss": 0.0106,
      "step": 673500
    },
    {
      "epoch": 0.037872668604316304,
      "grad_norm": 0.782306969165802,
      "learning_rate": 9.62668263385522e-05,
      "loss": 0.0104,
      "step": 674000
    },
    {
      "epoch": 0.037900764055803185,
      "grad_norm": 0.16192571818828583,
      "learning_rate": 9.626401521380713e-05,
      "loss": 0.0101,
      "step": 674500
    },
    {
      "epoch": 0.037928859507290066,
      "grad_norm": 0.27764570713043213,
      "learning_rate": 9.626120408906206e-05,
      "loss": 0.0105,
      "step": 675000
    },
    {
      "epoch": 0.03795695495877695,
      "grad_norm": 0.9055257439613342,
      "learning_rate": 9.6258392964317e-05,
      "loss": 0.0106,
      "step": 675500
    },
    {
      "epoch": 0.03798505041026383,
      "grad_norm": 0.6363778710365295,
      "learning_rate": 9.625558183957193e-05,
      "loss": 0.0106,
      "step": 676000
    },
    {
      "epoch": 0.03801314586175071,
      "grad_norm": 0.27593639492988586,
      "learning_rate": 9.625277071482685e-05,
      "loss": 0.0101,
      "step": 676500
    },
    {
      "epoch": 0.03804124131323759,
      "grad_norm": 0.14972896873950958,
      "learning_rate": 9.62499595900818e-05,
      "loss": 0.0099,
      "step": 677000
    },
    {
      "epoch": 0.038069336764724473,
      "grad_norm": 0.19395039975643158,
      "learning_rate": 9.624714846533672e-05,
      "loss": 0.0103,
      "step": 677500
    },
    {
      "epoch": 0.038097432216211355,
      "grad_norm": 0.3243873119354248,
      "learning_rate": 9.624433734059167e-05,
      "loss": 0.0096,
      "step": 678000
    },
    {
      "epoch": 0.038125527667698236,
      "grad_norm": 0.16458511352539062,
      "learning_rate": 9.62415262158466e-05,
      "loss": 0.0102,
      "step": 678500
    },
    {
      "epoch": 0.03815362311918512,
      "grad_norm": 0.15111827850341797,
      "learning_rate": 9.623871509110152e-05,
      "loss": 0.0104,
      "step": 679000
    },
    {
      "epoch": 0.038181718570672,
      "grad_norm": 0.1272558867931366,
      "learning_rate": 9.623590396635647e-05,
      "loss": 0.0106,
      "step": 679500
    },
    {
      "epoch": 0.03820981402215888,
      "grad_norm": 0.41518595814704895,
      "learning_rate": 9.623309284161139e-05,
      "loss": 0.0098,
      "step": 680000
    },
    {
      "epoch": 0.03820981402215888,
      "eval_loss": 0.00596647709608078,
      "eval_runtime": 19.7987,
      "eval_samples_per_second": 5050.842,
      "eval_steps_per_second": 78.945,
      "step": 680000
    },
    {
      "epoch": 0.03823790947364576,
      "grad_norm": 0.34547439217567444,
      "learning_rate": 9.623028171686634e-05,
      "loss": 0.0107,
      "step": 680500
    },
    {
      "epoch": 0.03826600492513264,
      "grad_norm": 0.4306347668170929,
      "learning_rate": 9.622747059212126e-05,
      "loss": 0.0105,
      "step": 681000
    },
    {
      "epoch": 0.038294100376619525,
      "grad_norm": 0.5553584098815918,
      "learning_rate": 9.62246594673762e-05,
      "loss": 0.0101,
      "step": 681500
    },
    {
      "epoch": 0.038322195828106406,
      "grad_norm": 0.3425924479961395,
      "learning_rate": 9.622184834263114e-05,
      "loss": 0.0105,
      "step": 682000
    },
    {
      "epoch": 0.03835029127959329,
      "grad_norm": 0.3408379554748535,
      "learning_rate": 9.621903721788606e-05,
      "loss": 0.01,
      "step": 682500
    },
    {
      "epoch": 0.03837838673108017,
      "grad_norm": 0.6650383472442627,
      "learning_rate": 9.621622609314101e-05,
      "loss": 0.01,
      "step": 683000
    },
    {
      "epoch": 0.03840648218256705,
      "grad_norm": 0.7647905349731445,
      "learning_rate": 9.621341496839593e-05,
      "loss": 0.0104,
      "step": 683500
    },
    {
      "epoch": 0.03843457763405393,
      "grad_norm": 0.8536266088485718,
      "learning_rate": 9.621060384365086e-05,
      "loss": 0.0102,
      "step": 684000
    },
    {
      "epoch": 0.03846267308554081,
      "grad_norm": 0.3505128026008606,
      "learning_rate": 9.62077927189058e-05,
      "loss": 0.01,
      "step": 684500
    },
    {
      "epoch": 0.038490768537027695,
      "grad_norm": 0.3508530855178833,
      "learning_rate": 9.620498159416073e-05,
      "loss": 0.0102,
      "step": 685000
    },
    {
      "epoch": 0.038518863988514576,
      "grad_norm": 1.7919031381607056,
      "learning_rate": 9.620217046941568e-05,
      "loss": 0.01,
      "step": 685500
    },
    {
      "epoch": 0.03854695944000146,
      "grad_norm": 0.4089028537273407,
      "learning_rate": 9.61993593446706e-05,
      "loss": 0.0102,
      "step": 686000
    },
    {
      "epoch": 0.038575054891488346,
      "grad_norm": 0.2717517614364624,
      "learning_rate": 9.619654821992554e-05,
      "loss": 0.0099,
      "step": 686500
    },
    {
      "epoch": 0.03860315034297523,
      "grad_norm": 0.21527211368083954,
      "learning_rate": 9.619373709518047e-05,
      "loss": 0.0104,
      "step": 687000
    },
    {
      "epoch": 0.03863124579446211,
      "grad_norm": 0.234043151140213,
      "learning_rate": 9.61909259704354e-05,
      "loss": 0.01,
      "step": 687500
    },
    {
      "epoch": 0.03865934124594899,
      "grad_norm": 0.5282320380210876,
      "learning_rate": 9.618811484569034e-05,
      "loss": 0.0108,
      "step": 688000
    },
    {
      "epoch": 0.03868743669743587,
      "grad_norm": 0.7601560950279236,
      "learning_rate": 9.618530372094527e-05,
      "loss": 0.0107,
      "step": 688500
    },
    {
      "epoch": 0.03871553214892275,
      "grad_norm": 0.4502071738243103,
      "learning_rate": 9.618249259620021e-05,
      "loss": 0.0108,
      "step": 689000
    },
    {
      "epoch": 0.038743627600409634,
      "grad_norm": 0.0405411571264267,
      "learning_rate": 9.617968147145514e-05,
      "loss": 0.0099,
      "step": 689500
    },
    {
      "epoch": 0.038771723051896516,
      "grad_norm": 0.09303831309080124,
      "learning_rate": 9.617687034671008e-05,
      "loss": 0.0102,
      "step": 690000
    },
    {
      "epoch": 0.038771723051896516,
      "eval_loss": 0.005668691825121641,
      "eval_runtime": 19.189,
      "eval_samples_per_second": 5211.315,
      "eval_steps_per_second": 81.453,
      "step": 690000
    },
    {
      "epoch": 0.0387998185033834,
      "grad_norm": 0.07428660988807678,
      "learning_rate": 9.617405922196501e-05,
      "loss": 0.0097,
      "step": 690500
    },
    {
      "epoch": 0.03882791395487028,
      "grad_norm": 0.9502098560333252,
      "learning_rate": 9.617124809721994e-05,
      "loss": 0.0103,
      "step": 691000
    },
    {
      "epoch": 0.03885600940635716,
      "grad_norm": 0.6626443266868591,
      "learning_rate": 9.616843697247488e-05,
      "loss": 0.0098,
      "step": 691500
    },
    {
      "epoch": 0.03888410485784404,
      "grad_norm": 0.30408579111099243,
      "learning_rate": 9.616562584772981e-05,
      "loss": 0.0101,
      "step": 692000
    },
    {
      "epoch": 0.03891220030933092,
      "grad_norm": 0.09475460648536682,
      "learning_rate": 9.616281472298473e-05,
      "loss": 0.0102,
      "step": 692500
    },
    {
      "epoch": 0.038940295760817804,
      "grad_norm": 0.49087944626808167,
      "learning_rate": 9.616000359823968e-05,
      "loss": 0.0097,
      "step": 693000
    },
    {
      "epoch": 0.038968391212304686,
      "grad_norm": 0.12791571021080017,
      "learning_rate": 9.615719247349462e-05,
      "loss": 0.0099,
      "step": 693500
    },
    {
      "epoch": 0.03899648666379157,
      "grad_norm": 0.33995768427848816,
      "learning_rate": 9.615438134874955e-05,
      "loss": 0.0101,
      "step": 694000
    },
    {
      "epoch": 0.03902458211527845,
      "grad_norm": 0.8744269013404846,
      "learning_rate": 9.615157022400448e-05,
      "loss": 0.0105,
      "step": 694500
    },
    {
      "epoch": 0.03905267756676533,
      "grad_norm": 0.15015660226345062,
      "learning_rate": 9.61487590992594e-05,
      "loss": 0.0105,
      "step": 695000
    },
    {
      "epoch": 0.03908077301825221,
      "grad_norm": 0.3283499777317047,
      "learning_rate": 9.614594797451435e-05,
      "loss": 0.0097,
      "step": 695500
    },
    {
      "epoch": 0.03910886846973909,
      "grad_norm": 0.35605013370513916,
      "learning_rate": 9.614313684976927e-05,
      "loss": 0.0105,
      "step": 696000
    },
    {
      "epoch": 0.039136963921225974,
      "grad_norm": 0.4347383379936218,
      "learning_rate": 9.614032572502422e-05,
      "loss": 0.0101,
      "step": 696500
    },
    {
      "epoch": 0.039165059372712856,
      "grad_norm": 0.7045116424560547,
      "learning_rate": 9.613751460027914e-05,
      "loss": 0.0102,
      "step": 697000
    },
    {
      "epoch": 0.03919315482419974,
      "grad_norm": 0.33792996406555176,
      "learning_rate": 9.613470347553408e-05,
      "loss": 0.0098,
      "step": 697500
    },
    {
      "epoch": 0.03922125027568662,
      "grad_norm": 0.5058469772338867,
      "learning_rate": 9.613189235078902e-05,
      "loss": 0.0098,
      "step": 698000
    },
    {
      "epoch": 0.0392493457271735,
      "grad_norm": 0.03724482282996178,
      "learning_rate": 9.612908122604394e-05,
      "loss": 0.0101,
      "step": 698500
    },
    {
      "epoch": 0.03927744117866038,
      "grad_norm": 0.30510273575782776,
      "learning_rate": 9.612627010129889e-05,
      "loss": 0.0105,
      "step": 699000
    },
    {
      "epoch": 0.03930553663014726,
      "grad_norm": 0.16031238436698914,
      "learning_rate": 9.612345897655381e-05,
      "loss": 0.0102,
      "step": 699500
    },
    {
      "epoch": 0.039333632081634144,
      "grad_norm": 0.24758991599082947,
      "learning_rate": 9.612064785180875e-05,
      "loss": 0.0098,
      "step": 700000
    },
    {
      "epoch": 0.039333632081634144,
      "eval_loss": 0.005714860744774342,
      "eval_runtime": 21.891,
      "eval_samples_per_second": 4568.096,
      "eval_steps_per_second": 71.399,
      "step": 700000
    },
    {
      "epoch": 0.039361727533121026,
      "grad_norm": 0.2910654544830322,
      "learning_rate": 9.611783672706368e-05,
      "loss": 0.0103,
      "step": 700500
    },
    {
      "epoch": 0.03938982298460791,
      "grad_norm": 0.19787395000457764,
      "learning_rate": 9.611502560231862e-05,
      "loss": 0.01,
      "step": 701000
    },
    {
      "epoch": 0.03941791843609479,
      "grad_norm": 0.30285927653312683,
      "learning_rate": 9.611221447757356e-05,
      "loss": 0.0099,
      "step": 701500
    },
    {
      "epoch": 0.03944601388758167,
      "grad_norm": 0.47025975584983826,
      "learning_rate": 9.610940335282848e-05,
      "loss": 0.0103,
      "step": 702000
    },
    {
      "epoch": 0.03947410933906855,
      "grad_norm": 0.19059333205223083,
      "learning_rate": 9.610659222808343e-05,
      "loss": 0.0103,
      "step": 702500
    },
    {
      "epoch": 0.03950220479055543,
      "grad_norm": 0.8007029891014099,
      "learning_rate": 9.610378110333835e-05,
      "loss": 0.01,
      "step": 703000
    },
    {
      "epoch": 0.039530300242042314,
      "grad_norm": 0.7203257083892822,
      "learning_rate": 9.610096997859329e-05,
      "loss": 0.0101,
      "step": 703500
    },
    {
      "epoch": 0.039558395693529196,
      "grad_norm": 0.16431428492069244,
      "learning_rate": 9.609815885384822e-05,
      "loss": 0.01,
      "step": 704000
    },
    {
      "epoch": 0.03958649114501608,
      "grad_norm": 0.23119065165519714,
      "learning_rate": 9.609534772910316e-05,
      "loss": 0.0101,
      "step": 704500
    },
    {
      "epoch": 0.03961458659650296,
      "grad_norm": 1.087343454360962,
      "learning_rate": 9.60925366043581e-05,
      "loss": 0.0093,
      "step": 705000
    },
    {
      "epoch": 0.03964268204798984,
      "grad_norm": 0.3464462459087372,
      "learning_rate": 9.608972547961302e-05,
      "loss": 0.0103,
      "step": 705500
    },
    {
      "epoch": 0.03967077749947672,
      "grad_norm": 0.17708919942378998,
      "learning_rate": 9.608691435486796e-05,
      "loss": 0.0098,
      "step": 706000
    },
    {
      "epoch": 0.0396988729509636,
      "grad_norm": 0.08647549152374268,
      "learning_rate": 9.608410323012289e-05,
      "loss": 0.0102,
      "step": 706500
    },
    {
      "epoch": 0.039726968402450484,
      "grad_norm": 0.41302987933158875,
      "learning_rate": 9.608129210537783e-05,
      "loss": 0.0101,
      "step": 707000
    },
    {
      "epoch": 0.039755063853937365,
      "grad_norm": 0.3867078125476837,
      "learning_rate": 9.607848098063276e-05,
      "loss": 0.0099,
      "step": 707500
    },
    {
      "epoch": 0.03978315930542425,
      "grad_norm": 0.3522298336029053,
      "learning_rate": 9.60756698558877e-05,
      "loss": 0.0096,
      "step": 708000
    },
    {
      "epoch": 0.03981125475691113,
      "grad_norm": 0.40010684728622437,
      "learning_rate": 9.607285873114263e-05,
      "loss": 0.0103,
      "step": 708500
    },
    {
      "epoch": 0.03983935020839801,
      "grad_norm": 0.20153342187404633,
      "learning_rate": 9.607004760639756e-05,
      "loss": 0.0102,
      "step": 709000
    },
    {
      "epoch": 0.03986744565988489,
      "grad_norm": 0.39571553468704224,
      "learning_rate": 9.60672364816525e-05,
      "loss": 0.0097,
      "step": 709500
    },
    {
      "epoch": 0.03989554111137177,
      "grad_norm": 0.6767528653144836,
      "learning_rate": 9.606442535690743e-05,
      "loss": 0.0099,
      "step": 710000
    },
    {
      "epoch": 0.03989554111137177,
      "eval_loss": 0.005798771977424622,
      "eval_runtime": 21.6735,
      "eval_samples_per_second": 4613.93,
      "eval_steps_per_second": 72.116,
      "step": 710000
    },
    {
      "epoch": 0.039923636562858654,
      "grad_norm": 0.33073902130126953,
      "learning_rate": 9.606161423216237e-05,
      "loss": 0.0096,
      "step": 710500
    },
    {
      "epoch": 0.039951732014345535,
      "grad_norm": 0.16313536465168,
      "learning_rate": 9.60588031074173e-05,
      "loss": 0.0098,
      "step": 711000
    },
    {
      "epoch": 0.03997982746583242,
      "grad_norm": 0.4379199743270874,
      "learning_rate": 9.605599198267223e-05,
      "loss": 0.0104,
      "step": 711500
    },
    {
      "epoch": 0.0400079229173193,
      "grad_norm": 0.12861427664756775,
      "learning_rate": 9.605318085792716e-05,
      "loss": 0.0099,
      "step": 712000
    },
    {
      "epoch": 0.04003601836880618,
      "grad_norm": 0.26462477445602417,
      "learning_rate": 9.60503697331821e-05,
      "loss": 0.0098,
      "step": 712500
    },
    {
      "epoch": 0.04006411382029306,
      "grad_norm": 0.11863231658935547,
      "learning_rate": 9.604755860843704e-05,
      "loss": 0.01,
      "step": 713000
    },
    {
      "epoch": 0.04009220927177994,
      "grad_norm": 0.07820233702659607,
      "learning_rate": 9.604474748369197e-05,
      "loss": 0.0096,
      "step": 713500
    },
    {
      "epoch": 0.040120304723266824,
      "grad_norm": 0.5471935868263245,
      "learning_rate": 9.60419363589469e-05,
      "loss": 0.0105,
      "step": 714000
    },
    {
      "epoch": 0.040148400174753705,
      "grad_norm": 0.4545566737651825,
      "learning_rate": 9.603912523420183e-05,
      "loss": 0.01,
      "step": 714500
    },
    {
      "epoch": 0.04017649562624059,
      "grad_norm": 0.4576303958892822,
      "learning_rate": 9.603631410945677e-05,
      "loss": 0.0095,
      "step": 715000
    },
    {
      "epoch": 0.04020459107772747,
      "grad_norm": 0.14379826188087463,
      "learning_rate": 9.60335029847117e-05,
      "loss": 0.0097,
      "step": 715500
    },
    {
      "epoch": 0.04023268652921435,
      "grad_norm": 0.49770447611808777,
      "learning_rate": 9.603069185996664e-05,
      "loss": 0.01,
      "step": 716000
    },
    {
      "epoch": 0.04026078198070123,
      "grad_norm": 0.3036491870880127,
      "learning_rate": 9.602788073522158e-05,
      "loss": 0.0102,
      "step": 716500
    },
    {
      "epoch": 0.04028887743218812,
      "grad_norm": 0.3816622793674469,
      "learning_rate": 9.60250696104765e-05,
      "loss": 0.0104,
      "step": 717000
    },
    {
      "epoch": 0.040316972883675,
      "grad_norm": 0.4247896075248718,
      "learning_rate": 9.602225848573145e-05,
      "loss": 0.01,
      "step": 717500
    },
    {
      "epoch": 0.04034506833516188,
      "grad_norm": 0.06392651796340942,
      "learning_rate": 9.601944736098637e-05,
      "loss": 0.0095,
      "step": 718000
    },
    {
      "epoch": 0.040373163786648764,
      "grad_norm": 0.3252761662006378,
      "learning_rate": 9.601663623624131e-05,
      "loss": 0.0101,
      "step": 718500
    },
    {
      "epoch": 0.040401259238135645,
      "grad_norm": 0.20123685896396637,
      "learning_rate": 9.601382511149623e-05,
      "loss": 0.0101,
      "step": 719000
    },
    {
      "epoch": 0.040429354689622526,
      "grad_norm": 0.17581261694431305,
      "learning_rate": 9.601101398675117e-05,
      "loss": 0.0102,
      "step": 719500
    },
    {
      "epoch": 0.04045745014110941,
      "grad_norm": 0.19027452170848846,
      "learning_rate": 9.60082028620061e-05,
      "loss": 0.0096,
      "step": 720000
    },
    {
      "epoch": 0.04045745014110941,
      "eval_loss": 0.0055234613828361034,
      "eval_runtime": 22.3095,
      "eval_samples_per_second": 4482.404,
      "eval_steps_per_second": 70.06,
      "step": 720000
    },
    {
      "epoch": 0.04048554559259629,
      "grad_norm": 0.45577552914619446,
      "learning_rate": 9.600539173726104e-05,
      "loss": 0.0103,
      "step": 720500
    },
    {
      "epoch": 0.04051364104408317,
      "grad_norm": 0.5142898559570312,
      "learning_rate": 9.600258061251599e-05,
      "loss": 0.0097,
      "step": 721000
    },
    {
      "epoch": 0.04054173649557005,
      "grad_norm": 0.09553756564855576,
      "learning_rate": 9.59997694877709e-05,
      "loss": 0.0106,
      "step": 721500
    },
    {
      "epoch": 0.040569831947056934,
      "grad_norm": 0.24082311987876892,
      "learning_rate": 9.599695836302584e-05,
      "loss": 0.0096,
      "step": 722000
    },
    {
      "epoch": 0.040597927398543815,
      "grad_norm": 0.0712345689535141,
      "learning_rate": 9.599414723828077e-05,
      "loss": 0.0096,
      "step": 722500
    },
    {
      "epoch": 0.040626022850030696,
      "grad_norm": 0.12132202833890915,
      "learning_rate": 9.599133611353571e-05,
      "loss": 0.0099,
      "step": 723000
    },
    {
      "epoch": 0.04065411830151758,
      "grad_norm": 0.413209468126297,
      "learning_rate": 9.598852498879064e-05,
      "loss": 0.0103,
      "step": 723500
    },
    {
      "epoch": 0.04068221375300446,
      "grad_norm": 0.2694492042064667,
      "learning_rate": 9.598571386404558e-05,
      "loss": 0.0094,
      "step": 724000
    },
    {
      "epoch": 0.04071030920449134,
      "grad_norm": 0.3078777492046356,
      "learning_rate": 9.598290273930051e-05,
      "loss": 0.0104,
      "step": 724500
    },
    {
      "epoch": 0.04073840465597822,
      "grad_norm": 0.08904270827770233,
      "learning_rate": 9.598009161455545e-05,
      "loss": 0.01,
      "step": 725000
    },
    {
      "epoch": 0.0407665001074651,
      "grad_norm": 0.5529532432556152,
      "learning_rate": 9.597728048981038e-05,
      "loss": 0.0097,
      "step": 725500
    },
    {
      "epoch": 0.040794595558951985,
      "grad_norm": 0.14867225289344788,
      "learning_rate": 9.597446936506531e-05,
      "loss": 0.0097,
      "step": 726000
    },
    {
      "epoch": 0.040822691010438866,
      "grad_norm": 0.030010508373379707,
      "learning_rate": 9.597165824032025e-05,
      "loss": 0.0101,
      "step": 726500
    },
    {
      "epoch": 0.04085078646192575,
      "grad_norm": 0.2890683710575104,
      "learning_rate": 9.596884711557518e-05,
      "loss": 0.0095,
      "step": 727000
    },
    {
      "epoch": 0.04087888191341263,
      "grad_norm": 0.20216180384159088,
      "learning_rate": 9.596603599083012e-05,
      "loss": 0.01,
      "step": 727500
    },
    {
      "epoch": 0.04090697736489951,
      "grad_norm": 0.20745445787906647,
      "learning_rate": 9.596322486608504e-05,
      "loss": 0.0096,
      "step": 728000
    },
    {
      "epoch": 0.04093507281638639,
      "grad_norm": 0.29274144768714905,
      "learning_rate": 9.596041374133999e-05,
      "loss": 0.0099,
      "step": 728500
    },
    {
      "epoch": 0.04096316826787327,
      "grad_norm": 0.24073857069015503,
      "learning_rate": 9.595760261659492e-05,
      "loss": 0.0097,
      "step": 729000
    },
    {
      "epoch": 0.040991263719360155,
      "grad_norm": 0.6718494296073914,
      "learning_rate": 9.595479149184985e-05,
      "loss": 0.0098,
      "step": 729500
    },
    {
      "epoch": 0.041019359170847036,
      "grad_norm": 0.5161051154136658,
      "learning_rate": 9.595198036710479e-05,
      "loss": 0.0099,
      "step": 730000
    },
    {
      "epoch": 0.041019359170847036,
      "eval_loss": 0.005736262071877718,
      "eval_runtime": 22.8193,
      "eval_samples_per_second": 4382.252,
      "eval_steps_per_second": 68.495,
      "step": 730000
    },
    {
      "epoch": 0.04104745462233392,
      "grad_norm": 0.1495356261730194,
      "learning_rate": 9.594916924235971e-05,
      "loss": 0.0098,
      "step": 730500
    },
    {
      "epoch": 0.0410755500738208,
      "grad_norm": 0.4240742325782776,
      "learning_rate": 9.594635811761466e-05,
      "loss": 0.0105,
      "step": 731000
    },
    {
      "epoch": 0.04110364552530768,
      "grad_norm": 0.30969977378845215,
      "learning_rate": 9.594354699286958e-05,
      "loss": 0.0097,
      "step": 731500
    },
    {
      "epoch": 0.04113174097679456,
      "grad_norm": 0.31630009412765503,
      "learning_rate": 9.594073586812453e-05,
      "loss": 0.0095,
      "step": 732000
    },
    {
      "epoch": 0.04115983642828144,
      "grad_norm": 0.1165136992931366,
      "learning_rate": 9.593792474337946e-05,
      "loss": 0.0099,
      "step": 732500
    },
    {
      "epoch": 0.041187931879768325,
      "grad_norm": 0.25421878695487976,
      "learning_rate": 9.593511361863438e-05,
      "loss": 0.0101,
      "step": 733000
    },
    {
      "epoch": 0.041216027331255206,
      "grad_norm": 0.40881529450416565,
      "learning_rate": 9.593230249388933e-05,
      "loss": 0.0099,
      "step": 733500
    },
    {
      "epoch": 0.04124412278274209,
      "grad_norm": 0.19463124871253967,
      "learning_rate": 9.592949136914425e-05,
      "loss": 0.0105,
      "step": 734000
    },
    {
      "epoch": 0.04127221823422897,
      "grad_norm": 0.19592370092868805,
      "learning_rate": 9.59266802443992e-05,
      "loss": 0.0097,
      "step": 734500
    },
    {
      "epoch": 0.04130031368571585,
      "grad_norm": 0.38478103280067444,
      "learning_rate": 9.592386911965412e-05,
      "loss": 0.0099,
      "step": 735000
    },
    {
      "epoch": 0.04132840913720273,
      "grad_norm": 0.2259792536497116,
      "learning_rate": 9.592105799490906e-05,
      "loss": 0.0098,
      "step": 735500
    },
    {
      "epoch": 0.04135650458868961,
      "grad_norm": 0.09315794706344604,
      "learning_rate": 9.5918246870164e-05,
      "loss": 0.0108,
      "step": 736000
    },
    {
      "epoch": 0.041384600040176495,
      "grad_norm": 0.4985218942165375,
      "learning_rate": 9.591543574541892e-05,
      "loss": 0.0099,
      "step": 736500
    },
    {
      "epoch": 0.041412695491663376,
      "grad_norm": 0.7767647504806519,
      "learning_rate": 9.591262462067387e-05,
      "loss": 0.0096,
      "step": 737000
    },
    {
      "epoch": 0.04144079094315026,
      "grad_norm": 0.03894205018877983,
      "learning_rate": 9.590981349592879e-05,
      "loss": 0.0097,
      "step": 737500
    },
    {
      "epoch": 0.04146888639463714,
      "grad_norm": 0.49047592282295227,
      "learning_rate": 9.590700237118374e-05,
      "loss": 0.0098,
      "step": 738000
    },
    {
      "epoch": 0.04149698184612402,
      "grad_norm": 0.8826667666435242,
      "learning_rate": 9.590419124643866e-05,
      "loss": 0.0097,
      "step": 738500
    },
    {
      "epoch": 0.0415250772976109,
      "grad_norm": 0.05788908153772354,
      "learning_rate": 9.590138012169359e-05,
      "loss": 0.0099,
      "step": 739000
    },
    {
      "epoch": 0.04155317274909778,
      "grad_norm": 0.04656201973557472,
      "learning_rate": 9.589856899694853e-05,
      "loss": 0.0096,
      "step": 739500
    },
    {
      "epoch": 0.041581268200584665,
      "grad_norm": 0.16849946975708008,
      "learning_rate": 9.589575787220346e-05,
      "loss": 0.0093,
      "step": 740000
    },
    {
      "epoch": 0.041581268200584665,
      "eval_loss": 0.0055123805068433285,
      "eval_runtime": 29.2061,
      "eval_samples_per_second": 3423.944,
      "eval_steps_per_second": 53.516,
      "step": 740000
    },
    {
      "epoch": 0.041609363652071546,
      "grad_norm": 0.12794287502765656,
      "learning_rate": 9.589294674745841e-05,
      "loss": 0.0096,
      "step": 740500
    },
    {
      "epoch": 0.04163745910355843,
      "grad_norm": 0.13573603332042694,
      "learning_rate": 9.589013562271333e-05,
      "loss": 0.0094,
      "step": 741000
    },
    {
      "epoch": 0.04166555455504531,
      "grad_norm": 0.3365662693977356,
      "learning_rate": 9.588732449796826e-05,
      "loss": 0.0102,
      "step": 741500
    },
    {
      "epoch": 0.04169365000653219,
      "grad_norm": 0.2712095081806183,
      "learning_rate": 9.58845133732232e-05,
      "loss": 0.0105,
      "step": 742000
    },
    {
      "epoch": 0.04172174545801907,
      "grad_norm": 0.19157256186008453,
      "learning_rate": 9.588170224847813e-05,
      "loss": 0.0102,
      "step": 742500
    },
    {
      "epoch": 0.04174984090950595,
      "grad_norm": 0.2861427962779999,
      "learning_rate": 9.587889112373307e-05,
      "loss": 0.0097,
      "step": 743000
    },
    {
      "epoch": 0.041777936360992834,
      "grad_norm": 0.5011641383171082,
      "learning_rate": 9.5876079998988e-05,
      "loss": 0.0101,
      "step": 743500
    },
    {
      "epoch": 0.041806031812479716,
      "grad_norm": 0.1440792977809906,
      "learning_rate": 9.587326887424293e-05,
      "loss": 0.0093,
      "step": 744000
    },
    {
      "epoch": 0.0418341272639666,
      "grad_norm": 0.13598018884658813,
      "learning_rate": 9.587045774949787e-05,
      "loss": 0.0104,
      "step": 744500
    },
    {
      "epoch": 0.04186222271545348,
      "grad_norm": 0.12164291739463806,
      "learning_rate": 9.58676466247528e-05,
      "loss": 0.0099,
      "step": 745000
    },
    {
      "epoch": 0.04189031816694036,
      "grad_norm": 0.5382039546966553,
      "learning_rate": 9.586483550000774e-05,
      "loss": 0.0107,
      "step": 745500
    },
    {
      "epoch": 0.04191841361842724,
      "grad_norm": 0.35780665278434753,
      "learning_rate": 9.586202437526267e-05,
      "loss": 0.0098,
      "step": 746000
    },
    {
      "epoch": 0.04194650906991412,
      "grad_norm": 0.2647660970687866,
      "learning_rate": 9.58592132505176e-05,
      "loss": 0.0104,
      "step": 746500
    },
    {
      "epoch": 0.041974604521401004,
      "grad_norm": 0.09898874908685684,
      "learning_rate": 9.585640212577254e-05,
      "loss": 0.0096,
      "step": 747000
    },
    {
      "epoch": 0.04200269997288789,
      "grad_norm": 0.1123654842376709,
      "learning_rate": 9.585359100102746e-05,
      "loss": 0.0095,
      "step": 747500
    },
    {
      "epoch": 0.042030795424374774,
      "grad_norm": 0.2501075267791748,
      "learning_rate": 9.585077987628241e-05,
      "loss": 0.0099,
      "step": 748000
    },
    {
      "epoch": 0.042058890875861656,
      "grad_norm": 0.08604743331670761,
      "learning_rate": 9.584796875153734e-05,
      "loss": 0.0093,
      "step": 748500
    },
    {
      "epoch": 0.04208698632734854,
      "grad_norm": 0.38834044337272644,
      "learning_rate": 9.584515762679228e-05,
      "loss": 0.01,
      "step": 749000
    },
    {
      "epoch": 0.04211508177883542,
      "grad_norm": 0.2280297875404358,
      "learning_rate": 9.584234650204721e-05,
      "loss": 0.01,
      "step": 749500
    },
    {
      "epoch": 0.0421431772303223,
      "grad_norm": 0.6903882026672363,
      "learning_rate": 9.583953537730213e-05,
      "loss": 0.0099,
      "step": 750000
    },
    {
      "epoch": 0.0421431772303223,
      "eval_loss": 0.005564965307712555,
      "eval_runtime": 22.9742,
      "eval_samples_per_second": 4352.706,
      "eval_steps_per_second": 68.033,
      "step": 750000
    },
    {
      "epoch": 0.04217127268180918,
      "grad_norm": 0.11845780909061432,
      "learning_rate": 9.583672425255708e-05,
      "loss": 0.0101,
      "step": 750500
    },
    {
      "epoch": 0.04219936813329606,
      "grad_norm": 0.08647377043962479,
      "learning_rate": 9.5833913127812e-05,
      "loss": 0.0096,
      "step": 751000
    },
    {
      "epoch": 0.042227463584782944,
      "grad_norm": 0.2764469385147095,
      "learning_rate": 9.583110200306695e-05,
      "loss": 0.0102,
      "step": 751500
    },
    {
      "epoch": 0.042255559036269826,
      "grad_norm": 0.3733387291431427,
      "learning_rate": 9.582829087832188e-05,
      "loss": 0.0101,
      "step": 752000
    },
    {
      "epoch": 0.04228365448775671,
      "grad_norm": 0.3735273480415344,
      "learning_rate": 9.58254797535768e-05,
      "loss": 0.0095,
      "step": 752500
    },
    {
      "epoch": 0.04231174993924359,
      "grad_norm": 0.13473372161388397,
      "learning_rate": 9.582266862883175e-05,
      "loss": 0.0097,
      "step": 753000
    },
    {
      "epoch": 0.04233984539073047,
      "grad_norm": 0.16246667504310608,
      "learning_rate": 9.581985750408667e-05,
      "loss": 0.0097,
      "step": 753500
    },
    {
      "epoch": 0.04236794084221735,
      "grad_norm": 0.3399142026901245,
      "learning_rate": 9.581704637934162e-05,
      "loss": 0.0099,
      "step": 754000
    },
    {
      "epoch": 0.04239603629370423,
      "grad_norm": 0.19086286425590515,
      "learning_rate": 9.581423525459654e-05,
      "loss": 0.0097,
      "step": 754500
    },
    {
      "epoch": 0.042424131745191114,
      "grad_norm": 0.7569756507873535,
      "learning_rate": 9.581142412985147e-05,
      "loss": 0.0097,
      "step": 755000
    },
    {
      "epoch": 0.042452227196677995,
      "grad_norm": 0.836261510848999,
      "learning_rate": 9.580861300510642e-05,
      "loss": 0.0098,
      "step": 755500
    },
    {
      "epoch": 0.04248032264816488,
      "grad_norm": 0.03769799694418907,
      "learning_rate": 9.580580188036134e-05,
      "loss": 0.0099,
      "step": 756000
    },
    {
      "epoch": 0.04250841809965176,
      "grad_norm": 0.8290422558784485,
      "learning_rate": 9.580299075561629e-05,
      "loss": 0.0099,
      "step": 756500
    },
    {
      "epoch": 0.04253651355113864,
      "grad_norm": 0.15137778222560883,
      "learning_rate": 9.580017963087121e-05,
      "loss": 0.0095,
      "step": 757000
    },
    {
      "epoch": 0.04256460900262552,
      "grad_norm": 0.6497160196304321,
      "learning_rate": 9.579736850612614e-05,
      "loss": 0.0099,
      "step": 757500
    },
    {
      "epoch": 0.0425927044541124,
      "grad_norm": 0.27801576256752014,
      "learning_rate": 9.579455738138108e-05,
      "loss": 0.0099,
      "step": 758000
    },
    {
      "epoch": 0.042620799905599284,
      "grad_norm": 0.5570974349975586,
      "learning_rate": 9.579174625663601e-05,
      "loss": 0.0104,
      "step": 758500
    },
    {
      "epoch": 0.042648895357086165,
      "grad_norm": 0.3263053894042969,
      "learning_rate": 9.578893513189095e-05,
      "loss": 0.0103,
      "step": 759000
    },
    {
      "epoch": 0.04267699080857305,
      "grad_norm": 0.10713844001293182,
      "learning_rate": 9.578612400714588e-05,
      "loss": 0.0093,
      "step": 759500
    },
    {
      "epoch": 0.04270508626005993,
      "grad_norm": 0.4424535930156708,
      "learning_rate": 9.578331288240082e-05,
      "loss": 0.0098,
      "step": 760000
    },
    {
      "epoch": 0.04270508626005993,
      "eval_loss": 0.005356182809919119,
      "eval_runtime": 21.4151,
      "eval_samples_per_second": 4669.604,
      "eval_steps_per_second": 72.986,
      "step": 760000
    },
    {
      "epoch": 0.04273318171154681,
      "grad_norm": 0.06494659930467606,
      "learning_rate": 9.578050175765575e-05,
      "loss": 0.0094,
      "step": 760500
    },
    {
      "epoch": 0.04276127716303369,
      "grad_norm": 0.04640860855579376,
      "learning_rate": 9.577769063291068e-05,
      "loss": 0.0097,
      "step": 761000
    },
    {
      "epoch": 0.04278937261452057,
      "grad_norm": 0.09727821499109268,
      "learning_rate": 9.577487950816562e-05,
      "loss": 0.0093,
      "step": 761500
    },
    {
      "epoch": 0.042817468066007454,
      "grad_norm": 0.28397130966186523,
      "learning_rate": 9.577206838342055e-05,
      "loss": 0.0097,
      "step": 762000
    },
    {
      "epoch": 0.042845563517494335,
      "grad_norm": 0.3108864724636078,
      "learning_rate": 9.576925725867549e-05,
      "loss": 0.0104,
      "step": 762500
    },
    {
      "epoch": 0.04287365896898122,
      "grad_norm": 1.0553042888641357,
      "learning_rate": 9.576644613393042e-05,
      "loss": 0.0095,
      "step": 763000
    },
    {
      "epoch": 0.0429017544204681,
      "grad_norm": 0.5482005476951599,
      "learning_rate": 9.576363500918536e-05,
      "loss": 0.0089,
      "step": 763500
    },
    {
      "epoch": 0.04292984987195498,
      "grad_norm": 0.49153932929039,
      "learning_rate": 9.576082388444029e-05,
      "loss": 0.0097,
      "step": 764000
    },
    {
      "epoch": 0.04295794532344186,
      "grad_norm": 0.4861029088497162,
      "learning_rate": 9.575801275969522e-05,
      "loss": 0.009,
      "step": 764500
    },
    {
      "epoch": 0.04298604077492874,
      "grad_norm": 0.20925405621528625,
      "learning_rate": 9.575520163495016e-05,
      "loss": 0.0096,
      "step": 765000
    },
    {
      "epoch": 0.043014136226415624,
      "grad_norm": 0.14814886450767517,
      "learning_rate": 9.575239051020509e-05,
      "loss": 0.0096,
      "step": 765500
    },
    {
      "epoch": 0.043042231677902505,
      "grad_norm": 0.570945143699646,
      "learning_rate": 9.574957938546001e-05,
      "loss": 0.0095,
      "step": 766000
    },
    {
      "epoch": 0.04307032712938939,
      "grad_norm": 0.08216442912817001,
      "learning_rate": 9.574676826071496e-05,
      "loss": 0.0098,
      "step": 766500
    },
    {
      "epoch": 0.04309842258087627,
      "grad_norm": 0.14209987223148346,
      "learning_rate": 9.57439571359699e-05,
      "loss": 0.0099,
      "step": 767000
    },
    {
      "epoch": 0.04312651803236315,
      "grad_norm": 0.37665313482284546,
      "learning_rate": 9.574114601122483e-05,
      "loss": 0.0096,
      "step": 767500
    },
    {
      "epoch": 0.04315461348385003,
      "grad_norm": 0.06881100684404373,
      "learning_rate": 9.573833488647976e-05,
      "loss": 0.0097,
      "step": 768000
    },
    {
      "epoch": 0.04318270893533691,
      "grad_norm": 0.20379550755023956,
      "learning_rate": 9.573552376173468e-05,
      "loss": 0.0093,
      "step": 768500
    },
    {
      "epoch": 0.043210804386823794,
      "grad_norm": 0.5685663819313049,
      "learning_rate": 9.573271263698963e-05,
      "loss": 0.0098,
      "step": 769000
    },
    {
      "epoch": 0.043238899838310675,
      "grad_norm": 0.17691567540168762,
      "learning_rate": 9.572990151224455e-05,
      "loss": 0.0092,
      "step": 769500
    },
    {
      "epoch": 0.04326699528979756,
      "grad_norm": 0.5803757309913635,
      "learning_rate": 9.57270903874995e-05,
      "loss": 0.0096,
      "step": 770000
    },
    {
      "epoch": 0.04326699528979756,
      "eval_loss": 0.005476799793541431,
      "eval_runtime": 22.1527,
      "eval_samples_per_second": 4514.125,
      "eval_steps_per_second": 70.556,
      "step": 770000
    },
    {
      "epoch": 0.04329509074128444,
      "grad_norm": 0.7151069641113281,
      "learning_rate": 9.572427926275442e-05,
      "loss": 0.0104,
      "step": 770500
    },
    {
      "epoch": 0.04332318619277132,
      "grad_norm": 0.4516797661781311,
      "learning_rate": 9.572146813800937e-05,
      "loss": 0.0095,
      "step": 771000
    },
    {
      "epoch": 0.0433512816442582,
      "grad_norm": 0.23963193595409393,
      "learning_rate": 9.57186570132643e-05,
      "loss": 0.0095,
      "step": 771500
    },
    {
      "epoch": 0.04337937709574508,
      "grad_norm": 0.14383679628372192,
      "learning_rate": 9.571584588851922e-05,
      "loss": 0.0098,
      "step": 772000
    },
    {
      "epoch": 0.043407472547231964,
      "grad_norm": 0.3651216924190521,
      "learning_rate": 9.571303476377417e-05,
      "loss": 0.0097,
      "step": 772500
    },
    {
      "epoch": 0.043435567998718845,
      "grad_norm": 0.18118681013584137,
      "learning_rate": 9.571022363902909e-05,
      "loss": 0.009,
      "step": 773000
    },
    {
      "epoch": 0.043463663450205726,
      "grad_norm": 0.38917505741119385,
      "learning_rate": 9.570741251428404e-05,
      "loss": 0.0097,
      "step": 773500
    },
    {
      "epoch": 0.04349175890169261,
      "grad_norm": 0.21130119264125824,
      "learning_rate": 9.570460138953896e-05,
      "loss": 0.0094,
      "step": 774000
    },
    {
      "epoch": 0.04351985435317949,
      "grad_norm": 1.2284274101257324,
      "learning_rate": 9.57017902647939e-05,
      "loss": 0.01,
      "step": 774500
    },
    {
      "epoch": 0.04354794980466637,
      "grad_norm": 0.3863881826400757,
      "learning_rate": 9.569897914004884e-05,
      "loss": 0.0099,
      "step": 775000
    },
    {
      "epoch": 0.04357604525615325,
      "grad_norm": 0.2105896919965744,
      "learning_rate": 9.569616801530376e-05,
      "loss": 0.0096,
      "step": 775500
    },
    {
      "epoch": 0.043604140707640134,
      "grad_norm": 0.30266517400741577,
      "learning_rate": 9.569335689055871e-05,
      "loss": 0.0097,
      "step": 776000
    },
    {
      "epoch": 0.043632236159127015,
      "grad_norm": 0.7219531536102295,
      "learning_rate": 9.569054576581363e-05,
      "loss": 0.0096,
      "step": 776500
    },
    {
      "epoch": 0.043660331610613896,
      "grad_norm": 0.3664410412311554,
      "learning_rate": 9.568773464106857e-05,
      "loss": 0.0094,
      "step": 777000
    },
    {
      "epoch": 0.04368842706210078,
      "grad_norm": 0.13637232780456543,
      "learning_rate": 9.56849235163235e-05,
      "loss": 0.0101,
      "step": 777500
    },
    {
      "epoch": 0.043716522513587666,
      "grad_norm": 0.19545195996761322,
      "learning_rate": 9.568211239157844e-05,
      "loss": 0.0095,
      "step": 778000
    },
    {
      "epoch": 0.04374461796507455,
      "grad_norm": 0.31213876605033875,
      "learning_rate": 9.567930126683337e-05,
      "loss": 0.01,
      "step": 778500
    },
    {
      "epoch": 0.04377271341656143,
      "grad_norm": 0.2750614583492279,
      "learning_rate": 9.56764901420883e-05,
      "loss": 0.0092,
      "step": 779000
    },
    {
      "epoch": 0.04380080886804831,
      "grad_norm": 0.09628211706876755,
      "learning_rate": 9.567367901734324e-05,
      "loss": 0.0102,
      "step": 779500
    },
    {
      "epoch": 0.04382890431953519,
      "grad_norm": 0.17495852708816528,
      "learning_rate": 9.567086789259817e-05,
      "loss": 0.0097,
      "step": 780000
    },
    {
      "epoch": 0.04382890431953519,
      "eval_loss": 0.005521629471331835,
      "eval_runtime": 20.0302,
      "eval_samples_per_second": 4992.47,
      "eval_steps_per_second": 78.032,
      "step": 780000
    },
    {
      "epoch": 0.04385699977102207,
      "grad_norm": 0.26168766617774963,
      "learning_rate": 9.56680567678531e-05,
      "loss": 0.0097,
      "step": 780500
    },
    {
      "epoch": 0.043885095222508955,
      "grad_norm": 0.41425997018814087,
      "learning_rate": 9.566524564310804e-05,
      "loss": 0.0091,
      "step": 781000
    },
    {
      "epoch": 0.043913190673995836,
      "grad_norm": 0.17976686358451843,
      "learning_rate": 9.566243451836297e-05,
      "loss": 0.0097,
      "step": 781500
    },
    {
      "epoch": 0.04394128612548272,
      "grad_norm": 0.5276573300361633,
      "learning_rate": 9.565962339361791e-05,
      "loss": 0.0095,
      "step": 782000
    },
    {
      "epoch": 0.0439693815769696,
      "grad_norm": 0.12244046479463577,
      "learning_rate": 9.565681226887284e-05,
      "loss": 0.0096,
      "step": 782500
    },
    {
      "epoch": 0.04399747702845648,
      "grad_norm": 0.29249492287635803,
      "learning_rate": 9.565400114412778e-05,
      "loss": 0.0094,
      "step": 783000
    },
    {
      "epoch": 0.04402557247994336,
      "grad_norm": 0.05329027771949768,
      "learning_rate": 9.565119001938271e-05,
      "loss": 0.0099,
      "step": 783500
    },
    {
      "epoch": 0.04405366793143024,
      "grad_norm": 0.5464810729026794,
      "learning_rate": 9.564837889463765e-05,
      "loss": 0.0094,
      "step": 784000
    },
    {
      "epoch": 0.044081763382917125,
      "grad_norm": 0.28654229640960693,
      "learning_rate": 9.564556776989258e-05,
      "loss": 0.0098,
      "step": 784500
    },
    {
      "epoch": 0.044109858834404006,
      "grad_norm": 0.21717271208763123,
      "learning_rate": 9.564275664514751e-05,
      "loss": 0.0091,
      "step": 785000
    },
    {
      "epoch": 0.04413795428589089,
      "grad_norm": 0.2602267563343048,
      "learning_rate": 9.563994552040244e-05,
      "loss": 0.01,
      "step": 785500
    },
    {
      "epoch": 0.04416604973737777,
      "grad_norm": 0.8347000479698181,
      "learning_rate": 9.563713439565738e-05,
      "loss": 0.0096,
      "step": 786000
    },
    {
      "epoch": 0.04419414518886465,
      "grad_norm": 0.08057591319084167,
      "learning_rate": 9.563432327091232e-05,
      "loss": 0.0096,
      "step": 786500
    },
    {
      "epoch": 0.04422224064035153,
      "grad_norm": 0.6261085867881775,
      "learning_rate": 9.563151214616725e-05,
      "loss": 0.0097,
      "step": 787000
    },
    {
      "epoch": 0.04425033609183841,
      "grad_norm": 0.09664259105920792,
      "learning_rate": 9.562870102142219e-05,
      "loss": 0.0098,
      "step": 787500
    },
    {
      "epoch": 0.044278431543325295,
      "grad_norm": 0.4647064208984375,
      "learning_rate": 9.56258898966771e-05,
      "loss": 0.0095,
      "step": 788000
    },
    {
      "epoch": 0.044306526994812176,
      "grad_norm": 0.4570316672325134,
      "learning_rate": 9.562307877193205e-05,
      "loss": 0.0098,
      "step": 788500
    },
    {
      "epoch": 0.04433462244629906,
      "grad_norm": 0.42581406235694885,
      "learning_rate": 9.562026764718697e-05,
      "loss": 0.0094,
      "step": 789000
    },
    {
      "epoch": 0.04436271789778594,
      "grad_norm": 0.24796003103256226,
      "learning_rate": 9.561745652244192e-05,
      "loss": 0.0094,
      "step": 789500
    },
    {
      "epoch": 0.04439081334927282,
      "grad_norm": 0.20687852799892426,
      "learning_rate": 9.561464539769684e-05,
      "loss": 0.01,
      "step": 790000
    },
    {
      "epoch": 0.04439081334927282,
      "eval_loss": 0.0055220541544258595,
      "eval_runtime": 19.507,
      "eval_samples_per_second": 5126.362,
      "eval_steps_per_second": 80.125,
      "step": 790000
    },
    {
      "epoch": 0.0444189088007597,
      "grad_norm": 0.850761890411377,
      "learning_rate": 9.561183427295178e-05,
      "loss": 0.0094,
      "step": 790500
    },
    {
      "epoch": 0.04444700425224658,
      "grad_norm": 0.14784882962703705,
      "learning_rate": 9.560902314820673e-05,
      "loss": 0.0093,
      "step": 791000
    },
    {
      "epoch": 0.044475099703733464,
      "grad_norm": 0.24739307165145874,
      "learning_rate": 9.560621202346165e-05,
      "loss": 0.0094,
      "step": 791500
    },
    {
      "epoch": 0.044503195155220346,
      "grad_norm": 0.26704326272010803,
      "learning_rate": 9.56034008987166e-05,
      "loss": 0.0097,
      "step": 792000
    },
    {
      "epoch": 0.04453129060670723,
      "grad_norm": 0.3459339141845703,
      "learning_rate": 9.560058977397151e-05,
      "loss": 0.0093,
      "step": 792500
    },
    {
      "epoch": 0.04455938605819411,
      "grad_norm": 0.23495055735111237,
      "learning_rate": 9.559777864922645e-05,
      "loss": 0.0094,
      "step": 793000
    },
    {
      "epoch": 0.04458748150968099,
      "grad_norm": 0.41639888286590576,
      "learning_rate": 9.559496752448138e-05,
      "loss": 0.0096,
      "step": 793500
    },
    {
      "epoch": 0.04461557696116787,
      "grad_norm": 0.5235443711280823,
      "learning_rate": 9.559215639973632e-05,
      "loss": 0.0094,
      "step": 794000
    },
    {
      "epoch": 0.04464367241265475,
      "grad_norm": 0.04646289721131325,
      "learning_rate": 9.558934527499127e-05,
      "loss": 0.0099,
      "step": 794500
    },
    {
      "epoch": 0.044671767864141634,
      "grad_norm": 0.07178719341754913,
      "learning_rate": 9.558653415024619e-05,
      "loss": 0.0095,
      "step": 795000
    },
    {
      "epoch": 0.044699863315628516,
      "grad_norm": 0.45051223039627075,
      "learning_rate": 9.558372302550112e-05,
      "loss": 0.0093,
      "step": 795500
    },
    {
      "epoch": 0.0447279587671154,
      "grad_norm": 0.10413616895675659,
      "learning_rate": 9.558091190075605e-05,
      "loss": 0.0096,
      "step": 796000
    },
    {
      "epoch": 0.04475605421860228,
      "grad_norm": 0.02635795623064041,
      "learning_rate": 9.557810077601099e-05,
      "loss": 0.0089,
      "step": 796500
    },
    {
      "epoch": 0.04478414967008916,
      "grad_norm": 0.6203141212463379,
      "learning_rate": 9.557528965126592e-05,
      "loss": 0.0093,
      "step": 797000
    },
    {
      "epoch": 0.04481224512157604,
      "grad_norm": 0.17070211470127106,
      "learning_rate": 9.557247852652086e-05,
      "loss": 0.0094,
      "step": 797500
    },
    {
      "epoch": 0.04484034057306292,
      "grad_norm": 0.26371267437934875,
      "learning_rate": 9.556966740177579e-05,
      "loss": 0.0093,
      "step": 798000
    },
    {
      "epoch": 0.044868436024549804,
      "grad_norm": 0.31330323219299316,
      "learning_rate": 9.556685627703073e-05,
      "loss": 0.0093,
      "step": 798500
    },
    {
      "epoch": 0.044896531476036686,
      "grad_norm": 0.7210363149642944,
      "learning_rate": 9.556404515228566e-05,
      "loss": 0.0097,
      "step": 799000
    },
    {
      "epoch": 0.04492462692752357,
      "grad_norm": 0.6795923113822937,
      "learning_rate": 9.55612340275406e-05,
      "loss": 0.0097,
      "step": 799500
    },
    {
      "epoch": 0.04495272237901045,
      "grad_norm": 0.1488826423883438,
      "learning_rate": 9.555842290279553e-05,
      "loss": 0.0095,
      "step": 800000
    },
    {
      "epoch": 0.04495272237901045,
      "eval_loss": 0.005527178291231394,
      "eval_runtime": 18.5267,
      "eval_samples_per_second": 5397.623,
      "eval_steps_per_second": 84.365,
      "step": 800000
    },
    {
      "epoch": 0.04498081783049733,
      "grad_norm": 0.3142434358596802,
      "learning_rate": 9.555561177805046e-05,
      "loss": 0.0091,
      "step": 800500
    },
    {
      "epoch": 0.04500891328198421,
      "grad_norm": 0.4490847587585449,
      "learning_rate": 9.55528006533054e-05,
      "loss": 0.0095,
      "step": 801000
    },
    {
      "epoch": 0.04503700873347109,
      "grad_norm": 0.10019293427467346,
      "learning_rate": 9.554998952856032e-05,
      "loss": 0.0091,
      "step": 801500
    },
    {
      "epoch": 0.045065104184957974,
      "grad_norm": 0.21093811094760895,
      "learning_rate": 9.554717840381527e-05,
      "loss": 0.0097,
      "step": 802000
    },
    {
      "epoch": 0.045093199636444856,
      "grad_norm": 0.34385043382644653,
      "learning_rate": 9.55443672790702e-05,
      "loss": 0.01,
      "step": 802500
    },
    {
      "epoch": 0.04512129508793174,
      "grad_norm": 0.5444852709770203,
      "learning_rate": 9.554155615432513e-05,
      "loss": 0.0092,
      "step": 803000
    },
    {
      "epoch": 0.04514939053941862,
      "grad_norm": 0.4679488241672516,
      "learning_rate": 9.553874502958007e-05,
      "loss": 0.0096,
      "step": 803500
    },
    {
      "epoch": 0.0451774859909055,
      "grad_norm": 0.2575174868106842,
      "learning_rate": 9.5535933904835e-05,
      "loss": 0.0095,
      "step": 804000
    },
    {
      "epoch": 0.04520558144239238,
      "grad_norm": 0.5412214994430542,
      "learning_rate": 9.553312278008994e-05,
      "loss": 0.0096,
      "step": 804500
    },
    {
      "epoch": 0.04523367689387926,
      "grad_norm": 0.17716334760189056,
      "learning_rate": 9.553031165534486e-05,
      "loss": 0.0097,
      "step": 805000
    },
    {
      "epoch": 0.045261772345366144,
      "grad_norm": 0.07122750580310822,
      "learning_rate": 9.55275005305998e-05,
      "loss": 0.0093,
      "step": 805500
    },
    {
      "epoch": 0.045289867796853026,
      "grad_norm": 0.2628433406352997,
      "learning_rate": 9.552468940585474e-05,
      "loss": 0.0094,
      "step": 806000
    },
    {
      "epoch": 0.04531796324833991,
      "grad_norm": 0.055870212614536285,
      "learning_rate": 9.552187828110967e-05,
      "loss": 0.0092,
      "step": 806500
    },
    {
      "epoch": 0.04534605869982679,
      "grad_norm": 0.3402252197265625,
      "learning_rate": 9.551906715636461e-05,
      "loss": 0.009,
      "step": 807000
    },
    {
      "epoch": 0.04537415415131367,
      "grad_norm": 0.19029918313026428,
      "learning_rate": 9.551625603161953e-05,
      "loss": 0.0097,
      "step": 807500
    },
    {
      "epoch": 0.04540224960280055,
      "grad_norm": 0.34501680731773376,
      "learning_rate": 9.551344490687448e-05,
      "loss": 0.009,
      "step": 808000
    },
    {
      "epoch": 0.04543034505428744,
      "grad_norm": 0.18194636702537537,
      "learning_rate": 9.55106337821294e-05,
      "loss": 0.0096,
      "step": 808500
    },
    {
      "epoch": 0.04545844050577432,
      "grad_norm": 0.029935555532574654,
      "learning_rate": 9.550782265738434e-05,
      "loss": 0.0095,
      "step": 809000
    },
    {
      "epoch": 0.0454865359572612,
      "grad_norm": 0.5298894643783569,
      "learning_rate": 9.550501153263927e-05,
      "loss": 0.0099,
      "step": 809500
    },
    {
      "epoch": 0.045514631408748084,
      "grad_norm": 0.0731540247797966,
      "learning_rate": 9.55022004078942e-05,
      "loss": 0.0093,
      "step": 810000
    },
    {
      "epoch": 0.045514631408748084,
      "eval_loss": 0.005563952028751373,
      "eval_runtime": 19.5838,
      "eval_samples_per_second": 5106.268,
      "eval_steps_per_second": 79.811,
      "step": 810000
    },
    {
      "epoch": 0.045542726860234965,
      "grad_norm": 0.2841494381427765,
      "learning_rate": 9.549938928314915e-05,
      "loss": 0.0097,
      "step": 810500
    },
    {
      "epoch": 0.04557082231172185,
      "grad_norm": 0.27725648880004883,
      "learning_rate": 9.549657815840407e-05,
      "loss": 0.01,
      "step": 811000
    },
    {
      "epoch": 0.04559891776320873,
      "grad_norm": 0.3351438343524933,
      "learning_rate": 9.549376703365902e-05,
      "loss": 0.0092,
      "step": 811500
    },
    {
      "epoch": 0.04562701321469561,
      "grad_norm": 0.32415300607681274,
      "learning_rate": 9.549095590891394e-05,
      "loss": 0.0092,
      "step": 812000
    },
    {
      "epoch": 0.04565510866618249,
      "grad_norm": 0.8180739879608154,
      "learning_rate": 9.548814478416887e-05,
      "loss": 0.0093,
      "step": 812500
    },
    {
      "epoch": 0.04568320411766937,
      "grad_norm": 0.18442600965499878,
      "learning_rate": 9.54853336594238e-05,
      "loss": 0.0097,
      "step": 813000
    },
    {
      "epoch": 0.045711299569156254,
      "grad_norm": 0.0491330623626709,
      "learning_rate": 9.548252253467874e-05,
      "loss": 0.0097,
      "step": 813500
    },
    {
      "epoch": 0.045739395020643135,
      "grad_norm": 0.4649833142757416,
      "learning_rate": 9.547971140993369e-05,
      "loss": 0.0092,
      "step": 814000
    },
    {
      "epoch": 0.04576749047213002,
      "grad_norm": 0.34559518098831177,
      "learning_rate": 9.547690028518861e-05,
      "loss": 0.0099,
      "step": 814500
    },
    {
      "epoch": 0.0457955859236169,
      "grad_norm": 0.20329786837100983,
      "learning_rate": 9.547408916044354e-05,
      "loss": 0.0091,
      "step": 815000
    },
    {
      "epoch": 0.04582368137510378,
      "grad_norm": 0.20324501395225525,
      "learning_rate": 9.547127803569848e-05,
      "loss": 0.0092,
      "step": 815500
    },
    {
      "epoch": 0.04585177682659066,
      "grad_norm": 0.3344654142856598,
      "learning_rate": 9.546846691095341e-05,
      "loss": 0.0093,
      "step": 816000
    },
    {
      "epoch": 0.04587987227807754,
      "grad_norm": 0.1230296865105629,
      "learning_rate": 9.546565578620834e-05,
      "loss": 0.0092,
      "step": 816500
    },
    {
      "epoch": 0.045907967729564424,
      "grad_norm": 0.6566554307937622,
      "learning_rate": 9.546284466146328e-05,
      "loss": 0.0097,
      "step": 817000
    },
    {
      "epoch": 0.045936063181051305,
      "grad_norm": 0.10549620538949966,
      "learning_rate": 9.546003353671821e-05,
      "loss": 0.0094,
      "step": 817500
    },
    {
      "epoch": 0.045964158632538187,
      "grad_norm": 0.2903597056865692,
      "learning_rate": 9.545722241197315e-05,
      "loss": 0.0091,
      "step": 818000
    },
    {
      "epoch": 0.04599225408402507,
      "grad_norm": 0.24356034398078918,
      "learning_rate": 9.545441128722808e-05,
      "loss": 0.0095,
      "step": 818500
    },
    {
      "epoch": 0.04602034953551195,
      "grad_norm": 0.13783060014247894,
      "learning_rate": 9.545160016248302e-05,
      "loss": 0.0094,
      "step": 819000
    },
    {
      "epoch": 0.04604844498699883,
      "grad_norm": 0.31852322816848755,
      "learning_rate": 9.544878903773795e-05,
      "loss": 0.0092,
      "step": 819500
    },
    {
      "epoch": 0.04607654043848571,
      "grad_norm": 0.39396604895591736,
      "learning_rate": 9.544597791299288e-05,
      "loss": 0.0092,
      "step": 820000
    },
    {
      "epoch": 0.04607654043848571,
      "eval_loss": 0.005484570749104023,
      "eval_runtime": 19.4742,
      "eval_samples_per_second": 5135.0,
      "eval_steps_per_second": 80.26,
      "step": 820000
    },
    {
      "epoch": 0.046104635889972594,
      "grad_norm": 0.3707585036754608,
      "learning_rate": 9.544316678824782e-05,
      "loss": 0.0096,
      "step": 820500
    },
    {
      "epoch": 0.046132731341459475,
      "grad_norm": 0.3727465271949768,
      "learning_rate": 9.544035566350274e-05,
      "loss": 0.0094,
      "step": 821000
    },
    {
      "epoch": 0.046160826792946356,
      "grad_norm": 0.5836064219474792,
      "learning_rate": 9.543754453875769e-05,
      "loss": 0.009,
      "step": 821500
    },
    {
      "epoch": 0.04618892224443324,
      "grad_norm": 0.21206611394882202,
      "learning_rate": 9.543473341401262e-05,
      "loss": 0.0096,
      "step": 822000
    },
    {
      "epoch": 0.04621701769592012,
      "grad_norm": 0.054736506193876266,
      "learning_rate": 9.543192228926756e-05,
      "loss": 0.009,
      "step": 822500
    },
    {
      "epoch": 0.046245113147407,
      "grad_norm": 0.15006043016910553,
      "learning_rate": 9.542911116452249e-05,
      "loss": 0.0091,
      "step": 823000
    },
    {
      "epoch": 0.04627320859889388,
      "grad_norm": 0.21420685946941376,
      "learning_rate": 9.542630003977741e-05,
      "loss": 0.0095,
      "step": 823500
    },
    {
      "epoch": 0.046301304050380764,
      "grad_norm": 0.22159814834594727,
      "learning_rate": 9.542348891503236e-05,
      "loss": 0.0098,
      "step": 824000
    },
    {
      "epoch": 0.046329399501867645,
      "grad_norm": 0.20712275803089142,
      "learning_rate": 9.542067779028728e-05,
      "loss": 0.0092,
      "step": 824500
    },
    {
      "epoch": 0.046357494953354526,
      "grad_norm": 0.4255990982055664,
      "learning_rate": 9.541786666554223e-05,
      "loss": 0.0094,
      "step": 825000
    },
    {
      "epoch": 0.04638559040484141,
      "grad_norm": 0.1771194189786911,
      "learning_rate": 9.541505554079716e-05,
      "loss": 0.0098,
      "step": 825500
    },
    {
      "epoch": 0.04641368585632829,
      "grad_norm": 0.19396893680095673,
      "learning_rate": 9.541224441605208e-05,
      "loss": 0.009,
      "step": 826000
    },
    {
      "epoch": 0.04644178130781517,
      "grad_norm": 0.38357144594192505,
      "learning_rate": 9.540943329130703e-05,
      "loss": 0.0097,
      "step": 826500
    },
    {
      "epoch": 0.04646987675930205,
      "grad_norm": 0.1416405737400055,
      "learning_rate": 9.540662216656195e-05,
      "loss": 0.0097,
      "step": 827000
    },
    {
      "epoch": 0.04649797221078893,
      "grad_norm": 0.19562092423439026,
      "learning_rate": 9.54038110418169e-05,
      "loss": 0.0094,
      "step": 827500
    },
    {
      "epoch": 0.046526067662275815,
      "grad_norm": 0.7444145679473877,
      "learning_rate": 9.540099991707182e-05,
      "loss": 0.0089,
      "step": 828000
    },
    {
      "epoch": 0.046554163113762696,
      "grad_norm": 0.931544303894043,
      "learning_rate": 9.539818879232675e-05,
      "loss": 0.0095,
      "step": 828500
    },
    {
      "epoch": 0.04658225856524958,
      "grad_norm": 0.48588868975639343,
      "learning_rate": 9.539537766758169e-05,
      "loss": 0.0092,
      "step": 829000
    },
    {
      "epoch": 0.04661035401673646,
      "grad_norm": 0.11095674335956573,
      "learning_rate": 9.539256654283662e-05,
      "loss": 0.0089,
      "step": 829500
    },
    {
      "epoch": 0.04663844946822334,
      "grad_norm": 0.1528552621603012,
      "learning_rate": 9.538975541809157e-05,
      "loss": 0.0094,
      "step": 830000
    },
    {
      "epoch": 0.04663844946822334,
      "eval_loss": 0.00541340559720993,
      "eval_runtime": 20.1097,
      "eval_samples_per_second": 4972.718,
      "eval_steps_per_second": 77.724,
      "step": 830000
    },
    {
      "epoch": 0.04666654491971022,
      "grad_norm": 0.15927942097187042,
      "learning_rate": 9.538694429334649e-05,
      "loss": 0.009,
      "step": 830500
    },
    {
      "epoch": 0.0466946403711971,
      "grad_norm": 0.39806777238845825,
      "learning_rate": 9.538413316860142e-05,
      "loss": 0.0093,
      "step": 831000
    },
    {
      "epoch": 0.046722735822683985,
      "grad_norm": 0.19281889498233795,
      "learning_rate": 9.538132204385636e-05,
      "loss": 0.0094,
      "step": 831500
    },
    {
      "epoch": 0.046750831274170866,
      "grad_norm": 0.26219937205314636,
      "learning_rate": 9.537851091911129e-05,
      "loss": 0.0097,
      "step": 832000
    },
    {
      "epoch": 0.04677892672565775,
      "grad_norm": 0.1706317961215973,
      "learning_rate": 9.537569979436623e-05,
      "loss": 0.009,
      "step": 832500
    },
    {
      "epoch": 0.04680702217714463,
      "grad_norm": 0.05772435665130615,
      "learning_rate": 9.537288866962116e-05,
      "loss": 0.0092,
      "step": 833000
    },
    {
      "epoch": 0.04683511762863151,
      "grad_norm": 0.0830855593085289,
      "learning_rate": 9.53700775448761e-05,
      "loss": 0.0095,
      "step": 833500
    },
    {
      "epoch": 0.04686321308011839,
      "grad_norm": 0.4679998457431793,
      "learning_rate": 9.536726642013103e-05,
      "loss": 0.009,
      "step": 834000
    },
    {
      "epoch": 0.04689130853160527,
      "grad_norm": 0.4389582574367523,
      "learning_rate": 9.536445529538596e-05,
      "loss": 0.0097,
      "step": 834500
    },
    {
      "epoch": 0.046919403983092155,
      "grad_norm": 0.10247041285037994,
      "learning_rate": 9.53616441706409e-05,
      "loss": 0.0099,
      "step": 835000
    },
    {
      "epoch": 0.046947499434579036,
      "grad_norm": 0.13185648620128632,
      "learning_rate": 9.535883304589583e-05,
      "loss": 0.0094,
      "step": 835500
    },
    {
      "epoch": 0.04697559488606592,
      "grad_norm": 0.6065747141838074,
      "learning_rate": 9.535602192115077e-05,
      "loss": 0.0092,
      "step": 836000
    },
    {
      "epoch": 0.0470036903375528,
      "grad_norm": 0.5411352515220642,
      "learning_rate": 9.53532107964057e-05,
      "loss": 0.0095,
      "step": 836500
    },
    {
      "epoch": 0.04703178578903968,
      "grad_norm": 0.32933419942855835,
      "learning_rate": 9.535039967166064e-05,
      "loss": 0.0093,
      "step": 837000
    },
    {
      "epoch": 0.04705988124052656,
      "grad_norm": 0.6889341473579407,
      "learning_rate": 9.534758854691557e-05,
      "loss": 0.0091,
      "step": 837500
    },
    {
      "epoch": 0.04708797669201344,
      "grad_norm": 0.3333606719970703,
      "learning_rate": 9.53447774221705e-05,
      "loss": 0.0095,
      "step": 838000
    },
    {
      "epoch": 0.047116072143500325,
      "grad_norm": 0.6099675297737122,
      "learning_rate": 9.534196629742544e-05,
      "loss": 0.0096,
      "step": 838500
    },
    {
      "epoch": 0.04714416759498721,
      "grad_norm": 0.19488123059272766,
      "learning_rate": 9.533915517268037e-05,
      "loss": 0.0093,
      "step": 839000
    },
    {
      "epoch": 0.047172263046474094,
      "grad_norm": 0.4970928430557251,
      "learning_rate": 9.53363440479353e-05,
      "loss": 0.0094,
      "step": 839500
    },
    {
      "epoch": 0.047200358497960976,
      "grad_norm": 0.22297550737857819,
      "learning_rate": 9.533353292319024e-05,
      "loss": 0.0091,
      "step": 840000
    },
    {
      "epoch": 0.047200358497960976,
      "eval_loss": 0.005334474612027407,
      "eval_runtime": 19.1136,
      "eval_samples_per_second": 5231.88,
      "eval_steps_per_second": 81.774,
      "step": 840000
    },
    {
      "epoch": 0.04722845394944786,
      "grad_norm": 0.0923820286989212,
      "learning_rate": 9.533072179844516e-05,
      "loss": 0.0094,
      "step": 840500
    },
    {
      "epoch": 0.04725654940093474,
      "grad_norm": 0.19138601422309875,
      "learning_rate": 9.532791067370011e-05,
      "loss": 0.0094,
      "step": 841000
    },
    {
      "epoch": 0.04728464485242162,
      "grad_norm": 0.42549437284469604,
      "learning_rate": 9.532509954895504e-05,
      "loss": 0.0092,
      "step": 841500
    },
    {
      "epoch": 0.0473127403039085,
      "grad_norm": 0.31679075956344604,
      "learning_rate": 9.532228842420998e-05,
      "loss": 0.0092,
      "step": 842000
    },
    {
      "epoch": 0.04734083575539538,
      "grad_norm": 0.18566927313804626,
      "learning_rate": 9.531947729946491e-05,
      "loss": 0.0096,
      "step": 842500
    },
    {
      "epoch": 0.047368931206882264,
      "grad_norm": 0.20348075032234192,
      "learning_rate": 9.531666617471983e-05,
      "loss": 0.0089,
      "step": 843000
    },
    {
      "epoch": 0.047397026658369146,
      "grad_norm": 0.12631046772003174,
      "learning_rate": 9.531385504997478e-05,
      "loss": 0.0092,
      "step": 843500
    },
    {
      "epoch": 0.04742512210985603,
      "grad_norm": 0.062218520790338516,
      "learning_rate": 9.53110439252297e-05,
      "loss": 0.0089,
      "step": 844000
    },
    {
      "epoch": 0.04745321756134291,
      "grad_norm": 0.2938418686389923,
      "learning_rate": 9.530823280048465e-05,
      "loss": 0.0092,
      "step": 844500
    },
    {
      "epoch": 0.04748131301282979,
      "grad_norm": 0.4913197457790375,
      "learning_rate": 9.530542167573958e-05,
      "loss": 0.0093,
      "step": 845000
    },
    {
      "epoch": 0.04750940846431667,
      "grad_norm": 0.09508000314235687,
      "learning_rate": 9.53026105509945e-05,
      "loss": 0.01,
      "step": 845500
    },
    {
      "epoch": 0.04753750391580355,
      "grad_norm": 0.4153411388397217,
      "learning_rate": 9.529979942624945e-05,
      "loss": 0.009,
      "step": 846000
    },
    {
      "epoch": 0.047565599367290434,
      "grad_norm": 0.4352404773235321,
      "learning_rate": 9.529698830150437e-05,
      "loss": 0.0089,
      "step": 846500
    },
    {
      "epoch": 0.047593694818777316,
      "grad_norm": 0.7845157980918884,
      "learning_rate": 9.529417717675932e-05,
      "loss": 0.0093,
      "step": 847000
    },
    {
      "epoch": 0.0476217902702642,
      "grad_norm": 0.4420844614505768,
      "learning_rate": 9.529136605201424e-05,
      "loss": 0.0092,
      "step": 847500
    },
    {
      "epoch": 0.04764988572175108,
      "grad_norm": 0.23186266422271729,
      "learning_rate": 9.528855492726918e-05,
      "loss": 0.0091,
      "step": 848000
    },
    {
      "epoch": 0.04767798117323796,
      "grad_norm": 0.19149890542030334,
      "learning_rate": 9.528574380252412e-05,
      "loss": 0.0095,
      "step": 848500
    },
    {
      "epoch": 0.04770607662472484,
      "grad_norm": 0.36363404989242554,
      "learning_rate": 9.528293267777904e-05,
      "loss": 0.0093,
      "step": 849000
    },
    {
      "epoch": 0.04773417207621172,
      "grad_norm": 0.0523507297039032,
      "learning_rate": 9.528012155303399e-05,
      "loss": 0.0089,
      "step": 849500
    },
    {
      "epoch": 0.047762267527698604,
      "grad_norm": 0.09427914768457413,
      "learning_rate": 9.527731042828891e-05,
      "loss": 0.009,
      "step": 850000
    },
    {
      "epoch": 0.047762267527698604,
      "eval_loss": 0.00527249975129962,
      "eval_runtime": 20.1779,
      "eval_samples_per_second": 4955.914,
      "eval_steps_per_second": 77.461,
      "step": 850000
    },
    {
      "epoch": 0.047790362979185486,
      "grad_norm": 0.3207687437534332,
      "learning_rate": 9.527449930354385e-05,
      "loss": 0.0095,
      "step": 850500
    },
    {
      "epoch": 0.04781845843067237,
      "grad_norm": 0.192702516913414,
      "learning_rate": 9.527168817879878e-05,
      "loss": 0.0089,
      "step": 851000
    },
    {
      "epoch": 0.04784655388215925,
      "grad_norm": 0.14931482076644897,
      "learning_rate": 9.526887705405371e-05,
      "loss": 0.009,
      "step": 851500
    },
    {
      "epoch": 0.04787464933364613,
      "grad_norm": 0.5925433039665222,
      "learning_rate": 9.526606592930865e-05,
      "loss": 0.0095,
      "step": 852000
    },
    {
      "epoch": 0.04790274478513301,
      "grad_norm": 0.16368037462234497,
      "learning_rate": 9.526325480456358e-05,
      "loss": 0.0091,
      "step": 852500
    },
    {
      "epoch": 0.04793084023661989,
      "grad_norm": 0.18126311898231506,
      "learning_rate": 9.526044367981852e-05,
      "loss": 0.0087,
      "step": 853000
    },
    {
      "epoch": 0.047958935688106774,
      "grad_norm": 0.2822069227695465,
      "learning_rate": 9.525763255507345e-05,
      "loss": 0.0094,
      "step": 853500
    },
    {
      "epoch": 0.047987031139593656,
      "grad_norm": 0.45157623291015625,
      "learning_rate": 9.525482143032839e-05,
      "loss": 0.0096,
      "step": 854000
    },
    {
      "epoch": 0.04801512659108054,
      "grad_norm": 0.17262059450149536,
      "learning_rate": 9.525201030558332e-05,
      "loss": 0.0091,
      "step": 854500
    },
    {
      "epoch": 0.04804322204256742,
      "grad_norm": 0.2938753366470337,
      "learning_rate": 9.524919918083825e-05,
      "loss": 0.0094,
      "step": 855000
    },
    {
      "epoch": 0.0480713174940543,
      "grad_norm": 0.13586542010307312,
      "learning_rate": 9.524638805609319e-05,
      "loss": 0.0094,
      "step": 855500
    },
    {
      "epoch": 0.04809941294554118,
      "grad_norm": 1.0537248849868774,
      "learning_rate": 9.524357693134812e-05,
      "loss": 0.0088,
      "step": 856000
    },
    {
      "epoch": 0.04812750839702806,
      "grad_norm": 0.040422648191452026,
      "learning_rate": 9.524076580660306e-05,
      "loss": 0.009,
      "step": 856500
    },
    {
      "epoch": 0.048155603848514944,
      "grad_norm": 0.10562899708747864,
      "learning_rate": 9.523795468185799e-05,
      "loss": 0.0093,
      "step": 857000
    },
    {
      "epoch": 0.048183699300001825,
      "grad_norm": 0.29416730999946594,
      "learning_rate": 9.523514355711293e-05,
      "loss": 0.0092,
      "step": 857500
    },
    {
      "epoch": 0.04821179475148871,
      "grad_norm": 0.38446637988090515,
      "learning_rate": 9.523233243236786e-05,
      "loss": 0.0094,
      "step": 858000
    },
    {
      "epoch": 0.04823989020297559,
      "grad_norm": 0.7582910060882568,
      "learning_rate": 9.52295213076228e-05,
      "loss": 0.0089,
      "step": 858500
    },
    {
      "epoch": 0.04826798565446247,
      "grad_norm": 0.16574208438396454,
      "learning_rate": 9.522671018287771e-05,
      "loss": 0.0096,
      "step": 859000
    },
    {
      "epoch": 0.04829608110594935,
      "grad_norm": 0.214682936668396,
      "learning_rate": 9.522389905813266e-05,
      "loss": 0.0092,
      "step": 859500
    },
    {
      "epoch": 0.04832417655743623,
      "grad_norm": 0.20082123577594757,
      "learning_rate": 9.522108793338758e-05,
      "loss": 0.0095,
      "step": 860000
    },
    {
      "epoch": 0.04832417655743623,
      "eval_loss": 0.005366628058254719,
      "eval_runtime": 19.4089,
      "eval_samples_per_second": 5152.266,
      "eval_steps_per_second": 80.53,
      "step": 860000
    },
    {
      "epoch": 0.048352272008923114,
      "grad_norm": 0.34665459394454956,
      "learning_rate": 9.521827680864253e-05,
      "loss": 0.009,
      "step": 860500
    },
    {
      "epoch": 0.048380367460409995,
      "grad_norm": 0.27852359414100647,
      "learning_rate": 9.521546568389747e-05,
      "loss": 0.0096,
      "step": 861000
    },
    {
      "epoch": 0.04840846291189688,
      "grad_norm": 0.17631688714027405,
      "learning_rate": 9.521265455915239e-05,
      "loss": 0.009,
      "step": 861500
    },
    {
      "epoch": 0.04843655836338376,
      "grad_norm": 1.0121924877166748,
      "learning_rate": 9.520984343440733e-05,
      "loss": 0.0088,
      "step": 862000
    },
    {
      "epoch": 0.04846465381487064,
      "grad_norm": 0.19959470629692078,
      "learning_rate": 9.520703230966225e-05,
      "loss": 0.0095,
      "step": 862500
    },
    {
      "epoch": 0.04849274926635752,
      "grad_norm": 0.07088791579008102,
      "learning_rate": 9.52042211849172e-05,
      "loss": 0.0093,
      "step": 863000
    },
    {
      "epoch": 0.0485208447178444,
      "grad_norm": 0.04575404152274132,
      "learning_rate": 9.520141006017212e-05,
      "loss": 0.0088,
      "step": 863500
    },
    {
      "epoch": 0.048548940169331284,
      "grad_norm": 0.1535876989364624,
      "learning_rate": 9.519859893542706e-05,
      "loss": 0.0084,
      "step": 864000
    },
    {
      "epoch": 0.048577035620818165,
      "grad_norm": 0.49669551849365234,
      "learning_rate": 9.5195787810682e-05,
      "loss": 0.0095,
      "step": 864500
    },
    {
      "epoch": 0.04860513107230505,
      "grad_norm": 0.6437605023384094,
      "learning_rate": 9.519297668593693e-05,
      "loss": 0.0091,
      "step": 865000
    },
    {
      "epoch": 0.04863322652379193,
      "grad_norm": 0.20994983613491058,
      "learning_rate": 9.519016556119187e-05,
      "loss": 0.0092,
      "step": 865500
    },
    {
      "epoch": 0.04866132197527881,
      "grad_norm": 0.16383665800094604,
      "learning_rate": 9.51873544364468e-05,
      "loss": 0.0092,
      "step": 866000
    },
    {
      "epoch": 0.04868941742676569,
      "grad_norm": 0.843838095664978,
      "learning_rate": 9.518454331170173e-05,
      "loss": 0.0095,
      "step": 866500
    },
    {
      "epoch": 0.04871751287825257,
      "grad_norm": 0.1156095340847969,
      "learning_rate": 9.518173218695666e-05,
      "loss": 0.0092,
      "step": 867000
    },
    {
      "epoch": 0.048745608329739454,
      "grad_norm": 0.10051435232162476,
      "learning_rate": 9.51789210622116e-05,
      "loss": 0.0093,
      "step": 867500
    },
    {
      "epoch": 0.048773703781226335,
      "grad_norm": 0.32333022356033325,
      "learning_rate": 9.517610993746654e-05,
      "loss": 0.0098,
      "step": 868000
    },
    {
      "epoch": 0.04880179923271322,
      "grad_norm": 0.16663551330566406,
      "learning_rate": 9.517329881272147e-05,
      "loss": 0.0091,
      "step": 868500
    },
    {
      "epoch": 0.0488298946842001,
      "grad_norm": 0.5567536354064941,
      "learning_rate": 9.51704876879764e-05,
      "loss": 0.009,
      "step": 869000
    },
    {
      "epoch": 0.048857990135686986,
      "grad_norm": 2.310032844543457,
      "learning_rate": 9.516767656323133e-05,
      "loss": 0.0086,
      "step": 869500
    },
    {
      "epoch": 0.04888608558717387,
      "grad_norm": 0.6623836159706116,
      "learning_rate": 9.516486543848627e-05,
      "loss": 0.0092,
      "step": 870000
    },
    {
      "epoch": 0.04888608558717387,
      "eval_loss": 0.00531691312789917,
      "eval_runtime": 19.6155,
      "eval_samples_per_second": 5097.999,
      "eval_steps_per_second": 79.682,
      "step": 870000
    },
    {
      "epoch": 0.04891418103866075,
      "grad_norm": 0.5446311235427856,
      "learning_rate": 9.51620543137412e-05,
      "loss": 0.0095,
      "step": 870500
    },
    {
      "epoch": 0.04894227649014763,
      "grad_norm": 0.29783111810684204,
      "learning_rate": 9.515924318899614e-05,
      "loss": 0.0091,
      "step": 871000
    },
    {
      "epoch": 0.04897037194163451,
      "grad_norm": 0.2654893100261688,
      "learning_rate": 9.515643206425107e-05,
      "loss": 0.009,
      "step": 871500
    },
    {
      "epoch": 0.048998467393121393,
      "grad_norm": 0.11488153040409088,
      "learning_rate": 9.5153620939506e-05,
      "loss": 0.0087,
      "step": 872000
    },
    {
      "epoch": 0.049026562844608275,
      "grad_norm": 0.016892852261662483,
      "learning_rate": 9.515080981476094e-05,
      "loss": 0.0091,
      "step": 872500
    },
    {
      "epoch": 0.049054658296095156,
      "grad_norm": 0.16784127056598663,
      "learning_rate": 9.514799869001587e-05,
      "loss": 0.0092,
      "step": 873000
    },
    {
      "epoch": 0.04908275374758204,
      "grad_norm": 0.21770060062408447,
      "learning_rate": 9.514518756527081e-05,
      "loss": 0.0096,
      "step": 873500
    },
    {
      "epoch": 0.04911084919906892,
      "grad_norm": 0.2217722088098526,
      "learning_rate": 9.514237644052574e-05,
      "loss": 0.009,
      "step": 874000
    },
    {
      "epoch": 0.0491389446505558,
      "grad_norm": 0.5552495718002319,
      "learning_rate": 9.513956531578068e-05,
      "loss": 0.0094,
      "step": 874500
    },
    {
      "epoch": 0.04916704010204268,
      "grad_norm": 0.1615263670682907,
      "learning_rate": 9.513675419103561e-05,
      "loss": 0.0094,
      "step": 875000
    },
    {
      "epoch": 0.04919513555352956,
      "grad_norm": 0.06630559265613556,
      "learning_rate": 9.513394306629054e-05,
      "loss": 0.0094,
      "step": 875500
    },
    {
      "epoch": 0.049223231005016445,
      "grad_norm": 0.19954970479011536,
      "learning_rate": 9.513113194154548e-05,
      "loss": 0.0089,
      "step": 876000
    },
    {
      "epoch": 0.049251326456503326,
      "grad_norm": 0.2648034393787384,
      "learning_rate": 9.512832081680041e-05,
      "loss": 0.0085,
      "step": 876500
    },
    {
      "epoch": 0.04927942190799021,
      "grad_norm": 0.2691318690776825,
      "learning_rate": 9.512550969205535e-05,
      "loss": 0.0094,
      "step": 877000
    },
    {
      "epoch": 0.04930751735947709,
      "grad_norm": 0.5660744309425354,
      "learning_rate": 9.512269856731028e-05,
      "loss": 0.0091,
      "step": 877500
    },
    {
      "epoch": 0.04933561281096397,
      "grad_norm": 1.0432863235473633,
      "learning_rate": 9.511988744256522e-05,
      "loss": 0.0093,
      "step": 878000
    },
    {
      "epoch": 0.04936370826245085,
      "grad_norm": 0.118109330534935,
      "learning_rate": 9.511707631782014e-05,
      "loss": 0.0086,
      "step": 878500
    },
    {
      "epoch": 0.04939180371393773,
      "grad_norm": 0.2127503752708435,
      "learning_rate": 9.511426519307508e-05,
      "loss": 0.0093,
      "step": 879000
    },
    {
      "epoch": 0.049419899165424615,
      "grad_norm": 0.18485097587108612,
      "learning_rate": 9.511145406833002e-05,
      "loss": 0.0085,
      "step": 879500
    },
    {
      "epoch": 0.049447994616911496,
      "grad_norm": 0.12255626916885376,
      "learning_rate": 9.510864294358495e-05,
      "loss": 0.0092,
      "step": 880000
    },
    {
      "epoch": 0.049447994616911496,
      "eval_loss": 0.005416202824562788,
      "eval_runtime": 19.2218,
      "eval_samples_per_second": 5202.42,
      "eval_steps_per_second": 81.314,
      "step": 880000
    },
    {
      "epoch": 0.04947609006839838,
      "grad_norm": 0.17056378722190857,
      "learning_rate": 9.510583181883989e-05,
      "loss": 0.0096,
      "step": 880500
    },
    {
      "epoch": 0.04950418551988526,
      "grad_norm": 0.1923234462738037,
      "learning_rate": 9.510302069409481e-05,
      "loss": 0.0092,
      "step": 881000
    },
    {
      "epoch": 0.04953228097137214,
      "grad_norm": 0.1427118480205536,
      "learning_rate": 9.510020956934976e-05,
      "loss": 0.0095,
      "step": 881500
    },
    {
      "epoch": 0.04956037642285902,
      "grad_norm": 0.8063790798187256,
      "learning_rate": 9.509739844460468e-05,
      "loss": 0.009,
      "step": 882000
    },
    {
      "epoch": 0.0495884718743459,
      "grad_norm": 0.1398969292640686,
      "learning_rate": 9.509458731985962e-05,
      "loss": 0.009,
      "step": 882500
    },
    {
      "epoch": 0.049616567325832785,
      "grad_norm": 0.08481825888156891,
      "learning_rate": 9.509177619511455e-05,
      "loss": 0.0089,
      "step": 883000
    },
    {
      "epoch": 0.049644662777319666,
      "grad_norm": 0.2554222643375397,
      "learning_rate": 9.508896507036948e-05,
      "loss": 0.0094,
      "step": 883500
    },
    {
      "epoch": 0.04967275822880655,
      "grad_norm": 0.18155431747436523,
      "learning_rate": 9.508615394562443e-05,
      "loss": 0.0089,
      "step": 884000
    },
    {
      "epoch": 0.04970085368029343,
      "grad_norm": 0.16199663281440735,
      "learning_rate": 9.508334282087935e-05,
      "loss": 0.0091,
      "step": 884500
    },
    {
      "epoch": 0.04972894913178031,
      "grad_norm": 0.21514371037483215,
      "learning_rate": 9.50805316961343e-05,
      "loss": 0.0088,
      "step": 885000
    },
    {
      "epoch": 0.04975704458326719,
      "grad_norm": 0.115298792719841,
      "learning_rate": 9.507772057138922e-05,
      "loss": 0.0092,
      "step": 885500
    },
    {
      "epoch": 0.04978514003475407,
      "grad_norm": 0.2560103237628937,
      "learning_rate": 9.507490944664415e-05,
      "loss": 0.009,
      "step": 886000
    },
    {
      "epoch": 0.049813235486240955,
      "grad_norm": 0.1759171336889267,
      "learning_rate": 9.507209832189908e-05,
      "loss": 0.0089,
      "step": 886500
    },
    {
      "epoch": 0.049841330937727836,
      "grad_norm": 0.34774357080459595,
      "learning_rate": 9.506928719715402e-05,
      "loss": 0.0093,
      "step": 887000
    },
    {
      "epoch": 0.04986942638921472,
      "grad_norm": 0.070098876953125,
      "learning_rate": 9.506647607240897e-05,
      "loss": 0.0091,
      "step": 887500
    },
    {
      "epoch": 0.0498975218407016,
      "grad_norm": 0.03696337714791298,
      "learning_rate": 9.506366494766389e-05,
      "loss": 0.0088,
      "step": 888000
    },
    {
      "epoch": 0.04992561729218848,
      "grad_norm": 0.291340708732605,
      "learning_rate": 9.506085382291882e-05,
      "loss": 0.009,
      "step": 888500
    },
    {
      "epoch": 0.04995371274367536,
      "grad_norm": 0.30413809418678284,
      "learning_rate": 9.505804269817376e-05,
      "loss": 0.0093,
      "step": 889000
    },
    {
      "epoch": 0.04998180819516224,
      "grad_norm": 0.11519090831279755,
      "learning_rate": 9.505523157342869e-05,
      "loss": 0.0086,
      "step": 889500
    },
    {
      "epoch": 0.050009903646649125,
      "grad_norm": 0.32626810669898987,
      "learning_rate": 9.505242044868362e-05,
      "loss": 0.0088,
      "step": 890000
    },
    {
      "epoch": 0.050009903646649125,
      "eval_loss": 0.005329031962901354,
      "eval_runtime": 19.5254,
      "eval_samples_per_second": 5121.537,
      "eval_steps_per_second": 80.05,
      "step": 890000
    },
    {
      "epoch": 0.050037999098136006,
      "grad_norm": 0.36060234904289246,
      "learning_rate": 9.504960932393856e-05,
      "loss": 0.0091,
      "step": 890500
    },
    {
      "epoch": 0.05006609454962289,
      "grad_norm": 0.2100476175546646,
      "learning_rate": 9.504679819919349e-05,
      "loss": 0.0096,
      "step": 891000
    },
    {
      "epoch": 0.05009419000110977,
      "grad_norm": 0.2095772922039032,
      "learning_rate": 9.504398707444843e-05,
      "loss": 0.0092,
      "step": 891500
    },
    {
      "epoch": 0.05012228545259665,
      "grad_norm": 0.29914647340774536,
      "learning_rate": 9.504117594970336e-05,
      "loss": 0.0092,
      "step": 892000
    },
    {
      "epoch": 0.05015038090408353,
      "grad_norm": 0.15217548608779907,
      "learning_rate": 9.50383648249583e-05,
      "loss": 0.0094,
      "step": 892500
    },
    {
      "epoch": 0.05017847635557041,
      "grad_norm": 0.17867052555084229,
      "learning_rate": 9.503555370021323e-05,
      "loss": 0.0085,
      "step": 893000
    },
    {
      "epoch": 0.050206571807057294,
      "grad_norm": 0.4166020452976227,
      "learning_rate": 9.503274257546816e-05,
      "loss": 0.0092,
      "step": 893500
    },
    {
      "epoch": 0.050234667258544176,
      "grad_norm": 0.47388166189193726,
      "learning_rate": 9.50299314507231e-05,
      "loss": 0.0087,
      "step": 894000
    },
    {
      "epoch": 0.05026276271003106,
      "grad_norm": 0.16889847815036774,
      "learning_rate": 9.502712032597802e-05,
      "loss": 0.0094,
      "step": 894500
    },
    {
      "epoch": 0.05029085816151794,
      "grad_norm": 0.8178918361663818,
      "learning_rate": 9.502430920123297e-05,
      "loss": 0.0088,
      "step": 895000
    },
    {
      "epoch": 0.05031895361300482,
      "grad_norm": 0.0363580659031868,
      "learning_rate": 9.50214980764879e-05,
      "loss": 0.0089,
      "step": 895500
    },
    {
      "epoch": 0.0503470490644917,
      "grad_norm": 0.197978675365448,
      "learning_rate": 9.501868695174284e-05,
      "loss": 0.009,
      "step": 896000
    },
    {
      "epoch": 0.05037514451597858,
      "grad_norm": 0.0860993042588234,
      "learning_rate": 9.501587582699777e-05,
      "loss": 0.0094,
      "step": 896500
    },
    {
      "epoch": 0.050403239967465464,
      "grad_norm": 0.09450644254684448,
      "learning_rate": 9.501306470225269e-05,
      "loss": 0.0089,
      "step": 897000
    },
    {
      "epoch": 0.050431335418952346,
      "grad_norm": 0.4832107722759247,
      "learning_rate": 9.501025357750764e-05,
      "loss": 0.0088,
      "step": 897500
    },
    {
      "epoch": 0.05045943087043923,
      "grad_norm": 0.10888858139514923,
      "learning_rate": 9.500744245276256e-05,
      "loss": 0.009,
      "step": 898000
    },
    {
      "epoch": 0.05048752632192611,
      "grad_norm": 0.26337361335754395,
      "learning_rate": 9.50046313280175e-05,
      "loss": 0.009,
      "step": 898500
    },
    {
      "epoch": 0.05051562177341299,
      "grad_norm": 0.2598961889743805,
      "learning_rate": 9.500182020327244e-05,
      "loss": 0.0092,
      "step": 899000
    },
    {
      "epoch": 0.05054371722489987,
      "grad_norm": 0.13177137076854706,
      "learning_rate": 9.499900907852736e-05,
      "loss": 0.0088,
      "step": 899500
    },
    {
      "epoch": 0.05057181267638676,
      "grad_norm": 0.1953253597021103,
      "learning_rate": 9.499619795378231e-05,
      "loss": 0.0087,
      "step": 900000
    },
    {
      "epoch": 0.05057181267638676,
      "eval_loss": 0.0052731833420693874,
      "eval_runtime": 19.0566,
      "eval_samples_per_second": 5247.536,
      "eval_steps_per_second": 82.019,
      "step": 900000
    },
    {
      "epoch": 0.05059990812787364,
      "grad_norm": 0.6655644774436951,
      "learning_rate": 9.499338682903723e-05,
      "loss": 0.0096,
      "step": 900500
    },
    {
      "epoch": 0.05062800357936052,
      "grad_norm": 0.9584806561470032,
      "learning_rate": 9.499057570429218e-05,
      "loss": 0.0093,
      "step": 901000
    },
    {
      "epoch": 0.050656099030847404,
      "grad_norm": 0.2513972818851471,
      "learning_rate": 9.49877645795471e-05,
      "loss": 0.0094,
      "step": 901500
    },
    {
      "epoch": 0.050684194482334285,
      "grad_norm": 0.43067824840545654,
      "learning_rate": 9.498495345480203e-05,
      "loss": 0.0089,
      "step": 902000
    },
    {
      "epoch": 0.05071228993382117,
      "grad_norm": 0.6543277502059937,
      "learning_rate": 9.498214233005697e-05,
      "loss": 0.0089,
      "step": 902500
    },
    {
      "epoch": 0.05074038538530805,
      "grad_norm": 0.031443994492292404,
      "learning_rate": 9.49793312053119e-05,
      "loss": 0.0088,
      "step": 903000
    },
    {
      "epoch": 0.05076848083679493,
      "grad_norm": 0.23342466354370117,
      "learning_rate": 9.497652008056685e-05,
      "loss": 0.0093,
      "step": 903500
    },
    {
      "epoch": 0.05079657628828181,
      "grad_norm": 0.18029719591140747,
      "learning_rate": 9.497370895582177e-05,
      "loss": 0.0089,
      "step": 904000
    },
    {
      "epoch": 0.05082467173976869,
      "grad_norm": 0.3564772605895996,
      "learning_rate": 9.49708978310767e-05,
      "loss": 0.009,
      "step": 904500
    },
    {
      "epoch": 0.050852767191255574,
      "grad_norm": 0.15320445597171783,
      "learning_rate": 9.496808670633164e-05,
      "loss": 0.009,
      "step": 905000
    },
    {
      "epoch": 0.050880862642742455,
      "grad_norm": 0.2577975392341614,
      "learning_rate": 9.496527558158657e-05,
      "loss": 0.0091,
      "step": 905500
    },
    {
      "epoch": 0.05090895809422934,
      "grad_norm": 0.16695855557918549,
      "learning_rate": 9.496246445684151e-05,
      "loss": 0.0095,
      "step": 906000
    },
    {
      "epoch": 0.05093705354571622,
      "grad_norm": 0.046200625598430634,
      "learning_rate": 9.495965333209644e-05,
      "loss": 0.0088,
      "step": 906500
    },
    {
      "epoch": 0.0509651489972031,
      "grad_norm": 0.1873391717672348,
      "learning_rate": 9.495684220735138e-05,
      "loss": 0.009,
      "step": 907000
    },
    {
      "epoch": 0.05099324444868998,
      "grad_norm": 0.2382773607969284,
      "learning_rate": 9.495403108260631e-05,
      "loss": 0.009,
      "step": 907500
    },
    {
      "epoch": 0.05102133990017686,
      "grad_norm": 0.26178357005119324,
      "learning_rate": 9.495121995786124e-05,
      "loss": 0.0086,
      "step": 908000
    },
    {
      "epoch": 0.051049435351663744,
      "grad_norm": 0.3911997079849243,
      "learning_rate": 9.494840883311618e-05,
      "loss": 0.009,
      "step": 908500
    },
    {
      "epoch": 0.051077530803150625,
      "grad_norm": 0.24165010452270508,
      "learning_rate": 9.494559770837111e-05,
      "loss": 0.0091,
      "step": 909000
    },
    {
      "epoch": 0.05110562625463751,
      "grad_norm": 0.5811505913734436,
      "learning_rate": 9.494278658362605e-05,
      "loss": 0.0091,
      "step": 909500
    },
    {
      "epoch": 0.05113372170612439,
      "grad_norm": 0.27582061290740967,
      "learning_rate": 9.493997545888098e-05,
      "loss": 0.0091,
      "step": 910000
    },
    {
      "epoch": 0.05113372170612439,
      "eval_loss": 0.005079680122435093,
      "eval_runtime": 19.5429,
      "eval_samples_per_second": 5116.949,
      "eval_steps_per_second": 79.978,
      "step": 910000
    },
    {
      "epoch": 0.05116181715761127,
      "grad_norm": 0.22976212203502655,
      "learning_rate": 9.493716433413592e-05,
      "loss": 0.0088,
      "step": 910500
    },
    {
      "epoch": 0.05118991260909815,
      "grad_norm": 0.18820586800575256,
      "learning_rate": 9.493435320939085e-05,
      "loss": 0.0088,
      "step": 911000
    },
    {
      "epoch": 0.05121800806058503,
      "grad_norm": 0.11503437906503677,
      "learning_rate": 9.493154208464578e-05,
      "loss": 0.0093,
      "step": 911500
    },
    {
      "epoch": 0.051246103512071914,
      "grad_norm": 0.49509286880493164,
      "learning_rate": 9.492873095990072e-05,
      "loss": 0.0092,
      "step": 912000
    },
    {
      "epoch": 0.051274198963558795,
      "grad_norm": 0.28003281354904175,
      "learning_rate": 9.492591983515565e-05,
      "loss": 0.009,
      "step": 912500
    },
    {
      "epoch": 0.05130229441504568,
      "grad_norm": 0.39097654819488525,
      "learning_rate": 9.492310871041059e-05,
      "loss": 0.0088,
      "step": 913000
    },
    {
      "epoch": 0.05133038986653256,
      "grad_norm": 0.49348220229148865,
      "learning_rate": 9.492029758566552e-05,
      "loss": 0.0088,
      "step": 913500
    },
    {
      "epoch": 0.05135848531801944,
      "grad_norm": 0.2747528851032257,
      "learning_rate": 9.491748646092044e-05,
      "loss": 0.0091,
      "step": 914000
    },
    {
      "epoch": 0.05138658076950632,
      "grad_norm": 0.3174374997615814,
      "learning_rate": 9.491467533617539e-05,
      "loss": 0.0087,
      "step": 914500
    },
    {
      "epoch": 0.0514146762209932,
      "grad_norm": 0.04399159550666809,
      "learning_rate": 9.491186421143032e-05,
      "loss": 0.0091,
      "step": 915000
    },
    {
      "epoch": 0.051442771672480084,
      "grad_norm": 0.1081840991973877,
      "learning_rate": 9.490905308668526e-05,
      "loss": 0.0092,
      "step": 915500
    },
    {
      "epoch": 0.051470867123966965,
      "grad_norm": 0.22272808849811554,
      "learning_rate": 9.490624196194019e-05,
      "loss": 0.0091,
      "step": 916000
    },
    {
      "epoch": 0.05149896257545385,
      "grad_norm": 0.4928687512874603,
      "learning_rate": 9.490343083719511e-05,
      "loss": 0.0094,
      "step": 916500
    },
    {
      "epoch": 0.05152705802694073,
      "grad_norm": 0.17207388579845428,
      "learning_rate": 9.490061971245006e-05,
      "loss": 0.0085,
      "step": 917000
    },
    {
      "epoch": 0.05155515347842761,
      "grad_norm": 0.1234125941991806,
      "learning_rate": 9.489780858770498e-05,
      "loss": 0.0088,
      "step": 917500
    },
    {
      "epoch": 0.05158324892991449,
      "grad_norm": 0.35431066155433655,
      "learning_rate": 9.489499746295993e-05,
      "loss": 0.0088,
      "step": 918000
    },
    {
      "epoch": 0.05161134438140137,
      "grad_norm": 0.21075277030467987,
      "learning_rate": 9.489218633821486e-05,
      "loss": 0.0089,
      "step": 918500
    },
    {
      "epoch": 0.051639439832888254,
      "grad_norm": 0.24506452679634094,
      "learning_rate": 9.488937521346978e-05,
      "loss": 0.0091,
      "step": 919000
    },
    {
      "epoch": 0.051667535284375135,
      "grad_norm": 0.14279529452323914,
      "learning_rate": 9.488656408872473e-05,
      "loss": 0.0091,
      "step": 919500
    },
    {
      "epoch": 0.051695630735862017,
      "grad_norm": 0.13781660795211792,
      "learning_rate": 9.488375296397965e-05,
      "loss": 0.0091,
      "step": 920000
    },
    {
      "epoch": 0.051695630735862017,
      "eval_loss": 0.005273736082017422,
      "eval_runtime": 19.6755,
      "eval_samples_per_second": 5082.471,
      "eval_steps_per_second": 79.439,
      "step": 920000
    },
    {
      "epoch": 0.0517237261873489,
      "grad_norm": 0.6771228313446045,
      "learning_rate": 9.48809418392346e-05,
      "loss": 0.0091,
      "step": 920500
    },
    {
      "epoch": 0.05175182163883578,
      "grad_norm": 0.18624377250671387,
      "learning_rate": 9.487813071448952e-05,
      "loss": 0.0089,
      "step": 921000
    },
    {
      "epoch": 0.05177991709032266,
      "grad_norm": 0.21852022409439087,
      "learning_rate": 9.487531958974445e-05,
      "loss": 0.0089,
      "step": 921500
    },
    {
      "epoch": 0.05180801254180954,
      "grad_norm": 0.5735841989517212,
      "learning_rate": 9.487250846499939e-05,
      "loss": 0.0091,
      "step": 922000
    },
    {
      "epoch": 0.051836107993296424,
      "grad_norm": 0.10734963417053223,
      "learning_rate": 9.486969734025432e-05,
      "loss": 0.0088,
      "step": 922500
    },
    {
      "epoch": 0.051864203444783305,
      "grad_norm": 0.32145455479621887,
      "learning_rate": 9.486688621550927e-05,
      "loss": 0.0085,
      "step": 923000
    },
    {
      "epoch": 0.051892298896270186,
      "grad_norm": 0.2725127041339874,
      "learning_rate": 9.486407509076419e-05,
      "loss": 0.009,
      "step": 923500
    },
    {
      "epoch": 0.05192039434775707,
      "grad_norm": 0.21443584561347961,
      "learning_rate": 9.486126396601913e-05,
      "loss": 0.0089,
      "step": 924000
    },
    {
      "epoch": 0.05194848979924395,
      "grad_norm": 0.07785982638597488,
      "learning_rate": 9.485845284127406e-05,
      "loss": 0.0094,
      "step": 924500
    },
    {
      "epoch": 0.05197658525073083,
      "grad_norm": 0.606465220451355,
      "learning_rate": 9.4855641716529e-05,
      "loss": 0.009,
      "step": 925000
    },
    {
      "epoch": 0.05200468070221771,
      "grad_norm": 0.3855498135089874,
      "learning_rate": 9.485283059178393e-05,
      "loss": 0.009,
      "step": 925500
    },
    {
      "epoch": 0.052032776153704594,
      "grad_norm": 0.3597146272659302,
      "learning_rate": 9.485001946703886e-05,
      "loss": 0.0088,
      "step": 926000
    },
    {
      "epoch": 0.052060871605191475,
      "grad_norm": 0.440360963344574,
      "learning_rate": 9.48472083422938e-05,
      "loss": 0.0087,
      "step": 926500
    },
    {
      "epoch": 0.052088967056678356,
      "grad_norm": 0.13874897360801697,
      "learning_rate": 9.484439721754873e-05,
      "loss": 0.0091,
      "step": 927000
    },
    {
      "epoch": 0.05211706250816524,
      "grad_norm": 0.1435459405183792,
      "learning_rate": 9.484158609280367e-05,
      "loss": 0.0085,
      "step": 927500
    },
    {
      "epoch": 0.05214515795965212,
      "grad_norm": 0.3887919485569,
      "learning_rate": 9.48387749680586e-05,
      "loss": 0.0094,
      "step": 928000
    },
    {
      "epoch": 0.052173253411139,
      "grad_norm": 0.923393964767456,
      "learning_rate": 9.483596384331353e-05,
      "loss": 0.0092,
      "step": 928500
    },
    {
      "epoch": 0.05220134886262588,
      "grad_norm": 0.46974360942840576,
      "learning_rate": 9.483315271856847e-05,
      "loss": 0.0095,
      "step": 929000
    },
    {
      "epoch": 0.05222944431411276,
      "grad_norm": 0.3154449760913849,
      "learning_rate": 9.48303415938234e-05,
      "loss": 0.009,
      "step": 929500
    },
    {
      "epoch": 0.052257539765599645,
      "grad_norm": 0.20068801939487457,
      "learning_rate": 9.482753046907834e-05,
      "loss": 0.0089,
      "step": 930000
    },
    {
      "epoch": 0.052257539765599645,
      "eval_loss": 0.005241870414465666,
      "eval_runtime": 19.4674,
      "eval_samples_per_second": 5136.798,
      "eval_steps_per_second": 80.288,
      "step": 930000
    },
    {
      "epoch": 0.05228563521708653,
      "grad_norm": 0.376726359128952,
      "learning_rate": 9.482471934433327e-05,
      "loss": 0.0088,
      "step": 930500
    },
    {
      "epoch": 0.052313730668573415,
      "grad_norm": 0.7086104154586792,
      "learning_rate": 9.48219082195882e-05,
      "loss": 0.0091,
      "step": 931000
    },
    {
      "epoch": 0.052341826120060296,
      "grad_norm": 0.21380211412906647,
      "learning_rate": 9.481909709484314e-05,
      "loss": 0.0084,
      "step": 931500
    },
    {
      "epoch": 0.05236992157154718,
      "grad_norm": 0.2462635636329651,
      "learning_rate": 9.481628597009807e-05,
      "loss": 0.0088,
      "step": 932000
    },
    {
      "epoch": 0.05239801702303406,
      "grad_norm": 0.5700987577438354,
      "learning_rate": 9.4813474845353e-05,
      "loss": 0.0089,
      "step": 932500
    },
    {
      "epoch": 0.05242611247452094,
      "grad_norm": 0.33426061272621155,
      "learning_rate": 9.481066372060794e-05,
      "loss": 0.0091,
      "step": 933000
    },
    {
      "epoch": 0.05245420792600782,
      "grad_norm": 0.29217904806137085,
      "learning_rate": 9.480785259586286e-05,
      "loss": 0.0085,
      "step": 933500
    },
    {
      "epoch": 0.0524823033774947,
      "grad_norm": 0.15970346331596375,
      "learning_rate": 9.480504147111781e-05,
      "loss": 0.0094,
      "step": 934000
    },
    {
      "epoch": 0.052510398828981585,
      "grad_norm": 0.037552058696746826,
      "learning_rate": 9.480223034637275e-05,
      "loss": 0.0091,
      "step": 934500
    },
    {
      "epoch": 0.052538494280468466,
      "grad_norm": 0.11391980946063995,
      "learning_rate": 9.479941922162767e-05,
      "loss": 0.0085,
      "step": 935000
    },
    {
      "epoch": 0.05256658973195535,
      "grad_norm": 1.0674594640731812,
      "learning_rate": 9.479660809688261e-05,
      "loss": 0.0092,
      "step": 935500
    },
    {
      "epoch": 0.05259468518344223,
      "grad_norm": 0.2363138496875763,
      "learning_rate": 9.479379697213753e-05,
      "loss": 0.0088,
      "step": 936000
    },
    {
      "epoch": 0.05262278063492911,
      "grad_norm": 1.0761371850967407,
      "learning_rate": 9.479098584739248e-05,
      "loss": 0.009,
      "step": 936500
    },
    {
      "epoch": 0.05265087608641599,
      "grad_norm": 0.09009476751089096,
      "learning_rate": 9.47881747226474e-05,
      "loss": 0.0086,
      "step": 937000
    },
    {
      "epoch": 0.05267897153790287,
      "grad_norm": 0.2219105362892151,
      "learning_rate": 9.478536359790234e-05,
      "loss": 0.0089,
      "step": 937500
    },
    {
      "epoch": 0.052707066989389754,
      "grad_norm": 0.06035986915230751,
      "learning_rate": 9.478255247315728e-05,
      "loss": 0.0089,
      "step": 938000
    },
    {
      "epoch": 0.052735162440876636,
      "grad_norm": 0.2461501657962799,
      "learning_rate": 9.47797413484122e-05,
      "loss": 0.0091,
      "step": 938500
    },
    {
      "epoch": 0.05276325789236352,
      "grad_norm": 0.2911461591720581,
      "learning_rate": 9.477693022366715e-05,
      "loss": 0.0089,
      "step": 939000
    },
    {
      "epoch": 0.0527913533438504,
      "grad_norm": 0.3794352114200592,
      "learning_rate": 9.477411909892207e-05,
      "loss": 0.009,
      "step": 939500
    },
    {
      "epoch": 0.05281944879533728,
      "grad_norm": 0.3588882088661194,
      "learning_rate": 9.477130797417701e-05,
      "loss": 0.0088,
      "step": 940000
    },
    {
      "epoch": 0.05281944879533728,
      "eval_loss": 0.005227159708738327,
      "eval_runtime": 20.0651,
      "eval_samples_per_second": 4983.778,
      "eval_steps_per_second": 77.896,
      "step": 940000
    },
    {
      "epoch": 0.05284754424682416,
      "grad_norm": 0.019173825159668922,
      "learning_rate": 9.476849684943194e-05,
      "loss": 0.0091,
      "step": 940500
    },
    {
      "epoch": 0.05287563969831104,
      "grad_norm": 0.1031152531504631,
      "learning_rate": 9.476568572468688e-05,
      "loss": 0.0093,
      "step": 941000
    },
    {
      "epoch": 0.052903735149797924,
      "grad_norm": 0.5665468573570251,
      "learning_rate": 9.476287459994181e-05,
      "loss": 0.0094,
      "step": 941500
    },
    {
      "epoch": 0.052931830601284806,
      "grad_norm": 0.1474328339099884,
      "learning_rate": 9.476006347519675e-05,
      "loss": 0.0086,
      "step": 942000
    },
    {
      "epoch": 0.05295992605277169,
      "grad_norm": 0.5411103367805481,
      "learning_rate": 9.475725235045168e-05,
      "loss": 0.0088,
      "step": 942500
    },
    {
      "epoch": 0.05298802150425857,
      "grad_norm": 0.02664460428059101,
      "learning_rate": 9.475444122570661e-05,
      "loss": 0.0085,
      "step": 943000
    },
    {
      "epoch": 0.05301611695574545,
      "grad_norm": 0.4129762649536133,
      "learning_rate": 9.475163010096155e-05,
      "loss": 0.0091,
      "step": 943500
    },
    {
      "epoch": 0.05304421240723233,
      "grad_norm": 0.4016517996788025,
      "learning_rate": 9.474881897621648e-05,
      "loss": 0.0085,
      "step": 944000
    },
    {
      "epoch": 0.05307230785871921,
      "grad_norm": 0.3630930483341217,
      "learning_rate": 9.474600785147142e-05,
      "loss": 0.009,
      "step": 944500
    },
    {
      "epoch": 0.053100403310206094,
      "grad_norm": 0.27936065196990967,
      "learning_rate": 9.474319672672635e-05,
      "loss": 0.0092,
      "step": 945000
    },
    {
      "epoch": 0.053128498761692976,
      "grad_norm": 0.19168215990066528,
      "learning_rate": 9.474038560198129e-05,
      "loss": 0.0084,
      "step": 945500
    },
    {
      "epoch": 0.05315659421317986,
      "grad_norm": 0.1441582441329956,
      "learning_rate": 9.473757447723622e-05,
      "loss": 0.009,
      "step": 946000
    },
    {
      "epoch": 0.05318468966466674,
      "grad_norm": 0.16549527645111084,
      "learning_rate": 9.473476335249115e-05,
      "loss": 0.0089,
      "step": 946500
    },
    {
      "epoch": 0.05321278511615362,
      "grad_norm": 0.4321097731590271,
      "learning_rate": 9.473195222774609e-05,
      "loss": 0.0089,
      "step": 947000
    },
    {
      "epoch": 0.0532408805676405,
      "grad_norm": 0.029737358912825584,
      "learning_rate": 9.472914110300102e-05,
      "loss": 0.0085,
      "step": 947500
    },
    {
      "epoch": 0.05326897601912738,
      "grad_norm": 0.21270672976970673,
      "learning_rate": 9.472632997825596e-05,
      "loss": 0.0095,
      "step": 948000
    },
    {
      "epoch": 0.053297071470614264,
      "grad_norm": 0.138302281498909,
      "learning_rate": 9.472351885351089e-05,
      "loss": 0.0091,
      "step": 948500
    },
    {
      "epoch": 0.053325166922101146,
      "grad_norm": 0.3591228425502777,
      "learning_rate": 9.472070772876582e-05,
      "loss": 0.0088,
      "step": 949000
    },
    {
      "epoch": 0.05335326237358803,
      "grad_norm": 0.06320951879024506,
      "learning_rate": 9.471789660402076e-05,
      "loss": 0.0096,
      "step": 949500
    },
    {
      "epoch": 0.05338135782507491,
      "grad_norm": 0.2061803936958313,
      "learning_rate": 9.471508547927569e-05,
      "loss": 0.0088,
      "step": 950000
    },
    {
      "epoch": 0.05338135782507491,
      "eval_loss": 0.0052050817757844925,
      "eval_runtime": 20.2873,
      "eval_samples_per_second": 4929.192,
      "eval_steps_per_second": 77.043,
      "step": 950000
    },
    {
      "epoch": 0.05340945327656179,
      "grad_norm": 0.44863614439964294,
      "learning_rate": 9.471227435453063e-05,
      "loss": 0.0093,
      "step": 950500
    },
    {
      "epoch": 0.05343754872804867,
      "grad_norm": 0.23434792459011078,
      "learning_rate": 9.470946322978556e-05,
      "loss": 0.0091,
      "step": 951000
    },
    {
      "epoch": 0.05346564417953555,
      "grad_norm": 0.24267712235450745,
      "learning_rate": 9.47066521050405e-05,
      "loss": 0.0088,
      "step": 951500
    },
    {
      "epoch": 0.053493739631022434,
      "grad_norm": 0.17601381242275238,
      "learning_rate": 9.470384098029542e-05,
      "loss": 0.0084,
      "step": 952000
    },
    {
      "epoch": 0.053521835082509316,
      "grad_norm": 0.13129088282585144,
      "learning_rate": 9.470102985555036e-05,
      "loss": 0.0093,
      "step": 952500
    },
    {
      "epoch": 0.0535499305339962,
      "grad_norm": 0.11551084369421005,
      "learning_rate": 9.469821873080529e-05,
      "loss": 0.009,
      "step": 953000
    },
    {
      "epoch": 0.05357802598548308,
      "grad_norm": 0.3179604113101959,
      "learning_rate": 9.469540760606023e-05,
      "loss": 0.009,
      "step": 953500
    },
    {
      "epoch": 0.05360612143696996,
      "grad_norm": 0.26962903141975403,
      "learning_rate": 9.469259648131517e-05,
      "loss": 0.009,
      "step": 954000
    },
    {
      "epoch": 0.05363421688845684,
      "grad_norm": 0.0886559933423996,
      "learning_rate": 9.468978535657009e-05,
      "loss": 0.0093,
      "step": 954500
    },
    {
      "epoch": 0.05366231233994372,
      "grad_norm": 0.3299482464790344,
      "learning_rate": 9.468697423182504e-05,
      "loss": 0.0087,
      "step": 955000
    },
    {
      "epoch": 0.053690407791430604,
      "grad_norm": 0.21481211483478546,
      "learning_rate": 9.468416310707996e-05,
      "loss": 0.0089,
      "step": 955500
    },
    {
      "epoch": 0.053718503242917486,
      "grad_norm": 0.026014115661382675,
      "learning_rate": 9.46813519823349e-05,
      "loss": 0.0089,
      "step": 956000
    },
    {
      "epoch": 0.05374659869440437,
      "grad_norm": 0.09079861640930176,
      "learning_rate": 9.467854085758982e-05,
      "loss": 0.0089,
      "step": 956500
    },
    {
      "epoch": 0.05377469414589125,
      "grad_norm": 0.31265413761138916,
      "learning_rate": 9.467572973284476e-05,
      "loss": 0.0088,
      "step": 957000
    },
    {
      "epoch": 0.05380278959737813,
      "grad_norm": 0.1217760220170021,
      "learning_rate": 9.467291860809971e-05,
      "loss": 0.0088,
      "step": 957500
    },
    {
      "epoch": 0.05383088504886501,
      "grad_norm": 0.21920327842235565,
      "learning_rate": 9.467010748335463e-05,
      "loss": 0.0085,
      "step": 958000
    },
    {
      "epoch": 0.05385898050035189,
      "grad_norm": 0.8256627917289734,
      "learning_rate": 9.466729635860958e-05,
      "loss": 0.0084,
      "step": 958500
    },
    {
      "epoch": 0.053887075951838774,
      "grad_norm": 0.29921090602874756,
      "learning_rate": 9.46644852338645e-05,
      "loss": 0.0095,
      "step": 959000
    },
    {
      "epoch": 0.053915171403325655,
      "grad_norm": 0.12197283655405045,
      "learning_rate": 9.466167410911943e-05,
      "loss": 0.0084,
      "step": 959500
    },
    {
      "epoch": 0.05394326685481254,
      "grad_norm": 0.4954530596733093,
      "learning_rate": 9.465886298437436e-05,
      "loss": 0.0085,
      "step": 960000
    },
    {
      "epoch": 0.05394326685481254,
      "eval_loss": 0.005110763479024172,
      "eval_runtime": 19.6171,
      "eval_samples_per_second": 5097.595,
      "eval_steps_per_second": 79.675,
      "step": 960000
    },
    {
      "epoch": 0.05397136230629942,
      "grad_norm": 0.25028517842292786,
      "learning_rate": 9.46560518596293e-05,
      "loss": 0.0088,
      "step": 960500
    },
    {
      "epoch": 0.05399945775778631,
      "grad_norm": 0.6921135187149048,
      "learning_rate": 9.465324073488425e-05,
      "loss": 0.0085,
      "step": 961000
    },
    {
      "epoch": 0.05402755320927319,
      "grad_norm": 0.0727284848690033,
      "learning_rate": 9.465042961013917e-05,
      "loss": 0.0089,
      "step": 961500
    },
    {
      "epoch": 0.05405564866076007,
      "grad_norm": 0.049247194081544876,
      "learning_rate": 9.46476184853941e-05,
      "loss": 0.0086,
      "step": 962000
    },
    {
      "epoch": 0.05408374411224695,
      "grad_norm": 0.09959887713193893,
      "learning_rate": 9.464480736064904e-05,
      "loss": 0.0083,
      "step": 962500
    },
    {
      "epoch": 0.05411183956373383,
      "grad_norm": 0.20049990713596344,
      "learning_rate": 9.464199623590397e-05,
      "loss": 0.0084,
      "step": 963000
    },
    {
      "epoch": 0.054139935015220714,
      "grad_norm": 0.375423789024353,
      "learning_rate": 9.46391851111589e-05,
      "loss": 0.0086,
      "step": 963500
    },
    {
      "epoch": 0.054168030466707595,
      "grad_norm": 0.07726951688528061,
      "learning_rate": 9.463637398641384e-05,
      "loss": 0.0087,
      "step": 964000
    },
    {
      "epoch": 0.05419612591819448,
      "grad_norm": 0.2718314528465271,
      "learning_rate": 9.463356286166877e-05,
      "loss": 0.009,
      "step": 964500
    },
    {
      "epoch": 0.05422422136968136,
      "grad_norm": 5.453738212585449,
      "learning_rate": 9.463075173692371e-05,
      "loss": 0.0085,
      "step": 965000
    },
    {
      "epoch": 0.05425231682116824,
      "grad_norm": 0.10007684677839279,
      "learning_rate": 9.462794061217864e-05,
      "loss": 0.0089,
      "step": 965500
    },
    {
      "epoch": 0.05428041227265512,
      "grad_norm": 0.26287713646888733,
      "learning_rate": 9.462512948743358e-05,
      "loss": 0.0087,
      "step": 966000
    },
    {
      "epoch": 0.054308507724142,
      "grad_norm": 0.37151169776916504,
      "learning_rate": 9.462231836268851e-05,
      "loss": 0.0089,
      "step": 966500
    },
    {
      "epoch": 0.054336603175628884,
      "grad_norm": 1.5284792184829712,
      "learning_rate": 9.461950723794344e-05,
      "loss": 0.008,
      "step": 967000
    },
    {
      "epoch": 0.054364698627115765,
      "grad_norm": 0.776301920413971,
      "learning_rate": 9.461669611319838e-05,
      "loss": 0.0084,
      "step": 967500
    },
    {
      "epoch": 0.054392794078602646,
      "grad_norm": 0.1419893354177475,
      "learning_rate": 9.46138849884533e-05,
      "loss": 0.0086,
      "step": 968000
    },
    {
      "epoch": 0.05442088953008953,
      "grad_norm": 0.09271334856748581,
      "learning_rate": 9.461107386370825e-05,
      "loss": 0.0084,
      "step": 968500
    },
    {
      "epoch": 0.05444898498157641,
      "grad_norm": 0.20247749984264374,
      "learning_rate": 9.460826273896318e-05,
      "loss": 0.0086,
      "step": 969000
    },
    {
      "epoch": 0.05447708043306329,
      "grad_norm": 0.24056357145309448,
      "learning_rate": 9.460545161421812e-05,
      "loss": 0.0083,
      "step": 969500
    },
    {
      "epoch": 0.05450517588455017,
      "grad_norm": 0.35901716351509094,
      "learning_rate": 9.460264048947305e-05,
      "loss": 0.0086,
      "step": 970000
    },
    {
      "epoch": 0.05450517588455017,
      "eval_loss": 0.004570933990180492,
      "eval_runtime": 18.4521,
      "eval_samples_per_second": 5419.452,
      "eval_steps_per_second": 84.706,
      "step": 970000
    },
    {
      "epoch": 0.054533271336037054,
      "grad_norm": 0.05664164200425148,
      "learning_rate": 9.459982936472797e-05,
      "loss": 0.0084,
      "step": 970500
    },
    {
      "epoch": 0.054561366787523935,
      "grad_norm": 0.18239036202430725,
      "learning_rate": 9.459701823998292e-05,
      "loss": 0.0083,
      "step": 971000
    },
    {
      "epoch": 0.054589462239010816,
      "grad_norm": 0.15516352653503418,
      "learning_rate": 9.459420711523784e-05,
      "loss": 0.008,
      "step": 971500
    },
    {
      "epoch": 0.0546175576904977,
      "grad_norm": 0.09754876792430878,
      "learning_rate": 9.459139599049279e-05,
      "loss": 0.0086,
      "step": 972000
    },
    {
      "epoch": 0.05464565314198458,
      "grad_norm": 0.1980436146259308,
      "learning_rate": 9.458858486574771e-05,
      "loss": 0.0084,
      "step": 972500
    },
    {
      "epoch": 0.05467374859347146,
      "grad_norm": 0.37477606534957886,
      "learning_rate": 9.458577374100264e-05,
      "loss": 0.0086,
      "step": 973000
    },
    {
      "epoch": 0.05470184404495834,
      "grad_norm": 0.2775787115097046,
      "learning_rate": 9.458296261625759e-05,
      "loss": 0.008,
      "step": 973500
    },
    {
      "epoch": 0.054729939496445223,
      "grad_norm": 0.06836254894733429,
      "learning_rate": 9.458015149151251e-05,
      "loss": 0.0079,
      "step": 974000
    },
    {
      "epoch": 0.054758034947932105,
      "grad_norm": 0.2821398675441742,
      "learning_rate": 9.457734036676746e-05,
      "loss": 0.0076,
      "step": 974500
    },
    {
      "epoch": 0.054786130399418986,
      "grad_norm": 0.0563991442322731,
      "learning_rate": 9.457452924202238e-05,
      "loss": 0.0079,
      "step": 975000
    },
    {
      "epoch": 0.05481422585090587,
      "grad_norm": 0.07409115880727768,
      "learning_rate": 9.457171811727731e-05,
      "loss": 0.0083,
      "step": 975500
    },
    {
      "epoch": 0.05484232130239275,
      "grad_norm": 0.3108732998371124,
      "learning_rate": 9.456890699253225e-05,
      "loss": 0.0085,
      "step": 976000
    },
    {
      "epoch": 0.05487041675387963,
      "grad_norm": 0.38822120428085327,
      "learning_rate": 9.456609586778718e-05,
      "loss": 0.008,
      "step": 976500
    },
    {
      "epoch": 0.05489851220536651,
      "grad_norm": 0.26746153831481934,
      "learning_rate": 9.456328474304213e-05,
      "loss": 0.0078,
      "step": 977000
    },
    {
      "epoch": 0.05492660765685339,
      "grad_norm": 0.3547424077987671,
      "learning_rate": 9.456047361829705e-05,
      "loss": 0.008,
      "step": 977500
    },
    {
      "epoch": 0.054954703108340275,
      "grad_norm": 0.07073407620191574,
      "learning_rate": 9.4557662493552e-05,
      "loss": 0.0081,
      "step": 978000
    },
    {
      "epoch": 0.054982798559827156,
      "grad_norm": 0.03285782411694527,
      "learning_rate": 9.455485136880692e-05,
      "loss": 0.008,
      "step": 978500
    },
    {
      "epoch": 0.05501089401131404,
      "grad_norm": 0.22397755086421967,
      "learning_rate": 9.455204024406185e-05,
      "loss": 0.0081,
      "step": 979000
    },
    {
      "epoch": 0.05503898946280092,
      "grad_norm": 0.572071373462677,
      "learning_rate": 9.454922911931679e-05,
      "loss": 0.0077,
      "step": 979500
    },
    {
      "epoch": 0.0550670849142878,
      "grad_norm": 0.21212990581989288,
      "learning_rate": 9.454641799457172e-05,
      "loss": 0.0081,
      "step": 980000
    },
    {
      "epoch": 0.0550670849142878,
      "eval_loss": 0.0041805352084338665,
      "eval_runtime": 19.5951,
      "eval_samples_per_second": 5103.327,
      "eval_steps_per_second": 79.765,
      "step": 980000
    },
    {
      "epoch": 0.05509518036577468,
      "grad_norm": 0.3621068298816681,
      "learning_rate": 9.454360686982667e-05,
      "loss": 0.0073,
      "step": 980500
    },
    {
      "epoch": 0.05512327581726156,
      "grad_norm": 0.1246485561132431,
      "learning_rate": 9.454079574508159e-05,
      "loss": 0.008,
      "step": 981000
    },
    {
      "epoch": 0.055151371268748445,
      "grad_norm": 0.07242214679718018,
      "learning_rate": 9.453798462033652e-05,
      "loss": 0.0074,
      "step": 981500
    },
    {
      "epoch": 0.055179466720235326,
      "grad_norm": 0.23047976195812225,
      "learning_rate": 9.453517349559146e-05,
      "loss": 0.0077,
      "step": 982000
    },
    {
      "epoch": 0.05520756217172221,
      "grad_norm": 0.38982653617858887,
      "learning_rate": 9.453236237084639e-05,
      "loss": 0.0074,
      "step": 982500
    },
    {
      "epoch": 0.05523565762320909,
      "grad_norm": 0.2811239957809448,
      "learning_rate": 9.452955124610133e-05,
      "loss": 0.0077,
      "step": 983000
    },
    {
      "epoch": 0.05526375307469597,
      "grad_norm": 0.1148081123828888,
      "learning_rate": 9.452674012135626e-05,
      "loss": 0.0074,
      "step": 983500
    },
    {
      "epoch": 0.05529184852618285,
      "grad_norm": 0.28826022148132324,
      "learning_rate": 9.45239289966112e-05,
      "loss": 0.0074,
      "step": 984000
    },
    {
      "epoch": 0.05531994397766973,
      "grad_norm": 0.12501484155654907,
      "learning_rate": 9.452111787186613e-05,
      "loss": 0.0069,
      "step": 984500
    },
    {
      "epoch": 0.055348039429156615,
      "grad_norm": 0.8862319588661194,
      "learning_rate": 9.451830674712106e-05,
      "loss": 0.0067,
      "step": 985000
    },
    {
      "epoch": 0.055376134880643496,
      "grad_norm": 0.0702730342745781,
      "learning_rate": 9.4515495622376e-05,
      "loss": 0.0063,
      "step": 985500
    },
    {
      "epoch": 0.05540423033213038,
      "grad_norm": 0.045840147882699966,
      "learning_rate": 9.451268449763093e-05,
      "loss": 0.0068,
      "step": 986000
    },
    {
      "epoch": 0.05543232578361726,
      "grad_norm": 0.10998285561800003,
      "learning_rate": 9.450987337288587e-05,
      "loss": 0.0062,
      "step": 986500
    },
    {
      "epoch": 0.05546042123510414,
      "grad_norm": 0.1073838323354721,
      "learning_rate": 9.45070622481408e-05,
      "loss": 0.0057,
      "step": 987000
    },
    {
      "epoch": 0.05548851668659102,
      "grad_norm": 0.24166566133499146,
      "learning_rate": 9.450425112339572e-05,
      "loss": 0.0064,
      "step": 987500
    },
    {
      "epoch": 0.0555166121380779,
      "grad_norm": 0.25495874881744385,
      "learning_rate": 9.450143999865067e-05,
      "loss": 0.0066,
      "step": 988000
    },
    {
      "epoch": 0.055544707589564785,
      "grad_norm": 0.22830963134765625,
      "learning_rate": 9.44986288739056e-05,
      "loss": 0.0067,
      "step": 988500
    },
    {
      "epoch": 0.055572803041051666,
      "grad_norm": 0.5426012277603149,
      "learning_rate": 9.449581774916054e-05,
      "loss": 0.0065,
      "step": 989000
    },
    {
      "epoch": 0.05560089849253855,
      "grad_norm": 0.12722907960414886,
      "learning_rate": 9.449300662441547e-05,
      "loss": 0.0062,
      "step": 989500
    },
    {
      "epoch": 0.05562899394402543,
      "grad_norm": 0.472575843334198,
      "learning_rate": 9.449019549967039e-05,
      "loss": 0.0063,
      "step": 990000
    },
    {
      "epoch": 0.05562899394402543,
      "eval_loss": 0.002266123192384839,
      "eval_runtime": 19.2273,
      "eval_samples_per_second": 5200.931,
      "eval_steps_per_second": 81.291,
      "step": 990000
    },
    {
      "epoch": 0.05565708939551231,
      "grad_norm": 0.07751372456550598,
      "learning_rate": 9.448738437492534e-05,
      "loss": 0.006,
      "step": 990500
    },
    {
      "epoch": 0.05568518484699919,
      "grad_norm": 0.19579535722732544,
      "learning_rate": 9.448457325018026e-05,
      "loss": 0.0059,
      "step": 991000
    },
    {
      "epoch": 0.05571328029848608,
      "grad_norm": 0.3797297775745392,
      "learning_rate": 9.448176212543521e-05,
      "loss": 0.0055,
      "step": 991500
    },
    {
      "epoch": 0.05574137574997296,
      "grad_norm": 0.531986653804779,
      "learning_rate": 9.447895100069013e-05,
      "loss": 0.0064,
      "step": 992000
    },
    {
      "epoch": 0.05576947120145984,
      "grad_norm": 0.3182501196861267,
      "learning_rate": 9.447613987594506e-05,
      "loss": 0.0064,
      "step": 992500
    },
    {
      "epoch": 0.055797566652946724,
      "grad_norm": 0.25627490878105164,
      "learning_rate": 9.447332875120001e-05,
      "loss": 0.0063,
      "step": 993000
    },
    {
      "epoch": 0.055825662104433606,
      "grad_norm": 0.06150306388735771,
      "learning_rate": 9.447051762645493e-05,
      "loss": 0.0059,
      "step": 993500
    },
    {
      "epoch": 0.05585375755592049,
      "grad_norm": 0.1977594792842865,
      "learning_rate": 9.446770650170988e-05,
      "loss": 0.0058,
      "step": 994000
    },
    {
      "epoch": 0.05588185300740737,
      "grad_norm": 0.21720221638679504,
      "learning_rate": 9.44648953769648e-05,
      "loss": 0.0059,
      "step": 994500
    },
    {
      "epoch": 0.05590994845889425,
      "grad_norm": 0.05759790539741516,
      "learning_rate": 9.446208425221973e-05,
      "loss": 0.0063,
      "step": 995000
    },
    {
      "epoch": 0.05593804391038113,
      "grad_norm": 0.340320348739624,
      "learning_rate": 9.445927312747467e-05,
      "loss": 0.0057,
      "step": 995500
    },
    {
      "epoch": 0.05596613936186801,
      "grad_norm": 0.29079046845436096,
      "learning_rate": 9.44564620027296e-05,
      "loss": 0.0062,
      "step": 996000
    },
    {
      "epoch": 0.055994234813354894,
      "grad_norm": 0.01769351027905941,
      "learning_rate": 9.445365087798455e-05,
      "loss": 0.006,
      "step": 996500
    },
    {
      "epoch": 0.056022330264841776,
      "grad_norm": 0.26164400577545166,
      "learning_rate": 9.445083975323947e-05,
      "loss": 0.006,
      "step": 997000
    },
    {
      "epoch": 0.05605042571632866,
      "grad_norm": 0.0992632508277893,
      "learning_rate": 9.44480286284944e-05,
      "loss": 0.006,
      "step": 997500
    },
    {
      "epoch": 0.05607852116781554,
      "grad_norm": 0.41676095128059387,
      "learning_rate": 9.444521750374934e-05,
      "loss": 0.0059,
      "step": 998000
    },
    {
      "epoch": 0.05610661661930242,
      "grad_norm": 0.11262457817792892,
      "learning_rate": 9.444240637900427e-05,
      "loss": 0.0061,
      "step": 998500
    },
    {
      "epoch": 0.0561347120707893,
      "grad_norm": 0.5516074299812317,
      "learning_rate": 9.443959525425921e-05,
      "loss": 0.0065,
      "step": 999000
    },
    {
      "epoch": 0.05616280752227618,
      "grad_norm": 0.16097323596477509,
      "learning_rate": 9.443678412951414e-05,
      "loss": 0.006,
      "step": 999500
    },
    {
      "epoch": 0.056190902973763064,
      "grad_norm": 0.3132604956626892,
      "learning_rate": 9.443397300476908e-05,
      "loss": 0.006,
      "step": 1000000
    },
    {
      "epoch": 0.056190902973763064,
      "eval_loss": 0.0022824257612228394,
      "eval_runtime": 19.1841,
      "eval_samples_per_second": 5212.66,
      "eval_steps_per_second": 81.474,
      "step": 1000000
    },
    {
      "epoch": 0.056218998425249946,
      "grad_norm": 0.11725126206874847,
      "learning_rate": 9.443116188002401e-05,
      "loss": 0.006,
      "step": 1000500
    },
    {
      "epoch": 0.05624709387673683,
      "grad_norm": 0.13893380761146545,
      "learning_rate": 9.442835075527895e-05,
      "loss": 0.0057,
      "step": 1001000
    },
    {
      "epoch": 0.05627518932822371,
      "grad_norm": 0.09486781805753708,
      "learning_rate": 9.442553963053388e-05,
      "loss": 0.0057,
      "step": 1001500
    },
    {
      "epoch": 0.05630328477971059,
      "grad_norm": 0.794069230556488,
      "learning_rate": 9.442272850578881e-05,
      "loss": 0.0066,
      "step": 1002000
    },
    {
      "epoch": 0.05633138023119747,
      "grad_norm": 0.2456064075231552,
      "learning_rate": 9.441991738104375e-05,
      "loss": 0.0059,
      "step": 1002500
    },
    {
      "epoch": 0.05635947568268435,
      "grad_norm": 0.421657919883728,
      "learning_rate": 9.441710625629868e-05,
      "loss": 0.0055,
      "step": 1003000
    },
    {
      "epoch": 0.056387571134171234,
      "grad_norm": 0.4422699213027954,
      "learning_rate": 9.44142951315536e-05,
      "loss": 0.0059,
      "step": 1003500
    },
    {
      "epoch": 0.056415666585658115,
      "grad_norm": 0.17850863933563232,
      "learning_rate": 9.441148400680855e-05,
      "loss": 0.0066,
      "step": 1004000
    },
    {
      "epoch": 0.056443762037145,
      "grad_norm": 0.10748935490846634,
      "learning_rate": 9.440867288206349e-05,
      "loss": 0.0061,
      "step": 1004500
    },
    {
      "epoch": 0.05647185748863188,
      "grad_norm": 0.026661822572350502,
      "learning_rate": 9.440586175731842e-05,
      "loss": 0.0058,
      "step": 1005000
    },
    {
      "epoch": 0.05649995294011876,
      "grad_norm": 0.19881075620651245,
      "learning_rate": 9.440305063257335e-05,
      "loss": 0.0062,
      "step": 1005500
    },
    {
      "epoch": 0.05652804839160564,
      "grad_norm": 0.1387328952550888,
      "learning_rate": 9.440023950782827e-05,
      "loss": 0.0055,
      "step": 1006000
    },
    {
      "epoch": 0.05655614384309252,
      "grad_norm": 0.13334153592586517,
      "learning_rate": 9.439742838308322e-05,
      "loss": 0.0058,
      "step": 1006500
    },
    {
      "epoch": 0.056584239294579404,
      "grad_norm": 0.3754226267337799,
      "learning_rate": 9.439461725833814e-05,
      "loss": 0.006,
      "step": 1007000
    },
    {
      "epoch": 0.056612334746066285,
      "grad_norm": 0.2208358496427536,
      "learning_rate": 9.439180613359309e-05,
      "loss": 0.0062,
      "step": 1007500
    },
    {
      "epoch": 0.05664043019755317,
      "grad_norm": 0.09334028512239456,
      "learning_rate": 9.438899500884802e-05,
      "loss": 0.0058,
      "step": 1008000
    },
    {
      "epoch": 0.05666852564904005,
      "grad_norm": 0.042059823870658875,
      "learning_rate": 9.438618388410295e-05,
      "loss": 0.0056,
      "step": 1008500
    },
    {
      "epoch": 0.05669662110052693,
      "grad_norm": 0.16320469975471497,
      "learning_rate": 9.43833727593579e-05,
      "loss": 0.0058,
      "step": 1009000
    },
    {
      "epoch": 0.05672471655201381,
      "grad_norm": 0.10705658048391342,
      "learning_rate": 9.438056163461281e-05,
      "loss": 0.006,
      "step": 1009500
    },
    {
      "epoch": 0.05675281200350069,
      "grad_norm": 0.0879867747426033,
      "learning_rate": 9.437775050986776e-05,
      "loss": 0.0068,
      "step": 1010000
    },
    {
      "epoch": 0.05675281200350069,
      "eval_loss": 0.002230176469311118,
      "eval_runtime": 19.0682,
      "eval_samples_per_second": 5244.321,
      "eval_steps_per_second": 81.969,
      "step": 1010000
    },
    {
      "epoch": 0.056780907454987574,
      "grad_norm": 0.47899842262268066,
      "learning_rate": 9.437493938512268e-05,
      "loss": 0.0062,
      "step": 1010500
    },
    {
      "epoch": 0.056809002906474455,
      "grad_norm": 0.07057905942201614,
      "learning_rate": 9.437212826037762e-05,
      "loss": 0.0059,
      "step": 1011000
    },
    {
      "epoch": 0.05683709835796134,
      "grad_norm": 0.12807485461235046,
      "learning_rate": 9.436931713563256e-05,
      "loss": 0.0057,
      "step": 1011500
    },
    {
      "epoch": 0.05686519380944822,
      "grad_norm": 0.14020729064941406,
      "learning_rate": 9.436650601088749e-05,
      "loss": 0.0062,
      "step": 1012000
    },
    {
      "epoch": 0.0568932892609351,
      "grad_norm": 0.08638536185026169,
      "learning_rate": 9.436369488614243e-05,
      "loss": 0.0058,
      "step": 1012500
    },
    {
      "epoch": 0.05692138471242198,
      "grad_norm": 0.38781824707984924,
      "learning_rate": 9.436088376139735e-05,
      "loss": 0.0064,
      "step": 1013000
    },
    {
      "epoch": 0.05694948016390886,
      "grad_norm": 0.22407223284244537,
      "learning_rate": 9.43580726366523e-05,
      "loss": 0.0065,
      "step": 1013500
    },
    {
      "epoch": 0.056977575615395744,
      "grad_norm": 0.08222321420907974,
      "learning_rate": 9.435526151190722e-05,
      "loss": 0.0064,
      "step": 1014000
    },
    {
      "epoch": 0.057005671066882625,
      "grad_norm": 0.054074447602033615,
      "learning_rate": 9.435245038716216e-05,
      "loss": 0.0056,
      "step": 1014500
    },
    {
      "epoch": 0.05703376651836951,
      "grad_norm": 0.2864433228969574,
      "learning_rate": 9.434963926241709e-05,
      "loss": 0.0056,
      "step": 1015000
    },
    {
      "epoch": 0.05706186196985639,
      "grad_norm": 0.7203058004379272,
      "learning_rate": 9.434682813767203e-05,
      "loss": 0.006,
      "step": 1015500
    },
    {
      "epoch": 0.05708995742134327,
      "grad_norm": 0.3431790769100189,
      "learning_rate": 9.434401701292697e-05,
      "loss": 0.0056,
      "step": 1016000
    },
    {
      "epoch": 0.05711805287283015,
      "grad_norm": 0.08655446022748947,
      "learning_rate": 9.43412058881819e-05,
      "loss": 0.006,
      "step": 1016500
    },
    {
      "epoch": 0.05714614832431703,
      "grad_norm": 0.08598200231790543,
      "learning_rate": 9.433839476343683e-05,
      "loss": 0.0062,
      "step": 1017000
    },
    {
      "epoch": 0.057174243775803914,
      "grad_norm": 0.06184503436088562,
      "learning_rate": 9.433558363869176e-05,
      "loss": 0.0058,
      "step": 1017500
    },
    {
      "epoch": 0.057202339227290795,
      "grad_norm": 0.06753017753362656,
      "learning_rate": 9.43327725139467e-05,
      "loss": 0.0059,
      "step": 1018000
    },
    {
      "epoch": 0.05723043467877768,
      "grad_norm": 0.13688305020332336,
      "learning_rate": 9.432996138920163e-05,
      "loss": 0.0059,
      "step": 1018500
    },
    {
      "epoch": 0.05725853013026456,
      "grad_norm": 0.26764601469039917,
      "learning_rate": 9.432715026445656e-05,
      "loss": 0.0055,
      "step": 1019000
    },
    {
      "epoch": 0.05728662558175144,
      "grad_norm": 0.07553829252719879,
      "learning_rate": 9.43243391397115e-05,
      "loss": 0.0058,
      "step": 1019500
    },
    {
      "epoch": 0.05731472103323832,
      "grad_norm": 0.8010857105255127,
      "learning_rate": 9.432152801496643e-05,
      "loss": 0.0057,
      "step": 1020000
    },
    {
      "epoch": 0.05731472103323832,
      "eval_loss": 0.002007012255489826,
      "eval_runtime": 20.1384,
      "eval_samples_per_second": 4965.643,
      "eval_steps_per_second": 77.613,
      "step": 1020000
    },
    {
      "epoch": 0.0573428164847252,
      "grad_norm": 0.48596304655075073,
      "learning_rate": 9.431871689022137e-05,
      "loss": 0.0061,
      "step": 1020500
    },
    {
      "epoch": 0.057370911936212084,
      "grad_norm": 0.04652145132422447,
      "learning_rate": 9.43159057654763e-05,
      "loss": 0.0059,
      "step": 1021000
    },
    {
      "epoch": 0.057399007387698965,
      "grad_norm": 0.4463963806629181,
      "learning_rate": 9.431309464073124e-05,
      "loss": 0.0058,
      "step": 1021500
    },
    {
      "epoch": 0.05742710283918585,
      "grad_norm": 0.21848636865615845,
      "learning_rate": 9.431028351598617e-05,
      "loss": 0.0059,
      "step": 1022000
    },
    {
      "epoch": 0.057455198290672735,
      "grad_norm": 0.18036803603172302,
      "learning_rate": 9.43074723912411e-05,
      "loss": 0.0058,
      "step": 1022500
    },
    {
      "epoch": 0.057483293742159616,
      "grad_norm": 0.03895827382802963,
      "learning_rate": 9.430466126649603e-05,
      "loss": 0.0054,
      "step": 1023000
    },
    {
      "epoch": 0.0575113891936465,
      "grad_norm": 0.2485528588294983,
      "learning_rate": 9.430185014175097e-05,
      "loss": 0.0064,
      "step": 1023500
    },
    {
      "epoch": 0.05753948464513338,
      "grad_norm": 0.07069829851388931,
      "learning_rate": 9.429903901700591e-05,
      "loss": 0.0056,
      "step": 1024000
    },
    {
      "epoch": 0.05756758009662026,
      "grad_norm": 0.18632197380065918,
      "learning_rate": 9.429622789226084e-05,
      "loss": 0.0063,
      "step": 1024500
    },
    {
      "epoch": 0.05759567554810714,
      "grad_norm": 0.07390689849853516,
      "learning_rate": 9.429341676751578e-05,
      "loss": 0.0058,
      "step": 1025000
    },
    {
      "epoch": 0.05762377099959402,
      "grad_norm": 0.41620302200317383,
      "learning_rate": 9.42906056427707e-05,
      "loss": 0.0056,
      "step": 1025500
    },
    {
      "epoch": 0.057651866451080905,
      "grad_norm": 0.08628528565168381,
      "learning_rate": 9.428779451802564e-05,
      "loss": 0.0065,
      "step": 1026000
    },
    {
      "epoch": 0.057679961902567786,
      "grad_norm": 0.10147810727357864,
      "learning_rate": 9.428498339328056e-05,
      "loss": 0.006,
      "step": 1026500
    },
    {
      "epoch": 0.05770805735405467,
      "grad_norm": 0.06869074702262878,
      "learning_rate": 9.428217226853551e-05,
      "loss": 0.0063,
      "step": 1027000
    },
    {
      "epoch": 0.05773615280554155,
      "grad_norm": 0.08632701635360718,
      "learning_rate": 9.427936114379045e-05,
      "loss": 0.0055,
      "step": 1027500
    },
    {
      "epoch": 0.05776424825702843,
      "grad_norm": 0.17373690009117126,
      "learning_rate": 9.427655001904537e-05,
      "loss": 0.0061,
      "step": 1028000
    },
    {
      "epoch": 0.05779234370851531,
      "grad_norm": 0.6814315915107727,
      "learning_rate": 9.427373889430032e-05,
      "loss": 0.0052,
      "step": 1028500
    },
    {
      "epoch": 0.05782043916000219,
      "grad_norm": 0.471828818321228,
      "learning_rate": 9.427092776955524e-05,
      "loss": 0.0059,
      "step": 1029000
    },
    {
      "epoch": 0.057848534611489075,
      "grad_norm": 0.18087413907051086,
      "learning_rate": 9.426811664481018e-05,
      "loss": 0.0059,
      "step": 1029500
    },
    {
      "epoch": 0.057876630062975956,
      "grad_norm": 0.5395269989967346,
      "learning_rate": 9.42653055200651e-05,
      "loss": 0.0059,
      "step": 1030000
    },
    {
      "epoch": 0.057876630062975956,
      "eval_loss": 0.001969653647392988,
      "eval_runtime": 19.6696,
      "eval_samples_per_second": 5083.983,
      "eval_steps_per_second": 79.463,
      "step": 1030000
    },
    {
      "epoch": 0.05790472551446284,
      "grad_norm": 0.18638700246810913,
      "learning_rate": 9.426249439532004e-05,
      "loss": 0.0056,
      "step": 1030500
    },
    {
      "epoch": 0.05793282096594972,
      "grad_norm": 0.44432708621025085,
      "learning_rate": 9.425968327057499e-05,
      "loss": 0.0054,
      "step": 1031000
    },
    {
      "epoch": 0.0579609164174366,
      "grad_norm": 0.5968712568283081,
      "learning_rate": 9.425687214582991e-05,
      "loss": 0.0054,
      "step": 1031500
    },
    {
      "epoch": 0.05798901186892348,
      "grad_norm": 0.19866973161697388,
      "learning_rate": 9.425406102108486e-05,
      "loss": 0.0057,
      "step": 1032000
    },
    {
      "epoch": 0.05801710732041036,
      "grad_norm": 0.3966352641582489,
      "learning_rate": 9.425124989633978e-05,
      "loss": 0.0075,
      "step": 1032500
    },
    {
      "epoch": 0.058045202771897245,
      "grad_norm": 0.23202066123485565,
      "learning_rate": 9.424843877159471e-05,
      "loss": 0.0081,
      "step": 1033000
    },
    {
      "epoch": 0.058073298223384126,
      "grad_norm": 0.38453951478004456,
      "learning_rate": 9.424562764684964e-05,
      "loss": 0.0056,
      "step": 1033500
    },
    {
      "epoch": 0.05810139367487101,
      "grad_norm": 0.03344098851084709,
      "learning_rate": 9.424281652210458e-05,
      "loss": 0.0051,
      "step": 1034000
    },
    {
      "epoch": 0.05812948912635789,
      "grad_norm": 0.4847237169742584,
      "learning_rate": 9.424000539735951e-05,
      "loss": 0.0054,
      "step": 1034500
    },
    {
      "epoch": 0.05815758457784477,
      "grad_norm": 1.1010239124298096,
      "learning_rate": 9.423719427261445e-05,
      "loss": 0.0057,
      "step": 1035000
    },
    {
      "epoch": 0.05818568002933165,
      "grad_norm": 0.3408287763595581,
      "learning_rate": 9.423438314786938e-05,
      "loss": 0.0049,
      "step": 1035500
    },
    {
      "epoch": 0.05821377548081853,
      "grad_norm": 0.07939291000366211,
      "learning_rate": 9.423157202312432e-05,
      "loss": 0.0058,
      "step": 1036000
    },
    {
      "epoch": 0.058241870932305415,
      "grad_norm": 0.24263262748718262,
      "learning_rate": 9.422876089837925e-05,
      "loss": 0.0058,
      "step": 1036500
    },
    {
      "epoch": 0.058269966383792296,
      "grad_norm": 0.6882963180541992,
      "learning_rate": 9.422594977363418e-05,
      "loss": 0.0055,
      "step": 1037000
    },
    {
      "epoch": 0.05829806183527918,
      "grad_norm": 0.8807448744773865,
      "learning_rate": 9.422313864888912e-05,
      "loss": 0.0059,
      "step": 1037500
    },
    {
      "epoch": 0.05832615728676606,
      "grad_norm": 0.1243123784661293,
      "learning_rate": 9.422032752414405e-05,
      "loss": 0.0053,
      "step": 1038000
    },
    {
      "epoch": 0.05835425273825294,
      "grad_norm": 0.05654731020331383,
      "learning_rate": 9.421751639939899e-05,
      "loss": 0.0051,
      "step": 1038500
    },
    {
      "epoch": 0.05838234818973982,
      "grad_norm": 0.11940524727106094,
      "learning_rate": 9.421470527465392e-05,
      "loss": 0.0056,
      "step": 1039000
    },
    {
      "epoch": 0.0584104436412267,
      "grad_norm": 0.3440818190574646,
      "learning_rate": 9.421189414990886e-05,
      "loss": 0.0054,
      "step": 1039500
    },
    {
      "epoch": 0.058438539092713584,
      "grad_norm": 0.3219764232635498,
      "learning_rate": 9.420908302516379e-05,
      "loss": 0.0058,
      "step": 1040000
    },
    {
      "epoch": 0.058438539092713584,
      "eval_loss": 0.0018597259186208248,
      "eval_runtime": 20.0049,
      "eval_samples_per_second": 4998.776,
      "eval_steps_per_second": 78.131,
      "step": 1040000
    },
    {
      "epoch": 0.058466634544200466,
      "grad_norm": 0.058961957693099976,
      "learning_rate": 9.420627190041872e-05,
      "loss": 0.0051,
      "step": 1040500
    },
    {
      "epoch": 0.05849472999568735,
      "grad_norm": 0.22350463271141052,
      "learning_rate": 9.420346077567366e-05,
      "loss": 0.0058,
      "step": 1041000
    },
    {
      "epoch": 0.05852282544717423,
      "grad_norm": 0.44681522250175476,
      "learning_rate": 9.420064965092858e-05,
      "loss": 0.0058,
      "step": 1041500
    },
    {
      "epoch": 0.05855092089866111,
      "grad_norm": 0.36007800698280334,
      "learning_rate": 9.419783852618353e-05,
      "loss": 0.0056,
      "step": 1042000
    },
    {
      "epoch": 0.05857901635014799,
      "grad_norm": 0.3681529462337494,
      "learning_rate": 9.419502740143845e-05,
      "loss": 0.006,
      "step": 1042500
    },
    {
      "epoch": 0.05860711180163487,
      "grad_norm": 0.24920400977134705,
      "learning_rate": 9.41922162766934e-05,
      "loss": 0.0053,
      "step": 1043000
    },
    {
      "epoch": 0.058635207253121754,
      "grad_norm": 0.5788966417312622,
      "learning_rate": 9.418940515194833e-05,
      "loss": 0.0052,
      "step": 1043500
    },
    {
      "epoch": 0.058663302704608636,
      "grad_norm": 0.10788857191801071,
      "learning_rate": 9.418659402720325e-05,
      "loss": 0.0049,
      "step": 1044000
    },
    {
      "epoch": 0.05869139815609552,
      "grad_norm": 0.25409218668937683,
      "learning_rate": 9.41837829024582e-05,
      "loss": 0.0054,
      "step": 1044500
    },
    {
      "epoch": 0.0587194936075824,
      "grad_norm": 0.325974702835083,
      "learning_rate": 9.418097177771312e-05,
      "loss": 0.0051,
      "step": 1045000
    },
    {
      "epoch": 0.05874758905906928,
      "grad_norm": 0.14308024942874908,
      "learning_rate": 9.417816065296807e-05,
      "loss": 0.0053,
      "step": 1045500
    },
    {
      "epoch": 0.05877568451055616,
      "grad_norm": 0.10792479664087296,
      "learning_rate": 9.417534952822299e-05,
      "loss": 0.0055,
      "step": 1046000
    },
    {
      "epoch": 0.05880377996204304,
      "grad_norm": 0.10221879929304123,
      "learning_rate": 9.417253840347793e-05,
      "loss": 0.0055,
      "step": 1046500
    },
    {
      "epoch": 0.058831875413529924,
      "grad_norm": 0.01788267120718956,
      "learning_rate": 9.416972727873287e-05,
      "loss": 0.0054,
      "step": 1047000
    },
    {
      "epoch": 0.058859970865016806,
      "grad_norm": 0.16223303973674774,
      "learning_rate": 9.416691615398779e-05,
      "loss": 0.0054,
      "step": 1047500
    },
    {
      "epoch": 0.05888806631650369,
      "grad_norm": 0.040320511907339096,
      "learning_rate": 9.416410502924274e-05,
      "loss": 0.0057,
      "step": 1048000
    },
    {
      "epoch": 0.05891616176799057,
      "grad_norm": 0.13057146966457367,
      "learning_rate": 9.416129390449766e-05,
      "loss": 0.0054,
      "step": 1048500
    },
    {
      "epoch": 0.05894425721947745,
      "grad_norm": 0.4179122745990753,
      "learning_rate": 9.41584827797526e-05,
      "loss": 0.0056,
      "step": 1049000
    },
    {
      "epoch": 0.05897235267096433,
      "grad_norm": 0.744359016418457,
      "learning_rate": 9.415567165500753e-05,
      "loss": 0.005,
      "step": 1049500
    },
    {
      "epoch": 0.05900044812245121,
      "grad_norm": 0.13442540168762207,
      "learning_rate": 9.415286053026246e-05,
      "loss": 0.0055,
      "step": 1050000
    },
    {
      "epoch": 0.05900044812245121,
      "eval_loss": 0.001751984702423215,
      "eval_runtime": 20.0923,
      "eval_samples_per_second": 4977.024,
      "eval_steps_per_second": 77.791,
      "step": 1050000
    },
    {
      "epoch": 0.059028543573938094,
      "grad_norm": 0.2074086219072342,
      "learning_rate": 9.415004940551741e-05,
      "loss": 0.0053,
      "step": 1050500
    },
    {
      "epoch": 0.059056639025424976,
      "grad_norm": 0.07191409915685654,
      "learning_rate": 9.414723828077233e-05,
      "loss": 0.0057,
      "step": 1051000
    },
    {
      "epoch": 0.05908473447691186,
      "grad_norm": 0.13443590700626373,
      "learning_rate": 9.414442715602728e-05,
      "loss": 0.005,
      "step": 1051500
    },
    {
      "epoch": 0.05911282992839874,
      "grad_norm": 0.27625772356987,
      "learning_rate": 9.41416160312822e-05,
      "loss": 0.0054,
      "step": 1052000
    },
    {
      "epoch": 0.05914092537988563,
      "grad_norm": 0.5286712050437927,
      "learning_rate": 9.413880490653713e-05,
      "loss": 0.0051,
      "step": 1052500
    },
    {
      "epoch": 0.05916902083137251,
      "grad_norm": 0.037989091128110886,
      "learning_rate": 9.413599378179207e-05,
      "loss": 0.0051,
      "step": 1053000
    },
    {
      "epoch": 0.05919711628285939,
      "grad_norm": 0.031353022903203964,
      "learning_rate": 9.4133182657047e-05,
      "loss": 0.0057,
      "step": 1053500
    },
    {
      "epoch": 0.05922521173434627,
      "grad_norm": 0.30285385251045227,
      "learning_rate": 9.413037153230193e-05,
      "loss": 0.0049,
      "step": 1054000
    },
    {
      "epoch": 0.05925330718583315,
      "grad_norm": 0.2800135314464569,
      "learning_rate": 9.412756040755687e-05,
      "loss": 0.0057,
      "step": 1054500
    },
    {
      "epoch": 0.059281402637320034,
      "grad_norm": 0.17868810892105103,
      "learning_rate": 9.41247492828118e-05,
      "loss": 0.0053,
      "step": 1055000
    },
    {
      "epoch": 0.059309498088806915,
      "grad_norm": 0.12454162538051605,
      "learning_rate": 9.412193815806674e-05,
      "loss": 0.0053,
      "step": 1055500
    },
    {
      "epoch": 0.0593375935402938,
      "grad_norm": 0.15717969834804535,
      "learning_rate": 9.411912703332167e-05,
      "loss": 0.005,
      "step": 1056000
    },
    {
      "epoch": 0.05936568899178068,
      "grad_norm": 0.14379501342773438,
      "learning_rate": 9.41163159085766e-05,
      "loss": 0.0053,
      "step": 1056500
    },
    {
      "epoch": 0.05939378444326756,
      "grad_norm": 0.3426077663898468,
      "learning_rate": 9.411350478383154e-05,
      "loss": 0.0054,
      "step": 1057000
    },
    {
      "epoch": 0.05942187989475444,
      "grad_norm": 0.31122326850891113,
      "learning_rate": 9.411069365908647e-05,
      "loss": 0.0054,
      "step": 1057500
    },
    {
      "epoch": 0.05944997534624132,
      "grad_norm": 0.216606006026268,
      "learning_rate": 9.410788253434141e-05,
      "loss": 0.0054,
      "step": 1058000
    },
    {
      "epoch": 0.059478070797728204,
      "grad_norm": 0.015387047082185745,
      "learning_rate": 9.410507140959634e-05,
      "loss": 0.0047,
      "step": 1058500
    },
    {
      "epoch": 0.059506166249215085,
      "grad_norm": 0.44823530316352844,
      "learning_rate": 9.410226028485128e-05,
      "loss": 0.0055,
      "step": 1059000
    },
    {
      "epoch": 0.05953426170070197,
      "grad_norm": 0.2627924382686615,
      "learning_rate": 9.409944916010621e-05,
      "loss": 0.0057,
      "step": 1059500
    },
    {
      "epoch": 0.05956235715218885,
      "grad_norm": 0.03279916197061539,
      "learning_rate": 9.409663803536115e-05,
      "loss": 0.0053,
      "step": 1060000
    },
    {
      "epoch": 0.05956235715218885,
      "eval_loss": 0.0018428622279316187,
      "eval_runtime": 19.0736,
      "eval_samples_per_second": 5242.847,
      "eval_steps_per_second": 81.946,
      "step": 1060000
    },
    {
      "epoch": 0.05959045260367573,
      "grad_norm": 0.025215189903974533,
      "learning_rate": 9.409382691061608e-05,
      "loss": 0.0048,
      "step": 1060500
    },
    {
      "epoch": 0.05961854805516261,
      "grad_norm": 0.12168458104133606,
      "learning_rate": 9.4091015785871e-05,
      "loss": 0.0056,
      "step": 1061000
    },
    {
      "epoch": 0.05964664350664949,
      "grad_norm": 0.014983178116381168,
      "learning_rate": 9.408820466112595e-05,
      "loss": 0.0051,
      "step": 1061500
    },
    {
      "epoch": 0.059674738958136374,
      "grad_norm": 0.44035592675209045,
      "learning_rate": 9.408539353638088e-05,
      "loss": 0.0057,
      "step": 1062000
    },
    {
      "epoch": 0.059702834409623255,
      "grad_norm": 0.7135604023933411,
      "learning_rate": 9.408258241163582e-05,
      "loss": 0.006,
      "step": 1062500
    },
    {
      "epoch": 0.05973092986111014,
      "grad_norm": 0.125388041138649,
      "learning_rate": 9.407977128689075e-05,
      "loss": 0.0052,
      "step": 1063000
    },
    {
      "epoch": 0.05975902531259702,
      "grad_norm": 0.2766834795475006,
      "learning_rate": 9.407696016214567e-05,
      "loss": 0.0051,
      "step": 1063500
    },
    {
      "epoch": 0.0597871207640839,
      "grad_norm": 0.6228426694869995,
      "learning_rate": 9.407414903740062e-05,
      "loss": 0.005,
      "step": 1064000
    },
    {
      "epoch": 0.05981521621557078,
      "grad_norm": 0.020105861127376556,
      "learning_rate": 9.407133791265554e-05,
      "loss": 0.0056,
      "step": 1064500
    },
    {
      "epoch": 0.05984331166705766,
      "grad_norm": 0.2660193145275116,
      "learning_rate": 9.406852678791049e-05,
      "loss": 0.0053,
      "step": 1065000
    },
    {
      "epoch": 0.059871407118544544,
      "grad_norm": 0.2549102008342743,
      "learning_rate": 9.406571566316541e-05,
      "loss": 0.0052,
      "step": 1065500
    },
    {
      "epoch": 0.059899502570031425,
      "grad_norm": 0.2330065369606018,
      "learning_rate": 9.406290453842034e-05,
      "loss": 0.0054,
      "step": 1066000
    },
    {
      "epoch": 0.05992759802151831,
      "grad_norm": 0.10881631076335907,
      "learning_rate": 9.406009341367529e-05,
      "loss": 0.0053,
      "step": 1066500
    },
    {
      "epoch": 0.05995569347300519,
      "grad_norm": 0.1842401772737503,
      "learning_rate": 9.405728228893021e-05,
      "loss": 0.0051,
      "step": 1067000
    },
    {
      "epoch": 0.05998378892449207,
      "grad_norm": 0.3881916105747223,
      "learning_rate": 9.405447116418516e-05,
      "loss": 0.0055,
      "step": 1067500
    },
    {
      "epoch": 0.06001188437597895,
      "grad_norm": 0.397443562746048,
      "learning_rate": 9.405166003944008e-05,
      "loss": 0.0056,
      "step": 1068000
    },
    {
      "epoch": 0.06003997982746583,
      "grad_norm": 0.5855713486671448,
      "learning_rate": 9.404884891469501e-05,
      "loss": 0.0048,
      "step": 1068500
    },
    {
      "epoch": 0.060068075278952714,
      "grad_norm": 0.1939539760351181,
      "learning_rate": 9.404603778994995e-05,
      "loss": 0.0051,
      "step": 1069000
    },
    {
      "epoch": 0.060096170730439595,
      "grad_norm": 0.21951383352279663,
      "learning_rate": 9.404322666520488e-05,
      "loss": 0.0049,
      "step": 1069500
    },
    {
      "epoch": 0.060124266181926476,
      "grad_norm": 0.1847667396068573,
      "learning_rate": 9.404041554045983e-05,
      "loss": 0.0055,
      "step": 1070000
    },
    {
      "epoch": 0.060124266181926476,
      "eval_loss": 0.001673010759986937,
      "eval_runtime": 18.8884,
      "eval_samples_per_second": 5294.241,
      "eval_steps_per_second": 82.749,
      "step": 1070000
    },
    {
      "epoch": 0.06015236163341336,
      "grad_norm": 0.7074588537216187,
      "learning_rate": 9.403760441571475e-05,
      "loss": 0.0047,
      "step": 1070500
    },
    {
      "epoch": 0.06018045708490024,
      "grad_norm": 0.31658416986465454,
      "learning_rate": 9.403479329096969e-05,
      "loss": 0.0052,
      "step": 1071000
    },
    {
      "epoch": 0.06020855253638712,
      "grad_norm": 0.3569304943084717,
      "learning_rate": 9.403198216622462e-05,
      "loss": 0.0051,
      "step": 1071500
    },
    {
      "epoch": 0.060236647987874,
      "grad_norm": 0.20368154346942902,
      "learning_rate": 9.402917104147955e-05,
      "loss": 0.0053,
      "step": 1072000
    },
    {
      "epoch": 0.060264743439360884,
      "grad_norm": 0.42743268609046936,
      "learning_rate": 9.402635991673449e-05,
      "loss": 0.0049,
      "step": 1072500
    },
    {
      "epoch": 0.060292838890847765,
      "grad_norm": 0.032965049147605896,
      "learning_rate": 9.402354879198942e-05,
      "loss": 0.0054,
      "step": 1073000
    },
    {
      "epoch": 0.060320934342334646,
      "grad_norm": 0.03945780172944069,
      "learning_rate": 9.402073766724436e-05,
      "loss": 0.0053,
      "step": 1073500
    },
    {
      "epoch": 0.06034902979382153,
      "grad_norm": 0.26966726779937744,
      "learning_rate": 9.401792654249929e-05,
      "loss": 0.0052,
      "step": 1074000
    },
    {
      "epoch": 0.06037712524530841,
      "grad_norm": 0.3899504244327545,
      "learning_rate": 9.401511541775423e-05,
      "loss": 0.0055,
      "step": 1074500
    },
    {
      "epoch": 0.06040522069679529,
      "grad_norm": 0.47442296147346497,
      "learning_rate": 9.401230429300916e-05,
      "loss": 0.0054,
      "step": 1075000
    },
    {
      "epoch": 0.06043331614828217,
      "grad_norm": 0.1171707957983017,
      "learning_rate": 9.40094931682641e-05,
      "loss": 0.0047,
      "step": 1075500
    },
    {
      "epoch": 0.060461411599769053,
      "grad_norm": 0.09206603467464447,
      "learning_rate": 9.400668204351903e-05,
      "loss": 0.0051,
      "step": 1076000
    },
    {
      "epoch": 0.060489507051255935,
      "grad_norm": 0.14267738163471222,
      "learning_rate": 9.400387091877396e-05,
      "loss": 0.0053,
      "step": 1076500
    },
    {
      "epoch": 0.060517602502742816,
      "grad_norm": 0.0889725461602211,
      "learning_rate": 9.400105979402888e-05,
      "loss": 0.0051,
      "step": 1077000
    },
    {
      "epoch": 0.0605456979542297,
      "grad_norm": 0.3307073712348938,
      "learning_rate": 9.399824866928383e-05,
      "loss": 0.0053,
      "step": 1077500
    },
    {
      "epoch": 0.06057379340571658,
      "grad_norm": 0.13739319145679474,
      "learning_rate": 9.399543754453876e-05,
      "loss": 0.0049,
      "step": 1078000
    },
    {
      "epoch": 0.06060188885720346,
      "grad_norm": 0.3063524067401886,
      "learning_rate": 9.39926264197937e-05,
      "loss": 0.0049,
      "step": 1078500
    },
    {
      "epoch": 0.06062998430869034,
      "grad_norm": 0.11743710935115814,
      "learning_rate": 9.398981529504863e-05,
      "loss": 0.0056,
      "step": 1079000
    },
    {
      "epoch": 0.06065807976017722,
      "grad_norm": 0.4071909487247467,
      "learning_rate": 9.398700417030355e-05,
      "loss": 0.0051,
      "step": 1079500
    },
    {
      "epoch": 0.060686175211664105,
      "grad_norm": 0.31458622217178345,
      "learning_rate": 9.39841930455585e-05,
      "loss": 0.0052,
      "step": 1080000
    },
    {
      "epoch": 0.060686175211664105,
      "eval_loss": 0.0015706965932622552,
      "eval_runtime": 19.6751,
      "eval_samples_per_second": 5082.556,
      "eval_steps_per_second": 79.44,
      "step": 1080000
    },
    {
      "epoch": 0.060714270663150986,
      "grad_norm": 0.08890416473150253,
      "learning_rate": 9.398138192081342e-05,
      "loss": 0.005,
      "step": 1080500
    },
    {
      "epoch": 0.06074236611463787,
      "grad_norm": 0.32751402258872986,
      "learning_rate": 9.397857079606837e-05,
      "loss": 0.0049,
      "step": 1081000
    },
    {
      "epoch": 0.06077046156612475,
      "grad_norm": 0.16127994656562805,
      "learning_rate": 9.39757596713233e-05,
      "loss": 0.0052,
      "step": 1081500
    },
    {
      "epoch": 0.06079855701761163,
      "grad_norm": 0.6192069053649902,
      "learning_rate": 9.397294854657824e-05,
      "loss": 0.0047,
      "step": 1082000
    },
    {
      "epoch": 0.06082665246909851,
      "grad_norm": 0.28999218344688416,
      "learning_rate": 9.397013742183317e-05,
      "loss": 0.0054,
      "step": 1082500
    },
    {
      "epoch": 0.0608547479205854,
      "grad_norm": 0.21057957410812378,
      "learning_rate": 9.39673262970881e-05,
      "loss": 0.0054,
      "step": 1083000
    },
    {
      "epoch": 0.06088284337207228,
      "grad_norm": 0.663947582244873,
      "learning_rate": 9.396451517234304e-05,
      "loss": 0.005,
      "step": 1083500
    },
    {
      "epoch": 0.06091093882355916,
      "grad_norm": 0.12851747870445251,
      "learning_rate": 9.396170404759796e-05,
      "loss": 0.0054,
      "step": 1084000
    },
    {
      "epoch": 0.060939034275046045,
      "grad_norm": 0.3931935429573059,
      "learning_rate": 9.395889292285291e-05,
      "loss": 0.0051,
      "step": 1084500
    },
    {
      "epoch": 0.060967129726532926,
      "grad_norm": 0.33744922280311584,
      "learning_rate": 9.395608179810783e-05,
      "loss": 0.0054,
      "step": 1085000
    },
    {
      "epoch": 0.06099522517801981,
      "grad_norm": 6.01773738861084,
      "learning_rate": 9.395327067336277e-05,
      "loss": 0.0055,
      "step": 1085500
    },
    {
      "epoch": 0.06102332062950669,
      "grad_norm": 0.33863309025764465,
      "learning_rate": 9.395045954861771e-05,
      "loss": 0.0051,
      "step": 1086000
    },
    {
      "epoch": 0.06105141608099357,
      "grad_norm": 0.17135383188724518,
      "learning_rate": 9.394764842387263e-05,
      "loss": 0.005,
      "step": 1086500
    },
    {
      "epoch": 0.06107951153248045,
      "grad_norm": 0.24581535160541534,
      "learning_rate": 9.394483729912758e-05,
      "loss": 0.0049,
      "step": 1087000
    },
    {
      "epoch": 0.06110760698396733,
      "grad_norm": 0.6195386648178101,
      "learning_rate": 9.39420261743825e-05,
      "loss": 0.0053,
      "step": 1087500
    },
    {
      "epoch": 0.061135702435454214,
      "grad_norm": 0.4892979860305786,
      "learning_rate": 9.393921504963744e-05,
      "loss": 0.0054,
      "step": 1088000
    },
    {
      "epoch": 0.061163797886941096,
      "grad_norm": 0.2955330014228821,
      "learning_rate": 9.393640392489237e-05,
      "loss": 0.0052,
      "step": 1088500
    },
    {
      "epoch": 0.06119189333842798,
      "grad_norm": 0.18101757764816284,
      "learning_rate": 9.39335928001473e-05,
      "loss": 0.0047,
      "step": 1089000
    },
    {
      "epoch": 0.06121998878991486,
      "grad_norm": 0.1383480280637741,
      "learning_rate": 9.393078167540225e-05,
      "loss": 0.0051,
      "step": 1089500
    },
    {
      "epoch": 0.06124808424140174,
      "grad_norm": 0.1077413335442543,
      "learning_rate": 9.392797055065717e-05,
      "loss": 0.0054,
      "step": 1090000
    },
    {
      "epoch": 0.06124808424140174,
      "eval_loss": 0.0016330601647496223,
      "eval_runtime": 18.9116,
      "eval_samples_per_second": 5287.748,
      "eval_steps_per_second": 82.648,
      "step": 1090000
    },
    {
      "epoch": 0.06127617969288862,
      "grad_norm": 0.11492325365543365,
      "learning_rate": 9.392515942591211e-05,
      "loss": 0.0047,
      "step": 1090500
    },
    {
      "epoch": 0.0613042751443755,
      "grad_norm": 0.17570753395557404,
      "learning_rate": 9.392234830116704e-05,
      "loss": 0.0046,
      "step": 1091000
    },
    {
      "epoch": 0.061332370595862384,
      "grad_norm": 0.30441397428512573,
      "learning_rate": 9.391953717642198e-05,
      "loss": 0.0053,
      "step": 1091500
    },
    {
      "epoch": 0.061360466047349266,
      "grad_norm": 0.15521873533725739,
      "learning_rate": 9.391672605167691e-05,
      "loss": 0.0051,
      "step": 1092000
    },
    {
      "epoch": 0.06138856149883615,
      "grad_norm": 0.585253119468689,
      "learning_rate": 9.391391492693184e-05,
      "loss": 0.0054,
      "step": 1092500
    },
    {
      "epoch": 0.06141665695032303,
      "grad_norm": 0.3800927996635437,
      "learning_rate": 9.391110380218678e-05,
      "loss": 0.005,
      "step": 1093000
    },
    {
      "epoch": 0.06144475240180991,
      "grad_norm": 0.5135586261749268,
      "learning_rate": 9.390829267744171e-05,
      "loss": 0.0055,
      "step": 1093500
    },
    {
      "epoch": 0.06147284785329679,
      "grad_norm": 0.22650089859962463,
      "learning_rate": 9.390548155269665e-05,
      "loss": 0.0051,
      "step": 1094000
    },
    {
      "epoch": 0.06150094330478367,
      "grad_norm": 0.02338278293609619,
      "learning_rate": 9.390267042795158e-05,
      "loss": 0.005,
      "step": 1094500
    },
    {
      "epoch": 0.061529038756270554,
      "grad_norm": 0.1625911146402359,
      "learning_rate": 9.389985930320652e-05,
      "loss": 0.0052,
      "step": 1095000
    },
    {
      "epoch": 0.061557134207757436,
      "grad_norm": 0.2850854992866516,
      "learning_rate": 9.389704817846145e-05,
      "loss": 0.005,
      "step": 1095500
    },
    {
      "epoch": 0.06158522965924432,
      "grad_norm": 1.2547379732131958,
      "learning_rate": 9.389423705371638e-05,
      "loss": 0.0048,
      "step": 1096000
    },
    {
      "epoch": 0.0616133251107312,
      "grad_norm": 0.4288261830806732,
      "learning_rate": 9.38914259289713e-05,
      "loss": 0.005,
      "step": 1096500
    },
    {
      "epoch": 0.06164142056221808,
      "grad_norm": 0.4287780821323395,
      "learning_rate": 9.388861480422625e-05,
      "loss": 0.0048,
      "step": 1097000
    },
    {
      "epoch": 0.06166951601370496,
      "grad_norm": 0.09885898977518082,
      "learning_rate": 9.388580367948119e-05,
      "loss": 0.0053,
      "step": 1097500
    },
    {
      "epoch": 0.06169761146519184,
      "grad_norm": 0.7639559507369995,
      "learning_rate": 9.388299255473612e-05,
      "loss": 0.0052,
      "step": 1098000
    },
    {
      "epoch": 0.061725706916678724,
      "grad_norm": 0.08824329078197479,
      "learning_rate": 9.388018142999106e-05,
      "loss": 0.0051,
      "step": 1098500
    },
    {
      "epoch": 0.061753802368165606,
      "grad_norm": 0.09085270762443542,
      "learning_rate": 9.387737030524598e-05,
      "loss": 0.005,
      "step": 1099000
    },
    {
      "epoch": 0.06178189781965249,
      "grad_norm": 0.06594830006361008,
      "learning_rate": 9.387455918050092e-05,
      "loss": 0.0055,
      "step": 1099500
    },
    {
      "epoch": 0.06180999327113937,
      "grad_norm": 0.10830726474523544,
      "learning_rate": 9.387174805575584e-05,
      "loss": 0.0048,
      "step": 1100000
    },
    {
      "epoch": 0.06180999327113937,
      "eval_loss": 0.0014496725052595139,
      "eval_runtime": 18.901,
      "eval_samples_per_second": 5290.724,
      "eval_steps_per_second": 82.694,
      "step": 1100000
    },
    {
      "epoch": 0.06183808872262625,
      "grad_norm": 0.2705358564853668,
      "learning_rate": 9.386893693101079e-05,
      "loss": 0.0048,
      "step": 1100500
    },
    {
      "epoch": 0.06186618417411313,
      "grad_norm": 0.3915024995803833,
      "learning_rate": 9.386612580626573e-05,
      "loss": 0.0051,
      "step": 1101000
    },
    {
      "epoch": 0.06189427962560001,
      "grad_norm": 0.23389066755771637,
      "learning_rate": 9.386331468152065e-05,
      "loss": 0.0048,
      "step": 1101500
    },
    {
      "epoch": 0.061922375077086894,
      "grad_norm": 0.3786902129650116,
      "learning_rate": 9.38605035567756e-05,
      "loss": 0.0052,
      "step": 1102000
    },
    {
      "epoch": 0.061950470528573776,
      "grad_norm": 0.29246985912323,
      "learning_rate": 9.385769243203052e-05,
      "loss": 0.0048,
      "step": 1102500
    },
    {
      "epoch": 0.06197856598006066,
      "grad_norm": 0.28723853826522827,
      "learning_rate": 9.385488130728546e-05,
      "loss": 0.0051,
      "step": 1103000
    },
    {
      "epoch": 0.06200666143154754,
      "grad_norm": 0.28554368019104004,
      "learning_rate": 9.385207018254038e-05,
      "loss": 0.0051,
      "step": 1103500
    },
    {
      "epoch": 0.06203475688303442,
      "grad_norm": 0.312127023935318,
      "learning_rate": 9.384925905779532e-05,
      "loss": 0.0047,
      "step": 1104000
    },
    {
      "epoch": 0.0620628523345213,
      "grad_norm": 0.6612734198570251,
      "learning_rate": 9.384644793305025e-05,
      "loss": 0.0046,
      "step": 1104500
    },
    {
      "epoch": 0.06209094778600818,
      "grad_norm": 0.03751600161194801,
      "learning_rate": 9.384363680830519e-05,
      "loss": 0.0052,
      "step": 1105000
    },
    {
      "epoch": 0.062119043237495064,
      "grad_norm": 0.06757282465696335,
      "learning_rate": 9.384082568356013e-05,
      "loss": 0.0049,
      "step": 1105500
    },
    {
      "epoch": 0.062147138688981945,
      "grad_norm": 0.13444636762142181,
      "learning_rate": 9.383801455881506e-05,
      "loss": 0.0054,
      "step": 1106000
    },
    {
      "epoch": 0.06217523414046883,
      "grad_norm": 0.04405927658081055,
      "learning_rate": 9.383520343406999e-05,
      "loss": 0.0048,
      "step": 1106500
    },
    {
      "epoch": 0.06220332959195571,
      "grad_norm": 0.18368379771709442,
      "learning_rate": 9.383239230932492e-05,
      "loss": 0.0048,
      "step": 1107000
    },
    {
      "epoch": 0.06223142504344259,
      "grad_norm": 0.21232984960079193,
      "learning_rate": 9.382958118457986e-05,
      "loss": 0.0049,
      "step": 1107500
    },
    {
      "epoch": 0.06225952049492947,
      "grad_norm": 0.3277660608291626,
      "learning_rate": 9.382677005983479e-05,
      "loss": 0.0055,
      "step": 1108000
    },
    {
      "epoch": 0.06228761594641635,
      "grad_norm": 0.29939189553260803,
      "learning_rate": 9.382395893508973e-05,
      "loss": 0.0054,
      "step": 1108500
    },
    {
      "epoch": 0.062315711397903234,
      "grad_norm": 0.33057743310928345,
      "learning_rate": 9.382114781034466e-05,
      "loss": 0.0049,
      "step": 1109000
    },
    {
      "epoch": 0.062343806849390115,
      "grad_norm": 0.2596227526664734,
      "learning_rate": 9.38183366855996e-05,
      "loss": 0.0051,
      "step": 1109500
    },
    {
      "epoch": 0.062371902300877,
      "grad_norm": 0.38791680335998535,
      "learning_rate": 9.381552556085453e-05,
      "loss": 0.0046,
      "step": 1110000
    },
    {
      "epoch": 0.062371902300877,
      "eval_loss": 0.0015984518686309457,
      "eval_runtime": 19.0445,
      "eval_samples_per_second": 5250.851,
      "eval_steps_per_second": 82.071,
      "step": 1110000
    },
    {
      "epoch": 0.06239999775236388,
      "grad_norm": 0.8913490772247314,
      "learning_rate": 9.381271443610946e-05,
      "loss": 0.0052,
      "step": 1110500
    },
    {
      "epoch": 0.06242809320385076,
      "grad_norm": 0.3786783516407013,
      "learning_rate": 9.38099033113644e-05,
      "loss": 0.0047,
      "step": 1111000
    },
    {
      "epoch": 0.06245618865533764,
      "grad_norm": 0.1343248188495636,
      "learning_rate": 9.380709218661933e-05,
      "loss": 0.0051,
      "step": 1111500
    },
    {
      "epoch": 0.06248428410682452,
      "grad_norm": 0.08436824381351471,
      "learning_rate": 9.380428106187427e-05,
      "loss": 0.0049,
      "step": 1112000
    },
    {
      "epoch": 0.0625123795583114,
      "grad_norm": 0.10957923531532288,
      "learning_rate": 9.38014699371292e-05,
      "loss": 0.0049,
      "step": 1112500
    },
    {
      "epoch": 0.06254047500979829,
      "grad_norm": 0.2323780059814453,
      "learning_rate": 9.379865881238413e-05,
      "loss": 0.0048,
      "step": 1113000
    },
    {
      "epoch": 0.06256857046128517,
      "grad_norm": 0.40224719047546387,
      "learning_rate": 9.379584768763907e-05,
      "loss": 0.0048,
      "step": 1113500
    },
    {
      "epoch": 0.06259666591277205,
      "grad_norm": 0.4358579218387604,
      "learning_rate": 9.3793036562894e-05,
      "loss": 0.0049,
      "step": 1114000
    },
    {
      "epoch": 0.06262476136425893,
      "grad_norm": 0.2321762591600418,
      "learning_rate": 9.379022543814894e-05,
      "loss": 0.0052,
      "step": 1114500
    },
    {
      "epoch": 0.06265285681574581,
      "grad_norm": 0.03128478303551674,
      "learning_rate": 9.378741431340387e-05,
      "loss": 0.0048,
      "step": 1115000
    },
    {
      "epoch": 0.06268095226723269,
      "grad_norm": 0.17248068749904633,
      "learning_rate": 9.37846031886588e-05,
      "loss": 0.0047,
      "step": 1115500
    },
    {
      "epoch": 0.06270904771871957,
      "grad_norm": 0.1104813739657402,
      "learning_rate": 9.378179206391373e-05,
      "loss": 0.0049,
      "step": 1116000
    },
    {
      "epoch": 0.06273714317020646,
      "grad_norm": 0.2076009064912796,
      "learning_rate": 9.377898093916867e-05,
      "loss": 0.0053,
      "step": 1116500
    },
    {
      "epoch": 0.06276523862169334,
      "grad_norm": 0.07577930390834808,
      "learning_rate": 9.377616981442361e-05,
      "loss": 0.005,
      "step": 1117000
    },
    {
      "epoch": 0.06279333407318022,
      "grad_norm": 0.08065864443778992,
      "learning_rate": 9.377335868967854e-05,
      "loss": 0.005,
      "step": 1117500
    },
    {
      "epoch": 0.0628214295246671,
      "grad_norm": 0.1396469920873642,
      "learning_rate": 9.377054756493348e-05,
      "loss": 0.0047,
      "step": 1118000
    },
    {
      "epoch": 0.06284952497615398,
      "grad_norm": 0.18099841475486755,
      "learning_rate": 9.37677364401884e-05,
      "loss": 0.0051,
      "step": 1118500
    },
    {
      "epoch": 0.06287762042764086,
      "grad_norm": 0.3489091694355011,
      "learning_rate": 9.376492531544335e-05,
      "loss": 0.005,
      "step": 1119000
    },
    {
      "epoch": 0.06290571587912774,
      "grad_norm": 0.20606838166713715,
      "learning_rate": 9.376211419069827e-05,
      "loss": 0.0051,
      "step": 1119500
    },
    {
      "epoch": 0.06293381133061463,
      "grad_norm": 0.05271552875638008,
      "learning_rate": 9.375930306595321e-05,
      "loss": 0.005,
      "step": 1120000
    },
    {
      "epoch": 0.06293381133061463,
      "eval_loss": 0.0014364621601998806,
      "eval_runtime": 20.0631,
      "eval_samples_per_second": 4984.281,
      "eval_steps_per_second": 77.904,
      "step": 1120000
    },
    {
      "epoch": 0.0629619067821015,
      "grad_norm": 0.16213618218898773,
      "learning_rate": 9.375649194120815e-05,
      "loss": 0.005,
      "step": 1120500
    },
    {
      "epoch": 0.06299000223358839,
      "grad_norm": 0.012914763763546944,
      "learning_rate": 9.375368081646307e-05,
      "loss": 0.0049,
      "step": 1121000
    },
    {
      "epoch": 0.06301809768507527,
      "grad_norm": 0.3232949674129486,
      "learning_rate": 9.375086969171802e-05,
      "loss": 0.0055,
      "step": 1121500
    },
    {
      "epoch": 0.06304619313656215,
      "grad_norm": 0.08840038627386093,
      "learning_rate": 9.374805856697294e-05,
      "loss": 0.0045,
      "step": 1122000
    },
    {
      "epoch": 0.06307428858804903,
      "grad_norm": 0.27526310086250305,
      "learning_rate": 9.374524744222789e-05,
      "loss": 0.0053,
      "step": 1122500
    },
    {
      "epoch": 0.06310238403953591,
      "grad_norm": 0.2232186198234558,
      "learning_rate": 9.37424363174828e-05,
      "loss": 0.0049,
      "step": 1123000
    },
    {
      "epoch": 0.0631304794910228,
      "grad_norm": 0.389444500207901,
      "learning_rate": 9.373962519273774e-05,
      "loss": 0.0047,
      "step": 1123500
    },
    {
      "epoch": 0.06315857494250968,
      "grad_norm": 0.35812506079673767,
      "learning_rate": 9.373681406799267e-05,
      "loss": 0.0049,
      "step": 1124000
    },
    {
      "epoch": 0.06318667039399656,
      "grad_norm": 0.41026848554611206,
      "learning_rate": 9.373400294324761e-05,
      "loss": 0.005,
      "step": 1124500
    },
    {
      "epoch": 0.06321476584548344,
      "grad_norm": 1.127695918083191,
      "learning_rate": 9.373119181850256e-05,
      "loss": 0.0052,
      "step": 1125000
    },
    {
      "epoch": 0.06324286129697032,
      "grad_norm": 0.5141569375991821,
      "learning_rate": 9.372838069375748e-05,
      "loss": 0.0047,
      "step": 1125500
    },
    {
      "epoch": 0.0632709567484572,
      "grad_norm": 0.12077575922012329,
      "learning_rate": 9.372556956901241e-05,
      "loss": 0.0051,
      "step": 1126000
    },
    {
      "epoch": 0.06329905219994408,
      "grad_norm": 0.23739224672317505,
      "learning_rate": 9.372275844426735e-05,
      "loss": 0.005,
      "step": 1126500
    },
    {
      "epoch": 0.06332714765143097,
      "grad_norm": 0.04900013282895088,
      "learning_rate": 9.371994731952228e-05,
      "loss": 0.0051,
      "step": 1127000
    },
    {
      "epoch": 0.06335524310291785,
      "grad_norm": 0.05391620099544525,
      "learning_rate": 9.371713619477721e-05,
      "loss": 0.0047,
      "step": 1127500
    },
    {
      "epoch": 0.06338333855440473,
      "grad_norm": 0.11966527253389359,
      "learning_rate": 9.371432507003215e-05,
      "loss": 0.0046,
      "step": 1128000
    },
    {
      "epoch": 0.06341143400589161,
      "grad_norm": 0.3550061285495758,
      "learning_rate": 9.371151394528708e-05,
      "loss": 0.0046,
      "step": 1128500
    },
    {
      "epoch": 0.0634395294573785,
      "grad_norm": 0.17302532494068146,
      "learning_rate": 9.370870282054202e-05,
      "loss": 0.0048,
      "step": 1129000
    },
    {
      "epoch": 0.06346762490886539,
      "grad_norm": 0.17468474805355072,
      "learning_rate": 9.370589169579695e-05,
      "loss": 0.0049,
      "step": 1129500
    },
    {
      "epoch": 0.06349572036035227,
      "grad_norm": 0.2648687958717346,
      "learning_rate": 9.370308057105189e-05,
      "loss": 0.0049,
      "step": 1130000
    },
    {
      "epoch": 0.06349572036035227,
      "eval_loss": 0.0013669918989762664,
      "eval_runtime": 19.6263,
      "eval_samples_per_second": 5095.198,
      "eval_steps_per_second": 79.638,
      "step": 1130000
    },
    {
      "epoch": 0.06352381581183915,
      "grad_norm": 0.02528376504778862,
      "learning_rate": 9.370026944630682e-05,
      "loss": 0.0051,
      "step": 1130500
    },
    {
      "epoch": 0.06355191126332603,
      "grad_norm": 0.17336057126522064,
      "learning_rate": 9.369745832156175e-05,
      "loss": 0.0047,
      "step": 1131000
    },
    {
      "epoch": 0.06358000671481291,
      "grad_norm": 0.2420903444290161,
      "learning_rate": 9.369464719681669e-05,
      "loss": 0.0053,
      "step": 1131500
    },
    {
      "epoch": 0.0636081021662998,
      "grad_norm": 0.4820394515991211,
      "learning_rate": 9.369183607207162e-05,
      "loss": 0.005,
      "step": 1132000
    },
    {
      "epoch": 0.06363619761778667,
      "grad_norm": 0.33651497960090637,
      "learning_rate": 9.368902494732656e-05,
      "loss": 0.0053,
      "step": 1132500
    },
    {
      "epoch": 0.06366429306927356,
      "grad_norm": 0.4759053587913513,
      "learning_rate": 9.368621382258149e-05,
      "loss": 0.0049,
      "step": 1133000
    },
    {
      "epoch": 0.06369238852076044,
      "grad_norm": 0.1873304694890976,
      "learning_rate": 9.368340269783643e-05,
      "loss": 0.0045,
      "step": 1133500
    },
    {
      "epoch": 0.06372048397224732,
      "grad_norm": 0.09800931811332703,
      "learning_rate": 9.368059157309136e-05,
      "loss": 0.0056,
      "step": 1134000
    },
    {
      "epoch": 0.0637485794237342,
      "grad_norm": 0.13398532569408417,
      "learning_rate": 9.367778044834628e-05,
      "loss": 0.0042,
      "step": 1134500
    },
    {
      "epoch": 0.06377667487522108,
      "grad_norm": 0.06356792151927948,
      "learning_rate": 9.367496932360123e-05,
      "loss": 0.0053,
      "step": 1135000
    },
    {
      "epoch": 0.06380477032670796,
      "grad_norm": 0.21488188207149506,
      "learning_rate": 9.367215819885615e-05,
      "loss": 0.0047,
      "step": 1135500
    },
    {
      "epoch": 0.06383286577819484,
      "grad_norm": 0.38834965229034424,
      "learning_rate": 9.36693470741111e-05,
      "loss": 0.0047,
      "step": 1136000
    },
    {
      "epoch": 0.06386096122968173,
      "grad_norm": 0.20168156921863556,
      "learning_rate": 9.366653594936603e-05,
      "loss": 0.005,
      "step": 1136500
    },
    {
      "epoch": 0.06388905668116861,
      "grad_norm": 0.32661935687065125,
      "learning_rate": 9.366372482462095e-05,
      "loss": 0.0043,
      "step": 1137000
    },
    {
      "epoch": 0.06391715213265549,
      "grad_norm": 0.527094841003418,
      "learning_rate": 9.36609136998759e-05,
      "loss": 0.0043,
      "step": 1137500
    },
    {
      "epoch": 0.06394524758414237,
      "grad_norm": 0.028035208582878113,
      "learning_rate": 9.365810257513082e-05,
      "loss": 0.0048,
      "step": 1138000
    },
    {
      "epoch": 0.06397334303562925,
      "grad_norm": 0.46393758058547974,
      "learning_rate": 9.365529145038577e-05,
      "loss": 0.0047,
      "step": 1138500
    },
    {
      "epoch": 0.06400143848711613,
      "grad_norm": 0.4571874737739563,
      "learning_rate": 9.365248032564069e-05,
      "loss": 0.0052,
      "step": 1139000
    },
    {
      "epoch": 0.06402953393860301,
      "grad_norm": 0.651707649230957,
      "learning_rate": 9.364966920089562e-05,
      "loss": 0.0054,
      "step": 1139500
    },
    {
      "epoch": 0.0640576293900899,
      "grad_norm": 0.2630011737346649,
      "learning_rate": 9.364685807615057e-05,
      "loss": 0.0048,
      "step": 1140000
    },
    {
      "epoch": 0.0640576293900899,
      "eval_loss": 0.0015000777784734964,
      "eval_runtime": 20.2303,
      "eval_samples_per_second": 4943.085,
      "eval_steps_per_second": 77.26,
      "step": 1140000
    },
    {
      "epoch": 0.06408572484157678,
      "grad_norm": 0.21208056807518005,
      "learning_rate": 9.364404695140549e-05,
      "loss": 0.0048,
      "step": 1140500
    },
    {
      "epoch": 0.06411382029306366,
      "grad_norm": 0.5384337902069092,
      "learning_rate": 9.364123582666044e-05,
      "loss": 0.0047,
      "step": 1141000
    },
    {
      "epoch": 0.06414191574455054,
      "grad_norm": 0.24876675009727478,
      "learning_rate": 9.363842470191536e-05,
      "loss": 0.0048,
      "step": 1141500
    },
    {
      "epoch": 0.06417001119603742,
      "grad_norm": 0.5343183875083923,
      "learning_rate": 9.36356135771703e-05,
      "loss": 0.0044,
      "step": 1142000
    },
    {
      "epoch": 0.0641981066475243,
      "grad_norm": 0.09437809884548187,
      "learning_rate": 9.363280245242523e-05,
      "loss": 0.0051,
      "step": 1142500
    },
    {
      "epoch": 0.06422620209901118,
      "grad_norm": 0.28784075379371643,
      "learning_rate": 9.362999132768016e-05,
      "loss": 0.0049,
      "step": 1143000
    },
    {
      "epoch": 0.06425429755049807,
      "grad_norm": 0.05575789138674736,
      "learning_rate": 9.362718020293511e-05,
      "loss": 0.0049,
      "step": 1143500
    },
    {
      "epoch": 0.06428239300198495,
      "grad_norm": 0.3455132246017456,
      "learning_rate": 9.362436907819003e-05,
      "loss": 0.0048,
      "step": 1144000
    },
    {
      "epoch": 0.06431048845347183,
      "grad_norm": 0.1607617735862732,
      "learning_rate": 9.362155795344497e-05,
      "loss": 0.0048,
      "step": 1144500
    },
    {
      "epoch": 0.06433858390495871,
      "grad_norm": 0.3841613531112671,
      "learning_rate": 9.36187468286999e-05,
      "loss": 0.0049,
      "step": 1145000
    },
    {
      "epoch": 0.06436667935644559,
      "grad_norm": 0.04668128862977028,
      "learning_rate": 9.361593570395483e-05,
      "loss": 0.0049,
      "step": 1145500
    },
    {
      "epoch": 0.06439477480793247,
      "grad_norm": 0.3941439688205719,
      "learning_rate": 9.361312457920977e-05,
      "loss": 0.0053,
      "step": 1146000
    },
    {
      "epoch": 0.06442287025941935,
      "grad_norm": 0.12105416506528854,
      "learning_rate": 9.36103134544647e-05,
      "loss": 0.0049,
      "step": 1146500
    },
    {
      "epoch": 0.06445096571090624,
      "grad_norm": 0.29785415530204773,
      "learning_rate": 9.360750232971964e-05,
      "loss": 0.0052,
      "step": 1147000
    },
    {
      "epoch": 0.06447906116239312,
      "grad_norm": 0.30447813868522644,
      "learning_rate": 9.360469120497457e-05,
      "loss": 0.0042,
      "step": 1147500
    },
    {
      "epoch": 0.06450715661388,
      "grad_norm": 0.05255844444036484,
      "learning_rate": 9.36018800802295e-05,
      "loss": 0.0047,
      "step": 1148000
    },
    {
      "epoch": 0.06453525206536688,
      "grad_norm": 0.6744040846824646,
      "learning_rate": 9.359906895548444e-05,
      "loss": 0.0045,
      "step": 1148500
    },
    {
      "epoch": 0.06456334751685376,
      "grad_norm": 0.9620641469955444,
      "learning_rate": 9.359625783073937e-05,
      "loss": 0.0045,
      "step": 1149000
    },
    {
      "epoch": 0.06459144296834064,
      "grad_norm": 0.17548353970050812,
      "learning_rate": 9.359344670599431e-05,
      "loss": 0.0043,
      "step": 1149500
    },
    {
      "epoch": 0.06461953841982752,
      "grad_norm": 0.06260289251804352,
      "learning_rate": 9.359063558124924e-05,
      "loss": 0.005,
      "step": 1150000
    },
    {
      "epoch": 0.06461953841982752,
      "eval_loss": 0.0014397556660696864,
      "eval_runtime": 19.1283,
      "eval_samples_per_second": 5227.855,
      "eval_steps_per_second": 81.711,
      "step": 1150000
    },
    {
      "epoch": 0.0646476338713144,
      "grad_norm": 0.18986527621746063,
      "learning_rate": 9.358782445650418e-05,
      "loss": 0.0045,
      "step": 1150500
    },
    {
      "epoch": 0.06467572932280129,
      "grad_norm": 0.10049720108509064,
      "learning_rate": 9.358501333175911e-05,
      "loss": 0.0046,
      "step": 1151000
    },
    {
      "epoch": 0.06470382477428817,
      "grad_norm": 0.13198904693126678,
      "learning_rate": 9.358220220701404e-05,
      "loss": 0.0046,
      "step": 1151500
    },
    {
      "epoch": 0.06473192022577505,
      "grad_norm": 0.16517052054405212,
      "learning_rate": 9.357939108226898e-05,
      "loss": 0.0047,
      "step": 1152000
    },
    {
      "epoch": 0.06476001567726193,
      "grad_norm": 0.48024263978004456,
      "learning_rate": 9.357657995752391e-05,
      "loss": 0.0048,
      "step": 1152500
    },
    {
      "epoch": 0.06478811112874881,
      "grad_norm": 0.03363317996263504,
      "learning_rate": 9.357376883277885e-05,
      "loss": 0.0049,
      "step": 1153000
    },
    {
      "epoch": 0.0648162065802357,
      "grad_norm": 0.17551198601722717,
      "learning_rate": 9.357095770803378e-05,
      "loss": 0.0044,
      "step": 1153500
    },
    {
      "epoch": 0.06484430203172258,
      "grad_norm": 0.15873834490776062,
      "learning_rate": 9.35681465832887e-05,
      "loss": 0.0056,
      "step": 1154000
    },
    {
      "epoch": 0.06487239748320946,
      "grad_norm": 0.47654592990875244,
      "learning_rate": 9.356533545854365e-05,
      "loss": 0.0046,
      "step": 1154500
    },
    {
      "epoch": 0.06490049293469634,
      "grad_norm": 0.42025139927864075,
      "learning_rate": 9.356252433379857e-05,
      "loss": 0.0047,
      "step": 1155000
    },
    {
      "epoch": 0.06492858838618322,
      "grad_norm": 0.2182794213294983,
      "learning_rate": 9.355971320905352e-05,
      "loss": 0.0048,
      "step": 1155500
    },
    {
      "epoch": 0.0649566838376701,
      "grad_norm": 0.1366206854581833,
      "learning_rate": 9.355690208430845e-05,
      "loss": 0.0044,
      "step": 1156000
    },
    {
      "epoch": 0.06498477928915698,
      "grad_norm": 0.15243270993232727,
      "learning_rate": 9.355409095956337e-05,
      "loss": 0.0051,
      "step": 1156500
    },
    {
      "epoch": 0.06501287474064386,
      "grad_norm": 0.1289025992155075,
      "learning_rate": 9.355127983481832e-05,
      "loss": 0.0048,
      "step": 1157000
    },
    {
      "epoch": 0.06504097019213075,
      "grad_norm": 0.19859102368354797,
      "learning_rate": 9.354846871007324e-05,
      "loss": 0.0045,
      "step": 1157500
    },
    {
      "epoch": 0.06506906564361763,
      "grad_norm": 0.3489075005054474,
      "learning_rate": 9.354565758532819e-05,
      "loss": 0.005,
      "step": 1158000
    },
    {
      "epoch": 0.06509716109510451,
      "grad_norm": 0.4520736336708069,
      "learning_rate": 9.354284646058311e-05,
      "loss": 0.0049,
      "step": 1158500
    },
    {
      "epoch": 0.06512525654659139,
      "grad_norm": 0.061069391667842865,
      "learning_rate": 9.354003533583804e-05,
      "loss": 0.0051,
      "step": 1159000
    },
    {
      "epoch": 0.06515335199807827,
      "grad_norm": 0.041601140052080154,
      "learning_rate": 9.353722421109299e-05,
      "loss": 0.0047,
      "step": 1159500
    },
    {
      "epoch": 0.06518144744956515,
      "grad_norm": 0.5816652178764343,
      "learning_rate": 9.353441308634791e-05,
      "loss": 0.0046,
      "step": 1160000
    },
    {
      "epoch": 0.06518144744956515,
      "eval_loss": 0.0013393063563853502,
      "eval_runtime": 19.6161,
      "eval_samples_per_second": 5097.854,
      "eval_steps_per_second": 79.679,
      "step": 1160000
    },
    {
      "epoch": 0.06520954290105203,
      "grad_norm": 0.10975463688373566,
      "learning_rate": 9.353160196160286e-05,
      "loss": 0.0049,
      "step": 1160500
    },
    {
      "epoch": 0.06523763835253892,
      "grad_norm": 0.15321604907512665,
      "learning_rate": 9.352879083685778e-05,
      "loss": 0.0048,
      "step": 1161000
    },
    {
      "epoch": 0.0652657338040258,
      "grad_norm": 0.08233823627233505,
      "learning_rate": 9.352597971211272e-05,
      "loss": 0.0048,
      "step": 1161500
    },
    {
      "epoch": 0.06529382925551268,
      "grad_norm": 0.47956278920173645,
      "learning_rate": 9.352316858736765e-05,
      "loss": 0.005,
      "step": 1162000
    },
    {
      "epoch": 0.06532192470699956,
      "grad_norm": 0.11142760515213013,
      "learning_rate": 9.352035746262258e-05,
      "loss": 0.0044,
      "step": 1162500
    },
    {
      "epoch": 0.06535002015848644,
      "grad_norm": 0.5512509346008301,
      "learning_rate": 9.351754633787753e-05,
      "loss": 0.0052,
      "step": 1163000
    },
    {
      "epoch": 0.06537811560997332,
      "grad_norm": 0.1607004553079605,
      "learning_rate": 9.351473521313245e-05,
      "loss": 0.0046,
      "step": 1163500
    },
    {
      "epoch": 0.0654062110614602,
      "grad_norm": 0.1337239146232605,
      "learning_rate": 9.351192408838739e-05,
      "loss": 0.0046,
      "step": 1164000
    },
    {
      "epoch": 0.06543430651294709,
      "grad_norm": 0.5856593251228333,
      "learning_rate": 9.350911296364232e-05,
      "loss": 0.0048,
      "step": 1164500
    },
    {
      "epoch": 0.06546240196443397,
      "grad_norm": 0.17011557519435883,
      "learning_rate": 9.350630183889726e-05,
      "loss": 0.0053,
      "step": 1165000
    },
    {
      "epoch": 0.06549049741592085,
      "grad_norm": 0.06532824039459229,
      "learning_rate": 9.350349071415219e-05,
      "loss": 0.0048,
      "step": 1165500
    },
    {
      "epoch": 0.06551859286740773,
      "grad_norm": 0.058778297156095505,
      "learning_rate": 9.350067958940712e-05,
      "loss": 0.0044,
      "step": 1166000
    },
    {
      "epoch": 0.06554668831889461,
      "grad_norm": 0.34068766236305237,
      "learning_rate": 9.349786846466206e-05,
      "loss": 0.0045,
      "step": 1166500
    },
    {
      "epoch": 0.06557478377038149,
      "grad_norm": 0.394116073846817,
      "learning_rate": 9.349505733991699e-05,
      "loss": 0.0049,
      "step": 1167000
    },
    {
      "epoch": 0.06560287922186837,
      "grad_norm": 0.10675385594367981,
      "learning_rate": 9.349224621517193e-05,
      "loss": 0.0047,
      "step": 1167500
    },
    {
      "epoch": 0.06563097467335526,
      "grad_norm": 0.37799015641212463,
      "learning_rate": 9.348943509042686e-05,
      "loss": 0.0046,
      "step": 1168000
    },
    {
      "epoch": 0.06565907012484214,
      "grad_norm": 0.3130979537963867,
      "learning_rate": 9.34866239656818e-05,
      "loss": 0.0046,
      "step": 1168500
    },
    {
      "epoch": 0.06568716557632902,
      "grad_norm": 0.42665085196495056,
      "learning_rate": 9.348381284093673e-05,
      "loss": 0.0046,
      "step": 1169000
    },
    {
      "epoch": 0.0657152610278159,
      "grad_norm": 0.21220239996910095,
      "learning_rate": 9.348100171619166e-05,
      "loss": 0.0052,
      "step": 1169500
    },
    {
      "epoch": 0.06574335647930278,
      "grad_norm": 0.34464508295059204,
      "learning_rate": 9.347819059144658e-05,
      "loss": 0.0046,
      "step": 1170000
    },
    {
      "epoch": 0.06574335647930278,
      "eval_loss": 0.0013421451440081,
      "eval_runtime": 19.7522,
      "eval_samples_per_second": 5062.729,
      "eval_steps_per_second": 79.13,
      "step": 1170000
    },
    {
      "epoch": 0.06577145193078966,
      "grad_norm": 0.011356959119439125,
      "learning_rate": 9.347537946670153e-05,
      "loss": 0.0051,
      "step": 1170500
    },
    {
      "epoch": 0.06579954738227654,
      "grad_norm": 0.168513685464859,
      "learning_rate": 9.347256834195647e-05,
      "loss": 0.0047,
      "step": 1171000
    },
    {
      "epoch": 0.06582764283376343,
      "grad_norm": 0.48162704706192017,
      "learning_rate": 9.34697572172114e-05,
      "loss": 0.0049,
      "step": 1171500
    },
    {
      "epoch": 0.0658557382852503,
      "grad_norm": 0.2890109121799469,
      "learning_rate": 9.346694609246634e-05,
      "loss": 0.0049,
      "step": 1172000
    },
    {
      "epoch": 0.06588383373673719,
      "grad_norm": 0.1364620178937912,
      "learning_rate": 9.346413496772126e-05,
      "loss": 0.0047,
      "step": 1172500
    },
    {
      "epoch": 0.06591192918822407,
      "grad_norm": 0.4178542196750641,
      "learning_rate": 9.34613238429762e-05,
      "loss": 0.0049,
      "step": 1173000
    },
    {
      "epoch": 0.06594002463971095,
      "grad_norm": 0.5924748778343201,
      "learning_rate": 9.345851271823112e-05,
      "loss": 0.0043,
      "step": 1173500
    },
    {
      "epoch": 0.06596812009119783,
      "grad_norm": 0.5772439241409302,
      "learning_rate": 9.345570159348607e-05,
      "loss": 0.0046,
      "step": 1174000
    },
    {
      "epoch": 0.06599621554268471,
      "grad_norm": 0.15247246623039246,
      "learning_rate": 9.3452890468741e-05,
      "loss": 0.0048,
      "step": 1174500
    },
    {
      "epoch": 0.0660243109941716,
      "grad_norm": 0.7823975086212158,
      "learning_rate": 9.345007934399593e-05,
      "loss": 0.0053,
      "step": 1175000
    },
    {
      "epoch": 0.06605240644565848,
      "grad_norm": 0.6617664694786072,
      "learning_rate": 9.344726821925087e-05,
      "loss": 0.0041,
      "step": 1175500
    },
    {
      "epoch": 0.06608050189714536,
      "grad_norm": 0.1519847959280014,
      "learning_rate": 9.34444570945058e-05,
      "loss": 0.0044,
      "step": 1176000
    },
    {
      "epoch": 0.06610859734863224,
      "grad_norm": 0.13506941497325897,
      "learning_rate": 9.344164596976074e-05,
      "loss": 0.0046,
      "step": 1176500
    },
    {
      "epoch": 0.06613669280011912,
      "grad_norm": 0.2203446924686432,
      "learning_rate": 9.343883484501566e-05,
      "loss": 0.0044,
      "step": 1177000
    },
    {
      "epoch": 0.066164788251606,
      "grad_norm": 0.08918147534132004,
      "learning_rate": 9.34360237202706e-05,
      "loss": 0.0046,
      "step": 1177500
    },
    {
      "epoch": 0.06619288370309288,
      "grad_norm": 0.13173386454582214,
      "learning_rate": 9.343321259552553e-05,
      "loss": 0.0052,
      "step": 1178000
    },
    {
      "epoch": 0.06622097915457976,
      "grad_norm": 0.7515295743942261,
      "learning_rate": 9.343040147078047e-05,
      "loss": 0.005,
      "step": 1178500
    },
    {
      "epoch": 0.06624907460606665,
      "grad_norm": 0.15062887966632843,
      "learning_rate": 9.342759034603541e-05,
      "loss": 0.0046,
      "step": 1179000
    },
    {
      "epoch": 0.06627717005755353,
      "grad_norm": 0.5355980396270752,
      "learning_rate": 9.342477922129034e-05,
      "loss": 0.0046,
      "step": 1179500
    },
    {
      "epoch": 0.06630526550904041,
      "grad_norm": 0.09928493946790695,
      "learning_rate": 9.342196809654527e-05,
      "loss": 0.0048,
      "step": 1180000
    },
    {
      "epoch": 0.06630526550904041,
      "eval_loss": 0.0014347204705700278,
      "eval_runtime": 19.9345,
      "eval_samples_per_second": 5016.434,
      "eval_steps_per_second": 78.407,
      "step": 1180000
    },
    {
      "epoch": 0.06633336096052729,
      "grad_norm": 0.22926728427410126,
      "learning_rate": 9.34191569718002e-05,
      "loss": 0.0051,
      "step": 1180500
    },
    {
      "epoch": 0.06636145641201417,
      "grad_norm": 0.2640828490257263,
      "learning_rate": 9.341634584705514e-05,
      "loss": 0.0047,
      "step": 1181000
    },
    {
      "epoch": 0.06638955186350105,
      "grad_norm": 0.0624953992664814,
      "learning_rate": 9.341353472231007e-05,
      "loss": 0.0045,
      "step": 1181500
    },
    {
      "epoch": 0.06641764731498793,
      "grad_norm": 0.07346361130475998,
      "learning_rate": 9.3410723597565e-05,
      "loss": 0.0043,
      "step": 1182000
    },
    {
      "epoch": 0.06644574276647482,
      "grad_norm": 0.2756996154785156,
      "learning_rate": 9.340791247281994e-05,
      "loss": 0.0049,
      "step": 1182500
    },
    {
      "epoch": 0.0664738382179617,
      "grad_norm": 0.15372391045093536,
      "learning_rate": 9.340510134807487e-05,
      "loss": 0.0052,
      "step": 1183000
    },
    {
      "epoch": 0.06650193366944858,
      "grad_norm": 0.572827935218811,
      "learning_rate": 9.340229022332981e-05,
      "loss": 0.0045,
      "step": 1183500
    },
    {
      "epoch": 0.06653002912093546,
      "grad_norm": 0.21106280386447906,
      "learning_rate": 9.339947909858474e-05,
      "loss": 0.0052,
      "step": 1184000
    },
    {
      "epoch": 0.06655812457242234,
      "grad_norm": 0.11164061725139618,
      "learning_rate": 9.339666797383968e-05,
      "loss": 0.0042,
      "step": 1184500
    },
    {
      "epoch": 0.06658622002390922,
      "grad_norm": 0.06213466450572014,
      "learning_rate": 9.339385684909461e-05,
      "loss": 0.0043,
      "step": 1185000
    },
    {
      "epoch": 0.0666143154753961,
      "grad_norm": 0.4875633418560028,
      "learning_rate": 9.339104572434955e-05,
      "loss": 0.0048,
      "step": 1185500
    },
    {
      "epoch": 0.06664241092688299,
      "grad_norm": 0.2800419330596924,
      "learning_rate": 9.338823459960448e-05,
      "loss": 0.005,
      "step": 1186000
    },
    {
      "epoch": 0.06667050637836987,
      "grad_norm": 0.0885082557797432,
      "learning_rate": 9.338542347485941e-05,
      "loss": 0.0049,
      "step": 1186500
    },
    {
      "epoch": 0.06669860182985675,
      "grad_norm": 0.1280752271413803,
      "learning_rate": 9.338261235011435e-05,
      "loss": 0.0042,
      "step": 1187000
    },
    {
      "epoch": 0.06672669728134363,
      "grad_norm": 0.11863008141517639,
      "learning_rate": 9.337980122536928e-05,
      "loss": 0.0043,
      "step": 1187500
    },
    {
      "epoch": 0.06675479273283051,
      "grad_norm": 0.17282146215438843,
      "learning_rate": 9.337699010062422e-05,
      "loss": 0.0042,
      "step": 1188000
    },
    {
      "epoch": 0.0667828881843174,
      "grad_norm": 0.04911097511649132,
      "learning_rate": 9.337417897587915e-05,
      "loss": 0.0047,
      "step": 1188500
    },
    {
      "epoch": 0.06681098363580427,
      "grad_norm": 0.4032708704471588,
      "learning_rate": 9.337136785113409e-05,
      "loss": 0.0043,
      "step": 1189000
    },
    {
      "epoch": 0.06683907908729116,
      "grad_norm": 0.1908935159444809,
      "learning_rate": 9.3368556726389e-05,
      "loss": 0.0043,
      "step": 1189500
    },
    {
      "epoch": 0.06686717453877805,
      "grad_norm": 0.032136984169483185,
      "learning_rate": 9.336574560164395e-05,
      "loss": 0.0045,
      "step": 1190000
    },
    {
      "epoch": 0.06686717453877805,
      "eval_loss": 0.0013354867696762085,
      "eval_runtime": 20.1075,
      "eval_samples_per_second": 4973.259,
      "eval_steps_per_second": 77.732,
      "step": 1190000
    },
    {
      "epoch": 0.06689526999026493,
      "grad_norm": 0.09500440955162048,
      "learning_rate": 9.336293447689889e-05,
      "loss": 0.0047,
      "step": 1190500
    },
    {
      "epoch": 0.06692336544175181,
      "grad_norm": 0.25016456842422485,
      "learning_rate": 9.336012335215382e-05,
      "loss": 0.0049,
      "step": 1191000
    },
    {
      "epoch": 0.0669514608932387,
      "grad_norm": 0.2556615173816681,
      "learning_rate": 9.335731222740876e-05,
      "loss": 0.0049,
      "step": 1191500
    },
    {
      "epoch": 0.06697955634472558,
      "grad_norm": 0.4102599322795868,
      "learning_rate": 9.335450110266368e-05,
      "loss": 0.0054,
      "step": 1192000
    },
    {
      "epoch": 0.06700765179621246,
      "grad_norm": 0.3079116940498352,
      "learning_rate": 9.335168997791863e-05,
      "loss": 0.0049,
      "step": 1192500
    },
    {
      "epoch": 0.06703574724769934,
      "grad_norm": 0.10881026089191437,
      "learning_rate": 9.334887885317355e-05,
      "loss": 0.0045,
      "step": 1193000
    },
    {
      "epoch": 0.06706384269918622,
      "grad_norm": 0.42212656140327454,
      "learning_rate": 9.33460677284285e-05,
      "loss": 0.0043,
      "step": 1193500
    },
    {
      "epoch": 0.0670919381506731,
      "grad_norm": 0.5762458443641663,
      "learning_rate": 9.334325660368343e-05,
      "loss": 0.0042,
      "step": 1194000
    },
    {
      "epoch": 0.06712003360215998,
      "grad_norm": 0.05718683451414108,
      "learning_rate": 9.334044547893835e-05,
      "loss": 0.0048,
      "step": 1194500
    },
    {
      "epoch": 0.06714812905364687,
      "grad_norm": 0.1097845509648323,
      "learning_rate": 9.33376343541933e-05,
      "loss": 0.0043,
      "step": 1195000
    },
    {
      "epoch": 0.06717622450513375,
      "grad_norm": 0.023115282878279686,
      "learning_rate": 9.333482322944822e-05,
      "loss": 0.0045,
      "step": 1195500
    },
    {
      "epoch": 0.06720431995662063,
      "grad_norm": 0.5211696624755859,
      "learning_rate": 9.333201210470317e-05,
      "loss": 0.0052,
      "step": 1196000
    },
    {
      "epoch": 0.06723241540810751,
      "grad_norm": 0.37376534938812256,
      "learning_rate": 9.332920097995809e-05,
      "loss": 0.0048,
      "step": 1196500
    },
    {
      "epoch": 0.06726051085959439,
      "grad_norm": 0.40867429971694946,
      "learning_rate": 9.332638985521302e-05,
      "loss": 0.0045,
      "step": 1197000
    },
    {
      "epoch": 0.06728860631108127,
      "grad_norm": 0.0925007164478302,
      "learning_rate": 9.332357873046795e-05,
      "loss": 0.0044,
      "step": 1197500
    },
    {
      "epoch": 0.06731670176256815,
      "grad_norm": 0.10217656195163727,
      "learning_rate": 9.332076760572289e-05,
      "loss": 0.0046,
      "step": 1198000
    },
    {
      "epoch": 0.06734479721405504,
      "grad_norm": 0.20478254556655884,
      "learning_rate": 9.331795648097784e-05,
      "loss": 0.0046,
      "step": 1198500
    },
    {
      "epoch": 0.06737289266554192,
      "grad_norm": 0.24828937649726868,
      "learning_rate": 9.331514535623276e-05,
      "loss": 0.0052,
      "step": 1199000
    },
    {
      "epoch": 0.0674009881170288,
      "grad_norm": 0.2535903751850128,
      "learning_rate": 9.331233423148769e-05,
      "loss": 0.0052,
      "step": 1199500
    },
    {
      "epoch": 0.06742908356851568,
      "grad_norm": 0.15365813672542572,
      "learning_rate": 9.330952310674263e-05,
      "loss": 0.0047,
      "step": 1200000
    },
    {
      "epoch": 0.06742908356851568,
      "eval_loss": 0.0011348742991685867,
      "eval_runtime": 20.0992,
      "eval_samples_per_second": 4975.32,
      "eval_steps_per_second": 77.764,
      "step": 1200000
    },
    {
      "epoch": 0.06745717902000256,
      "grad_norm": 0.3409108519554138,
      "learning_rate": 9.330671198199756e-05,
      "loss": 0.0043,
      "step": 1200500
    },
    {
      "epoch": 0.06748527447148944,
      "grad_norm": 0.05894523859024048,
      "learning_rate": 9.33039008572525e-05,
      "loss": 0.0045,
      "step": 1201000
    },
    {
      "epoch": 0.06751336992297632,
      "grad_norm": 0.45232897996902466,
      "learning_rate": 9.330108973250743e-05,
      "loss": 0.005,
      "step": 1201500
    },
    {
      "epoch": 0.0675414653744632,
      "grad_norm": 0.25890839099884033,
      "learning_rate": 9.329827860776236e-05,
      "loss": 0.0054,
      "step": 1202000
    },
    {
      "epoch": 0.06756956082595009,
      "grad_norm": 0.3946909010410309,
      "learning_rate": 9.32954674830173e-05,
      "loss": 0.0049,
      "step": 1202500
    },
    {
      "epoch": 0.06759765627743697,
      "grad_norm": 0.14282865822315216,
      "learning_rate": 9.329265635827223e-05,
      "loss": 0.0046,
      "step": 1203000
    },
    {
      "epoch": 0.06762575172892385,
      "grad_norm": 0.061320412904024124,
      "learning_rate": 9.328984523352717e-05,
      "loss": 0.0048,
      "step": 1203500
    },
    {
      "epoch": 0.06765384718041073,
      "grad_norm": 0.36295369267463684,
      "learning_rate": 9.32870341087821e-05,
      "loss": 0.0046,
      "step": 1204000
    },
    {
      "epoch": 0.06768194263189761,
      "grad_norm": 0.008156182244420052,
      "learning_rate": 9.328422298403703e-05,
      "loss": 0.0047,
      "step": 1204500
    },
    {
      "epoch": 0.0677100380833845,
      "grad_norm": 0.3058546483516693,
      "learning_rate": 9.328141185929197e-05,
      "loss": 0.0044,
      "step": 1205000
    },
    {
      "epoch": 0.06773813353487138,
      "grad_norm": 1.1399409770965576,
      "learning_rate": 9.327860073454689e-05,
      "loss": 0.0048,
      "step": 1205500
    },
    {
      "epoch": 0.06776622898635826,
      "grad_norm": 0.1035606861114502,
      "learning_rate": 9.327578960980184e-05,
      "loss": 0.0045,
      "step": 1206000
    },
    {
      "epoch": 0.06779432443784514,
      "grad_norm": 0.11939886957406998,
      "learning_rate": 9.327297848505677e-05,
      "loss": 0.0049,
      "step": 1206500
    },
    {
      "epoch": 0.06782241988933202,
      "grad_norm": 0.4638929069042206,
      "learning_rate": 9.32701673603117e-05,
      "loss": 0.0045,
      "step": 1207000
    },
    {
      "epoch": 0.0678505153408189,
      "grad_norm": 0.3727402091026306,
      "learning_rate": 9.326735623556664e-05,
      "loss": 0.0041,
      "step": 1207500
    },
    {
      "epoch": 0.06787861079230578,
      "grad_norm": 0.024905391037464142,
      "learning_rate": 9.326454511082156e-05,
      "loss": 0.0045,
      "step": 1208000
    },
    {
      "epoch": 0.06790670624379266,
      "grad_norm": 0.177735835313797,
      "learning_rate": 9.326173398607651e-05,
      "loss": 0.0044,
      "step": 1208500
    },
    {
      "epoch": 0.06793480169527955,
      "grad_norm": 0.024382585659623146,
      "learning_rate": 9.325892286133143e-05,
      "loss": 0.0049,
      "step": 1209000
    },
    {
      "epoch": 0.06796289714676643,
      "grad_norm": 0.09514071047306061,
      "learning_rate": 9.325611173658638e-05,
      "loss": 0.0047,
      "step": 1209500
    },
    {
      "epoch": 0.06799099259825331,
      "grad_norm": 0.12802667915821075,
      "learning_rate": 9.325330061184131e-05,
      "loss": 0.0044,
      "step": 1210000
    },
    {
      "epoch": 0.06799099259825331,
      "eval_loss": 0.0013840271858498454,
      "eval_runtime": 19.6174,
      "eval_samples_per_second": 5097.507,
      "eval_steps_per_second": 79.674,
      "step": 1210000
    },
    {
      "epoch": 0.06801908804974019,
      "grad_norm": 0.22488126158714294,
      "learning_rate": 9.325048948709623e-05,
      "loss": 0.0048,
      "step": 1210500
    },
    {
      "epoch": 0.06804718350122707,
      "grad_norm": 0.1402442753314972,
      "learning_rate": 9.324767836235118e-05,
      "loss": 0.0048,
      "step": 1211000
    },
    {
      "epoch": 0.06807527895271395,
      "grad_norm": 0.015393905341625214,
      "learning_rate": 9.32448672376061e-05,
      "loss": 0.0045,
      "step": 1211500
    },
    {
      "epoch": 0.06810337440420083,
      "grad_norm": 0.11317278444766998,
      "learning_rate": 9.324205611286105e-05,
      "loss": 0.0048,
      "step": 1212000
    },
    {
      "epoch": 0.06813146985568772,
      "grad_norm": 0.07140105962753296,
      "learning_rate": 9.323924498811597e-05,
      "loss": 0.0048,
      "step": 1212500
    },
    {
      "epoch": 0.0681595653071746,
      "grad_norm": 0.6573716998100281,
      "learning_rate": 9.32364338633709e-05,
      "loss": 0.0044,
      "step": 1213000
    },
    {
      "epoch": 0.06818766075866148,
      "grad_norm": 0.1025351732969284,
      "learning_rate": 9.323362273862585e-05,
      "loss": 0.0045,
      "step": 1213500
    },
    {
      "epoch": 0.06821575621014836,
      "grad_norm": 0.45481085777282715,
      "learning_rate": 9.323081161388077e-05,
      "loss": 0.0049,
      "step": 1214000
    },
    {
      "epoch": 0.06824385166163524,
      "grad_norm": 0.15885674953460693,
      "learning_rate": 9.322800048913572e-05,
      "loss": 0.0053,
      "step": 1214500
    },
    {
      "epoch": 0.06827194711312212,
      "grad_norm": 0.18253736197948456,
      "learning_rate": 9.322518936439064e-05,
      "loss": 0.0045,
      "step": 1215000
    },
    {
      "epoch": 0.068300042564609,
      "grad_norm": 0.0547325424849987,
      "learning_rate": 9.322237823964557e-05,
      "loss": 0.0051,
      "step": 1215500
    },
    {
      "epoch": 0.06832813801609589,
      "grad_norm": 0.27383407950401306,
      "learning_rate": 9.321956711490051e-05,
      "loss": 0.0046,
      "step": 1216000
    },
    {
      "epoch": 0.06835623346758277,
      "grad_norm": 0.5296064019203186,
      "learning_rate": 9.321675599015544e-05,
      "loss": 0.0042,
      "step": 1216500
    },
    {
      "epoch": 0.06838432891906965,
      "grad_norm": 0.8356098532676697,
      "learning_rate": 9.321394486541038e-05,
      "loss": 0.0045,
      "step": 1217000
    },
    {
      "epoch": 0.06841242437055653,
      "grad_norm": 0.4206276535987854,
      "learning_rate": 9.321113374066531e-05,
      "loss": 0.0051,
      "step": 1217500
    },
    {
      "epoch": 0.06844051982204341,
      "grad_norm": 0.2911919057369232,
      "learning_rate": 9.320832261592024e-05,
      "loss": 0.0051,
      "step": 1218000
    },
    {
      "epoch": 0.06846861527353029,
      "grad_norm": 0.1112481951713562,
      "learning_rate": 9.320551149117518e-05,
      "loss": 0.0046,
      "step": 1218500
    },
    {
      "epoch": 0.06849671072501717,
      "grad_norm": 0.03586609661579132,
      "learning_rate": 9.320270036643011e-05,
      "loss": 0.0045,
      "step": 1219000
    },
    {
      "epoch": 0.06852480617650406,
      "grad_norm": 0.22799807786941528,
      "learning_rate": 9.319988924168505e-05,
      "loss": 0.0048,
      "step": 1219500
    },
    {
      "epoch": 0.06855290162799094,
      "grad_norm": 0.05943838134407997,
      "learning_rate": 9.319707811693998e-05,
      "loss": 0.0048,
      "step": 1220000
    },
    {
      "epoch": 0.06855290162799094,
      "eval_loss": 0.001365048112347722,
      "eval_runtime": 19.1562,
      "eval_samples_per_second": 5220.242,
      "eval_steps_per_second": 81.592,
      "step": 1220000
    },
    {
      "epoch": 0.06858099707947782,
      "grad_norm": 0.1500120460987091,
      "learning_rate": 9.319426699219492e-05,
      "loss": 0.0047,
      "step": 1220500
    },
    {
      "epoch": 0.0686090925309647,
      "grad_norm": 0.19512970745563507,
      "learning_rate": 9.319145586744985e-05,
      "loss": 0.0046,
      "step": 1221000
    },
    {
      "epoch": 0.06863718798245158,
      "grad_norm": 0.5326313376426697,
      "learning_rate": 9.318864474270478e-05,
      "loss": 0.0046,
      "step": 1221500
    },
    {
      "epoch": 0.06866528343393846,
      "grad_norm": 0.032475776970386505,
      "learning_rate": 9.318583361795972e-05,
      "loss": 0.0043,
      "step": 1222000
    },
    {
      "epoch": 0.06869337888542534,
      "grad_norm": 0.41887277364730835,
      "learning_rate": 9.318302249321465e-05,
      "loss": 0.0046,
      "step": 1222500
    },
    {
      "epoch": 0.06872147433691222,
      "grad_norm": 0.4993094205856323,
      "learning_rate": 9.318021136846959e-05,
      "loss": 0.0046,
      "step": 1223000
    },
    {
      "epoch": 0.0687495697883991,
      "grad_norm": 0.22685043513774872,
      "learning_rate": 9.317740024372452e-05,
      "loss": 0.0048,
      "step": 1223500
    },
    {
      "epoch": 0.06877766523988599,
      "grad_norm": 0.13153505325317383,
      "learning_rate": 9.317458911897946e-05,
      "loss": 0.0047,
      "step": 1224000
    },
    {
      "epoch": 0.06880576069137287,
      "grad_norm": 0.4000224173069,
      "learning_rate": 9.317177799423439e-05,
      "loss": 0.0044,
      "step": 1224500
    },
    {
      "epoch": 0.06883385614285975,
      "grad_norm": 0.6279466152191162,
      "learning_rate": 9.316896686948932e-05,
      "loss": 0.0042,
      "step": 1225000
    },
    {
      "epoch": 0.06886195159434663,
      "grad_norm": 0.037936169654130936,
      "learning_rate": 9.316615574474426e-05,
      "loss": 0.0047,
      "step": 1225500
    },
    {
      "epoch": 0.06889004704583351,
      "grad_norm": 0.2303171157836914,
      "learning_rate": 9.316334461999919e-05,
      "loss": 0.0051,
      "step": 1226000
    },
    {
      "epoch": 0.0689181424973204,
      "grad_norm": 0.24939095973968506,
      "learning_rate": 9.316053349525413e-05,
      "loss": 0.0048,
      "step": 1226500
    },
    {
      "epoch": 0.06894623794880728,
      "grad_norm": 0.32971930503845215,
      "learning_rate": 9.315772237050906e-05,
      "loss": 0.0047,
      "step": 1227000
    },
    {
      "epoch": 0.06897433340029416,
      "grad_norm": 0.17538924515247345,
      "learning_rate": 9.315491124576398e-05,
      "loss": 0.0046,
      "step": 1227500
    },
    {
      "epoch": 0.06900242885178104,
      "grad_norm": 0.17274457216262817,
      "learning_rate": 9.315210012101893e-05,
      "loss": 0.0049,
      "step": 1228000
    },
    {
      "epoch": 0.06903052430326792,
      "grad_norm": 0.12709380686283112,
      "learning_rate": 9.314928899627385e-05,
      "loss": 0.0043,
      "step": 1228500
    },
    {
      "epoch": 0.0690586197547548,
      "grad_norm": 0.05284078046679497,
      "learning_rate": 9.31464778715288e-05,
      "loss": 0.0045,
      "step": 1229000
    },
    {
      "epoch": 0.06908671520624168,
      "grad_norm": 0.26147955656051636,
      "learning_rate": 9.314366674678373e-05,
      "loss": 0.0045,
      "step": 1229500
    },
    {
      "epoch": 0.06911481065772856,
      "grad_norm": 0.6444987654685974,
      "learning_rate": 9.314085562203865e-05,
      "loss": 0.0046,
      "step": 1230000
    },
    {
      "epoch": 0.06911481065772856,
      "eval_loss": 0.0012519118608906865,
      "eval_runtime": 19.3677,
      "eval_samples_per_second": 5163.241,
      "eval_steps_per_second": 80.701,
      "step": 1230000
    },
    {
      "epoch": 0.06914290610921545,
      "grad_norm": 0.19107170403003693,
      "learning_rate": 9.31380444972936e-05,
      "loss": 0.0046,
      "step": 1230500
    },
    {
      "epoch": 0.06917100156070233,
      "grad_norm": 0.3477802276611328,
      "learning_rate": 9.313523337254852e-05,
      "loss": 0.005,
      "step": 1231000
    },
    {
      "epoch": 0.06919909701218921,
      "grad_norm": 0.4190952777862549,
      "learning_rate": 9.313242224780347e-05,
      "loss": 0.0045,
      "step": 1231500
    },
    {
      "epoch": 0.06922719246367609,
      "grad_norm": 0.1351233571767807,
      "learning_rate": 9.312961112305839e-05,
      "loss": 0.0048,
      "step": 1232000
    },
    {
      "epoch": 0.06925528791516297,
      "grad_norm": 0.20477060973644257,
      "learning_rate": 9.312679999831332e-05,
      "loss": 0.0047,
      "step": 1232500
    },
    {
      "epoch": 0.06928338336664985,
      "grad_norm": 0.14345118403434753,
      "learning_rate": 9.312398887356827e-05,
      "loss": 0.0045,
      "step": 1233000
    },
    {
      "epoch": 0.06931147881813673,
      "grad_norm": 0.3021540939807892,
      "learning_rate": 9.312117774882319e-05,
      "loss": 0.0043,
      "step": 1233500
    },
    {
      "epoch": 0.06933957426962362,
      "grad_norm": 0.3858053386211395,
      "learning_rate": 9.311836662407814e-05,
      "loss": 0.0047,
      "step": 1234000
    },
    {
      "epoch": 0.0693676697211105,
      "grad_norm": 0.5059074759483337,
      "learning_rate": 9.311555549933306e-05,
      "loss": 0.0047,
      "step": 1234500
    },
    {
      "epoch": 0.06939576517259738,
      "grad_norm": 0.341627299785614,
      "learning_rate": 9.3112744374588e-05,
      "loss": 0.0043,
      "step": 1235000
    },
    {
      "epoch": 0.06942386062408426,
      "grad_norm": 0.1845259666442871,
      "learning_rate": 9.310993324984293e-05,
      "loss": 0.0047,
      "step": 1235500
    },
    {
      "epoch": 0.06945195607557114,
      "grad_norm": 0.223242849111557,
      "learning_rate": 9.310712212509786e-05,
      "loss": 0.0047,
      "step": 1236000
    },
    {
      "epoch": 0.06948005152705802,
      "grad_norm": 0.24493001401424408,
      "learning_rate": 9.31043110003528e-05,
      "loss": 0.0046,
      "step": 1236500
    },
    {
      "epoch": 0.0695081469785449,
      "grad_norm": 0.3033718764781952,
      "learning_rate": 9.310149987560773e-05,
      "loss": 0.0044,
      "step": 1237000
    },
    {
      "epoch": 0.06953624243003179,
      "grad_norm": 0.1091822162270546,
      "learning_rate": 9.309868875086267e-05,
      "loss": 0.0044,
      "step": 1237500
    },
    {
      "epoch": 0.06956433788151867,
      "grad_norm": 0.2653898596763611,
      "learning_rate": 9.30958776261176e-05,
      "loss": 0.0044,
      "step": 1238000
    },
    {
      "epoch": 0.06959243333300555,
      "grad_norm": 0.25924989581108093,
      "learning_rate": 9.309306650137254e-05,
      "loss": 0.0045,
      "step": 1238500
    },
    {
      "epoch": 0.06962052878449243,
      "grad_norm": 0.682643711566925,
      "learning_rate": 9.309025537662747e-05,
      "loss": 0.0044,
      "step": 1239000
    },
    {
      "epoch": 0.06964862423597931,
      "grad_norm": 0.1664118617773056,
      "learning_rate": 9.30874442518824e-05,
      "loss": 0.0047,
      "step": 1239500
    },
    {
      "epoch": 0.0696767196874662,
      "grad_norm": 0.3029654920101166,
      "learning_rate": 9.308463312713734e-05,
      "loss": 0.0046,
      "step": 1240000
    },
    {
      "epoch": 0.0696767196874662,
      "eval_loss": 0.0013629831373691559,
      "eval_runtime": 19.7485,
      "eval_samples_per_second": 5063.671,
      "eval_steps_per_second": 79.145,
      "step": 1240000
    },
    {
      "epoch": 0.06970481513895307,
      "grad_norm": 0.17663177847862244,
      "learning_rate": 9.308182200239227e-05,
      "loss": 0.0044,
      "step": 1240500
    },
    {
      "epoch": 0.06973291059043996,
      "grad_norm": 0.19200299680233002,
      "learning_rate": 9.30790108776472e-05,
      "loss": 0.0049,
      "step": 1241000
    },
    {
      "epoch": 0.06976100604192684,
      "grad_norm": 0.24302507936954498,
      "learning_rate": 9.307619975290214e-05,
      "loss": 0.0045,
      "step": 1241500
    },
    {
      "epoch": 0.06978910149341372,
      "grad_norm": 0.1991298943758011,
      "learning_rate": 9.307338862815708e-05,
      "loss": 0.0045,
      "step": 1242000
    },
    {
      "epoch": 0.0698171969449006,
      "grad_norm": 0.08169085532426834,
      "learning_rate": 9.307057750341201e-05,
      "loss": 0.0048,
      "step": 1242500
    },
    {
      "epoch": 0.06984529239638748,
      "grad_norm": 0.08907917141914368,
      "learning_rate": 9.306776637866694e-05,
      "loss": 0.0041,
      "step": 1243000
    },
    {
      "epoch": 0.06987338784787436,
      "grad_norm": 0.23779864609241486,
      "learning_rate": 9.306495525392186e-05,
      "loss": 0.0047,
      "step": 1243500
    },
    {
      "epoch": 0.06990148329936124,
      "grad_norm": 0.2635398805141449,
      "learning_rate": 9.306214412917681e-05,
      "loss": 0.0045,
      "step": 1244000
    },
    {
      "epoch": 0.06992957875084813,
      "grad_norm": 0.0742851048707962,
      "learning_rate": 9.305933300443175e-05,
      "loss": 0.0043,
      "step": 1244500
    },
    {
      "epoch": 0.06995767420233501,
      "grad_norm": 0.21337245404720306,
      "learning_rate": 9.305652187968668e-05,
      "loss": 0.0045,
      "step": 1245000
    },
    {
      "epoch": 0.06998576965382189,
      "grad_norm": 0.04616366699337959,
      "learning_rate": 9.305371075494161e-05,
      "loss": 0.0044,
      "step": 1245500
    },
    {
      "epoch": 0.07001386510530877,
      "grad_norm": 0.14147157967090607,
      "learning_rate": 9.305089963019654e-05,
      "loss": 0.0042,
      "step": 1246000
    },
    {
      "epoch": 0.07004196055679565,
      "grad_norm": 0.29297369718551636,
      "learning_rate": 9.304808850545148e-05,
      "loss": 0.005,
      "step": 1246500
    },
    {
      "epoch": 0.07007005600828253,
      "grad_norm": 0.237108513712883,
      "learning_rate": 9.30452773807064e-05,
      "loss": 0.0047,
      "step": 1247000
    },
    {
      "epoch": 0.07009815145976941,
      "grad_norm": 0.11597423255443573,
      "learning_rate": 9.304246625596135e-05,
      "loss": 0.0043,
      "step": 1247500
    },
    {
      "epoch": 0.0701262469112563,
      "grad_norm": 0.3904441297054291,
      "learning_rate": 9.303965513121627e-05,
      "loss": 0.0045,
      "step": 1248000
    },
    {
      "epoch": 0.07015434236274318,
      "grad_norm": 0.2286556363105774,
      "learning_rate": 9.30368440064712e-05,
      "loss": 0.0043,
      "step": 1248500
    },
    {
      "epoch": 0.07018243781423006,
      "grad_norm": 0.15695250034332275,
      "learning_rate": 9.303403288172615e-05,
      "loss": 0.0047,
      "step": 1249000
    },
    {
      "epoch": 0.07021053326571694,
      "grad_norm": 0.22283047437667847,
      "learning_rate": 9.303122175698108e-05,
      "loss": 0.0043,
      "step": 1249500
    },
    {
      "epoch": 0.07023862871720382,
      "grad_norm": 0.36983001232147217,
      "learning_rate": 9.302841063223602e-05,
      "loss": 0.0044,
      "step": 1250000
    },
    {
      "epoch": 0.07023862871720382,
      "eval_loss": 0.001169345574453473,
      "eval_runtime": 19.9922,
      "eval_samples_per_second": 5001.943,
      "eval_steps_per_second": 78.18,
      "step": 1250000
    },
    {
      "epoch": 0.0702667241686907,
      "grad_norm": 0.06467494368553162,
      "learning_rate": 9.302559950749094e-05,
      "loss": 0.0043,
      "step": 1250500
    },
    {
      "epoch": 0.0702948196201776,
      "grad_norm": 0.3672172725200653,
      "learning_rate": 9.302278838274588e-05,
      "loss": 0.0039,
      "step": 1251000
    },
    {
      "epoch": 0.07032291507166448,
      "grad_norm": 0.0672328919172287,
      "learning_rate": 9.301997725800081e-05,
      "loss": 0.0044,
      "step": 1251500
    },
    {
      "epoch": 0.07035101052315136,
      "grad_norm": 0.4509352445602417,
      "learning_rate": 9.301716613325575e-05,
      "loss": 0.0046,
      "step": 1252000
    },
    {
      "epoch": 0.07037910597463824,
      "grad_norm": 0.5732831358909607,
      "learning_rate": 9.30143550085107e-05,
      "loss": 0.0045,
      "step": 1252500
    },
    {
      "epoch": 0.07040720142612512,
      "grad_norm": 0.07257754355669022,
      "learning_rate": 9.301154388376561e-05,
      "loss": 0.004,
      "step": 1253000
    },
    {
      "epoch": 0.070435296877612,
      "grad_norm": 0.34931448101997375,
      "learning_rate": 9.300873275902055e-05,
      "loss": 0.0049,
      "step": 1253500
    },
    {
      "epoch": 0.07046339232909889,
      "grad_norm": 0.418368399143219,
      "learning_rate": 9.300592163427548e-05,
      "loss": 0.0046,
      "step": 1254000
    },
    {
      "epoch": 0.07049148778058577,
      "grad_norm": 0.1266842931509018,
      "learning_rate": 9.300311050953042e-05,
      "loss": 0.0043,
      "step": 1254500
    },
    {
      "epoch": 0.07051958323207265,
      "grad_norm": 0.14054161310195923,
      "learning_rate": 9.300029938478535e-05,
      "loss": 0.0044,
      "step": 1255000
    },
    {
      "epoch": 0.07054767868355953,
      "grad_norm": 0.7927107810974121,
      "learning_rate": 9.299748826004029e-05,
      "loss": 0.0043,
      "step": 1255500
    },
    {
      "epoch": 0.07057577413504641,
      "grad_norm": 0.2109067291021347,
      "learning_rate": 9.299467713529523e-05,
      "loss": 0.0046,
      "step": 1256000
    },
    {
      "epoch": 0.0706038695865333,
      "grad_norm": 0.19832438230514526,
      "learning_rate": 9.299186601055015e-05,
      "loss": 0.0045,
      "step": 1256500
    },
    {
      "epoch": 0.07063196503802018,
      "grad_norm": 0.07599147409200668,
      "learning_rate": 9.298905488580509e-05,
      "loss": 0.0048,
      "step": 1257000
    },
    {
      "epoch": 0.07066006048950706,
      "grad_norm": 0.2770104706287384,
      "learning_rate": 9.298624376106002e-05,
      "loss": 0.0047,
      "step": 1257500
    },
    {
      "epoch": 0.07068815594099394,
      "grad_norm": 0.13536447286605835,
      "learning_rate": 9.298343263631496e-05,
      "loss": 0.0045,
      "step": 1258000
    },
    {
      "epoch": 0.07071625139248082,
      "grad_norm": 0.14349673688411713,
      "learning_rate": 9.298062151156989e-05,
      "loss": 0.0043,
      "step": 1258500
    },
    {
      "epoch": 0.0707443468439677,
      "grad_norm": 0.13672442734241486,
      "learning_rate": 9.297781038682483e-05,
      "loss": 0.0044,
      "step": 1259000
    },
    {
      "epoch": 0.07077244229545458,
      "grad_norm": 0.19861972332000732,
      "learning_rate": 9.297499926207976e-05,
      "loss": 0.004,
      "step": 1259500
    },
    {
      "epoch": 0.07080053774694146,
      "grad_norm": 0.04455384612083435,
      "learning_rate": 9.29721881373347e-05,
      "loss": 0.0045,
      "step": 1260000
    },
    {
      "epoch": 0.07080053774694146,
      "eval_loss": 0.0014067520387470722,
      "eval_runtime": 19.7448,
      "eval_samples_per_second": 5064.616,
      "eval_steps_per_second": 79.16,
      "step": 1260000
    },
    {
      "epoch": 0.07082863319842835,
      "grad_norm": 0.11766640096902847,
      "learning_rate": 9.296937701258963e-05,
      "loss": 0.0044,
      "step": 1260500
    },
    {
      "epoch": 0.07085672864991523,
      "grad_norm": 0.3445173501968384,
      "learning_rate": 9.296656588784456e-05,
      "loss": 0.0043,
      "step": 1261000
    },
    {
      "epoch": 0.07088482410140211,
      "grad_norm": 0.22323380410671234,
      "learning_rate": 9.29637547630995e-05,
      "loss": 0.0049,
      "step": 1261500
    },
    {
      "epoch": 0.07091291955288899,
      "grad_norm": 0.2605381906032562,
      "learning_rate": 9.296094363835443e-05,
      "loss": 0.0047,
      "step": 1262000
    },
    {
      "epoch": 0.07094101500437587,
      "grad_norm": 0.25032058358192444,
      "learning_rate": 9.295813251360937e-05,
      "loss": 0.0045,
      "step": 1262500
    },
    {
      "epoch": 0.07096911045586275,
      "grad_norm": 0.16083700954914093,
      "learning_rate": 9.295532138886429e-05,
      "loss": 0.0045,
      "step": 1263000
    },
    {
      "epoch": 0.07099720590734963,
      "grad_norm": 0.19811846315860748,
      "learning_rate": 9.295251026411923e-05,
      "loss": 0.005,
      "step": 1263500
    },
    {
      "epoch": 0.07102530135883652,
      "grad_norm": 0.2579875588417053,
      "learning_rate": 9.294969913937417e-05,
      "loss": 0.0045,
      "step": 1264000
    },
    {
      "epoch": 0.0710533968103234,
      "grad_norm": 0.22503158450126648,
      "learning_rate": 9.29468880146291e-05,
      "loss": 0.004,
      "step": 1264500
    },
    {
      "epoch": 0.07108149226181028,
      "grad_norm": 0.24849897623062134,
      "learning_rate": 9.294407688988404e-05,
      "loss": 0.0048,
      "step": 1265000
    },
    {
      "epoch": 0.07110958771329716,
      "grad_norm": 0.7288106679916382,
      "learning_rate": 9.294126576513896e-05,
      "loss": 0.0049,
      "step": 1265500
    },
    {
      "epoch": 0.07113768316478404,
      "grad_norm": 0.46932047605514526,
      "learning_rate": 9.29384546403939e-05,
      "loss": 0.0041,
      "step": 1266000
    },
    {
      "epoch": 0.07116577861627092,
      "grad_norm": 0.37760454416275024,
      "learning_rate": 9.293564351564883e-05,
      "loss": 0.0045,
      "step": 1266500
    },
    {
      "epoch": 0.0711938740677578,
      "grad_norm": 0.2646547555923462,
      "learning_rate": 9.293283239090377e-05,
      "loss": 0.0045,
      "step": 1267000
    },
    {
      "epoch": 0.07122196951924468,
      "grad_norm": 0.04222584143280983,
      "learning_rate": 9.29300212661587e-05,
      "loss": 0.0041,
      "step": 1267500
    },
    {
      "epoch": 0.07125006497073157,
      "grad_norm": 0.3907439708709717,
      "learning_rate": 9.292721014141363e-05,
      "loss": 0.0048,
      "step": 1268000
    },
    {
      "epoch": 0.07127816042221845,
      "grad_norm": 0.2849254310131073,
      "learning_rate": 9.292439901666858e-05,
      "loss": 0.0047,
      "step": 1268500
    },
    {
      "epoch": 0.07130625587370533,
      "grad_norm": 0.1282050609588623,
      "learning_rate": 9.29215878919235e-05,
      "loss": 0.0044,
      "step": 1269000
    },
    {
      "epoch": 0.07133435132519221,
      "grad_norm": 0.5972998738288879,
      "learning_rate": 9.291877676717845e-05,
      "loss": 0.0046,
      "step": 1269500
    },
    {
      "epoch": 0.07136244677667909,
      "grad_norm": 0.06868849694728851,
      "learning_rate": 9.291596564243337e-05,
      "loss": 0.0047,
      "step": 1270000
    },
    {
      "epoch": 0.07136244677667909,
      "eval_loss": 0.0011965885059908032,
      "eval_runtime": 19.4586,
      "eval_samples_per_second": 5139.112,
      "eval_steps_per_second": 80.324,
      "step": 1270000
    },
    {
      "epoch": 0.07139054222816597,
      "grad_norm": 0.3772716820240021,
      "learning_rate": 9.29131545176883e-05,
      "loss": 0.0044,
      "step": 1270500
    },
    {
      "epoch": 0.07141863767965285,
      "grad_norm": 0.17611652612686157,
      "learning_rate": 9.291034339294323e-05,
      "loss": 0.0042,
      "step": 1271000
    },
    {
      "epoch": 0.07144673313113974,
      "grad_norm": 0.25105443596839905,
      "learning_rate": 9.290753226819817e-05,
      "loss": 0.0047,
      "step": 1271500
    },
    {
      "epoch": 0.07147482858262662,
      "grad_norm": 0.2446085661649704,
      "learning_rate": 9.290472114345312e-05,
      "loss": 0.0041,
      "step": 1272000
    },
    {
      "epoch": 0.0715029240341135,
      "grad_norm": 0.04184594005346298,
      "learning_rate": 9.290191001870804e-05,
      "loss": 0.0044,
      "step": 1272500
    },
    {
      "epoch": 0.07153101948560038,
      "grad_norm": 0.24597276747226715,
      "learning_rate": 9.289909889396297e-05,
      "loss": 0.0043,
      "step": 1273000
    },
    {
      "epoch": 0.07155911493708726,
      "grad_norm": 0.9456381797790527,
      "learning_rate": 9.28962877692179e-05,
      "loss": 0.0046,
      "step": 1273500
    },
    {
      "epoch": 0.07158721038857414,
      "grad_norm": 0.043563537299633026,
      "learning_rate": 9.289347664447284e-05,
      "loss": 0.0044,
      "step": 1274000
    },
    {
      "epoch": 0.07161530584006102,
      "grad_norm": 0.050802651792764664,
      "learning_rate": 9.289066551972777e-05,
      "loss": 0.0041,
      "step": 1274500
    },
    {
      "epoch": 0.0716434012915479,
      "grad_norm": 0.5787827372550964,
      "learning_rate": 9.288785439498271e-05,
      "loss": 0.0048,
      "step": 1275000
    },
    {
      "epoch": 0.07167149674303479,
      "grad_norm": 0.12978309392929077,
      "learning_rate": 9.288504327023764e-05,
      "loss": 0.005,
      "step": 1275500
    },
    {
      "epoch": 0.07169959219452167,
      "grad_norm": 0.26360204815864563,
      "learning_rate": 9.288223214549258e-05,
      "loss": 0.0045,
      "step": 1276000
    },
    {
      "epoch": 0.07172768764600855,
      "grad_norm": 0.28198114037513733,
      "learning_rate": 9.287942102074751e-05,
      "loss": 0.0041,
      "step": 1276500
    },
    {
      "epoch": 0.07175578309749543,
      "grad_norm": 1.2106835842132568,
      "learning_rate": 9.287660989600245e-05,
      "loss": 0.0043,
      "step": 1277000
    },
    {
      "epoch": 0.07178387854898231,
      "grad_norm": 0.1372264325618744,
      "learning_rate": 9.287379877125738e-05,
      "loss": 0.0041,
      "step": 1277500
    },
    {
      "epoch": 0.0718119740004692,
      "grad_norm": 0.15024864673614502,
      "learning_rate": 9.287098764651231e-05,
      "loss": 0.0042,
      "step": 1278000
    },
    {
      "epoch": 0.07184006945195608,
      "grad_norm": 0.18100228905677795,
      "learning_rate": 9.286817652176725e-05,
      "loss": 0.0045,
      "step": 1278500
    },
    {
      "epoch": 0.07186816490344296,
      "grad_norm": 0.02361135557293892,
      "learning_rate": 9.286536539702217e-05,
      "loss": 0.0046,
      "step": 1279000
    },
    {
      "epoch": 0.07189626035492984,
      "grad_norm": 0.21657496690750122,
      "learning_rate": 9.286255427227712e-05,
      "loss": 0.0044,
      "step": 1279500
    },
    {
      "epoch": 0.07192435580641672,
      "grad_norm": 0.009427539072930813,
      "learning_rate": 9.285974314753205e-05,
      "loss": 0.0042,
      "step": 1280000
    },
    {
      "epoch": 0.07192435580641672,
      "eval_loss": 0.0012957291910424829,
      "eval_runtime": 19.55,
      "eval_samples_per_second": 5115.091,
      "eval_steps_per_second": 79.949,
      "step": 1280000
    },
    {
      "epoch": 0.0719524512579036,
      "grad_norm": 0.18138659000396729,
      "learning_rate": 9.285693202278698e-05,
      "loss": 0.0045,
      "step": 1280500
    },
    {
      "epoch": 0.07198054670939048,
      "grad_norm": 0.08744893968105316,
      "learning_rate": 9.285412089804192e-05,
      "loss": 0.0043,
      "step": 1281000
    },
    {
      "epoch": 0.07200864216087736,
      "grad_norm": 0.05480003356933594,
      "learning_rate": 9.285130977329684e-05,
      "loss": 0.0049,
      "step": 1281500
    },
    {
      "epoch": 0.07203673761236425,
      "grad_norm": 0.04039471969008446,
      "learning_rate": 9.284849864855179e-05,
      "loss": 0.0042,
      "step": 1282000
    },
    {
      "epoch": 0.07206483306385113,
      "grad_norm": 0.05612834542989731,
      "learning_rate": 9.284568752380671e-05,
      "loss": 0.0039,
      "step": 1282500
    },
    {
      "epoch": 0.07209292851533801,
      "grad_norm": 0.30983349680900574,
      "learning_rate": 9.284287639906166e-05,
      "loss": 0.0041,
      "step": 1283000
    },
    {
      "epoch": 0.07212102396682489,
      "grad_norm": 0.19369350373744965,
      "learning_rate": 9.284006527431659e-05,
      "loss": 0.0042,
      "step": 1283500
    },
    {
      "epoch": 0.07214911941831177,
      "grad_norm": 0.08021149784326553,
      "learning_rate": 9.283725414957151e-05,
      "loss": 0.0048,
      "step": 1284000
    },
    {
      "epoch": 0.07217721486979865,
      "grad_norm": 0.19176095724105835,
      "learning_rate": 9.283444302482646e-05,
      "loss": 0.0043,
      "step": 1284500
    },
    {
      "epoch": 0.07220531032128553,
      "grad_norm": 0.025898780673742294,
      "learning_rate": 9.283163190008138e-05,
      "loss": 0.0044,
      "step": 1285000
    },
    {
      "epoch": 0.07223340577277242,
      "grad_norm": 0.41468748450279236,
      "learning_rate": 9.282882077533633e-05,
      "loss": 0.0046,
      "step": 1285500
    },
    {
      "epoch": 0.0722615012242593,
      "grad_norm": 0.22909224033355713,
      "learning_rate": 9.282600965059125e-05,
      "loss": 0.0041,
      "step": 1286000
    },
    {
      "epoch": 0.07228959667574618,
      "grad_norm": 0.18260788917541504,
      "learning_rate": 9.282319852584618e-05,
      "loss": 0.0043,
      "step": 1286500
    },
    {
      "epoch": 0.07231769212723306,
      "grad_norm": 0.32358935475349426,
      "learning_rate": 9.282038740110112e-05,
      "loss": 0.0045,
      "step": 1287000
    },
    {
      "epoch": 0.07234578757871994,
      "grad_norm": 0.04659191146492958,
      "learning_rate": 9.281757627635605e-05,
      "loss": 0.0046,
      "step": 1287500
    },
    {
      "epoch": 0.07237388303020682,
      "grad_norm": 0.20207540690898895,
      "learning_rate": 9.2814765151611e-05,
      "loss": 0.005,
      "step": 1288000
    },
    {
      "epoch": 0.0724019784816937,
      "grad_norm": 0.07069682329893112,
      "learning_rate": 9.281195402686592e-05,
      "loss": 0.0048,
      "step": 1288500
    },
    {
      "epoch": 0.07243007393318059,
      "grad_norm": 0.3287128508090973,
      "learning_rate": 9.280914290212087e-05,
      "loss": 0.0041,
      "step": 1289000
    },
    {
      "epoch": 0.07245816938466747,
      "grad_norm": 0.09493987262248993,
      "learning_rate": 9.280633177737579e-05,
      "loss": 0.0044,
      "step": 1289500
    },
    {
      "epoch": 0.07248626483615435,
      "grad_norm": 0.13843655586242676,
      "learning_rate": 9.280352065263072e-05,
      "loss": 0.0041,
      "step": 1290000
    },
    {
      "epoch": 0.07248626483615435,
      "eval_loss": 0.001329504419118166,
      "eval_runtime": 20.2081,
      "eval_samples_per_second": 4948.507,
      "eval_steps_per_second": 77.345,
      "step": 1290000
    },
    {
      "epoch": 0.07251436028764123,
      "grad_norm": 0.48924732208251953,
      "learning_rate": 9.280070952788566e-05,
      "loss": 0.0042,
      "step": 1290500
    },
    {
      "epoch": 0.07254245573912811,
      "grad_norm": 0.08872361481189728,
      "learning_rate": 9.279789840314059e-05,
      "loss": 0.0044,
      "step": 1291000
    },
    {
      "epoch": 0.07257055119061499,
      "grad_norm": 0.1515006273984909,
      "learning_rate": 9.279508727839554e-05,
      "loss": 0.004,
      "step": 1291500
    },
    {
      "epoch": 0.07259864664210187,
      "grad_norm": 0.5256432890892029,
      "learning_rate": 9.279227615365046e-05,
      "loss": 0.0041,
      "step": 1292000
    },
    {
      "epoch": 0.07262674209358876,
      "grad_norm": 0.3814910650253296,
      "learning_rate": 9.278946502890539e-05,
      "loss": 0.0047,
      "step": 1292500
    },
    {
      "epoch": 0.07265483754507564,
      "grad_norm": 0.16858255863189697,
      "learning_rate": 9.278665390416033e-05,
      "loss": 0.0042,
      "step": 1293000
    },
    {
      "epoch": 0.07268293299656252,
      "grad_norm": 0.2975068688392639,
      "learning_rate": 9.278384277941526e-05,
      "loss": 0.0049,
      "step": 1293500
    },
    {
      "epoch": 0.0727110284480494,
      "grad_norm": 0.022860761731863022,
      "learning_rate": 9.27810316546702e-05,
      "loss": 0.004,
      "step": 1294000
    },
    {
      "epoch": 0.07273912389953628,
      "grad_norm": 0.045689720660448074,
      "learning_rate": 9.277822052992513e-05,
      "loss": 0.0044,
      "step": 1294500
    },
    {
      "epoch": 0.07276721935102316,
      "grad_norm": 0.2033642679452896,
      "learning_rate": 9.277540940518006e-05,
      "loss": 0.0044,
      "step": 1295000
    },
    {
      "epoch": 0.07279531480251004,
      "grad_norm": 0.06745057553052902,
      "learning_rate": 9.2772598280435e-05,
      "loss": 0.0048,
      "step": 1295500
    },
    {
      "epoch": 0.07282341025399693,
      "grad_norm": 0.019182875752449036,
      "learning_rate": 9.276978715568993e-05,
      "loss": 0.0048,
      "step": 1296000
    },
    {
      "epoch": 0.07285150570548381,
      "grad_norm": 0.2557309865951538,
      "learning_rate": 9.276697603094487e-05,
      "loss": 0.0044,
      "step": 1296500
    },
    {
      "epoch": 0.07287960115697069,
      "grad_norm": 0.045735981315374374,
      "learning_rate": 9.27641649061998e-05,
      "loss": 0.0046,
      "step": 1297000
    },
    {
      "epoch": 0.07290769660845757,
      "grad_norm": 0.23179122805595398,
      "learning_rate": 9.276135378145474e-05,
      "loss": 0.0043,
      "step": 1297500
    },
    {
      "epoch": 0.07293579205994445,
      "grad_norm": 0.1374799907207489,
      "learning_rate": 9.275854265670967e-05,
      "loss": 0.0047,
      "step": 1298000
    },
    {
      "epoch": 0.07296388751143133,
      "grad_norm": 0.08083818107843399,
      "learning_rate": 9.275573153196459e-05,
      "loss": 0.0042,
      "step": 1298500
    },
    {
      "epoch": 0.07299198296291821,
      "grad_norm": 0.05402608960866928,
      "learning_rate": 9.275292040721954e-05,
      "loss": 0.0041,
      "step": 1299000
    },
    {
      "epoch": 0.0730200784144051,
      "grad_norm": 0.5696998238563538,
      "learning_rate": 9.275010928247447e-05,
      "loss": 0.0045,
      "step": 1299500
    },
    {
      "epoch": 0.07304817386589198,
      "grad_norm": 0.24153994023799896,
      "learning_rate": 9.274729815772941e-05,
      "loss": 0.0039,
      "step": 1300000
    },
    {
      "epoch": 0.07304817386589198,
      "eval_loss": 0.0016009635291993618,
      "eval_runtime": 19.4463,
      "eval_samples_per_second": 5142.353,
      "eval_steps_per_second": 80.375,
      "step": 1300000
    },
    {
      "epoch": 0.07307626931737886,
      "grad_norm": 0.033738937228918076,
      "learning_rate": 9.274448703298434e-05,
      "loss": 0.0047,
      "step": 1300500
    },
    {
      "epoch": 0.07310436476886574,
      "grad_norm": 0.08257807046175003,
      "learning_rate": 9.274167590823926e-05,
      "loss": 0.0047,
      "step": 1301000
    },
    {
      "epoch": 0.07313246022035262,
      "grad_norm": 0.4339054822921753,
      "learning_rate": 9.273886478349421e-05,
      "loss": 0.0047,
      "step": 1301500
    },
    {
      "epoch": 0.0731605556718395,
      "grad_norm": 0.47454094886779785,
      "learning_rate": 9.273605365874913e-05,
      "loss": 0.0046,
      "step": 1302000
    },
    {
      "epoch": 0.07318865112332638,
      "grad_norm": 0.5902476906776428,
      "learning_rate": 9.273324253400408e-05,
      "loss": 0.004,
      "step": 1302500
    },
    {
      "epoch": 0.07321674657481327,
      "grad_norm": 0.2162393033504486,
      "learning_rate": 9.273043140925901e-05,
      "loss": 0.0045,
      "step": 1303000
    },
    {
      "epoch": 0.07324484202630015,
      "grad_norm": 0.14859342575073242,
      "learning_rate": 9.272762028451393e-05,
      "loss": 0.0046,
      "step": 1303500
    },
    {
      "epoch": 0.07327293747778703,
      "grad_norm": 0.26434364914894104,
      "learning_rate": 9.272480915976888e-05,
      "loss": 0.0043,
      "step": 1304000
    },
    {
      "epoch": 0.07330103292927391,
      "grad_norm": 0.043111350387334824,
      "learning_rate": 9.27219980350238e-05,
      "loss": 0.0046,
      "step": 1304500
    },
    {
      "epoch": 0.07332912838076079,
      "grad_norm": 0.65419602394104,
      "learning_rate": 9.271918691027875e-05,
      "loss": 0.0044,
      "step": 1305000
    },
    {
      "epoch": 0.07335722383224767,
      "grad_norm": 0.1130642294883728,
      "learning_rate": 9.271637578553367e-05,
      "loss": 0.0047,
      "step": 1305500
    },
    {
      "epoch": 0.07338531928373455,
      "grad_norm": 0.31618377566337585,
      "learning_rate": 9.27135646607886e-05,
      "loss": 0.005,
      "step": 1306000
    },
    {
      "epoch": 0.07341341473522144,
      "grad_norm": 0.04364752769470215,
      "learning_rate": 9.271075353604355e-05,
      "loss": 0.0046,
      "step": 1306500
    },
    {
      "epoch": 0.07344151018670832,
      "grad_norm": 0.26241376996040344,
      "learning_rate": 9.270794241129847e-05,
      "loss": 0.0041,
      "step": 1307000
    },
    {
      "epoch": 0.0734696056381952,
      "grad_norm": 0.5325015187263489,
      "learning_rate": 9.270513128655342e-05,
      "loss": 0.004,
      "step": 1307500
    },
    {
      "epoch": 0.07349770108968208,
      "grad_norm": 0.09231435507535934,
      "learning_rate": 9.270232016180834e-05,
      "loss": 0.0045,
      "step": 1308000
    },
    {
      "epoch": 0.07352579654116896,
      "grad_norm": 0.13217894732952118,
      "learning_rate": 9.269950903706328e-05,
      "loss": 0.0044,
      "step": 1308500
    },
    {
      "epoch": 0.07355389199265584,
      "grad_norm": 0.4352426528930664,
      "learning_rate": 9.269669791231821e-05,
      "loss": 0.0047,
      "step": 1309000
    },
    {
      "epoch": 0.07358198744414272,
      "grad_norm": 0.43458452820777893,
      "learning_rate": 9.269388678757314e-05,
      "loss": 0.0045,
      "step": 1309500
    },
    {
      "epoch": 0.0736100828956296,
      "grad_norm": 0.5732224583625793,
      "learning_rate": 9.269107566282808e-05,
      "loss": 0.0044,
      "step": 1310000
    },
    {
      "epoch": 0.0736100828956296,
      "eval_loss": 0.001287859515286982,
      "eval_runtime": 20.3425,
      "eval_samples_per_second": 4915.814,
      "eval_steps_per_second": 76.834,
      "step": 1310000
    },
    {
      "epoch": 0.07363817834711649,
      "grad_norm": 0.3768959045410156,
      "learning_rate": 9.268826453808301e-05,
      "loss": 0.0049,
      "step": 1310500
    },
    {
      "epoch": 0.07366627379860337,
      "grad_norm": 0.6705289483070374,
      "learning_rate": 9.268545341333795e-05,
      "loss": 0.0048,
      "step": 1311000
    },
    {
      "epoch": 0.07369436925009025,
      "grad_norm": 0.3981703519821167,
      "learning_rate": 9.268264228859288e-05,
      "loss": 0.0042,
      "step": 1311500
    },
    {
      "epoch": 0.07372246470157715,
      "grad_norm": 1.012170433998108,
      "learning_rate": 9.267983116384782e-05,
      "loss": 0.0043,
      "step": 1312000
    },
    {
      "epoch": 0.07375056015306403,
      "grad_norm": 0.3764869272708893,
      "learning_rate": 9.267702003910275e-05,
      "loss": 0.0048,
      "step": 1312500
    },
    {
      "epoch": 0.07377865560455091,
      "grad_norm": 0.2862779498100281,
      "learning_rate": 9.267420891435768e-05,
      "loss": 0.0048,
      "step": 1313000
    },
    {
      "epoch": 0.07380675105603779,
      "grad_norm": 0.2977513074874878,
      "learning_rate": 9.267139778961262e-05,
      "loss": 0.0047,
      "step": 1313500
    },
    {
      "epoch": 0.07383484650752467,
      "grad_norm": 0.5110979080200195,
      "learning_rate": 9.266858666486755e-05,
      "loss": 0.0041,
      "step": 1314000
    },
    {
      "epoch": 0.07386294195901155,
      "grad_norm": 0.08231990039348602,
      "learning_rate": 9.266577554012249e-05,
      "loss": 0.0044,
      "step": 1314500
    },
    {
      "epoch": 0.07389103741049843,
      "grad_norm": 0.4602494239807129,
      "learning_rate": 9.266296441537742e-05,
      "loss": 0.0041,
      "step": 1315000
    },
    {
      "epoch": 0.07391913286198531,
      "grad_norm": 0.07161370664834976,
      "learning_rate": 9.266015329063235e-05,
      "loss": 0.0044,
      "step": 1315500
    },
    {
      "epoch": 0.0739472283134722,
      "grad_norm": 0.16364002227783203,
      "learning_rate": 9.265734216588729e-05,
      "loss": 0.0045,
      "step": 1316000
    },
    {
      "epoch": 0.07397532376495908,
      "grad_norm": 0.42774319648742676,
      "learning_rate": 9.265453104114222e-05,
      "loss": 0.0042,
      "step": 1316500
    },
    {
      "epoch": 0.07400341921644596,
      "grad_norm": 0.036561910063028336,
      "learning_rate": 9.265171991639714e-05,
      "loss": 0.0042,
      "step": 1317000
    },
    {
      "epoch": 0.07403151466793284,
      "grad_norm": 0.520455539226532,
      "learning_rate": 9.264890879165209e-05,
      "loss": 0.0043,
      "step": 1317500
    },
    {
      "epoch": 0.07405961011941972,
      "grad_norm": 0.05262121185660362,
      "learning_rate": 9.264609766690701e-05,
      "loss": 0.0046,
      "step": 1318000
    },
    {
      "epoch": 0.0740877055709066,
      "grad_norm": 0.33227309584617615,
      "learning_rate": 9.264328654216196e-05,
      "loss": 0.0047,
      "step": 1318500
    },
    {
      "epoch": 0.07411580102239348,
      "grad_norm": 0.09397350996732712,
      "learning_rate": 9.26404754174169e-05,
      "loss": 0.0045,
      "step": 1319000
    },
    {
      "epoch": 0.07414389647388037,
      "grad_norm": 0.08451895415782928,
      "learning_rate": 9.263766429267182e-05,
      "loss": 0.004,
      "step": 1319500
    },
    {
      "epoch": 0.07417199192536725,
      "grad_norm": 0.18338069319725037,
      "learning_rate": 9.263485316792676e-05,
      "loss": 0.0041,
      "step": 1320000
    },
    {
      "epoch": 0.07417199192536725,
      "eval_loss": 0.0011621188605204225,
      "eval_runtime": 20.3277,
      "eval_samples_per_second": 4919.399,
      "eval_steps_per_second": 76.89,
      "step": 1320000
    },
    {
      "epoch": 0.07420008737685413,
      "grad_norm": 0.26226508617401123,
      "learning_rate": 9.263204204318168e-05,
      "loss": 0.0048,
      "step": 1320500
    },
    {
      "epoch": 0.07422818282834101,
      "grad_norm": 0.13769352436065674,
      "learning_rate": 9.262923091843663e-05,
      "loss": 0.0047,
      "step": 1321000
    },
    {
      "epoch": 0.07425627827982789,
      "grad_norm": 0.10333327949047089,
      "learning_rate": 9.262641979369155e-05,
      "loss": 0.0041,
      "step": 1321500
    },
    {
      "epoch": 0.07428437373131477,
      "grad_norm": 0.12882240116596222,
      "learning_rate": 9.262360866894649e-05,
      "loss": 0.005,
      "step": 1322000
    },
    {
      "epoch": 0.07431246918280165,
      "grad_norm": 0.08575531095266342,
      "learning_rate": 9.262079754420143e-05,
      "loss": 0.0045,
      "step": 1322500
    },
    {
      "epoch": 0.07434056463428854,
      "grad_norm": 1.6853803396224976,
      "learning_rate": 9.261798641945635e-05,
      "loss": 0.0042,
      "step": 1323000
    },
    {
      "epoch": 0.07436866008577542,
      "grad_norm": 0.11584397405385971,
      "learning_rate": 9.26151752947113e-05,
      "loss": 0.004,
      "step": 1323500
    },
    {
      "epoch": 0.0743967555372623,
      "grad_norm": 0.5714424848556519,
      "learning_rate": 9.261236416996622e-05,
      "loss": 0.0043,
      "step": 1324000
    },
    {
      "epoch": 0.07442485098874918,
      "grad_norm": 0.32722657918930054,
      "learning_rate": 9.260955304522117e-05,
      "loss": 0.0045,
      "step": 1324500
    },
    {
      "epoch": 0.07445294644023606,
      "grad_norm": 0.33739641308784485,
      "learning_rate": 9.260674192047609e-05,
      "loss": 0.0047,
      "step": 1325000
    },
    {
      "epoch": 0.07448104189172294,
      "grad_norm": 0.48981696367263794,
      "learning_rate": 9.260393079573103e-05,
      "loss": 0.0044,
      "step": 1325500
    },
    {
      "epoch": 0.07450913734320982,
      "grad_norm": 0.09018227458000183,
      "learning_rate": 9.260111967098597e-05,
      "loss": 0.0047,
      "step": 1326000
    },
    {
      "epoch": 0.0745372327946967,
      "grad_norm": 0.07004231214523315,
      "learning_rate": 9.25983085462409e-05,
      "loss": 0.0043,
      "step": 1326500
    },
    {
      "epoch": 0.07456532824618359,
      "grad_norm": 0.03386007621884346,
      "learning_rate": 9.259549742149584e-05,
      "loss": 0.0046,
      "step": 1327000
    },
    {
      "epoch": 0.07459342369767047,
      "grad_norm": 0.22226443886756897,
      "learning_rate": 9.259268629675076e-05,
      "loss": 0.004,
      "step": 1327500
    },
    {
      "epoch": 0.07462151914915735,
      "grad_norm": 0.011935829184949398,
      "learning_rate": 9.25898751720057e-05,
      "loss": 0.0045,
      "step": 1328000
    },
    {
      "epoch": 0.07464961460064423,
      "grad_norm": 0.4896121919155121,
      "learning_rate": 9.258706404726063e-05,
      "loss": 0.0044,
      "step": 1328500
    },
    {
      "epoch": 0.07467771005213111,
      "grad_norm": 0.290561705827713,
      "learning_rate": 9.258425292251557e-05,
      "loss": 0.004,
      "step": 1329000
    },
    {
      "epoch": 0.074705805503618,
      "grad_norm": 0.026555202901363373,
      "learning_rate": 9.25814417977705e-05,
      "loss": 0.0044,
      "step": 1329500
    },
    {
      "epoch": 0.07473390095510488,
      "grad_norm": 0.3029841482639313,
      "learning_rate": 9.257863067302543e-05,
      "loss": 0.0044,
      "step": 1330000
    },
    {
      "epoch": 0.07473390095510488,
      "eval_loss": 0.0012899501016363502,
      "eval_runtime": 21.1825,
      "eval_samples_per_second": 4720.882,
      "eval_steps_per_second": 73.787,
      "step": 1330000
    },
    {
      "epoch": 0.07476199640659176,
      "grad_norm": 0.051224689930677414,
      "learning_rate": 9.257581954828037e-05,
      "loss": 0.0045,
      "step": 1330500
    },
    {
      "epoch": 0.07479009185807864,
      "grad_norm": 0.3658980131149292,
      "learning_rate": 9.25730084235353e-05,
      "loss": 0.0049,
      "step": 1331000
    },
    {
      "epoch": 0.07481818730956552,
      "grad_norm": 0.26982948184013367,
      "learning_rate": 9.257019729879024e-05,
      "loss": 0.0046,
      "step": 1331500
    },
    {
      "epoch": 0.0748462827610524,
      "grad_norm": 0.025785936042666435,
      "learning_rate": 9.256738617404517e-05,
      "loss": 0.0041,
      "step": 1332000
    },
    {
      "epoch": 0.07487437821253928,
      "grad_norm": 0.23516108095645905,
      "learning_rate": 9.25645750493001e-05,
      "loss": 0.0043,
      "step": 1332500
    },
    {
      "epoch": 0.07490247366402616,
      "grad_norm": 0.2791218161582947,
      "learning_rate": 9.256176392455504e-05,
      "loss": 0.0039,
      "step": 1333000
    },
    {
      "epoch": 0.07493056911551305,
      "grad_norm": 0.24585774540901184,
      "learning_rate": 9.255895279980997e-05,
      "loss": 0.0046,
      "step": 1333500
    },
    {
      "epoch": 0.07495866456699993,
      "grad_norm": 0.03466976433992386,
      "learning_rate": 9.255614167506491e-05,
      "loss": 0.004,
      "step": 1334000
    },
    {
      "epoch": 0.07498676001848681,
      "grad_norm": 0.16867339611053467,
      "learning_rate": 9.255333055031984e-05,
      "loss": 0.0049,
      "step": 1334500
    },
    {
      "epoch": 0.07501485546997369,
      "grad_norm": 0.5218355059623718,
      "learning_rate": 9.255051942557478e-05,
      "loss": 0.0044,
      "step": 1335000
    },
    {
      "epoch": 0.07504295092146057,
      "grad_norm": 0.33565616607666016,
      "learning_rate": 9.254770830082971e-05,
      "loss": 0.0041,
      "step": 1335500
    },
    {
      "epoch": 0.07507104637294745,
      "grad_norm": 0.45921894907951355,
      "learning_rate": 9.254489717608465e-05,
      "loss": 0.0045,
      "step": 1336000
    },
    {
      "epoch": 0.07509914182443433,
      "grad_norm": 0.21512708067893982,
      "learning_rate": 9.254208605133957e-05,
      "loss": 0.0045,
      "step": 1336500
    },
    {
      "epoch": 0.07512723727592122,
      "grad_norm": 0.1948002725839615,
      "learning_rate": 9.253927492659451e-05,
      "loss": 0.0045,
      "step": 1337000
    },
    {
      "epoch": 0.0751553327274081,
      "grad_norm": 0.07411311566829681,
      "learning_rate": 9.253646380184943e-05,
      "loss": 0.0047,
      "step": 1337500
    },
    {
      "epoch": 0.07518342817889498,
      "grad_norm": 0.24225789308547974,
      "learning_rate": 9.253365267710438e-05,
      "loss": 0.0041,
      "step": 1338000
    },
    {
      "epoch": 0.07521152363038186,
      "grad_norm": 0.0514221228659153,
      "learning_rate": 9.253084155235932e-05,
      "loss": 0.0043,
      "step": 1338500
    },
    {
      "epoch": 0.07523961908186874,
      "grad_norm": 0.2958485782146454,
      "learning_rate": 9.252803042761424e-05,
      "loss": 0.0047,
      "step": 1339000
    },
    {
      "epoch": 0.07526771453335562,
      "grad_norm": 0.3463197648525238,
      "learning_rate": 9.252521930286919e-05,
      "loss": 0.0048,
      "step": 1339500
    },
    {
      "epoch": 0.0752958099848425,
      "grad_norm": 0.030194764956831932,
      "learning_rate": 9.25224081781241e-05,
      "loss": 0.0046,
      "step": 1340000
    },
    {
      "epoch": 0.0752958099848425,
      "eval_loss": 0.0012571322731673717,
      "eval_runtime": 19.4835,
      "eval_samples_per_second": 5132.558,
      "eval_steps_per_second": 80.222,
      "step": 1340000
    },
    {
      "epoch": 0.07532390543632939,
      "grad_norm": 0.19535574316978455,
      "learning_rate": 9.251959705337905e-05,
      "loss": 0.0046,
      "step": 1340500
    },
    {
      "epoch": 0.07535200088781627,
      "grad_norm": 0.0422782376408577,
      "learning_rate": 9.251678592863397e-05,
      "loss": 0.0043,
      "step": 1341000
    },
    {
      "epoch": 0.07538009633930315,
      "grad_norm": 0.19906103610992432,
      "learning_rate": 9.251397480388891e-05,
      "loss": 0.0042,
      "step": 1341500
    },
    {
      "epoch": 0.07540819179079003,
      "grad_norm": 0.12052644789218903,
      "learning_rate": 9.251116367914386e-05,
      "loss": 0.0043,
      "step": 1342000
    },
    {
      "epoch": 0.07543628724227691,
      "grad_norm": 0.07323934882879257,
      "learning_rate": 9.250835255439878e-05,
      "loss": 0.0042,
      "step": 1342500
    },
    {
      "epoch": 0.07546438269376379,
      "grad_norm": 0.36558952927589417,
      "learning_rate": 9.250554142965372e-05,
      "loss": 0.0044,
      "step": 1343000
    },
    {
      "epoch": 0.07549247814525067,
      "grad_norm": 0.03704998642206192,
      "learning_rate": 9.250273030490865e-05,
      "loss": 0.0044,
      "step": 1343500
    },
    {
      "epoch": 0.07552057359673756,
      "grad_norm": 0.2683878242969513,
      "learning_rate": 9.249991918016358e-05,
      "loss": 0.0043,
      "step": 1344000
    },
    {
      "epoch": 0.07554866904822444,
      "grad_norm": 0.5286833047866821,
      "learning_rate": 9.249710805541851e-05,
      "loss": 0.0044,
      "step": 1344500
    },
    {
      "epoch": 0.07557676449971132,
      "grad_norm": 0.48161712288856506,
      "learning_rate": 9.249429693067345e-05,
      "loss": 0.004,
      "step": 1345000
    },
    {
      "epoch": 0.0756048599511982,
      "grad_norm": 0.01607399433851242,
      "learning_rate": 9.24914858059284e-05,
      "loss": 0.0042,
      "step": 1345500
    },
    {
      "epoch": 0.07563295540268508,
      "grad_norm": 0.037892431020736694,
      "learning_rate": 9.248867468118332e-05,
      "loss": 0.0044,
      "step": 1346000
    },
    {
      "epoch": 0.07566105085417196,
      "grad_norm": 0.3077225387096405,
      "learning_rate": 9.248586355643825e-05,
      "loss": 0.0044,
      "step": 1346500
    },
    {
      "epoch": 0.07568914630565884,
      "grad_norm": 0.24125607311725616,
      "learning_rate": 9.248305243169319e-05,
      "loss": 0.0042,
      "step": 1347000
    },
    {
      "epoch": 0.07571724175714573,
      "grad_norm": 0.19284258782863617,
      "learning_rate": 9.248024130694812e-05,
      "loss": 0.0041,
      "step": 1347500
    },
    {
      "epoch": 0.07574533720863261,
      "grad_norm": 0.420508474111557,
      "learning_rate": 9.247743018220305e-05,
      "loss": 0.0047,
      "step": 1348000
    },
    {
      "epoch": 0.07577343266011949,
      "grad_norm": 0.0909590795636177,
      "learning_rate": 9.247461905745799e-05,
      "loss": 0.0047,
      "step": 1348500
    },
    {
      "epoch": 0.07580152811160637,
      "grad_norm": 0.35250380635261536,
      "learning_rate": 9.247180793271292e-05,
      "loss": 0.0046,
      "step": 1349000
    },
    {
      "epoch": 0.07582962356309325,
      "grad_norm": 0.4335801601409912,
      "learning_rate": 9.246899680796786e-05,
      "loss": 0.004,
      "step": 1349500
    },
    {
      "epoch": 0.07585771901458013,
      "grad_norm": 0.5260201692581177,
      "learning_rate": 9.246618568322279e-05,
      "loss": 0.0045,
      "step": 1350000
    },
    {
      "epoch": 0.07585771901458013,
      "eval_loss": 0.001263810321688652,
      "eval_runtime": 19.8172,
      "eval_samples_per_second": 5046.132,
      "eval_steps_per_second": 78.871,
      "step": 1350000
    },
    {
      "epoch": 0.07588581446606701,
      "grad_norm": 0.4159782826900482,
      "learning_rate": 9.246337455847772e-05,
      "loss": 0.0041,
      "step": 1350500
    },
    {
      "epoch": 0.0759139099175539,
      "grad_norm": 0.08993906527757645,
      "learning_rate": 9.246056343373266e-05,
      "loss": 0.0039,
      "step": 1351000
    },
    {
      "epoch": 0.07594200536904078,
      "grad_norm": 0.32880157232284546,
      "learning_rate": 9.24577523089876e-05,
      "loss": 0.0044,
      "step": 1351500
    },
    {
      "epoch": 0.07597010082052766,
      "grad_norm": 0.1926371157169342,
      "learning_rate": 9.245494118424253e-05,
      "loss": 0.0045,
      "step": 1352000
    },
    {
      "epoch": 0.07599819627201454,
      "grad_norm": 0.4851250946521759,
      "learning_rate": 9.245213005949745e-05,
      "loss": 0.0047,
      "step": 1352500
    },
    {
      "epoch": 0.07602629172350142,
      "grad_norm": 0.2750406265258789,
      "learning_rate": 9.24493189347524e-05,
      "loss": 0.0044,
      "step": 1353000
    },
    {
      "epoch": 0.0760543871749883,
      "grad_norm": 0.0788438469171524,
      "learning_rate": 9.244650781000733e-05,
      "loss": 0.004,
      "step": 1353500
    },
    {
      "epoch": 0.07608248262647518,
      "grad_norm": 0.14161568880081177,
      "learning_rate": 9.244369668526226e-05,
      "loss": 0.0045,
      "step": 1354000
    },
    {
      "epoch": 0.07611057807796207,
      "grad_norm": 0.12403719127178192,
      "learning_rate": 9.24408855605172e-05,
      "loss": 0.0038,
      "step": 1354500
    },
    {
      "epoch": 0.07613867352944895,
      "grad_norm": 0.08138200640678406,
      "learning_rate": 9.243807443577212e-05,
      "loss": 0.0039,
      "step": 1355000
    },
    {
      "epoch": 0.07616676898093583,
      "grad_norm": 0.12274215370416641,
      "learning_rate": 9.243526331102707e-05,
      "loss": 0.0044,
      "step": 1355500
    },
    {
      "epoch": 0.07619486443242271,
      "grad_norm": 0.3243960738182068,
      "learning_rate": 9.243245218628199e-05,
      "loss": 0.0042,
      "step": 1356000
    },
    {
      "epoch": 0.07622295988390959,
      "grad_norm": 0.6839873194694519,
      "learning_rate": 9.242964106153694e-05,
      "loss": 0.0044,
      "step": 1356500
    },
    {
      "epoch": 0.07625105533539647,
      "grad_norm": 1.1295356750488281,
      "learning_rate": 9.242682993679187e-05,
      "loss": 0.0041,
      "step": 1357000
    },
    {
      "epoch": 0.07627915078688335,
      "grad_norm": 0.20236729085445404,
      "learning_rate": 9.24240188120468e-05,
      "loss": 0.0044,
      "step": 1357500
    },
    {
      "epoch": 0.07630724623837024,
      "grad_norm": 0.08115245401859283,
      "learning_rate": 9.242120768730174e-05,
      "loss": 0.0043,
      "step": 1358000
    },
    {
      "epoch": 0.07633534168985712,
      "grad_norm": 0.03488209471106529,
      "learning_rate": 9.241839656255666e-05,
      "loss": 0.0043,
      "step": 1358500
    },
    {
      "epoch": 0.076363437141344,
      "grad_norm": 0.2588885724544525,
      "learning_rate": 9.241558543781161e-05,
      "loss": 0.0042,
      "step": 1359000
    },
    {
      "epoch": 0.07639153259283088,
      "grad_norm": 0.20087337493896484,
      "learning_rate": 9.241277431306653e-05,
      "loss": 0.0043,
      "step": 1359500
    },
    {
      "epoch": 0.07641962804431776,
      "grad_norm": 0.6511173248291016,
      "learning_rate": 9.240996318832148e-05,
      "loss": 0.0045,
      "step": 1360000
    },
    {
      "epoch": 0.07641962804431776,
      "eval_loss": 0.001324690179899335,
      "eval_runtime": 19.8784,
      "eval_samples_per_second": 5030.591,
      "eval_steps_per_second": 78.628,
      "step": 1360000
    },
    {
      "epoch": 0.07644772349580464,
      "grad_norm": 0.0389852449297905,
      "learning_rate": 9.24071520635764e-05,
      "loss": 0.0043,
      "step": 1360500
    },
    {
      "epoch": 0.07647581894729152,
      "grad_norm": 0.18912601470947266,
      "learning_rate": 9.240434093883133e-05,
      "loss": 0.004,
      "step": 1361000
    },
    {
      "epoch": 0.0765039143987784,
      "grad_norm": 0.1455731987953186,
      "learning_rate": 9.240152981408628e-05,
      "loss": 0.0041,
      "step": 1361500
    },
    {
      "epoch": 0.07653200985026529,
      "grad_norm": 0.08002670109272003,
      "learning_rate": 9.23987186893412e-05,
      "loss": 0.0043,
      "step": 1362000
    },
    {
      "epoch": 0.07656010530175217,
      "grad_norm": 0.11683276295661926,
      "learning_rate": 9.239590756459615e-05,
      "loss": 0.005,
      "step": 1362500
    },
    {
      "epoch": 0.07658820075323905,
      "grad_norm": 0.15390828251838684,
      "learning_rate": 9.239309643985107e-05,
      "loss": 0.0042,
      "step": 1363000
    },
    {
      "epoch": 0.07661629620472593,
      "grad_norm": 0.1655581146478653,
      "learning_rate": 9.2390285315106e-05,
      "loss": 0.0045,
      "step": 1363500
    },
    {
      "epoch": 0.07664439165621281,
      "grad_norm": 0.17677363753318787,
      "learning_rate": 9.238747419036094e-05,
      "loss": 0.0043,
      "step": 1364000
    },
    {
      "epoch": 0.0766724871076997,
      "grad_norm": 0.2018565982580185,
      "learning_rate": 9.238466306561587e-05,
      "loss": 0.0038,
      "step": 1364500
    },
    {
      "epoch": 0.07670058255918658,
      "grad_norm": 0.07092374563217163,
      "learning_rate": 9.238185194087082e-05,
      "loss": 0.0042,
      "step": 1365000
    },
    {
      "epoch": 0.07672867801067346,
      "grad_norm": 0.4263842701911926,
      "learning_rate": 9.237904081612574e-05,
      "loss": 0.0048,
      "step": 1365500
    },
    {
      "epoch": 0.07675677346216034,
      "grad_norm": 0.36857712268829346,
      "learning_rate": 9.237622969138067e-05,
      "loss": 0.0039,
      "step": 1366000
    },
    {
      "epoch": 0.07678486891364722,
      "grad_norm": 0.031676068902015686,
      "learning_rate": 9.237341856663561e-05,
      "loss": 0.0039,
      "step": 1366500
    },
    {
      "epoch": 0.0768129643651341,
      "grad_norm": 0.15249569714069366,
      "learning_rate": 9.237060744189054e-05,
      "loss": 0.0043,
      "step": 1367000
    },
    {
      "epoch": 0.07684105981662098,
      "grad_norm": 0.2352922558784485,
      "learning_rate": 9.236779631714548e-05,
      "loss": 0.0044,
      "step": 1367500
    },
    {
      "epoch": 0.07686915526810786,
      "grad_norm": 0.020108023658394814,
      "learning_rate": 9.236498519240041e-05,
      "loss": 0.0043,
      "step": 1368000
    },
    {
      "epoch": 0.07689725071959475,
      "grad_norm": 0.7374274730682373,
      "learning_rate": 9.236217406765534e-05,
      "loss": 0.0051,
      "step": 1368500
    },
    {
      "epoch": 0.07692534617108163,
      "grad_norm": 0.024969886988401413,
      "learning_rate": 9.235936294291028e-05,
      "loss": 0.0042,
      "step": 1369000
    },
    {
      "epoch": 0.07695344162256851,
      "grad_norm": 0.23345795273780823,
      "learning_rate": 9.235655181816521e-05,
      "loss": 0.0044,
      "step": 1369500
    },
    {
      "epoch": 0.07698153707405539,
      "grad_norm": 0.23341232538223267,
      "learning_rate": 9.235374069342015e-05,
      "loss": 0.0038,
      "step": 1370000
    },
    {
      "epoch": 0.07698153707405539,
      "eval_loss": 0.0011618054704740644,
      "eval_runtime": 19.867,
      "eval_samples_per_second": 5033.467,
      "eval_steps_per_second": 78.673,
      "step": 1370000
    },
    {
      "epoch": 0.07700963252554227,
      "grad_norm": 0.5253039002418518,
      "learning_rate": 9.235092956867508e-05,
      "loss": 0.0041,
      "step": 1370500
    },
    {
      "epoch": 0.07703772797702915,
      "grad_norm": 0.21184590458869934,
      "learning_rate": 9.234811844393002e-05,
      "loss": 0.0042,
      "step": 1371000
    },
    {
      "epoch": 0.07706582342851603,
      "grad_norm": 0.07744526863098145,
      "learning_rate": 9.234530731918495e-05,
      "loss": 0.0043,
      "step": 1371500
    },
    {
      "epoch": 0.07709391888000292,
      "grad_norm": 0.23239174485206604,
      "learning_rate": 9.234249619443987e-05,
      "loss": 0.0045,
      "step": 1372000
    },
    {
      "epoch": 0.0771220143314898,
      "grad_norm": 0.34650397300720215,
      "learning_rate": 9.233968506969482e-05,
      "loss": 0.004,
      "step": 1372500
    },
    {
      "epoch": 0.07715010978297669,
      "grad_norm": 0.4266705811023712,
      "learning_rate": 9.233687394494975e-05,
      "loss": 0.0041,
      "step": 1373000
    },
    {
      "epoch": 0.07717820523446357,
      "grad_norm": 0.22972795367240906,
      "learning_rate": 9.233406282020469e-05,
      "loss": 0.004,
      "step": 1373500
    },
    {
      "epoch": 0.07720630068595045,
      "grad_norm": 0.08827313035726547,
      "learning_rate": 9.233125169545962e-05,
      "loss": 0.0044,
      "step": 1374000
    },
    {
      "epoch": 0.07723439613743734,
      "grad_norm": 0.1188984289765358,
      "learning_rate": 9.232844057071454e-05,
      "loss": 0.004,
      "step": 1374500
    },
    {
      "epoch": 0.07726249158892422,
      "grad_norm": 0.45572930574417114,
      "learning_rate": 9.232562944596949e-05,
      "loss": 0.0041,
      "step": 1375000
    },
    {
      "epoch": 0.0772905870404111,
      "grad_norm": 0.4508099853992462,
      "learning_rate": 9.232281832122441e-05,
      "loss": 0.0041,
      "step": 1375500
    },
    {
      "epoch": 0.07731868249189798,
      "grad_norm": 0.6024333238601685,
      "learning_rate": 9.232000719647936e-05,
      "loss": 0.0047,
      "step": 1376000
    },
    {
      "epoch": 0.07734677794338486,
      "grad_norm": 0.012190250679850578,
      "learning_rate": 9.231719607173429e-05,
      "loss": 0.0042,
      "step": 1376500
    },
    {
      "epoch": 0.07737487339487174,
      "grad_norm": 0.2868897616863251,
      "learning_rate": 9.231438494698921e-05,
      "loss": 0.0044,
      "step": 1377000
    },
    {
      "epoch": 0.07740296884635862,
      "grad_norm": 0.04593917354941368,
      "learning_rate": 9.231157382224416e-05,
      "loss": 0.0046,
      "step": 1377500
    },
    {
      "epoch": 0.0774310642978455,
      "grad_norm": 0.24580951035022736,
      "learning_rate": 9.230876269749908e-05,
      "loss": 0.0038,
      "step": 1378000
    },
    {
      "epoch": 0.07745915974933239,
      "grad_norm": 0.533161997795105,
      "learning_rate": 9.230595157275403e-05,
      "loss": 0.004,
      "step": 1378500
    },
    {
      "epoch": 0.07748725520081927,
      "grad_norm": 0.7497829794883728,
      "learning_rate": 9.230314044800895e-05,
      "loss": 0.0046,
      "step": 1379000
    },
    {
      "epoch": 0.07751535065230615,
      "grad_norm": 0.3252786099910736,
      "learning_rate": 9.230032932326388e-05,
      "loss": 0.0044,
      "step": 1379500
    },
    {
      "epoch": 0.07754344610379303,
      "grad_norm": 0.08961545675992966,
      "learning_rate": 9.229751819851882e-05,
      "loss": 0.004,
      "step": 1380000
    },
    {
      "epoch": 0.07754344610379303,
      "eval_loss": 0.001295963884331286,
      "eval_runtime": 20.3112,
      "eval_samples_per_second": 4923.393,
      "eval_steps_per_second": 76.953,
      "step": 1380000
    },
    {
      "epoch": 0.07757154155527991,
      "grad_norm": 0.1785600334405899,
      "learning_rate": 9.229470707377375e-05,
      "loss": 0.0039,
      "step": 1380500
    },
    {
      "epoch": 0.0775996370067668,
      "grad_norm": 0.16736558079719543,
      "learning_rate": 9.22918959490287e-05,
      "loss": 0.0043,
      "step": 1381000
    },
    {
      "epoch": 0.07762773245825368,
      "grad_norm": 0.20185229182243347,
      "learning_rate": 9.228908482428362e-05,
      "loss": 0.0045,
      "step": 1381500
    },
    {
      "epoch": 0.07765582790974056,
      "grad_norm": 0.0643620491027832,
      "learning_rate": 9.228627369953856e-05,
      "loss": 0.0045,
      "step": 1382000
    },
    {
      "epoch": 0.07768392336122744,
      "grad_norm": 0.1679830700159073,
      "learning_rate": 9.228346257479349e-05,
      "loss": 0.0045,
      "step": 1382500
    },
    {
      "epoch": 0.07771201881271432,
      "grad_norm": 0.198592409491539,
      "learning_rate": 9.228065145004842e-05,
      "loss": 0.004,
      "step": 1383000
    },
    {
      "epoch": 0.0777401142642012,
      "grad_norm": 0.24709387123584747,
      "learning_rate": 9.227784032530336e-05,
      "loss": 0.0042,
      "step": 1383500
    },
    {
      "epoch": 0.07776820971568808,
      "grad_norm": 0.030975032597780228,
      "learning_rate": 9.227502920055829e-05,
      "loss": 0.0042,
      "step": 1384000
    },
    {
      "epoch": 0.07779630516717496,
      "grad_norm": 0.30649369955062866,
      "learning_rate": 9.227221807581323e-05,
      "loss": 0.0041,
      "step": 1384500
    },
    {
      "epoch": 0.07782440061866185,
      "grad_norm": 0.06345676630735397,
      "learning_rate": 9.226940695106816e-05,
      "loss": 0.0039,
      "step": 1385000
    },
    {
      "epoch": 0.07785249607014873,
      "grad_norm": 0.07127106189727783,
      "learning_rate": 9.22665958263231e-05,
      "loss": 0.0042,
      "step": 1385500
    },
    {
      "epoch": 0.07788059152163561,
      "grad_norm": 0.22902798652648926,
      "learning_rate": 9.226378470157803e-05,
      "loss": 0.0039,
      "step": 1386000
    },
    {
      "epoch": 0.07790868697312249,
      "grad_norm": 0.12581126391887665,
      "learning_rate": 9.226097357683296e-05,
      "loss": 0.0044,
      "step": 1386500
    },
    {
      "epoch": 0.07793678242460937,
      "grad_norm": 0.525110125541687,
      "learning_rate": 9.22581624520879e-05,
      "loss": 0.0045,
      "step": 1387000
    },
    {
      "epoch": 0.07796487787609625,
      "grad_norm": 0.08108743280172348,
      "learning_rate": 9.225535132734283e-05,
      "loss": 0.0044,
      "step": 1387500
    },
    {
      "epoch": 0.07799297332758313,
      "grad_norm": 1.2724944353103638,
      "learning_rate": 9.225254020259777e-05,
      "loss": 0.0037,
      "step": 1388000
    },
    {
      "epoch": 0.07802106877907002,
      "grad_norm": 0.23366683721542358,
      "learning_rate": 9.22497290778527e-05,
      "loss": 0.0042,
      "step": 1388500
    },
    {
      "epoch": 0.0780491642305569,
      "grad_norm": 0.8246022462844849,
      "learning_rate": 9.224691795310763e-05,
      "loss": 0.0037,
      "step": 1389000
    },
    {
      "epoch": 0.07807725968204378,
      "grad_norm": 0.07661687582731247,
      "learning_rate": 9.224410682836257e-05,
      "loss": 0.0042,
      "step": 1389500
    },
    {
      "epoch": 0.07810535513353066,
      "grad_norm": 0.09303580969572067,
      "learning_rate": 9.22412957036175e-05,
      "loss": 0.0039,
      "step": 1390000
    },
    {
      "epoch": 0.07810535513353066,
      "eval_loss": 0.0013198755914345384,
      "eval_runtime": 19.8347,
      "eval_samples_per_second": 5041.679,
      "eval_steps_per_second": 78.801,
      "step": 1390000
    },
    {
      "epoch": 0.07813345058501754,
      "grad_norm": 0.7140307426452637,
      "learning_rate": 9.223848457887244e-05,
      "loss": 0.0043,
      "step": 1390500
    },
    {
      "epoch": 0.07816154603650442,
      "grad_norm": 0.019746577367186546,
      "learning_rate": 9.223567345412737e-05,
      "loss": 0.0041,
      "step": 1391000
    },
    {
      "epoch": 0.0781896414879913,
      "grad_norm": 0.4582226276397705,
      "learning_rate": 9.223286232938229e-05,
      "loss": 0.0042,
      "step": 1391500
    },
    {
      "epoch": 0.07821773693947819,
      "grad_norm": 0.4105529189109802,
      "learning_rate": 9.223005120463724e-05,
      "loss": 0.0047,
      "step": 1392000
    },
    {
      "epoch": 0.07824583239096507,
      "grad_norm": 0.12465637922286987,
      "learning_rate": 9.222724007989217e-05,
      "loss": 0.0041,
      "step": 1392500
    },
    {
      "epoch": 0.07827392784245195,
      "grad_norm": 0.05632847920060158,
      "learning_rate": 9.222442895514711e-05,
      "loss": 0.004,
      "step": 1393000
    },
    {
      "epoch": 0.07830202329393883,
      "grad_norm": 0.03860973194241524,
      "learning_rate": 9.222161783040204e-05,
      "loss": 0.0042,
      "step": 1393500
    },
    {
      "epoch": 0.07833011874542571,
      "grad_norm": 0.22418205440044403,
      "learning_rate": 9.221880670565696e-05,
      "loss": 0.0044,
      "step": 1394000
    },
    {
      "epoch": 0.07835821419691259,
      "grad_norm": 0.28459399938583374,
      "learning_rate": 9.221599558091191e-05,
      "loss": 0.0043,
      "step": 1394500
    },
    {
      "epoch": 0.07838630964839947,
      "grad_norm": 0.26347583532333374,
      "learning_rate": 9.221318445616683e-05,
      "loss": 0.0043,
      "step": 1395000
    },
    {
      "epoch": 0.07841440509988636,
      "grad_norm": 0.5375164151191711,
      "learning_rate": 9.221037333142178e-05,
      "loss": 0.0047,
      "step": 1395500
    },
    {
      "epoch": 0.07844250055137324,
      "grad_norm": 0.19195552170276642,
      "learning_rate": 9.220756220667671e-05,
      "loss": 0.0042,
      "step": 1396000
    },
    {
      "epoch": 0.07847059600286012,
      "grad_norm": 0.06785415858030319,
      "learning_rate": 9.220475108193163e-05,
      "loss": 0.0043,
      "step": 1396500
    },
    {
      "epoch": 0.078498691454347,
      "grad_norm": 0.07572267204523087,
      "learning_rate": 9.220193995718658e-05,
      "loss": 0.0039,
      "step": 1397000
    },
    {
      "epoch": 0.07852678690583388,
      "grad_norm": 0.35619285702705383,
      "learning_rate": 9.21991288324415e-05,
      "loss": 0.0037,
      "step": 1397500
    },
    {
      "epoch": 0.07855488235732076,
      "grad_norm": 0.12033534795045853,
      "learning_rate": 9.219631770769645e-05,
      "loss": 0.0039,
      "step": 1398000
    },
    {
      "epoch": 0.07858297780880764,
      "grad_norm": 0.37893176078796387,
      "learning_rate": 9.219350658295137e-05,
      "loss": 0.0039,
      "step": 1398500
    },
    {
      "epoch": 0.07861107326029453,
      "grad_norm": 0.13193537294864655,
      "learning_rate": 9.21906954582063e-05,
      "loss": 0.0038,
      "step": 1399000
    },
    {
      "epoch": 0.07863916871178141,
      "grad_norm": 0.23120926320552826,
      "learning_rate": 9.218788433346124e-05,
      "loss": 0.004,
      "step": 1399500
    },
    {
      "epoch": 0.07866726416326829,
      "grad_norm": 0.4613368809223175,
      "learning_rate": 9.218507320871617e-05,
      "loss": 0.0045,
      "step": 1400000
    },
    {
      "epoch": 0.07866726416326829,
      "eval_loss": 0.0012710882583633065,
      "eval_runtime": 20.3972,
      "eval_samples_per_second": 4902.634,
      "eval_steps_per_second": 76.628,
      "step": 1400000
    },
    {
      "epoch": 0.07869535961475517,
      "grad_norm": 0.02296152524650097,
      "learning_rate": 9.218226208397112e-05,
      "loss": 0.004,
      "step": 1400500
    },
    {
      "epoch": 0.07872345506624205,
      "grad_norm": 0.16684933006763458,
      "learning_rate": 9.217945095922604e-05,
      "loss": 0.0044,
      "step": 1401000
    },
    {
      "epoch": 0.07875155051772893,
      "grad_norm": 0.04075764864683151,
      "learning_rate": 9.217663983448098e-05,
      "loss": 0.004,
      "step": 1401500
    },
    {
      "epoch": 0.07877964596921581,
      "grad_norm": 0.03481050208210945,
      "learning_rate": 9.217382870973591e-05,
      "loss": 0.0041,
      "step": 1402000
    },
    {
      "epoch": 0.0788077414207027,
      "grad_norm": 0.022946128621697426,
      "learning_rate": 9.217101758499085e-05,
      "loss": 0.0041,
      "step": 1402500
    },
    {
      "epoch": 0.07883583687218958,
      "grad_norm": 0.16406337916851044,
      "learning_rate": 9.216820646024578e-05,
      "loss": 0.0045,
      "step": 1403000
    },
    {
      "epoch": 0.07886393232367646,
      "grad_norm": 0.1513497233390808,
      "learning_rate": 9.216539533550071e-05,
      "loss": 0.0042,
      "step": 1403500
    },
    {
      "epoch": 0.07889202777516334,
      "grad_norm": 0.2133549004793167,
      "learning_rate": 9.216258421075565e-05,
      "loss": 0.0042,
      "step": 1404000
    },
    {
      "epoch": 0.07892012322665022,
      "grad_norm": 0.03403119742870331,
      "learning_rate": 9.215977308601058e-05,
      "loss": 0.0039,
      "step": 1404500
    },
    {
      "epoch": 0.0789482186781371,
      "grad_norm": 0.09242034703493118,
      "learning_rate": 9.215696196126552e-05,
      "loss": 0.0045,
      "step": 1405000
    },
    {
      "epoch": 0.07897631412962398,
      "grad_norm": 0.0901731625199318,
      "learning_rate": 9.215415083652045e-05,
      "loss": 0.0042,
      "step": 1405500
    },
    {
      "epoch": 0.07900440958111087,
      "grad_norm": 0.22685514390468597,
      "learning_rate": 9.215133971177539e-05,
      "loss": 0.0046,
      "step": 1406000
    },
    {
      "epoch": 0.07903250503259775,
      "grad_norm": 0.3586338460445404,
      "learning_rate": 9.214852858703032e-05,
      "loss": 0.0041,
      "step": 1406500
    },
    {
      "epoch": 0.07906060048408463,
      "grad_norm": 0.4380034804344177,
      "learning_rate": 9.214571746228525e-05,
      "loss": 0.0045,
      "step": 1407000
    },
    {
      "epoch": 0.07908869593557151,
      "grad_norm": 0.09290343523025513,
      "learning_rate": 9.214290633754019e-05,
      "loss": 0.0043,
      "step": 1407500
    },
    {
      "epoch": 0.07911679138705839,
      "grad_norm": 0.6220573782920837,
      "learning_rate": 9.214009521279512e-05,
      "loss": 0.0038,
      "step": 1408000
    },
    {
      "epoch": 0.07914488683854527,
      "grad_norm": 0.030052751302719116,
      "learning_rate": 9.213728408805006e-05,
      "loss": 0.0041,
      "step": 1408500
    },
    {
      "epoch": 0.07917298229003215,
      "grad_norm": 0.12996219098567963,
      "learning_rate": 9.213447296330499e-05,
      "loss": 0.0036,
      "step": 1409000
    },
    {
      "epoch": 0.07920107774151904,
      "grad_norm": 0.043059248477220535,
      "learning_rate": 9.213166183855993e-05,
      "loss": 0.0041,
      "step": 1409500
    },
    {
      "epoch": 0.07922917319300592,
      "grad_norm": 0.10851451754570007,
      "learning_rate": 9.212885071381485e-05,
      "loss": 0.0048,
      "step": 1410000
    },
    {
      "epoch": 0.07922917319300592,
      "eval_loss": 0.0012457964476197958,
      "eval_runtime": 19.4064,
      "eval_samples_per_second": 5152.939,
      "eval_steps_per_second": 80.54,
      "step": 1410000
    },
    {
      "epoch": 0.0792572686444928,
      "grad_norm": 0.15548667311668396,
      "learning_rate": 9.21260395890698e-05,
      "loss": 0.0044,
      "step": 1410500
    },
    {
      "epoch": 0.07928536409597968,
      "grad_norm": 0.35481563210487366,
      "learning_rate": 9.212322846432471e-05,
      "loss": 0.0042,
      "step": 1411000
    },
    {
      "epoch": 0.07931345954746656,
      "grad_norm": 0.13528166711330414,
      "learning_rate": 9.212041733957966e-05,
      "loss": 0.0044,
      "step": 1411500
    },
    {
      "epoch": 0.07934155499895344,
      "grad_norm": 0.13466863334178925,
      "learning_rate": 9.21176062148346e-05,
      "loss": 0.0041,
      "step": 1412000
    },
    {
      "epoch": 0.07936965045044032,
      "grad_norm": 0.17942368984222412,
      "learning_rate": 9.211479509008952e-05,
      "loss": 0.0042,
      "step": 1412500
    },
    {
      "epoch": 0.0793977459019272,
      "grad_norm": 0.12437499314546585,
      "learning_rate": 9.211198396534446e-05,
      "loss": 0.0041,
      "step": 1413000
    },
    {
      "epoch": 0.07942584135341409,
      "grad_norm": 0.17672419548034668,
      "learning_rate": 9.210917284059939e-05,
      "loss": 0.0041,
      "step": 1413500
    },
    {
      "epoch": 0.07945393680490097,
      "grad_norm": 0.799381673336029,
      "learning_rate": 9.210636171585433e-05,
      "loss": 0.0042,
      "step": 1414000
    },
    {
      "epoch": 0.07948203225638785,
      "grad_norm": 0.10394112020730972,
      "learning_rate": 9.210355059110925e-05,
      "loss": 0.005,
      "step": 1414500
    },
    {
      "epoch": 0.07951012770787473,
      "grad_norm": 0.2880711555480957,
      "learning_rate": 9.210073946636419e-05,
      "loss": 0.0041,
      "step": 1415000
    },
    {
      "epoch": 0.07953822315936161,
      "grad_norm": 0.1500767320394516,
      "learning_rate": 9.209792834161914e-05,
      "loss": 0.0043,
      "step": 1415500
    },
    {
      "epoch": 0.0795663186108485,
      "grad_norm": 0.10117150843143463,
      "learning_rate": 9.209511721687406e-05,
      "loss": 0.0041,
      "step": 1416000
    },
    {
      "epoch": 0.07959441406233538,
      "grad_norm": 0.6020141839981079,
      "learning_rate": 9.2092306092129e-05,
      "loss": 0.0043,
      "step": 1416500
    },
    {
      "epoch": 0.07962250951382226,
      "grad_norm": 0.3531707525253296,
      "learning_rate": 9.208949496738393e-05,
      "loss": 0.004,
      "step": 1417000
    },
    {
      "epoch": 0.07965060496530914,
      "grad_norm": 0.37772682309150696,
      "learning_rate": 9.208668384263886e-05,
      "loss": 0.0045,
      "step": 1417500
    },
    {
      "epoch": 0.07967870041679602,
      "grad_norm": 0.2830813229084015,
      "learning_rate": 9.20838727178938e-05,
      "loss": 0.0041,
      "step": 1418000
    },
    {
      "epoch": 0.0797067958682829,
      "grad_norm": 0.16185757517814636,
      "learning_rate": 9.208106159314873e-05,
      "loss": 0.0042,
      "step": 1418500
    },
    {
      "epoch": 0.07973489131976978,
      "grad_norm": 0.4225875735282898,
      "learning_rate": 9.207825046840366e-05,
      "loss": 0.0038,
      "step": 1419000
    },
    {
      "epoch": 0.07976298677125666,
      "grad_norm": 0.05669966712594032,
      "learning_rate": 9.20754393436586e-05,
      "loss": 0.0046,
      "step": 1419500
    },
    {
      "epoch": 0.07979108222274355,
      "grad_norm": 0.26977577805519104,
      "learning_rate": 9.207262821891353e-05,
      "loss": 0.0041,
      "step": 1420000
    },
    {
      "epoch": 0.07979108222274355,
      "eval_loss": 0.0011269187089055777,
      "eval_runtime": 20.8391,
      "eval_samples_per_second": 4798.664,
      "eval_steps_per_second": 75.003,
      "step": 1420000
    },
    {
      "epoch": 0.07981917767423043,
      "grad_norm": 0.21038788557052612,
      "learning_rate": 9.206981709416846e-05,
      "loss": 0.0042,
      "step": 1420500
    },
    {
      "epoch": 0.07984727312571731,
      "grad_norm": 0.31332454085350037,
      "learning_rate": 9.20670059694234e-05,
      "loss": 0.0039,
      "step": 1421000
    },
    {
      "epoch": 0.07987536857720419,
      "grad_norm": 0.03425291180610657,
      "learning_rate": 9.206419484467833e-05,
      "loss": 0.0043,
      "step": 1421500
    },
    {
      "epoch": 0.07990346402869107,
      "grad_norm": 0.22482740879058838,
      "learning_rate": 9.206138371993327e-05,
      "loss": 0.0045,
      "step": 1422000
    },
    {
      "epoch": 0.07993155948017795,
      "grad_norm": 0.010739686898887157,
      "learning_rate": 9.20585725951882e-05,
      "loss": 0.0041,
      "step": 1422500
    },
    {
      "epoch": 0.07995965493166483,
      "grad_norm": 0.1151396781206131,
      "learning_rate": 9.205576147044314e-05,
      "loss": 0.0038,
      "step": 1423000
    },
    {
      "epoch": 0.07998775038315172,
      "grad_norm": 0.033245477825403214,
      "learning_rate": 9.205295034569807e-05,
      "loss": 0.004,
      "step": 1423500
    },
    {
      "epoch": 0.0800158458346386,
      "grad_norm": 0.24750298261642456,
      "learning_rate": 9.2050139220953e-05,
      "loss": 0.004,
      "step": 1424000
    },
    {
      "epoch": 0.08004394128612548,
      "grad_norm": 0.10113499313592911,
      "learning_rate": 9.204732809620794e-05,
      "loss": 0.0042,
      "step": 1424500
    },
    {
      "epoch": 0.08007203673761236,
      "grad_norm": 0.3109482526779175,
      "learning_rate": 9.204451697146287e-05,
      "loss": 0.0041,
      "step": 1425000
    },
    {
      "epoch": 0.08010013218909924,
      "grad_norm": 0.47271037101745605,
      "learning_rate": 9.204170584671781e-05,
      "loss": 0.0036,
      "step": 1425500
    },
    {
      "epoch": 0.08012822764058612,
      "grad_norm": 0.035818733274936676,
      "learning_rate": 9.203889472197274e-05,
      "loss": 0.0046,
      "step": 1426000
    },
    {
      "epoch": 0.080156323092073,
      "grad_norm": 0.13728919625282288,
      "learning_rate": 9.203608359722768e-05,
      "loss": 0.0045,
      "step": 1426500
    },
    {
      "epoch": 0.08018441854355988,
      "grad_norm": 0.23352162539958954,
      "learning_rate": 9.203327247248261e-05,
      "loss": 0.004,
      "step": 1427000
    },
    {
      "epoch": 0.08021251399504677,
      "grad_norm": 0.021719062700867653,
      "learning_rate": 9.203046134773754e-05,
      "loss": 0.0047,
      "step": 1427500
    },
    {
      "epoch": 0.08024060944653365,
      "grad_norm": 0.408233106136322,
      "learning_rate": 9.202765022299248e-05,
      "loss": 0.004,
      "step": 1428000
    },
    {
      "epoch": 0.08026870489802053,
      "grad_norm": 0.025676677003502846,
      "learning_rate": 9.202483909824741e-05,
      "loss": 0.0041,
      "step": 1428500
    },
    {
      "epoch": 0.08029680034950741,
      "grad_norm": 0.09649895876646042,
      "learning_rate": 9.202202797350235e-05,
      "loss": 0.004,
      "step": 1429000
    },
    {
      "epoch": 0.08032489580099429,
      "grad_norm": 0.41626131534576416,
      "learning_rate": 9.201921684875727e-05,
      "loss": 0.0039,
      "step": 1429500
    },
    {
      "epoch": 0.08035299125248117,
      "grad_norm": 0.28954750299453735,
      "learning_rate": 9.201640572401222e-05,
      "loss": 0.004,
      "step": 1430000
    },
    {
      "epoch": 0.08035299125248117,
      "eval_loss": 0.00120051228441298,
      "eval_runtime": 19.7235,
      "eval_samples_per_second": 5070.083,
      "eval_steps_per_second": 79.245,
      "step": 1430000
    },
    {
      "epoch": 0.08038108670396805,
      "grad_norm": 0.06743858009576797,
      "learning_rate": 9.201359459926714e-05,
      "loss": 0.004,
      "step": 1430500
    },
    {
      "epoch": 0.08040918215545494,
      "grad_norm": 0.09082018584012985,
      "learning_rate": 9.201078347452208e-05,
      "loss": 0.0045,
      "step": 1431000
    },
    {
      "epoch": 0.08043727760694182,
      "grad_norm": 0.026170998811721802,
      "learning_rate": 9.200797234977702e-05,
      "loss": 0.0042,
      "step": 1431500
    },
    {
      "epoch": 0.0804653730584287,
      "grad_norm": 0.30722203850746155,
      "learning_rate": 9.200516122503194e-05,
      "loss": 0.0043,
      "step": 1432000
    },
    {
      "epoch": 0.08049346850991558,
      "grad_norm": 0.40923914313316345,
      "learning_rate": 9.200235010028689e-05,
      "loss": 0.0041,
      "step": 1432500
    },
    {
      "epoch": 0.08052156396140246,
      "grad_norm": 0.4051154851913452,
      "learning_rate": 9.199953897554181e-05,
      "loss": 0.0041,
      "step": 1433000
    },
    {
      "epoch": 0.08054965941288934,
      "grad_norm": 0.1443418562412262,
      "learning_rate": 9.199672785079676e-05,
      "loss": 0.0042,
      "step": 1433500
    },
    {
      "epoch": 0.08057775486437624,
      "grad_norm": 0.2547617554664612,
      "learning_rate": 9.199391672605168e-05,
      "loss": 0.0041,
      "step": 1434000
    },
    {
      "epoch": 0.08060585031586312,
      "grad_norm": 0.9928321242332458,
      "learning_rate": 9.199110560130661e-05,
      "loss": 0.0042,
      "step": 1434500
    },
    {
      "epoch": 0.08063394576735,
      "grad_norm": 0.6008008718490601,
      "learning_rate": 9.198829447656156e-05,
      "loss": 0.0042,
      "step": 1435000
    },
    {
      "epoch": 0.08066204121883688,
      "grad_norm": 0.20579370856285095,
      "learning_rate": 9.198548335181648e-05,
      "loss": 0.0038,
      "step": 1435500
    },
    {
      "epoch": 0.08069013667032376,
      "grad_norm": 0.47116121649742126,
      "learning_rate": 9.198267222707143e-05,
      "loss": 0.0041,
      "step": 1436000
    },
    {
      "epoch": 0.08071823212181065,
      "grad_norm": 0.3135811686515808,
      "learning_rate": 9.197986110232635e-05,
      "loss": 0.0042,
      "step": 1436500
    },
    {
      "epoch": 0.08074632757329753,
      "grad_norm": 0.19292953610420227,
      "learning_rate": 9.197704997758128e-05,
      "loss": 0.0038,
      "step": 1437000
    },
    {
      "epoch": 0.08077442302478441,
      "grad_norm": 0.4265933930873871,
      "learning_rate": 9.197423885283622e-05,
      "loss": 0.004,
      "step": 1437500
    },
    {
      "epoch": 0.08080251847627129,
      "grad_norm": 0.062224868685007095,
      "learning_rate": 9.197142772809115e-05,
      "loss": 0.0042,
      "step": 1438000
    },
    {
      "epoch": 0.08083061392775817,
      "grad_norm": 0.02693498320877552,
      "learning_rate": 9.19686166033461e-05,
      "loss": 0.0039,
      "step": 1438500
    },
    {
      "epoch": 0.08085870937924505,
      "grad_norm": 0.24125809967517853,
      "learning_rate": 9.196580547860102e-05,
      "loss": 0.0044,
      "step": 1439000
    },
    {
      "epoch": 0.08088680483073193,
      "grad_norm": 0.14504653215408325,
      "learning_rate": 9.196299435385595e-05,
      "loss": 0.0043,
      "step": 1439500
    },
    {
      "epoch": 0.08091490028221882,
      "grad_norm": 0.26858916878700256,
      "learning_rate": 9.196018322911089e-05,
      "loss": 0.0042,
      "step": 1440000
    },
    {
      "epoch": 0.08091490028221882,
      "eval_loss": 0.001159794395789504,
      "eval_runtime": 19.4448,
      "eval_samples_per_second": 5142.763,
      "eval_steps_per_second": 80.381,
      "step": 1440000
    },
    {
      "epoch": 0.0809429957337057,
      "grad_norm": 0.10074281692504883,
      "learning_rate": 9.195737210436582e-05,
      "loss": 0.0041,
      "step": 1440500
    },
    {
      "epoch": 0.08097109118519258,
      "grad_norm": 0.4048595130443573,
      "learning_rate": 9.195456097962076e-05,
      "loss": 0.0041,
      "step": 1441000
    },
    {
      "epoch": 0.08099918663667946,
      "grad_norm": 0.025819888338446617,
      "learning_rate": 9.195174985487569e-05,
      "loss": 0.0042,
      "step": 1441500
    },
    {
      "epoch": 0.08102728208816634,
      "grad_norm": 0.03663138300180435,
      "learning_rate": 9.194893873013062e-05,
      "loss": 0.0039,
      "step": 1442000
    },
    {
      "epoch": 0.08105537753965322,
      "grad_norm": 0.17866548895835876,
      "learning_rate": 9.194612760538556e-05,
      "loss": 0.0042,
      "step": 1442500
    },
    {
      "epoch": 0.0810834729911401,
      "grad_norm": 0.17771391570568085,
      "learning_rate": 9.194331648064049e-05,
      "loss": 0.0039,
      "step": 1443000
    },
    {
      "epoch": 0.08111156844262699,
      "grad_norm": 0.11105639487504959,
      "learning_rate": 9.194050535589543e-05,
      "loss": 0.004,
      "step": 1443500
    },
    {
      "epoch": 0.08113966389411387,
      "grad_norm": 0.15811681747436523,
      "learning_rate": 9.193769423115036e-05,
      "loss": 0.0044,
      "step": 1444000
    },
    {
      "epoch": 0.08116775934560075,
      "grad_norm": 0.10743281245231628,
      "learning_rate": 9.19348831064053e-05,
      "loss": 0.0041,
      "step": 1444500
    },
    {
      "epoch": 0.08119585479708763,
      "grad_norm": 0.11302339285612106,
      "learning_rate": 9.193207198166023e-05,
      "loss": 0.004,
      "step": 1445000
    },
    {
      "epoch": 0.08122395024857451,
      "grad_norm": 0.21773068606853485,
      "learning_rate": 9.192926085691515e-05,
      "loss": 0.0041,
      "step": 1445500
    },
    {
      "epoch": 0.08125204570006139,
      "grad_norm": 0.22822266817092896,
      "learning_rate": 9.19264497321701e-05,
      "loss": 0.0045,
      "step": 1446000
    },
    {
      "epoch": 0.08128014115154827,
      "grad_norm": 0.1675204336643219,
      "learning_rate": 9.192363860742503e-05,
      "loss": 0.0038,
      "step": 1446500
    },
    {
      "epoch": 0.08130823660303516,
      "grad_norm": 0.1458785980939865,
      "learning_rate": 9.192082748267997e-05,
      "loss": 0.004,
      "step": 1447000
    },
    {
      "epoch": 0.08133633205452204,
      "grad_norm": 0.2954089343547821,
      "learning_rate": 9.19180163579349e-05,
      "loss": 0.0041,
      "step": 1447500
    },
    {
      "epoch": 0.08136442750600892,
      "grad_norm": 0.031091010197997093,
      "learning_rate": 9.191520523318982e-05,
      "loss": 0.0041,
      "step": 1448000
    },
    {
      "epoch": 0.0813925229574958,
      "grad_norm": 0.08620013296604156,
      "learning_rate": 9.191239410844477e-05,
      "loss": 0.0045,
      "step": 1448500
    },
    {
      "epoch": 0.08142061840898268,
      "grad_norm": 0.19650590419769287,
      "learning_rate": 9.190958298369969e-05,
      "loss": 0.0041,
      "step": 1449000
    },
    {
      "epoch": 0.08144871386046956,
      "grad_norm": 0.08163172751665115,
      "learning_rate": 9.190677185895464e-05,
      "loss": 0.004,
      "step": 1449500
    },
    {
      "epoch": 0.08147680931195644,
      "grad_norm": 0.727287769317627,
      "learning_rate": 9.190396073420956e-05,
      "loss": 0.0044,
      "step": 1450000
    },
    {
      "epoch": 0.08147680931195644,
      "eval_loss": 0.0012401314452290535,
      "eval_runtime": 20.2759,
      "eval_samples_per_second": 4931.97,
      "eval_steps_per_second": 77.087,
      "step": 1450000
    },
    {
      "epoch": 0.08150490476344333,
      "grad_norm": 0.3009626269340515,
      "learning_rate": 9.190114960946449e-05,
      "loss": 0.004,
      "step": 1450500
    },
    {
      "epoch": 0.0815330002149302,
      "grad_norm": 0.02712097577750683,
      "learning_rate": 9.189833848471944e-05,
      "loss": 0.0035,
      "step": 1451000
    },
    {
      "epoch": 0.08156109566641709,
      "grad_norm": 0.4081106185913086,
      "learning_rate": 9.189552735997436e-05,
      "loss": 0.004,
      "step": 1451500
    },
    {
      "epoch": 0.08158919111790397,
      "grad_norm": 0.5825388431549072,
      "learning_rate": 9.189271623522931e-05,
      "loss": 0.0046,
      "step": 1452000
    },
    {
      "epoch": 0.08161728656939085,
      "grad_norm": 0.270636647939682,
      "learning_rate": 9.188990511048423e-05,
      "loss": 0.004,
      "step": 1452500
    },
    {
      "epoch": 0.08164538202087773,
      "grad_norm": 0.07234751433134079,
      "learning_rate": 9.188709398573916e-05,
      "loss": 0.0044,
      "step": 1453000
    },
    {
      "epoch": 0.08167347747236461,
      "grad_norm": 0.2661117613315582,
      "learning_rate": 9.18842828609941e-05,
      "loss": 0.004,
      "step": 1453500
    },
    {
      "epoch": 0.0817015729238515,
      "grad_norm": 0.025594083592295647,
      "learning_rate": 9.188147173624903e-05,
      "loss": 0.0041,
      "step": 1454000
    },
    {
      "epoch": 0.08172966837533838,
      "grad_norm": 0.03984348103404045,
      "learning_rate": 9.187866061150398e-05,
      "loss": 0.004,
      "step": 1454500
    },
    {
      "epoch": 0.08175776382682526,
      "grad_norm": 0.15902075171470642,
      "learning_rate": 9.18758494867589e-05,
      "loss": 0.004,
      "step": 1455000
    },
    {
      "epoch": 0.08178585927831214,
      "grad_norm": 0.17976440489292145,
      "learning_rate": 9.187303836201383e-05,
      "loss": 0.0045,
      "step": 1455500
    },
    {
      "epoch": 0.08181395472979902,
      "grad_norm": 0.01345999538898468,
      "learning_rate": 9.187022723726877e-05,
      "loss": 0.0046,
      "step": 1456000
    },
    {
      "epoch": 0.0818420501812859,
      "grad_norm": 0.11592357605695724,
      "learning_rate": 9.18674161125237e-05,
      "loss": 0.0045,
      "step": 1456500
    },
    {
      "epoch": 0.08187014563277278,
      "grad_norm": 0.06743894517421722,
      "learning_rate": 9.186460498777864e-05,
      "loss": 0.0039,
      "step": 1457000
    },
    {
      "epoch": 0.08189824108425967,
      "grad_norm": 0.11222032457590103,
      "learning_rate": 9.186179386303357e-05,
      "loss": 0.0039,
      "step": 1457500
    },
    {
      "epoch": 0.08192633653574655,
      "grad_norm": 0.361887127161026,
      "learning_rate": 9.18589827382885e-05,
      "loss": 0.0043,
      "step": 1458000
    },
    {
      "epoch": 0.08195443198723343,
      "grad_norm": 0.33998143672943115,
      "learning_rate": 9.185617161354344e-05,
      "loss": 0.0038,
      "step": 1458500
    },
    {
      "epoch": 0.08198252743872031,
      "grad_norm": 0.4856203496456146,
      "learning_rate": 9.185336048879837e-05,
      "loss": 0.0042,
      "step": 1459000
    },
    {
      "epoch": 0.08201062289020719,
      "grad_norm": 0.18353062868118286,
      "learning_rate": 9.185054936405331e-05,
      "loss": 0.004,
      "step": 1459500
    },
    {
      "epoch": 0.08203871834169407,
      "grad_norm": 0.38694021105766296,
      "learning_rate": 9.184773823930824e-05,
      "loss": 0.0043,
      "step": 1460000
    },
    {
      "epoch": 0.08203871834169407,
      "eval_loss": 0.0012400249252095819,
      "eval_runtime": 20.5393,
      "eval_samples_per_second": 4868.719,
      "eval_steps_per_second": 76.098,
      "step": 1460000
    },
    {
      "epoch": 0.08206681379318095,
      "grad_norm": 0.35142311453819275,
      "learning_rate": 9.184492711456318e-05,
      "loss": 0.0041,
      "step": 1460500
    },
    {
      "epoch": 0.08209490924466784,
      "grad_norm": 1.1987403631210327,
      "learning_rate": 9.184211598981811e-05,
      "loss": 0.0045,
      "step": 1461000
    },
    {
      "epoch": 0.08212300469615472,
      "grad_norm": 0.06671493500471115,
      "learning_rate": 9.183930486507305e-05,
      "loss": 0.0042,
      "step": 1461500
    },
    {
      "epoch": 0.0821511001476416,
      "grad_norm": 0.3790663182735443,
      "learning_rate": 9.183649374032798e-05,
      "loss": 0.0046,
      "step": 1462000
    },
    {
      "epoch": 0.08217919559912848,
      "grad_norm": 0.2666700780391693,
      "learning_rate": 9.183368261558291e-05,
      "loss": 0.0041,
      "step": 1462500
    },
    {
      "epoch": 0.08220729105061536,
      "grad_norm": 0.20672468841075897,
      "learning_rate": 9.183087149083785e-05,
      "loss": 0.0043,
      "step": 1463000
    },
    {
      "epoch": 0.08223538650210224,
      "grad_norm": 0.01628264971077442,
      "learning_rate": 9.182806036609278e-05,
      "loss": 0.004,
      "step": 1463500
    },
    {
      "epoch": 0.08226348195358912,
      "grad_norm": 0.1744951754808426,
      "learning_rate": 9.182524924134772e-05,
      "loss": 0.0041,
      "step": 1464000
    },
    {
      "epoch": 0.082291577405076,
      "grad_norm": 0.01839599944651127,
      "learning_rate": 9.182243811660265e-05,
      "loss": 0.0043,
      "step": 1464500
    },
    {
      "epoch": 0.08231967285656289,
      "grad_norm": 0.1708553433418274,
      "learning_rate": 9.181962699185757e-05,
      "loss": 0.0042,
      "step": 1465000
    },
    {
      "epoch": 0.08234776830804977,
      "grad_norm": 0.04382532089948654,
      "learning_rate": 9.181681586711252e-05,
      "loss": 0.0043,
      "step": 1465500
    },
    {
      "epoch": 0.08237586375953665,
      "grad_norm": 0.18954704701900482,
      "learning_rate": 9.181400474236745e-05,
      "loss": 0.0041,
      "step": 1466000
    },
    {
      "epoch": 0.08240395921102353,
      "grad_norm": 0.21931909024715424,
      "learning_rate": 9.181119361762239e-05,
      "loss": 0.004,
      "step": 1466500
    },
    {
      "epoch": 0.08243205466251041,
      "grad_norm": 0.3176397383213043,
      "learning_rate": 9.180838249287732e-05,
      "loss": 0.004,
      "step": 1467000
    },
    {
      "epoch": 0.0824601501139973,
      "grad_norm": 0.0816333070397377,
      "learning_rate": 9.180557136813224e-05,
      "loss": 0.0042,
      "step": 1467500
    },
    {
      "epoch": 0.08248824556548418,
      "grad_norm": 0.2584221661090851,
      "learning_rate": 9.180276024338719e-05,
      "loss": 0.0043,
      "step": 1468000
    },
    {
      "epoch": 0.08251634101697106,
      "grad_norm": 0.28182077407836914,
      "learning_rate": 9.179994911864211e-05,
      "loss": 0.0042,
      "step": 1468500
    },
    {
      "epoch": 0.08254443646845794,
      "grad_norm": 0.25988900661468506,
      "learning_rate": 9.179713799389706e-05,
      "loss": 0.0038,
      "step": 1469000
    },
    {
      "epoch": 0.08257253191994482,
      "grad_norm": 0.4054681062698364,
      "learning_rate": 9.1794326869152e-05,
      "loss": 0.0041,
      "step": 1469500
    },
    {
      "epoch": 0.0826006273714317,
      "grad_norm": 0.1390819549560547,
      "learning_rate": 9.179151574440691e-05,
      "loss": 0.0041,
      "step": 1470000
    },
    {
      "epoch": 0.0826006273714317,
      "eval_loss": 0.00148544751573354,
      "eval_runtime": 19.6961,
      "eval_samples_per_second": 5077.14,
      "eval_steps_per_second": 79.356,
      "step": 1470000
    },
    {
      "epoch": 0.08262872282291858,
      "grad_norm": 0.17673426866531372,
      "learning_rate": 9.178870461966186e-05,
      "loss": 0.0039,
      "step": 1470500
    },
    {
      "epoch": 0.08265681827440546,
      "grad_norm": 0.2798915207386017,
      "learning_rate": 9.178589349491678e-05,
      "loss": 0.004,
      "step": 1471000
    },
    {
      "epoch": 0.08268491372589235,
      "grad_norm": 0.16656213998794556,
      "learning_rate": 9.178308237017173e-05,
      "loss": 0.0039,
      "step": 1471500
    },
    {
      "epoch": 0.08271300917737923,
      "grad_norm": 0.2748488485813141,
      "learning_rate": 9.178027124542665e-05,
      "loss": 0.0041,
      "step": 1472000
    },
    {
      "epoch": 0.08274110462886611,
      "grad_norm": 0.4493762254714966,
      "learning_rate": 9.177746012068159e-05,
      "loss": 0.0046,
      "step": 1472500
    },
    {
      "epoch": 0.08276920008035299,
      "grad_norm": 0.3574664890766144,
      "learning_rate": 9.177464899593652e-05,
      "loss": 0.0045,
      "step": 1473000
    },
    {
      "epoch": 0.08279729553183987,
      "grad_norm": 0.03599251061677933,
      "learning_rate": 9.177183787119145e-05,
      "loss": 0.0039,
      "step": 1473500
    },
    {
      "epoch": 0.08282539098332675,
      "grad_norm": 0.38557589054107666,
      "learning_rate": 9.17690267464464e-05,
      "loss": 0.0039,
      "step": 1474000
    },
    {
      "epoch": 0.08285348643481363,
      "grad_norm": 0.01950492523610592,
      "learning_rate": 9.176621562170132e-05,
      "loss": 0.0045,
      "step": 1474500
    },
    {
      "epoch": 0.08288158188630051,
      "grad_norm": 0.41930297017097473,
      "learning_rate": 9.176340449695626e-05,
      "loss": 0.0042,
      "step": 1475000
    },
    {
      "epoch": 0.0829096773377874,
      "grad_norm": 0.08449012041091919,
      "learning_rate": 9.176059337221119e-05,
      "loss": 0.0037,
      "step": 1475500
    },
    {
      "epoch": 0.08293777278927428,
      "grad_norm": 0.08296201378107071,
      "learning_rate": 9.175778224746613e-05,
      "loss": 0.0041,
      "step": 1476000
    },
    {
      "epoch": 0.08296586824076116,
      "grad_norm": 0.04037023335695267,
      "learning_rate": 9.175497112272106e-05,
      "loss": 0.0042,
      "step": 1476500
    },
    {
      "epoch": 0.08299396369224804,
      "grad_norm": 0.12253770232200623,
      "learning_rate": 9.1752159997976e-05,
      "loss": 0.0038,
      "step": 1477000
    },
    {
      "epoch": 0.08302205914373492,
      "grad_norm": 0.08636791259050369,
      "learning_rate": 9.174934887323093e-05,
      "loss": 0.0044,
      "step": 1477500
    },
    {
      "epoch": 0.0830501545952218,
      "grad_norm": 0.49697890877723694,
      "learning_rate": 9.174653774848586e-05,
      "loss": 0.0043,
      "step": 1478000
    },
    {
      "epoch": 0.08307825004670868,
      "grad_norm": 0.10252349078655243,
      "learning_rate": 9.17437266237408e-05,
      "loss": 0.0039,
      "step": 1478500
    },
    {
      "epoch": 0.08310634549819557,
      "grad_norm": 0.29127180576324463,
      "learning_rate": 9.174091549899573e-05,
      "loss": 0.0043,
      "step": 1479000
    },
    {
      "epoch": 0.08313444094968245,
      "grad_norm": 0.15303027629852295,
      "learning_rate": 9.173810437425067e-05,
      "loss": 0.0041,
      "step": 1479500
    },
    {
      "epoch": 0.08316253640116933,
      "grad_norm": 0.2880306541919708,
      "learning_rate": 9.17352932495056e-05,
      "loss": 0.004,
      "step": 1480000
    },
    {
      "epoch": 0.08316253640116933,
      "eval_loss": 0.0011394418543204665,
      "eval_runtime": 20.6927,
      "eval_samples_per_second": 4832.627,
      "eval_steps_per_second": 75.534,
      "step": 1480000
    },
    {
      "epoch": 0.08319063185265621,
      "grad_norm": 0.07367059588432312,
      "learning_rate": 9.173248212476053e-05,
      "loss": 0.0044,
      "step": 1480500
    },
    {
      "epoch": 0.08321872730414309,
      "grad_norm": 0.14331021904945374,
      "learning_rate": 9.172967100001545e-05,
      "loss": 0.0044,
      "step": 1481000
    },
    {
      "epoch": 0.08324682275562997,
      "grad_norm": 0.11787784844636917,
      "learning_rate": 9.17268598752704e-05,
      "loss": 0.0043,
      "step": 1481500
    },
    {
      "epoch": 0.08327491820711685,
      "grad_norm": 0.3364868462085724,
      "learning_rate": 9.172404875052534e-05,
      "loss": 0.0039,
      "step": 1482000
    },
    {
      "epoch": 0.08330301365860374,
      "grad_norm": 0.1300998032093048,
      "learning_rate": 9.172123762578027e-05,
      "loss": 0.004,
      "step": 1482500
    },
    {
      "epoch": 0.08333110911009062,
      "grad_norm": 0.6931967735290527,
      "learning_rate": 9.17184265010352e-05,
      "loss": 0.0042,
      "step": 1483000
    },
    {
      "epoch": 0.0833592045615775,
      "grad_norm": 0.03407838195562363,
      "learning_rate": 9.171561537629013e-05,
      "loss": 0.0043,
      "step": 1483500
    },
    {
      "epoch": 0.08338730001306438,
      "grad_norm": 0.021838409826159477,
      "learning_rate": 9.171280425154507e-05,
      "loss": 0.0039,
      "step": 1484000
    },
    {
      "epoch": 0.08341539546455126,
      "grad_norm": 0.20012974739074707,
      "learning_rate": 9.17099931268e-05,
      "loss": 0.0039,
      "step": 1484500
    },
    {
      "epoch": 0.08344349091603814,
      "grad_norm": 1.1531915664672852,
      "learning_rate": 9.170718200205494e-05,
      "loss": 0.0044,
      "step": 1485000
    },
    {
      "epoch": 0.08347158636752502,
      "grad_norm": 0.5067146420478821,
      "learning_rate": 9.170437087730988e-05,
      "loss": 0.0036,
      "step": 1485500
    },
    {
      "epoch": 0.0834996818190119,
      "grad_norm": 0.028588980436325073,
      "learning_rate": 9.17015597525648e-05,
      "loss": 0.0042,
      "step": 1486000
    },
    {
      "epoch": 0.08352777727049879,
      "grad_norm": 0.3890509009361267,
      "learning_rate": 9.169874862781974e-05,
      "loss": 0.0042,
      "step": 1486500
    },
    {
      "epoch": 0.08355587272198567,
      "grad_norm": 0.4711430072784424,
      "learning_rate": 9.169593750307467e-05,
      "loss": 0.0043,
      "step": 1487000
    },
    {
      "epoch": 0.08358396817347255,
      "grad_norm": 0.07397280633449554,
      "learning_rate": 9.169312637832961e-05,
      "loss": 0.0037,
      "step": 1487500
    },
    {
      "epoch": 0.08361206362495943,
      "grad_norm": 0.019973358139395714,
      "learning_rate": 9.169031525358453e-05,
      "loss": 0.0042,
      "step": 1488000
    },
    {
      "epoch": 0.08364015907644631,
      "grad_norm": 0.44058117270469666,
      "learning_rate": 9.168750412883947e-05,
      "loss": 0.0039,
      "step": 1488500
    },
    {
      "epoch": 0.0836682545279332,
      "grad_norm": 0.18478438258171082,
      "learning_rate": 9.168469300409442e-05,
      "loss": 0.0043,
      "step": 1489000
    },
    {
      "epoch": 0.08369634997942008,
      "grad_norm": 0.0997297391295433,
      "learning_rate": 9.168188187934934e-05,
      "loss": 0.004,
      "step": 1489500
    },
    {
      "epoch": 0.08372444543090696,
      "grad_norm": 0.4163980782032013,
      "learning_rate": 9.167907075460428e-05,
      "loss": 0.0042,
      "step": 1490000
    },
    {
      "epoch": 0.08372444543090696,
      "eval_loss": 0.001071937964297831,
      "eval_runtime": 20.691,
      "eval_samples_per_second": 4833.017,
      "eval_steps_per_second": 75.54,
      "step": 1490000
    },
    {
      "epoch": 0.08375254088239384,
      "grad_norm": 0.2825066149234772,
      "learning_rate": 9.16762596298592e-05,
      "loss": 0.0048,
      "step": 1490500
    },
    {
      "epoch": 0.08378063633388072,
      "grad_norm": 0.1601543426513672,
      "learning_rate": 9.167344850511414e-05,
      "loss": 0.004,
      "step": 1491000
    },
    {
      "epoch": 0.0838087317853676,
      "grad_norm": 0.5199728012084961,
      "learning_rate": 9.167063738036907e-05,
      "loss": 0.0035,
      "step": 1491500
    },
    {
      "epoch": 0.08383682723685448,
      "grad_norm": 0.27034151554107666,
      "learning_rate": 9.166782625562401e-05,
      "loss": 0.0041,
      "step": 1492000
    },
    {
      "epoch": 0.08386492268834136,
      "grad_norm": 0.575320839881897,
      "learning_rate": 9.166501513087894e-05,
      "loss": 0.0038,
      "step": 1492500
    },
    {
      "epoch": 0.08389301813982825,
      "grad_norm": 0.07388018816709518,
      "learning_rate": 9.166220400613388e-05,
      "loss": 0.0044,
      "step": 1493000
    },
    {
      "epoch": 0.08392111359131513,
      "grad_norm": 0.07159138470888138,
      "learning_rate": 9.165939288138881e-05,
      "loss": 0.0041,
      "step": 1493500
    },
    {
      "epoch": 0.08394920904280201,
      "grad_norm": 0.2772182524204254,
      "learning_rate": 9.165658175664374e-05,
      "loss": 0.0049,
      "step": 1494000
    },
    {
      "epoch": 0.08397730449428889,
      "grad_norm": 0.3131168484687805,
      "learning_rate": 9.165377063189868e-05,
      "loss": 0.0041,
      "step": 1494500
    },
    {
      "epoch": 0.08400539994577579,
      "grad_norm": 0.44807684421539307,
      "learning_rate": 9.165095950715361e-05,
      "loss": 0.0045,
      "step": 1495000
    },
    {
      "epoch": 0.08403349539726267,
      "grad_norm": 0.19870691001415253,
      "learning_rate": 9.164814838240855e-05,
      "loss": 0.0042,
      "step": 1495500
    },
    {
      "epoch": 0.08406159084874955,
      "grad_norm": 0.764259397983551,
      "learning_rate": 9.164533725766348e-05,
      "loss": 0.0039,
      "step": 1496000
    },
    {
      "epoch": 0.08408968630023643,
      "grad_norm": 0.6037519574165344,
      "learning_rate": 9.164252613291842e-05,
      "loss": 0.004,
      "step": 1496500
    },
    {
      "epoch": 0.08411778175172331,
      "grad_norm": 0.021422313526272774,
      "learning_rate": 9.163971500817335e-05,
      "loss": 0.004,
      "step": 1497000
    },
    {
      "epoch": 0.08414587720321019,
      "grad_norm": 0.05310460552573204,
      "learning_rate": 9.163690388342828e-05,
      "loss": 0.0039,
      "step": 1497500
    },
    {
      "epoch": 0.08417397265469707,
      "grad_norm": 0.16313718259334564,
      "learning_rate": 9.163409275868322e-05,
      "loss": 0.0043,
      "step": 1498000
    },
    {
      "epoch": 0.08420206810618396,
      "grad_norm": 0.05152420327067375,
      "learning_rate": 9.163128163393815e-05,
      "loss": 0.004,
      "step": 1498500
    },
    {
      "epoch": 0.08423016355767084,
      "grad_norm": 0.11703494936227798,
      "learning_rate": 9.162847050919309e-05,
      "loss": 0.0041,
      "step": 1499000
    },
    {
      "epoch": 0.08425825900915772,
      "grad_norm": 0.47162342071533203,
      "learning_rate": 9.162565938444802e-05,
      "loss": 0.0038,
      "step": 1499500
    },
    {
      "epoch": 0.0842863544606446,
      "grad_norm": 0.01116473600268364,
      "learning_rate": 9.162284825970296e-05,
      "loss": 0.004,
      "step": 1500000
    },
    {
      "epoch": 0.0842863544606446,
      "eval_loss": 0.001041233423165977,
      "eval_runtime": 20.1094,
      "eval_samples_per_second": 4972.797,
      "eval_steps_per_second": 77.725,
      "step": 1500000
    },
    {
      "epoch": 0.08431444991213148,
      "grad_norm": 0.654288113117218,
      "learning_rate": 9.162003713495788e-05,
      "loss": 0.0037,
      "step": 1500500
    },
    {
      "epoch": 0.08434254536361836,
      "grad_norm": 0.029378890991210938,
      "learning_rate": 9.161722601021282e-05,
      "loss": 0.0042,
      "step": 1501000
    },
    {
      "epoch": 0.08437064081510524,
      "grad_norm": 0.2815649211406708,
      "learning_rate": 9.161441488546776e-05,
      "loss": 0.0036,
      "step": 1501500
    },
    {
      "epoch": 0.08439873626659213,
      "grad_norm": 0.12947623431682587,
      "learning_rate": 9.161160376072269e-05,
      "loss": 0.0044,
      "step": 1502000
    },
    {
      "epoch": 0.084426831718079,
      "grad_norm": 0.4363923966884613,
      "learning_rate": 9.160879263597763e-05,
      "loss": 0.0039,
      "step": 1502500
    },
    {
      "epoch": 0.08445492716956589,
      "grad_norm": 0.49910175800323486,
      "learning_rate": 9.160598151123255e-05,
      "loss": 0.0043,
      "step": 1503000
    },
    {
      "epoch": 0.08448302262105277,
      "grad_norm": 0.08611723780632019,
      "learning_rate": 9.16031703864875e-05,
      "loss": 0.0038,
      "step": 1503500
    },
    {
      "epoch": 0.08451111807253965,
      "grad_norm": 0.035397980362176895,
      "learning_rate": 9.160035926174242e-05,
      "loss": 0.0036,
      "step": 1504000
    },
    {
      "epoch": 0.08453921352402653,
      "grad_norm": 0.05360938608646393,
      "learning_rate": 9.159754813699736e-05,
      "loss": 0.0039,
      "step": 1504500
    },
    {
      "epoch": 0.08456730897551341,
      "grad_norm": 0.17195382714271545,
      "learning_rate": 9.15947370122523e-05,
      "loss": 0.0041,
      "step": 1505000
    },
    {
      "epoch": 0.0845954044270003,
      "grad_norm": 0.08522327244281769,
      "learning_rate": 9.159192588750722e-05,
      "loss": 0.0041,
      "step": 1505500
    },
    {
      "epoch": 0.08462349987848718,
      "grad_norm": 0.30863696336746216,
      "learning_rate": 9.158911476276217e-05,
      "loss": 0.0044,
      "step": 1506000
    },
    {
      "epoch": 0.08465159532997406,
      "grad_norm": 0.2304120808839798,
      "learning_rate": 9.158630363801709e-05,
      "loss": 0.0042,
      "step": 1506500
    },
    {
      "epoch": 0.08467969078146094,
      "grad_norm": 0.04694037884473801,
      "learning_rate": 9.158349251327203e-05,
      "loss": 0.0043,
      "step": 1507000
    },
    {
      "epoch": 0.08470778623294782,
      "grad_norm": 0.04171455278992653,
      "learning_rate": 9.158068138852696e-05,
      "loss": 0.0042,
      "step": 1507500
    },
    {
      "epoch": 0.0847358816844347,
      "grad_norm": 0.0796101987361908,
      "learning_rate": 9.157787026378189e-05,
      "loss": 0.0039,
      "step": 1508000
    },
    {
      "epoch": 0.08476397713592158,
      "grad_norm": 0.1535109281539917,
      "learning_rate": 9.157505913903684e-05,
      "loss": 0.0042,
      "step": 1508500
    },
    {
      "epoch": 0.08479207258740847,
      "grad_norm": 0.07768414914608002,
      "learning_rate": 9.157224801429176e-05,
      "loss": 0.004,
      "step": 1509000
    },
    {
      "epoch": 0.08482016803889535,
      "grad_norm": 0.07088643312454224,
      "learning_rate": 9.15694368895467e-05,
      "loss": 0.0039,
      "step": 1509500
    },
    {
      "epoch": 0.08484826349038223,
      "grad_norm": 0.10946362465620041,
      "learning_rate": 9.156662576480163e-05,
      "loss": 0.0042,
      "step": 1510000
    },
    {
      "epoch": 0.08484826349038223,
      "eval_loss": 0.0011943681165575981,
      "eval_runtime": 19.6988,
      "eval_samples_per_second": 5076.446,
      "eval_steps_per_second": 79.345,
      "step": 1510000
    },
    {
      "epoch": 0.08487635894186911,
      "grad_norm": 0.15603414177894592,
      "learning_rate": 9.156381464005656e-05,
      "loss": 0.0041,
      "step": 1510500
    },
    {
      "epoch": 0.08490445439335599,
      "grad_norm": 0.28107210993766785,
      "learning_rate": 9.15610035153115e-05,
      "loss": 0.0038,
      "step": 1511000
    },
    {
      "epoch": 0.08493254984484287,
      "grad_norm": 0.16462920606136322,
      "learning_rate": 9.155819239056643e-05,
      "loss": 0.0044,
      "step": 1511500
    },
    {
      "epoch": 0.08496064529632975,
      "grad_norm": 0.12683263421058655,
      "learning_rate": 9.155538126582136e-05,
      "loss": 0.0037,
      "step": 1512000
    },
    {
      "epoch": 0.08498874074781664,
      "grad_norm": 0.34239816665649414,
      "learning_rate": 9.15525701410763e-05,
      "loss": 0.0042,
      "step": 1512500
    },
    {
      "epoch": 0.08501683619930352,
      "grad_norm": 0.43242666125297546,
      "learning_rate": 9.154975901633123e-05,
      "loss": 0.0043,
      "step": 1513000
    },
    {
      "epoch": 0.0850449316507904,
      "grad_norm": 0.21653202176094055,
      "learning_rate": 9.154694789158617e-05,
      "loss": 0.0037,
      "step": 1513500
    },
    {
      "epoch": 0.08507302710227728,
      "grad_norm": 0.1107492446899414,
      "learning_rate": 9.15441367668411e-05,
      "loss": 0.0037,
      "step": 1514000
    },
    {
      "epoch": 0.08510112255376416,
      "grad_norm": 0.017662040889263153,
      "learning_rate": 9.154132564209604e-05,
      "loss": 0.0036,
      "step": 1514500
    },
    {
      "epoch": 0.08512921800525104,
      "grad_norm": 0.10646255314350128,
      "learning_rate": 9.153851451735097e-05,
      "loss": 0.0039,
      "step": 1515000
    },
    {
      "epoch": 0.08515731345673792,
      "grad_norm": 0.33026179671287537,
      "learning_rate": 9.15357033926059e-05,
      "loss": 0.0042,
      "step": 1515500
    },
    {
      "epoch": 0.0851854089082248,
      "grad_norm": 0.053802672773599625,
      "learning_rate": 9.153289226786084e-05,
      "loss": 0.004,
      "step": 1516000
    },
    {
      "epoch": 0.08521350435971169,
      "grad_norm": 0.16230528056621552,
      "learning_rate": 9.153008114311577e-05,
      "loss": 0.0042,
      "step": 1516500
    },
    {
      "epoch": 0.08524159981119857,
      "grad_norm": 0.14009785652160645,
      "learning_rate": 9.15272700183707e-05,
      "loss": 0.0043,
      "step": 1517000
    },
    {
      "epoch": 0.08526969526268545,
      "grad_norm": 0.2680814862251282,
      "learning_rate": 9.152445889362564e-05,
      "loss": 0.0042,
      "step": 1517500
    },
    {
      "epoch": 0.08529779071417233,
      "grad_norm": 0.06572630256414413,
      "learning_rate": 9.152164776888057e-05,
      "loss": 0.0042,
      "step": 1518000
    },
    {
      "epoch": 0.08532588616565921,
      "grad_norm": 0.2729344367980957,
      "learning_rate": 9.151883664413551e-05,
      "loss": 0.0041,
      "step": 1518500
    },
    {
      "epoch": 0.0853539816171461,
      "grad_norm": 0.36142095923423767,
      "learning_rate": 9.151602551939043e-05,
      "loss": 0.0039,
      "step": 1519000
    },
    {
      "epoch": 0.08538207706863297,
      "grad_norm": 0.10892460495233536,
      "learning_rate": 9.151321439464538e-05,
      "loss": 0.0041,
      "step": 1519500
    },
    {
      "epoch": 0.08541017252011986,
      "grad_norm": 0.5815353989601135,
      "learning_rate": 9.151040326990031e-05,
      "loss": 0.0045,
      "step": 1520000
    },
    {
      "epoch": 0.08541017252011986,
      "eval_loss": 0.0012224741512909532,
      "eval_runtime": 20.3743,
      "eval_samples_per_second": 4908.147,
      "eval_steps_per_second": 76.714,
      "step": 1520000
    },
    {
      "epoch": 0.08543826797160674,
      "grad_norm": 0.3778327703475952,
      "learning_rate": 9.150759214515525e-05,
      "loss": 0.0039,
      "step": 1520500
    },
    {
      "epoch": 0.08546636342309362,
      "grad_norm": 0.258637011051178,
      "learning_rate": 9.150478102041018e-05,
      "loss": 0.0041,
      "step": 1521000
    },
    {
      "epoch": 0.0854944588745805,
      "grad_norm": 0.2094823122024536,
      "learning_rate": 9.15019698956651e-05,
      "loss": 0.0042,
      "step": 1521500
    },
    {
      "epoch": 0.08552255432606738,
      "grad_norm": 0.5320716500282288,
      "learning_rate": 9.149915877092005e-05,
      "loss": 0.0038,
      "step": 1522000
    },
    {
      "epoch": 0.08555064977755426,
      "grad_norm": 0.2910502552986145,
      "learning_rate": 9.149634764617497e-05,
      "loss": 0.0034,
      "step": 1522500
    },
    {
      "epoch": 0.08557874522904114,
      "grad_norm": 0.4879923164844513,
      "learning_rate": 9.149353652142992e-05,
      "loss": 0.004,
      "step": 1523000
    },
    {
      "epoch": 0.08560684068052803,
      "grad_norm": 0.3833621144294739,
      "learning_rate": 9.149072539668484e-05,
      "loss": 0.0041,
      "step": 1523500
    },
    {
      "epoch": 0.08563493613201491,
      "grad_norm": 0.29649093747138977,
      "learning_rate": 9.148791427193977e-05,
      "loss": 0.0038,
      "step": 1524000
    },
    {
      "epoch": 0.08566303158350179,
      "grad_norm": 0.5585158467292786,
      "learning_rate": 9.148510314719472e-05,
      "loss": 0.0039,
      "step": 1524500
    },
    {
      "epoch": 0.08569112703498867,
      "grad_norm": 0.0544448159635067,
      "learning_rate": 9.148229202244964e-05,
      "loss": 0.0039,
      "step": 1525000
    },
    {
      "epoch": 0.08571922248647555,
      "grad_norm": 0.2235546112060547,
      "learning_rate": 9.147948089770459e-05,
      "loss": 0.004,
      "step": 1525500
    },
    {
      "epoch": 0.08574731793796243,
      "grad_norm": 0.26121190190315247,
      "learning_rate": 9.147666977295951e-05,
      "loss": 0.004,
      "step": 1526000
    },
    {
      "epoch": 0.08577541338944931,
      "grad_norm": 0.1932906210422516,
      "learning_rate": 9.147385864821444e-05,
      "loss": 0.0043,
      "step": 1526500
    },
    {
      "epoch": 0.0858035088409362,
      "grad_norm": 0.04070640355348587,
      "learning_rate": 9.147104752346938e-05,
      "loss": 0.0042,
      "step": 1527000
    },
    {
      "epoch": 0.08583160429242308,
      "grad_norm": 0.031014984473586082,
      "learning_rate": 9.146823639872431e-05,
      "loss": 0.0036,
      "step": 1527500
    },
    {
      "epoch": 0.08585969974390996,
      "grad_norm": 0.46518054604530334,
      "learning_rate": 9.146542527397926e-05,
      "loss": 0.004,
      "step": 1528000
    },
    {
      "epoch": 0.08588779519539684,
      "grad_norm": 0.08830756694078445,
      "learning_rate": 9.146261414923418e-05,
      "loss": 0.0037,
      "step": 1528500
    },
    {
      "epoch": 0.08591589064688372,
      "grad_norm": 0.3908664584159851,
      "learning_rate": 9.145980302448911e-05,
      "loss": 0.0038,
      "step": 1529000
    },
    {
      "epoch": 0.0859439860983706,
      "grad_norm": 0.038856104016304016,
      "learning_rate": 9.145699189974405e-05,
      "loss": 0.0044,
      "step": 1529500
    },
    {
      "epoch": 0.08597208154985748,
      "grad_norm": 0.14412030577659607,
      "learning_rate": 9.145418077499898e-05,
      "loss": 0.0038,
      "step": 1530000
    },
    {
      "epoch": 0.08597208154985748,
      "eval_loss": 0.0011141038266941905,
      "eval_runtime": 20.2194,
      "eval_samples_per_second": 4945.741,
      "eval_steps_per_second": 77.302,
      "step": 1530000
    },
    {
      "epoch": 0.08600017700134437,
      "grad_norm": 0.11004232615232468,
      "learning_rate": 9.145136965025392e-05,
      "loss": 0.0037,
      "step": 1530500
    },
    {
      "epoch": 0.08602827245283125,
      "grad_norm": 0.12229900062084198,
      "learning_rate": 9.144855852550885e-05,
      "loss": 0.0039,
      "step": 1531000
    },
    {
      "epoch": 0.08605636790431813,
      "grad_norm": 0.06584224104881287,
      "learning_rate": 9.144574740076379e-05,
      "loss": 0.0039,
      "step": 1531500
    },
    {
      "epoch": 0.08608446335580501,
      "grad_norm": 0.010824856348335743,
      "learning_rate": 9.144293627601872e-05,
      "loss": 0.004,
      "step": 1532000
    },
    {
      "epoch": 0.08611255880729189,
      "grad_norm": 0.015693247318267822,
      "learning_rate": 9.144012515127365e-05,
      "loss": 0.0041,
      "step": 1532500
    },
    {
      "epoch": 0.08614065425877877,
      "grad_norm": 0.4783543348312378,
      "learning_rate": 9.143731402652859e-05,
      "loss": 0.0036,
      "step": 1533000
    },
    {
      "epoch": 0.08616874971026565,
      "grad_norm": 0.2678646147251129,
      "learning_rate": 9.143450290178352e-05,
      "loss": 0.0045,
      "step": 1533500
    },
    {
      "epoch": 0.08619684516175254,
      "grad_norm": 0.14263908565044403,
      "learning_rate": 9.143169177703846e-05,
      "loss": 0.0042,
      "step": 1534000
    },
    {
      "epoch": 0.08622494061323942,
      "grad_norm": 0.06075136363506317,
      "learning_rate": 9.142888065229339e-05,
      "loss": 0.004,
      "step": 1534500
    },
    {
      "epoch": 0.0862530360647263,
      "grad_norm": 0.4080432951450348,
      "learning_rate": 9.142606952754833e-05,
      "loss": 0.0042,
      "step": 1535000
    },
    {
      "epoch": 0.08628113151621318,
      "grad_norm": 0.04586140066385269,
      "learning_rate": 9.142325840280326e-05,
      "loss": 0.004,
      "step": 1535500
    },
    {
      "epoch": 0.08630922696770006,
      "grad_norm": 0.3481305241584778,
      "learning_rate": 9.14204472780582e-05,
      "loss": 0.0033,
      "step": 1536000
    },
    {
      "epoch": 0.08633732241918694,
      "grad_norm": 0.14107780158519745,
      "learning_rate": 9.141763615331313e-05,
      "loss": 0.0041,
      "step": 1536500
    },
    {
      "epoch": 0.08636541787067382,
      "grad_norm": 0.24521462619304657,
      "learning_rate": 9.141482502856806e-05,
      "loss": 0.0045,
      "step": 1537000
    },
    {
      "epoch": 0.0863935133221607,
      "grad_norm": 0.3957388401031494,
      "learning_rate": 9.1412013903823e-05,
      "loss": 0.0043,
      "step": 1537500
    },
    {
      "epoch": 0.08642160877364759,
      "grad_norm": 0.010449866764247417,
      "learning_rate": 9.140920277907793e-05,
      "loss": 0.0037,
      "step": 1538000
    },
    {
      "epoch": 0.08644970422513447,
      "grad_norm": 0.06847306340932846,
      "learning_rate": 9.140639165433285e-05,
      "loss": 0.0041,
      "step": 1538500
    },
    {
      "epoch": 0.08647779967662135,
      "grad_norm": 0.8423534631729126,
      "learning_rate": 9.14035805295878e-05,
      "loss": 0.0036,
      "step": 1539000
    },
    {
      "epoch": 0.08650589512810823,
      "grad_norm": 0.5640254020690918,
      "learning_rate": 9.140076940484273e-05,
      "loss": 0.0036,
      "step": 1539500
    },
    {
      "epoch": 0.08653399057959511,
      "grad_norm": 0.4134969413280487,
      "learning_rate": 9.139795828009767e-05,
      "loss": 0.0038,
      "step": 1540000
    },
    {
      "epoch": 0.08653399057959511,
      "eval_loss": 0.001139998552389443,
      "eval_runtime": 20.5307,
      "eval_samples_per_second": 4870.751,
      "eval_steps_per_second": 76.13,
      "step": 1540000
    },
    {
      "epoch": 0.086562086031082,
      "grad_norm": 0.053811248391866684,
      "learning_rate": 9.13951471553526e-05,
      "loss": 0.0039,
      "step": 1540500
    },
    {
      "epoch": 0.08659018148256888,
      "grad_norm": 0.2821972966194153,
      "learning_rate": 9.139233603060752e-05,
      "loss": 0.0045,
      "step": 1541000
    },
    {
      "epoch": 0.08661827693405576,
      "grad_norm": 0.21205784380435944,
      "learning_rate": 9.138952490586247e-05,
      "loss": 0.0036,
      "step": 1541500
    },
    {
      "epoch": 0.08664637238554264,
      "grad_norm": 0.43326497077941895,
      "learning_rate": 9.138671378111739e-05,
      "loss": 0.0043,
      "step": 1542000
    },
    {
      "epoch": 0.08667446783702952,
      "grad_norm": 0.02056696079671383,
      "learning_rate": 9.138390265637234e-05,
      "loss": 0.004,
      "step": 1542500
    },
    {
      "epoch": 0.0867025632885164,
      "grad_norm": 0.19120025634765625,
      "learning_rate": 9.138109153162726e-05,
      "loss": 0.0037,
      "step": 1543000
    },
    {
      "epoch": 0.08673065874000328,
      "grad_norm": 0.3122916519641876,
      "learning_rate": 9.13782804068822e-05,
      "loss": 0.0039,
      "step": 1543500
    },
    {
      "epoch": 0.08675875419149016,
      "grad_norm": 0.04641985148191452,
      "learning_rate": 9.137546928213714e-05,
      "loss": 0.0041,
      "step": 1544000
    },
    {
      "epoch": 0.08678684964297705,
      "grad_norm": 0.6439205408096313,
      "learning_rate": 9.137265815739206e-05,
      "loss": 0.0043,
      "step": 1544500
    },
    {
      "epoch": 0.08681494509446393,
      "grad_norm": 0.09438008069992065,
      "learning_rate": 9.136984703264701e-05,
      "loss": 0.0037,
      "step": 1545000
    },
    {
      "epoch": 0.08684304054595081,
      "grad_norm": 0.022931061685085297,
      "learning_rate": 9.136703590790193e-05,
      "loss": 0.0043,
      "step": 1545500
    },
    {
      "epoch": 0.08687113599743769,
      "grad_norm": 0.05435488373041153,
      "learning_rate": 9.136422478315687e-05,
      "loss": 0.0039,
      "step": 1546000
    },
    {
      "epoch": 0.08689923144892457,
      "grad_norm": 0.034764040261507034,
      "learning_rate": 9.13614136584118e-05,
      "loss": 0.0041,
      "step": 1546500
    },
    {
      "epoch": 0.08692732690041145,
      "grad_norm": 0.2372083067893982,
      "learning_rate": 9.135860253366673e-05,
      "loss": 0.004,
      "step": 1547000
    },
    {
      "epoch": 0.08695542235189833,
      "grad_norm": 0.2675325572490692,
      "learning_rate": 9.135579140892168e-05,
      "loss": 0.0039,
      "step": 1547500
    },
    {
      "epoch": 0.08698351780338522,
      "grad_norm": 0.1324385553598404,
      "learning_rate": 9.13529802841766e-05,
      "loss": 0.0041,
      "step": 1548000
    },
    {
      "epoch": 0.0870116132548721,
      "grad_norm": 0.04094678908586502,
      "learning_rate": 9.135016915943154e-05,
      "loss": 0.004,
      "step": 1548500
    },
    {
      "epoch": 0.08703970870635898,
      "grad_norm": 0.48142436146736145,
      "learning_rate": 9.134735803468647e-05,
      "loss": 0.0035,
      "step": 1549000
    },
    {
      "epoch": 0.08706780415784586,
      "grad_norm": 0.33162572979927063,
      "learning_rate": 9.13445469099414e-05,
      "loss": 0.004,
      "step": 1549500
    },
    {
      "epoch": 0.08709589960933274,
      "grad_norm": 0.1410248875617981,
      "learning_rate": 9.134173578519634e-05,
      "loss": 0.004,
      "step": 1550000
    },
    {
      "epoch": 0.08709589960933274,
      "eval_loss": 0.0011904943967238069,
      "eval_runtime": 20.8737,
      "eval_samples_per_second": 4790.718,
      "eval_steps_per_second": 74.879,
      "step": 1550000
    },
    {
      "epoch": 0.08712399506081962,
      "grad_norm": 0.17569969594478607,
      "learning_rate": 9.133892466045127e-05,
      "loss": 0.0039,
      "step": 1550500
    },
    {
      "epoch": 0.0871520905123065,
      "grad_norm": 0.27593427896499634,
      "learning_rate": 9.133611353570621e-05,
      "loss": 0.0041,
      "step": 1551000
    },
    {
      "epoch": 0.08718018596379339,
      "grad_norm": 0.10992365330457687,
      "learning_rate": 9.133330241096114e-05,
      "loss": 0.0038,
      "step": 1551500
    },
    {
      "epoch": 0.08720828141528027,
      "grad_norm": 0.025394143536686897,
      "learning_rate": 9.133049128621608e-05,
      "loss": 0.0036,
      "step": 1552000
    },
    {
      "epoch": 0.08723637686676715,
      "grad_norm": 0.016789397224783897,
      "learning_rate": 9.132768016147101e-05,
      "loss": 0.004,
      "step": 1552500
    },
    {
      "epoch": 0.08726447231825403,
      "grad_norm": 0.10999050736427307,
      "learning_rate": 9.132486903672594e-05,
      "loss": 0.004,
      "step": 1553000
    },
    {
      "epoch": 0.08729256776974091,
      "grad_norm": 0.2365020215511322,
      "learning_rate": 9.132205791198088e-05,
      "loss": 0.0044,
      "step": 1553500
    },
    {
      "epoch": 0.08732066322122779,
      "grad_norm": 0.01890670321881771,
      "learning_rate": 9.131924678723581e-05,
      "loss": 0.004,
      "step": 1554000
    },
    {
      "epoch": 0.08734875867271467,
      "grad_norm": 0.22667112946510315,
      "learning_rate": 9.131643566249073e-05,
      "loss": 0.0039,
      "step": 1554500
    },
    {
      "epoch": 0.08737685412420156,
      "grad_norm": 0.31133225560188293,
      "learning_rate": 9.131362453774568e-05,
      "loss": 0.0041,
      "step": 1555000
    },
    {
      "epoch": 0.08740494957568844,
      "grad_norm": 0.013672580942511559,
      "learning_rate": 9.131081341300062e-05,
      "loss": 0.0043,
      "step": 1555500
    },
    {
      "epoch": 0.08743304502717533,
      "grad_norm": 0.02682550437748432,
      "learning_rate": 9.130800228825555e-05,
      "loss": 0.0043,
      "step": 1556000
    },
    {
      "epoch": 0.08746114047866221,
      "grad_norm": 0.04404769092798233,
      "learning_rate": 9.130519116351048e-05,
      "loss": 0.0046,
      "step": 1556500
    },
    {
      "epoch": 0.0874892359301491,
      "grad_norm": 0.05549395829439163,
      "learning_rate": 9.13023800387654e-05,
      "loss": 0.0038,
      "step": 1557000
    },
    {
      "epoch": 0.08751733138163598,
      "grad_norm": 0.04178968444466591,
      "learning_rate": 9.129956891402035e-05,
      "loss": 0.0041,
      "step": 1557500
    },
    {
      "epoch": 0.08754542683312286,
      "grad_norm": 0.18114401400089264,
      "learning_rate": 9.129675778927527e-05,
      "loss": 0.0035,
      "step": 1558000
    },
    {
      "epoch": 0.08757352228460974,
      "grad_norm": 0.44035664200782776,
      "learning_rate": 9.129394666453022e-05,
      "loss": 0.0041,
      "step": 1558500
    },
    {
      "epoch": 0.08760161773609662,
      "grad_norm": 0.7126044034957886,
      "learning_rate": 9.129113553978516e-05,
      "loss": 0.004,
      "step": 1559000
    },
    {
      "epoch": 0.0876297131875835,
      "grad_norm": 0.22902792692184448,
      "learning_rate": 9.128832441504008e-05,
      "loss": 0.0039,
      "step": 1559500
    },
    {
      "epoch": 0.08765780863907038,
      "grad_norm": 0.013026115484535694,
      "learning_rate": 9.128551329029502e-05,
      "loss": 0.0039,
      "step": 1560000
    },
    {
      "epoch": 0.08765780863907038,
      "eval_loss": 0.0011162107111886144,
      "eval_runtime": 20.584,
      "eval_samples_per_second": 4858.147,
      "eval_steps_per_second": 75.933,
      "step": 1560000
    },
    {
      "epoch": 0.08768590409055727,
      "grad_norm": 0.4491311311721802,
      "learning_rate": 9.128270216554994e-05,
      "loss": 0.0044,
      "step": 1560500
    },
    {
      "epoch": 0.08771399954204415,
      "grad_norm": 0.02012440375983715,
      "learning_rate": 9.127989104080489e-05,
      "loss": 0.004,
      "step": 1561000
    },
    {
      "epoch": 0.08774209499353103,
      "grad_norm": 0.6489871144294739,
      "learning_rate": 9.127707991605981e-05,
      "loss": 0.004,
      "step": 1561500
    },
    {
      "epoch": 0.08777019044501791,
      "grad_norm": 0.19605974853038788,
      "learning_rate": 9.127426879131475e-05,
      "loss": 0.0038,
      "step": 1562000
    },
    {
      "epoch": 0.08779828589650479,
      "grad_norm": 0.20529158413410187,
      "learning_rate": 9.127145766656968e-05,
      "loss": 0.0042,
      "step": 1562500
    },
    {
      "epoch": 0.08782638134799167,
      "grad_norm": 0.49598029255867004,
      "learning_rate": 9.126864654182462e-05,
      "loss": 0.004,
      "step": 1563000
    },
    {
      "epoch": 0.08785447679947855,
      "grad_norm": 0.09454791992902756,
      "learning_rate": 9.126583541707956e-05,
      "loss": 0.0041,
      "step": 1563500
    },
    {
      "epoch": 0.08788257225096544,
      "grad_norm": 0.5116626620292664,
      "learning_rate": 9.126302429233448e-05,
      "loss": 0.004,
      "step": 1564000
    },
    {
      "epoch": 0.08791066770245232,
      "grad_norm": 0.19699586927890778,
      "learning_rate": 9.126021316758942e-05,
      "loss": 0.004,
      "step": 1564500
    },
    {
      "epoch": 0.0879387631539392,
      "grad_norm": 0.21662144362926483,
      "learning_rate": 9.125740204284435e-05,
      "loss": 0.0041,
      "step": 1565000
    },
    {
      "epoch": 0.08796685860542608,
      "grad_norm": 0.42177820205688477,
      "learning_rate": 9.125459091809929e-05,
      "loss": 0.0039,
      "step": 1565500
    },
    {
      "epoch": 0.08799495405691296,
      "grad_norm": 0.0213119238615036,
      "learning_rate": 9.125177979335422e-05,
      "loss": 0.004,
      "step": 1566000
    },
    {
      "epoch": 0.08802304950839984,
      "grad_norm": 0.029573503881692886,
      "learning_rate": 9.124896866860916e-05,
      "loss": 0.0038,
      "step": 1566500
    },
    {
      "epoch": 0.08805114495988672,
      "grad_norm": 0.3271399140357971,
      "learning_rate": 9.12461575438641e-05,
      "loss": 0.0045,
      "step": 1567000
    },
    {
      "epoch": 0.0880792404113736,
      "grad_norm": 0.031792521476745605,
      "learning_rate": 9.124334641911902e-05,
      "loss": 0.0037,
      "step": 1567500
    },
    {
      "epoch": 0.08810733586286049,
      "grad_norm": 0.054128531366586685,
      "learning_rate": 9.124053529437396e-05,
      "loss": 0.0037,
      "step": 1568000
    },
    {
      "epoch": 0.08813543131434737,
      "grad_norm": 0.03065231814980507,
      "learning_rate": 9.123772416962889e-05,
      "loss": 0.0039,
      "step": 1568500
    },
    {
      "epoch": 0.08816352676583425,
      "grad_norm": 0.1730147898197174,
      "learning_rate": 9.123491304488383e-05,
      "loss": 0.0038,
      "step": 1569000
    },
    {
      "epoch": 0.08819162221732113,
      "grad_norm": 0.15668880939483643,
      "learning_rate": 9.123210192013876e-05,
      "loss": 0.0038,
      "step": 1569500
    },
    {
      "epoch": 0.08821971766880801,
      "grad_norm": 0.3119974136352539,
      "learning_rate": 9.12292907953937e-05,
      "loss": 0.004,
      "step": 1570000
    },
    {
      "epoch": 0.08821971766880801,
      "eval_loss": 0.0012099763844162226,
      "eval_runtime": 20.7404,
      "eval_samples_per_second": 4821.516,
      "eval_steps_per_second": 75.36,
      "step": 1570000
    },
    {
      "epoch": 0.0882478131202949,
      "grad_norm": 0.28985926508903503,
      "learning_rate": 9.122647967064863e-05,
      "loss": 0.0039,
      "step": 1570500
    },
    {
      "epoch": 0.08827590857178177,
      "grad_norm": 0.09914004057645798,
      "learning_rate": 9.122366854590356e-05,
      "loss": 0.0035,
      "step": 1571000
    },
    {
      "epoch": 0.08830400402326866,
      "grad_norm": 0.10413748025894165,
      "learning_rate": 9.12208574211585e-05,
      "loss": 0.0038,
      "step": 1571500
    },
    {
      "epoch": 0.08833209947475554,
      "grad_norm": 0.25201892852783203,
      "learning_rate": 9.121804629641343e-05,
      "loss": 0.004,
      "step": 1572000
    },
    {
      "epoch": 0.08836019492624242,
      "grad_norm": 0.015017653815448284,
      "learning_rate": 9.121523517166837e-05,
      "loss": 0.0042,
      "step": 1572500
    },
    {
      "epoch": 0.0883882903777293,
      "grad_norm": 0.490450918674469,
      "learning_rate": 9.12124240469233e-05,
      "loss": 0.0042,
      "step": 1573000
    },
    {
      "epoch": 0.08841638582921618,
      "grad_norm": 0.394808292388916,
      "learning_rate": 9.120961292217824e-05,
      "loss": 0.0042,
      "step": 1573500
    },
    {
      "epoch": 0.08844448128070306,
      "grad_norm": 0.3988030254840851,
      "learning_rate": 9.120680179743316e-05,
      "loss": 0.0041,
      "step": 1574000
    },
    {
      "epoch": 0.08847257673218994,
      "grad_norm": 0.28520020842552185,
      "learning_rate": 9.12039906726881e-05,
      "loss": 0.0039,
      "step": 1574500
    },
    {
      "epoch": 0.08850067218367683,
      "grad_norm": 0.1419280469417572,
      "learning_rate": 9.120117954794304e-05,
      "loss": 0.004,
      "step": 1575000
    },
    {
      "epoch": 0.08852876763516371,
      "grad_norm": 0.14788997173309326,
      "learning_rate": 9.119836842319797e-05,
      "loss": 0.0038,
      "step": 1575500
    },
    {
      "epoch": 0.08855686308665059,
      "grad_norm": 0.12758754193782806,
      "learning_rate": 9.11955572984529e-05,
      "loss": 0.0039,
      "step": 1576000
    },
    {
      "epoch": 0.08858495853813747,
      "grad_norm": 0.11994606256484985,
      "learning_rate": 9.119274617370783e-05,
      "loss": 0.0041,
      "step": 1576500
    },
    {
      "epoch": 0.08861305398962435,
      "grad_norm": 0.3543838560581207,
      "learning_rate": 9.118993504896277e-05,
      "loss": 0.0041,
      "step": 1577000
    },
    {
      "epoch": 0.08864114944111123,
      "grad_norm": 0.05262681841850281,
      "learning_rate": 9.11871239242177e-05,
      "loss": 0.004,
      "step": 1577500
    },
    {
      "epoch": 0.08866924489259811,
      "grad_norm": 0.10518103092908859,
      "learning_rate": 9.118431279947264e-05,
      "loss": 0.0035,
      "step": 1578000
    },
    {
      "epoch": 0.088697340344085,
      "grad_norm": 0.2402726262807846,
      "learning_rate": 9.118150167472758e-05,
      "loss": 0.0037,
      "step": 1578500
    },
    {
      "epoch": 0.08872543579557188,
      "grad_norm": 0.19410917162895203,
      "learning_rate": 9.11786905499825e-05,
      "loss": 0.0042,
      "step": 1579000
    },
    {
      "epoch": 0.08875353124705876,
      "grad_norm": 0.07561566680669785,
      "learning_rate": 9.117587942523745e-05,
      "loss": 0.0037,
      "step": 1579500
    },
    {
      "epoch": 0.08878162669854564,
      "grad_norm": 0.04521047696471214,
      "learning_rate": 9.117306830049237e-05,
      "loss": 0.0037,
      "step": 1580000
    },
    {
      "epoch": 0.08878162669854564,
      "eval_loss": 0.0010784383630380034,
      "eval_runtime": 20.2083,
      "eval_samples_per_second": 4948.46,
      "eval_steps_per_second": 77.344,
      "step": 1580000
    },
    {
      "epoch": 0.08880972215003252,
      "grad_norm": 0.3628878593444824,
      "learning_rate": 9.117025717574731e-05,
      "loss": 0.0041,
      "step": 1580500
    },
    {
      "epoch": 0.0888378176015194,
      "grad_norm": 0.30869942903518677,
      "learning_rate": 9.116744605100224e-05,
      "loss": 0.0037,
      "step": 1581000
    },
    {
      "epoch": 0.08886591305300628,
      "grad_norm": 0.11505274474620819,
      "learning_rate": 9.116463492625717e-05,
      "loss": 0.004,
      "step": 1581500
    },
    {
      "epoch": 0.08889400850449317,
      "grad_norm": 0.12434596568346024,
      "learning_rate": 9.11618238015121e-05,
      "loss": 0.0041,
      "step": 1582000
    },
    {
      "epoch": 0.08892210395598005,
      "grad_norm": 0.09985139220952988,
      "learning_rate": 9.115901267676704e-05,
      "loss": 0.0042,
      "step": 1582500
    },
    {
      "epoch": 0.08895019940746693,
      "grad_norm": 0.18162328004837036,
      "learning_rate": 9.115620155202199e-05,
      "loss": 0.004,
      "step": 1583000
    },
    {
      "epoch": 0.08897829485895381,
      "grad_norm": 0.07826970517635345,
      "learning_rate": 9.11533904272769e-05,
      "loss": 0.0042,
      "step": 1583500
    },
    {
      "epoch": 0.08900639031044069,
      "grad_norm": 0.10160968452692032,
      "learning_rate": 9.115057930253184e-05,
      "loss": 0.004,
      "step": 1584000
    },
    {
      "epoch": 0.08903448576192757,
      "grad_norm": 0.10369100421667099,
      "learning_rate": 9.114776817778678e-05,
      "loss": 0.0042,
      "step": 1584500
    },
    {
      "epoch": 0.08906258121341445,
      "grad_norm": 0.12357442080974579,
      "learning_rate": 9.114495705304171e-05,
      "loss": 0.0037,
      "step": 1585000
    },
    {
      "epoch": 0.08909067666490134,
      "grad_norm": 0.008764121681451797,
      "learning_rate": 9.114214592829664e-05,
      "loss": 0.0041,
      "step": 1585500
    },
    {
      "epoch": 0.08911877211638822,
      "grad_norm": 0.22943995893001556,
      "learning_rate": 9.113933480355158e-05,
      "loss": 0.0038,
      "step": 1586000
    },
    {
      "epoch": 0.0891468675678751,
      "grad_norm": 0.03274567052721977,
      "learning_rate": 9.113652367880651e-05,
      "loss": 0.0037,
      "step": 1586500
    },
    {
      "epoch": 0.08917496301936198,
      "grad_norm": 0.44892430305480957,
      "learning_rate": 9.113371255406145e-05,
      "loss": 0.0038,
      "step": 1587000
    },
    {
      "epoch": 0.08920305847084886,
      "grad_norm": 0.037989091128110886,
      "learning_rate": 9.113090142931638e-05,
      "loss": 0.0043,
      "step": 1587500
    },
    {
      "epoch": 0.08923115392233574,
      "grad_norm": 0.0858360081911087,
      "learning_rate": 9.112809030457131e-05,
      "loss": 0.004,
      "step": 1588000
    },
    {
      "epoch": 0.08925924937382262,
      "grad_norm": 0.22088249027729034,
      "learning_rate": 9.112527917982625e-05,
      "loss": 0.0037,
      "step": 1588500
    },
    {
      "epoch": 0.0892873448253095,
      "grad_norm": 0.97029048204422,
      "learning_rate": 9.112246805508118e-05,
      "loss": 0.0039,
      "step": 1589000
    },
    {
      "epoch": 0.08931544027679639,
      "grad_norm": 1.3446624279022217,
      "learning_rate": 9.111965693033612e-05,
      "loss": 0.0039,
      "step": 1589500
    },
    {
      "epoch": 0.08934353572828327,
      "grad_norm": 0.36068370938301086,
      "learning_rate": 9.111684580559105e-05,
      "loss": 0.0037,
      "step": 1590000
    },
    {
      "epoch": 0.08934353572828327,
      "eval_loss": 0.0011668456718325615,
      "eval_runtime": 20.3925,
      "eval_samples_per_second": 4903.759,
      "eval_steps_per_second": 76.646,
      "step": 1590000
    },
    {
      "epoch": 0.08937163117977015,
      "grad_norm": 0.16326281428337097,
      "learning_rate": 9.111403468084599e-05,
      "loss": 0.004,
      "step": 1590500
    },
    {
      "epoch": 0.08939972663125703,
      "grad_norm": 1.0711690187454224,
      "learning_rate": 9.111122355610092e-05,
      "loss": 0.0039,
      "step": 1591000
    },
    {
      "epoch": 0.08942782208274391,
      "grad_norm": 0.3077475130558014,
      "learning_rate": 9.110841243135585e-05,
      "loss": 0.004,
      "step": 1591500
    },
    {
      "epoch": 0.0894559175342308,
      "grad_norm": 0.08805596828460693,
      "learning_rate": 9.110560130661079e-05,
      "loss": 0.004,
      "step": 1592000
    },
    {
      "epoch": 0.08948401298571768,
      "grad_norm": 0.12996308505535126,
      "learning_rate": 9.110279018186571e-05,
      "loss": 0.0042,
      "step": 1592500
    },
    {
      "epoch": 0.08951210843720456,
      "grad_norm": 0.10139758884906769,
      "learning_rate": 9.109997905712066e-05,
      "loss": 0.0034,
      "step": 1593000
    },
    {
      "epoch": 0.08954020388869144,
      "grad_norm": 0.17227737605571747,
      "learning_rate": 9.109716793237558e-05,
      "loss": 0.0042,
      "step": 1593500
    },
    {
      "epoch": 0.08956829934017832,
      "grad_norm": 0.21171411871910095,
      "learning_rate": 9.109435680763053e-05,
      "loss": 0.0041,
      "step": 1594000
    },
    {
      "epoch": 0.0895963947916652,
      "grad_norm": 0.27916449308395386,
      "learning_rate": 9.109154568288546e-05,
      "loss": 0.0036,
      "step": 1594500
    },
    {
      "epoch": 0.08962449024315208,
      "grad_norm": 0.10632629692554474,
      "learning_rate": 9.108873455814038e-05,
      "loss": 0.0041,
      "step": 1595000
    },
    {
      "epoch": 0.08965258569463896,
      "grad_norm": 0.11510789394378662,
      "learning_rate": 9.108592343339533e-05,
      "loss": 0.0042,
      "step": 1595500
    },
    {
      "epoch": 0.08968068114612585,
      "grad_norm": 0.45831507444381714,
      "learning_rate": 9.108311230865025e-05,
      "loss": 0.0043,
      "step": 1596000
    },
    {
      "epoch": 0.08970877659761273,
      "grad_norm": 0.25351497530937195,
      "learning_rate": 9.10803011839052e-05,
      "loss": 0.0037,
      "step": 1596500
    },
    {
      "epoch": 0.08973687204909961,
      "grad_norm": 0.021216798573732376,
      "learning_rate": 9.107749005916012e-05,
      "loss": 0.0037,
      "step": 1597000
    },
    {
      "epoch": 0.08976496750058649,
      "grad_norm": 0.09771518409252167,
      "learning_rate": 9.107467893441505e-05,
      "loss": 0.0038,
      "step": 1597500
    },
    {
      "epoch": 0.08979306295207337,
      "grad_norm": 0.020434359088540077,
      "learning_rate": 9.107186780967e-05,
      "loss": 0.0036,
      "step": 1598000
    },
    {
      "epoch": 0.08982115840356025,
      "grad_norm": 0.2832837998867035,
      "learning_rate": 9.106905668492492e-05,
      "loss": 0.0038,
      "step": 1598500
    },
    {
      "epoch": 0.08984925385504713,
      "grad_norm": 0.010729147121310234,
      "learning_rate": 9.106624556017987e-05,
      "loss": 0.004,
      "step": 1599000
    },
    {
      "epoch": 0.08987734930653402,
      "grad_norm": 0.547836184501648,
      "learning_rate": 9.106343443543479e-05,
      "loss": 0.004,
      "step": 1599500
    },
    {
      "epoch": 0.0899054447580209,
      "grad_norm": 0.2136327028274536,
      "learning_rate": 9.106062331068974e-05,
      "loss": 0.0036,
      "step": 1600000
    },
    {
      "epoch": 0.0899054447580209,
      "eval_loss": 0.0011375588364899158,
      "eval_runtime": 19.9486,
      "eval_samples_per_second": 5012.887,
      "eval_steps_per_second": 78.351,
      "step": 1600000
    },
    {
      "epoch": 0.08993354020950778,
      "grad_norm": 0.15223920345306396,
      "learning_rate": 9.105781218594466e-05,
      "loss": 0.0042,
      "step": 1600500
    },
    {
      "epoch": 0.08996163566099466,
      "grad_norm": 0.03331950679421425,
      "learning_rate": 9.105500106119959e-05,
      "loss": 0.0038,
      "step": 1601000
    },
    {
      "epoch": 0.08998973111248154,
      "grad_norm": 0.35218220949172974,
      "learning_rate": 9.105218993645454e-05,
      "loss": 0.004,
      "step": 1601500
    },
    {
      "epoch": 0.09001782656396842,
      "grad_norm": 0.003970785532146692,
      "learning_rate": 9.104937881170946e-05,
      "loss": 0.0037,
      "step": 1602000
    },
    {
      "epoch": 0.0900459220154553,
      "grad_norm": 0.5397996306419373,
      "learning_rate": 9.104656768696441e-05,
      "loss": 0.004,
      "step": 1602500
    },
    {
      "epoch": 0.09007401746694219,
      "grad_norm": 0.7381001114845276,
      "learning_rate": 9.104375656221933e-05,
      "loss": 0.004,
      "step": 1603000
    },
    {
      "epoch": 0.09010211291842907,
      "grad_norm": 0.5565468668937683,
      "learning_rate": 9.104094543747426e-05,
      "loss": 0.0036,
      "step": 1603500
    },
    {
      "epoch": 0.09013020836991595,
      "grad_norm": 0.15430006384849548,
      "learning_rate": 9.10381343127292e-05,
      "loss": 0.0038,
      "step": 1604000
    },
    {
      "epoch": 0.09015830382140283,
      "grad_norm": 0.211095929145813,
      "learning_rate": 9.103532318798413e-05,
      "loss": 0.0039,
      "step": 1604500
    },
    {
      "epoch": 0.09018639927288971,
      "grad_norm": 0.2369997203350067,
      "learning_rate": 9.103251206323907e-05,
      "loss": 0.0039,
      "step": 1605000
    },
    {
      "epoch": 0.09021449472437659,
      "grad_norm": 0.1439349502325058,
      "learning_rate": 9.1029700938494e-05,
      "loss": 0.0036,
      "step": 1605500
    },
    {
      "epoch": 0.09024259017586347,
      "grad_norm": 0.06224390119314194,
      "learning_rate": 9.102688981374893e-05,
      "loss": 0.0039,
      "step": 1606000
    },
    {
      "epoch": 0.09027068562735036,
      "grad_norm": 0.005461996421217918,
      "learning_rate": 9.102407868900387e-05,
      "loss": 0.0036,
      "step": 1606500
    },
    {
      "epoch": 0.09029878107883724,
      "grad_norm": 0.33220744132995605,
      "learning_rate": 9.10212675642588e-05,
      "loss": 0.0039,
      "step": 1607000
    },
    {
      "epoch": 0.09032687653032412,
      "grad_norm": 0.0363832525908947,
      "learning_rate": 9.101845643951374e-05,
      "loss": 0.0041,
      "step": 1607500
    },
    {
      "epoch": 0.090354971981811,
      "grad_norm": 0.32547539472579956,
      "learning_rate": 9.101564531476867e-05,
      "loss": 0.0042,
      "step": 1608000
    },
    {
      "epoch": 0.09038306743329788,
      "grad_norm": 0.3642481863498688,
      "learning_rate": 9.10128341900236e-05,
      "loss": 0.0042,
      "step": 1608500
    },
    {
      "epoch": 0.09041116288478476,
      "grad_norm": 0.3202168345451355,
      "learning_rate": 9.101002306527854e-05,
      "loss": 0.0038,
      "step": 1609000
    },
    {
      "epoch": 0.09043925833627164,
      "grad_norm": 0.28442126512527466,
      "learning_rate": 9.100721194053347e-05,
      "loss": 0.0039,
      "step": 1609500
    },
    {
      "epoch": 0.09046735378775853,
      "grad_norm": 0.11282740533351898,
      "learning_rate": 9.100440081578841e-05,
      "loss": 0.0041,
      "step": 1610000
    },
    {
      "epoch": 0.09046735378775853,
      "eval_loss": 0.0011123920558020473,
      "eval_runtime": 19.7852,
      "eval_samples_per_second": 5054.272,
      "eval_steps_per_second": 78.998,
      "step": 1610000
    },
    {
      "epoch": 0.0904954492392454,
      "grad_norm": 0.12507547438144684,
      "learning_rate": 9.100158969104334e-05,
      "loss": 0.0041,
      "step": 1610500
    },
    {
      "epoch": 0.09052354469073229,
      "grad_norm": 0.20315328240394592,
      "learning_rate": 9.099877856629828e-05,
      "loss": 0.0043,
      "step": 1611000
    },
    {
      "epoch": 0.09055164014221917,
      "grad_norm": 0.35630476474761963,
      "learning_rate": 9.099596744155321e-05,
      "loss": 0.0039,
      "step": 1611500
    },
    {
      "epoch": 0.09057973559370605,
      "grad_norm": 0.08855681866407394,
      "learning_rate": 9.099315631680813e-05,
      "loss": 0.0043,
      "step": 1612000
    },
    {
      "epoch": 0.09060783104519293,
      "grad_norm": 0.18627728521823883,
      "learning_rate": 9.099034519206308e-05,
      "loss": 0.0038,
      "step": 1612500
    },
    {
      "epoch": 0.09063592649667981,
      "grad_norm": 0.05971309915184975,
      "learning_rate": 9.0987534067318e-05,
      "loss": 0.0038,
      "step": 1613000
    },
    {
      "epoch": 0.0906640219481667,
      "grad_norm": 0.20546138286590576,
      "learning_rate": 9.098472294257295e-05,
      "loss": 0.0041,
      "step": 1613500
    },
    {
      "epoch": 0.09069211739965358,
      "grad_norm": 0.26059114933013916,
      "learning_rate": 9.098191181782788e-05,
      "loss": 0.0039,
      "step": 1614000
    },
    {
      "epoch": 0.09072021285114046,
      "grad_norm": 0.09812148660421371,
      "learning_rate": 9.09791006930828e-05,
      "loss": 0.0039,
      "step": 1614500
    },
    {
      "epoch": 0.09074830830262734,
      "grad_norm": 0.6533840894699097,
      "learning_rate": 9.097628956833775e-05,
      "loss": 0.0039,
      "step": 1615000
    },
    {
      "epoch": 0.09077640375411422,
      "grad_norm": 0.4101197421550751,
      "learning_rate": 9.097347844359267e-05,
      "loss": 0.0041,
      "step": 1615500
    },
    {
      "epoch": 0.0908044992056011,
      "grad_norm": 0.14488692581653595,
      "learning_rate": 9.097066731884762e-05,
      "loss": 0.0041,
      "step": 1616000
    },
    {
      "epoch": 0.09083259465708798,
      "grad_norm": 0.053623225539922714,
      "learning_rate": 9.096785619410254e-05,
      "loss": 0.0039,
      "step": 1616500
    },
    {
      "epoch": 0.09086069010857488,
      "grad_norm": 0.12615947425365448,
      "learning_rate": 9.096504506935747e-05,
      "loss": 0.0036,
      "step": 1617000
    },
    {
      "epoch": 0.09088878556006176,
      "grad_norm": 0.043144889175891876,
      "learning_rate": 9.096223394461242e-05,
      "loss": 0.0045,
      "step": 1617500
    },
    {
      "epoch": 0.09091688101154864,
      "grad_norm": 0.1596677303314209,
      "learning_rate": 9.095942281986734e-05,
      "loss": 0.004,
      "step": 1618000
    },
    {
      "epoch": 0.09094497646303552,
      "grad_norm": 0.022457025945186615,
      "learning_rate": 9.095661169512229e-05,
      "loss": 0.0035,
      "step": 1618500
    },
    {
      "epoch": 0.0909730719145224,
      "grad_norm": 0.5010203123092651,
      "learning_rate": 9.095380057037721e-05,
      "loss": 0.0038,
      "step": 1619000
    },
    {
      "epoch": 0.09100116736600929,
      "grad_norm": 0.23423627018928528,
      "learning_rate": 9.095098944563215e-05,
      "loss": 0.0038,
      "step": 1619500
    },
    {
      "epoch": 0.09102926281749617,
      "grad_norm": 0.13646258413791656,
      "learning_rate": 9.094817832088708e-05,
      "loss": 0.004,
      "step": 1620000
    },
    {
      "epoch": 0.09102926281749617,
      "eval_loss": 0.0011576790129765868,
      "eval_runtime": 19.9868,
      "eval_samples_per_second": 5003.297,
      "eval_steps_per_second": 78.202,
      "step": 1620000
    },
    {
      "epoch": 0.09105735826898305,
      "grad_norm": 0.7213113307952881,
      "learning_rate": 9.094536719614201e-05,
      "loss": 0.0041,
      "step": 1620500
    },
    {
      "epoch": 0.09108545372046993,
      "grad_norm": 0.3208649158477783,
      "learning_rate": 9.094255607139696e-05,
      "loss": 0.0036,
      "step": 1621000
    },
    {
      "epoch": 0.09111354917195681,
      "grad_norm": 0.05066542699933052,
      "learning_rate": 9.093974494665188e-05,
      "loss": 0.0037,
      "step": 1621500
    },
    {
      "epoch": 0.0911416446234437,
      "grad_norm": 0.053615618497133255,
      "learning_rate": 9.093693382190682e-05,
      "loss": 0.0041,
      "step": 1622000
    },
    {
      "epoch": 0.09116974007493057,
      "grad_norm": 0.49555379152297974,
      "learning_rate": 9.093412269716175e-05,
      "loss": 0.0041,
      "step": 1622500
    },
    {
      "epoch": 0.09119783552641746,
      "grad_norm": 0.16185642778873444,
      "learning_rate": 9.093131157241668e-05,
      "loss": 0.0039,
      "step": 1623000
    },
    {
      "epoch": 0.09122593097790434,
      "grad_norm": 0.4256211519241333,
      "learning_rate": 9.092850044767162e-05,
      "loss": 0.0036,
      "step": 1623500
    },
    {
      "epoch": 0.09125402642939122,
      "grad_norm": 0.042760420590639114,
      "learning_rate": 9.092568932292655e-05,
      "loss": 0.0039,
      "step": 1624000
    },
    {
      "epoch": 0.0912821218808781,
      "grad_norm": 0.3226237893104553,
      "learning_rate": 9.092287819818149e-05,
      "loss": 0.0038,
      "step": 1624500
    },
    {
      "epoch": 0.09131021733236498,
      "grad_norm": 0.5407249927520752,
      "learning_rate": 9.092006707343642e-05,
      "loss": 0.004,
      "step": 1625000
    },
    {
      "epoch": 0.09133831278385186,
      "grad_norm": 0.14052025973796844,
      "learning_rate": 9.091725594869136e-05,
      "loss": 0.0042,
      "step": 1625500
    },
    {
      "epoch": 0.09136640823533874,
      "grad_norm": 0.40852752327919006,
      "learning_rate": 9.091444482394629e-05,
      "loss": 0.0042,
      "step": 1626000
    },
    {
      "epoch": 0.09139450368682563,
      "grad_norm": 0.22088949382305145,
      "learning_rate": 9.091163369920122e-05,
      "loss": 0.0036,
      "step": 1626500
    },
    {
      "epoch": 0.09142259913831251,
      "grad_norm": 0.32434219121932983,
      "learning_rate": 9.090882257445616e-05,
      "loss": 0.0036,
      "step": 1627000
    },
    {
      "epoch": 0.09145069458979939,
      "grad_norm": 0.7520169615745544,
      "learning_rate": 9.090601144971109e-05,
      "loss": 0.0039,
      "step": 1627500
    },
    {
      "epoch": 0.09147879004128627,
      "grad_norm": 0.8002349138259888,
      "learning_rate": 9.090320032496601e-05,
      "loss": 0.0034,
      "step": 1628000
    },
    {
      "epoch": 0.09150688549277315,
      "grad_norm": 0.12618744373321533,
      "learning_rate": 9.090038920022096e-05,
      "loss": 0.004,
      "step": 1628500
    },
    {
      "epoch": 0.09153498094426003,
      "grad_norm": 0.02668565697968006,
      "learning_rate": 9.08975780754759e-05,
      "loss": 0.0035,
      "step": 1629000
    },
    {
      "epoch": 0.09156307639574691,
      "grad_norm": 0.18338651955127716,
      "learning_rate": 9.089476695073083e-05,
      "loss": 0.0039,
      "step": 1629500
    },
    {
      "epoch": 0.0915911718472338,
      "grad_norm": 0.028676684945821762,
      "learning_rate": 9.089195582598576e-05,
      "loss": 0.0036,
      "step": 1630000
    },
    {
      "epoch": 0.0915911718472338,
      "eval_loss": 0.001111685298383236,
      "eval_runtime": 20.0399,
      "eval_samples_per_second": 4990.036,
      "eval_steps_per_second": 77.994,
      "step": 1630000
    },
    {
      "epoch": 0.09161926729872068,
      "grad_norm": 0.09622747451066971,
      "learning_rate": 9.088914470124068e-05,
      "loss": 0.0041,
      "step": 1630500
    },
    {
      "epoch": 0.09164736275020756,
      "grad_norm": 0.10534439235925674,
      "learning_rate": 9.088633357649563e-05,
      "loss": 0.0038,
      "step": 1631000
    },
    {
      "epoch": 0.09167545820169444,
      "grad_norm": 0.07189839333295822,
      "learning_rate": 9.088352245175055e-05,
      "loss": 0.004,
      "step": 1631500
    },
    {
      "epoch": 0.09170355365318132,
      "grad_norm": 0.16451457142829895,
      "learning_rate": 9.08807113270055e-05,
      "loss": 0.0038,
      "step": 1632000
    },
    {
      "epoch": 0.0917316491046682,
      "grad_norm": 0.058964263647794724,
      "learning_rate": 9.087790020226042e-05,
      "loss": 0.0043,
      "step": 1632500
    },
    {
      "epoch": 0.09175974455615508,
      "grad_norm": 0.11678600311279297,
      "learning_rate": 9.087508907751537e-05,
      "loss": 0.0037,
      "step": 1633000
    },
    {
      "epoch": 0.09178784000764197,
      "grad_norm": 0.36869704723358154,
      "learning_rate": 9.08722779527703e-05,
      "loss": 0.0039,
      "step": 1633500
    },
    {
      "epoch": 0.09181593545912885,
      "grad_norm": 0.40280812978744507,
      "learning_rate": 9.086946682802522e-05,
      "loss": 0.0037,
      "step": 1634000
    },
    {
      "epoch": 0.09184403091061573,
      "grad_norm": 0.4091412425041199,
      "learning_rate": 9.086665570328017e-05,
      "loss": 0.004,
      "step": 1634500
    },
    {
      "epoch": 0.09187212636210261,
      "grad_norm": 0.26739439368247986,
      "learning_rate": 9.086384457853509e-05,
      "loss": 0.0042,
      "step": 1635000
    },
    {
      "epoch": 0.09190022181358949,
      "grad_norm": 0.3601144254207611,
      "learning_rate": 9.086103345379004e-05,
      "loss": 0.0038,
      "step": 1635500
    },
    {
      "epoch": 0.09192831726507637,
      "grad_norm": 0.17623065412044525,
      "learning_rate": 9.085822232904496e-05,
      "loss": 0.0039,
      "step": 1636000
    },
    {
      "epoch": 0.09195641271656325,
      "grad_norm": 0.7607191801071167,
      "learning_rate": 9.08554112042999e-05,
      "loss": 0.0039,
      "step": 1636500
    },
    {
      "epoch": 0.09198450816805014,
      "grad_norm": 0.08754992485046387,
      "learning_rate": 9.085260007955484e-05,
      "loss": 0.0036,
      "step": 1637000
    },
    {
      "epoch": 0.09201260361953702,
      "grad_norm": 0.05801717936992645,
      "learning_rate": 9.084978895480976e-05,
      "loss": 0.0037,
      "step": 1637500
    },
    {
      "epoch": 0.0920406990710239,
      "grad_norm": 0.48198381066322327,
      "learning_rate": 9.084697783006471e-05,
      "loss": 0.0036,
      "step": 1638000
    },
    {
      "epoch": 0.09206879452251078,
      "grad_norm": 0.11556106805801392,
      "learning_rate": 9.084416670531963e-05,
      "loss": 0.004,
      "step": 1638500
    },
    {
      "epoch": 0.09209688997399766,
      "grad_norm": 0.2681701183319092,
      "learning_rate": 9.084135558057457e-05,
      "loss": 0.0039,
      "step": 1639000
    },
    {
      "epoch": 0.09212498542548454,
      "grad_norm": 0.0984814241528511,
      "learning_rate": 9.08385444558295e-05,
      "loss": 0.0038,
      "step": 1639500
    },
    {
      "epoch": 0.09215308087697142,
      "grad_norm": 0.05195704102516174,
      "learning_rate": 9.083573333108444e-05,
      "loss": 0.004,
      "step": 1640000
    },
    {
      "epoch": 0.09215308087697142,
      "eval_loss": 0.0011270364047959447,
      "eval_runtime": 19.7789,
      "eval_samples_per_second": 5055.902,
      "eval_steps_per_second": 79.024,
      "step": 1640000
    },
    {
      "epoch": 0.0921811763284583,
      "grad_norm": 0.02731511928141117,
      "learning_rate": 9.083292220633938e-05,
      "loss": 0.0034,
      "step": 1640500
    },
    {
      "epoch": 0.09220927177994519,
      "grad_norm": 0.28648170828819275,
      "learning_rate": 9.08301110815943e-05,
      "loss": 0.0041,
      "step": 1641000
    },
    {
      "epoch": 0.09223736723143207,
      "grad_norm": 1.5491225719451904,
      "learning_rate": 9.082729995684924e-05,
      "loss": 0.0042,
      "step": 1641500
    },
    {
      "epoch": 0.09226546268291895,
      "grad_norm": 0.7169439792633057,
      "learning_rate": 9.082448883210417e-05,
      "loss": 0.0041,
      "step": 1642000
    },
    {
      "epoch": 0.09229355813440583,
      "grad_norm": 0.09758022427558899,
      "learning_rate": 9.082167770735911e-05,
      "loss": 0.0038,
      "step": 1642500
    },
    {
      "epoch": 0.09232165358589271,
      "grad_norm": 0.30884164571762085,
      "learning_rate": 9.081886658261404e-05,
      "loss": 0.0041,
      "step": 1643000
    },
    {
      "epoch": 0.0923497490373796,
      "grad_norm": 0.053802650421857834,
      "learning_rate": 9.081605545786898e-05,
      "loss": 0.0036,
      "step": 1643500
    },
    {
      "epoch": 0.09237784448886648,
      "grad_norm": 0.01769903302192688,
      "learning_rate": 9.081324433312391e-05,
      "loss": 0.0036,
      "step": 1644000
    },
    {
      "epoch": 0.09240593994035336,
      "grad_norm": 0.19841524958610535,
      "learning_rate": 9.081043320837884e-05,
      "loss": 0.0038,
      "step": 1644500
    },
    {
      "epoch": 0.09243403539184024,
      "grad_norm": 0.0785452127456665,
      "learning_rate": 9.080762208363378e-05,
      "loss": 0.0035,
      "step": 1645000
    },
    {
      "epoch": 0.09246213084332712,
      "grad_norm": 0.38527944684028625,
      "learning_rate": 9.080481095888871e-05,
      "loss": 0.0039,
      "step": 1645500
    },
    {
      "epoch": 0.092490226294814,
      "grad_norm": 0.004699893295764923,
      "learning_rate": 9.080199983414365e-05,
      "loss": 0.0035,
      "step": 1646000
    },
    {
      "epoch": 0.09251832174630088,
      "grad_norm": 0.17585815489292145,
      "learning_rate": 9.079918870939858e-05,
      "loss": 0.0036,
      "step": 1646500
    },
    {
      "epoch": 0.09254641719778776,
      "grad_norm": 0.31323838233947754,
      "learning_rate": 9.079637758465351e-05,
      "loss": 0.0038,
      "step": 1647000
    },
    {
      "epoch": 0.09257451264927465,
      "grad_norm": 0.06258762627840042,
      "learning_rate": 9.079356645990844e-05,
      "loss": 0.0039,
      "step": 1647500
    },
    {
      "epoch": 0.09260260810076153,
      "grad_norm": 0.024574147537350655,
      "learning_rate": 9.079075533516338e-05,
      "loss": 0.0041,
      "step": 1648000
    },
    {
      "epoch": 0.09263070355224841,
      "grad_norm": 0.014131389558315277,
      "learning_rate": 9.078794421041832e-05,
      "loss": 0.0038,
      "step": 1648500
    },
    {
      "epoch": 0.09265879900373529,
      "grad_norm": 0.16082745790481567,
      "learning_rate": 9.078513308567325e-05,
      "loss": 0.0037,
      "step": 1649000
    },
    {
      "epoch": 0.09268689445522217,
      "grad_norm": 0.1282658874988556,
      "learning_rate": 9.078232196092819e-05,
      "loss": 0.0041,
      "step": 1649500
    },
    {
      "epoch": 0.09271498990670905,
      "grad_norm": 0.15228071808815002,
      "learning_rate": 9.077951083618311e-05,
      "loss": 0.0037,
      "step": 1650000
    },
    {
      "epoch": 0.09271498990670905,
      "eval_loss": 0.0011510018957778811,
      "eval_runtime": 20.3546,
      "eval_samples_per_second": 4912.889,
      "eval_steps_per_second": 76.788,
      "step": 1650000
    },
    {
      "epoch": 0.09274308535819593,
      "grad_norm": 0.01350729912519455,
      "learning_rate": 9.077669971143805e-05,
      "loss": 0.0037,
      "step": 1650500
    },
    {
      "epoch": 0.09277118080968282,
      "grad_norm": 0.01881069876253605,
      "learning_rate": 9.077388858669298e-05,
      "loss": 0.0038,
      "step": 1651000
    },
    {
      "epoch": 0.0927992762611697,
      "grad_norm": 0.034835513681173325,
      "learning_rate": 9.077107746194792e-05,
      "loss": 0.0042,
      "step": 1651500
    },
    {
      "epoch": 0.09282737171265658,
      "grad_norm": 0.05142775923013687,
      "learning_rate": 9.076826633720286e-05,
      "loss": 0.0042,
      "step": 1652000
    },
    {
      "epoch": 0.09285546716414346,
      "grad_norm": 0.5625782608985901,
      "learning_rate": 9.076545521245778e-05,
      "loss": 0.004,
      "step": 1652500
    },
    {
      "epoch": 0.09288356261563034,
      "grad_norm": 0.23918431997299194,
      "learning_rate": 9.076264408771273e-05,
      "loss": 0.0034,
      "step": 1653000
    },
    {
      "epoch": 0.09291165806711722,
      "grad_norm": 0.04015732556581497,
      "learning_rate": 9.075983296296765e-05,
      "loss": 0.0038,
      "step": 1653500
    },
    {
      "epoch": 0.0929397535186041,
      "grad_norm": 0.12529486417770386,
      "learning_rate": 9.07570218382226e-05,
      "loss": 0.0038,
      "step": 1654000
    },
    {
      "epoch": 0.09296784897009099,
      "grad_norm": 0.3505423367023468,
      "learning_rate": 9.075421071347752e-05,
      "loss": 0.0037,
      "step": 1654500
    },
    {
      "epoch": 0.09299594442157787,
      "grad_norm": 0.43923860788345337,
      "learning_rate": 9.075139958873245e-05,
      "loss": 0.0036,
      "step": 1655000
    },
    {
      "epoch": 0.09302403987306475,
      "grad_norm": 0.12877005338668823,
      "learning_rate": 9.074858846398738e-05,
      "loss": 0.0039,
      "step": 1655500
    },
    {
      "epoch": 0.09305213532455163,
      "grad_norm": 0.19561313092708588,
      "learning_rate": 9.074577733924232e-05,
      "loss": 0.0038,
      "step": 1656000
    },
    {
      "epoch": 0.09308023077603851,
      "grad_norm": 0.0311676524579525,
      "learning_rate": 9.074296621449727e-05,
      "loss": 0.0041,
      "step": 1656500
    },
    {
      "epoch": 0.09310832622752539,
      "grad_norm": 0.6360352635383606,
      "learning_rate": 9.074015508975219e-05,
      "loss": 0.0037,
      "step": 1657000
    },
    {
      "epoch": 0.09313642167901227,
      "grad_norm": 0.059029433876276016,
      "learning_rate": 9.073734396500712e-05,
      "loss": 0.0038,
      "step": 1657500
    },
    {
      "epoch": 0.09316451713049916,
      "grad_norm": 0.09478097409009933,
      "learning_rate": 9.073453284026205e-05,
      "loss": 0.0039,
      "step": 1658000
    },
    {
      "epoch": 0.09319261258198604,
      "grad_norm": 0.16068530082702637,
      "learning_rate": 9.073172171551699e-05,
      "loss": 0.0039,
      "step": 1658500
    },
    {
      "epoch": 0.09322070803347292,
      "grad_norm": 0.13120394945144653,
      "learning_rate": 9.072891059077192e-05,
      "loss": 0.0036,
      "step": 1659000
    },
    {
      "epoch": 0.0932488034849598,
      "grad_norm": 0.021925626322627068,
      "learning_rate": 9.072609946602686e-05,
      "loss": 0.004,
      "step": 1659500
    },
    {
      "epoch": 0.09327689893644668,
      "grad_norm": 0.48453500866889954,
      "learning_rate": 9.072328834128179e-05,
      "loss": 0.0039,
      "step": 1660000
    },
    {
      "epoch": 0.09327689893644668,
      "eval_loss": 0.0012053397949784994,
      "eval_runtime": 21.1256,
      "eval_samples_per_second": 4733.584,
      "eval_steps_per_second": 73.986,
      "step": 1660000
    },
    {
      "epoch": 0.09330499438793356,
      "grad_norm": 0.36683389544487,
      "learning_rate": 9.072047721653673e-05,
      "loss": 0.0034,
      "step": 1660500
    },
    {
      "epoch": 0.09333308983942044,
      "grad_norm": 0.05619305744767189,
      "learning_rate": 9.071766609179166e-05,
      "loss": 0.004,
      "step": 1661000
    },
    {
      "epoch": 0.09336118529090733,
      "grad_norm": 0.06096334010362625,
      "learning_rate": 9.07148549670466e-05,
      "loss": 0.0033,
      "step": 1661500
    },
    {
      "epoch": 0.0933892807423942,
      "grad_norm": 0.008027797564864159,
      "learning_rate": 9.071204384230153e-05,
      "loss": 0.0042,
      "step": 1662000
    },
    {
      "epoch": 0.09341737619388109,
      "grad_norm": 0.09831204265356064,
      "learning_rate": 9.070923271755646e-05,
      "loss": 0.0037,
      "step": 1662500
    },
    {
      "epoch": 0.09344547164536797,
      "grad_norm": 0.05031588673591614,
      "learning_rate": 9.07064215928114e-05,
      "loss": 0.0039,
      "step": 1663000
    },
    {
      "epoch": 0.09347356709685485,
      "grad_norm": 0.18531730771064758,
      "learning_rate": 9.070361046806632e-05,
      "loss": 0.0038,
      "step": 1663500
    },
    {
      "epoch": 0.09350166254834173,
      "grad_norm": 0.17584511637687683,
      "learning_rate": 9.070079934332127e-05,
      "loss": 0.0031,
      "step": 1664000
    },
    {
      "epoch": 0.09352975799982861,
      "grad_norm": 0.4415457248687744,
      "learning_rate": 9.06979882185762e-05,
      "loss": 0.0039,
      "step": 1664500
    },
    {
      "epoch": 0.0935578534513155,
      "grad_norm": 0.4342288672924042,
      "learning_rate": 9.069517709383113e-05,
      "loss": 0.0041,
      "step": 1665000
    },
    {
      "epoch": 0.09358594890280238,
      "grad_norm": 0.9068686366081238,
      "learning_rate": 9.069236596908607e-05,
      "loss": 0.004,
      "step": 1665500
    },
    {
      "epoch": 0.09361404435428926,
      "grad_norm": 0.14636477828025818,
      "learning_rate": 9.068955484434099e-05,
      "loss": 0.0044,
      "step": 1666000
    },
    {
      "epoch": 0.09364213980577614,
      "grad_norm": 0.017717763781547546,
      "learning_rate": 9.068674371959594e-05,
      "loss": 0.004,
      "step": 1666500
    },
    {
      "epoch": 0.09367023525726302,
      "grad_norm": 0.1433444321155548,
      "learning_rate": 9.068393259485086e-05,
      "loss": 0.0041,
      "step": 1667000
    },
    {
      "epoch": 0.0936983307087499,
      "grad_norm": 0.24122369289398193,
      "learning_rate": 9.06811214701058e-05,
      "loss": 0.0039,
      "step": 1667500
    },
    {
      "epoch": 0.09372642616023678,
      "grad_norm": 0.11704442650079727,
      "learning_rate": 9.067831034536074e-05,
      "loss": 0.0037,
      "step": 1668000
    },
    {
      "epoch": 0.09375452161172367,
      "grad_norm": 0.14338047802448273,
      "learning_rate": 9.067549922061567e-05,
      "loss": 0.004,
      "step": 1668500
    },
    {
      "epoch": 0.09378261706321055,
      "grad_norm": 0.3693179190158844,
      "learning_rate": 9.067268809587061e-05,
      "loss": 0.004,
      "step": 1669000
    },
    {
      "epoch": 0.09381071251469743,
      "grad_norm": 0.0974908396601677,
      "learning_rate": 9.066987697112553e-05,
      "loss": 0.0036,
      "step": 1669500
    },
    {
      "epoch": 0.09383880796618431,
      "grad_norm": 0.012516598217189312,
      "learning_rate": 9.066706584638048e-05,
      "loss": 0.0039,
      "step": 1670000
    },
    {
      "epoch": 0.09383880796618431,
      "eval_loss": 0.0010779352160170674,
      "eval_runtime": 20.7714,
      "eval_samples_per_second": 4814.319,
      "eval_steps_per_second": 75.248,
      "step": 1670000
    },
    {
      "epoch": 0.09386690341767119,
      "grad_norm": 0.3532401919364929,
      "learning_rate": 9.06642547216354e-05,
      "loss": 0.0037,
      "step": 1670500
    },
    {
      "epoch": 0.09389499886915807,
      "grad_norm": 0.4755534529685974,
      "learning_rate": 9.066144359689035e-05,
      "loss": 0.004,
      "step": 1671000
    },
    {
      "epoch": 0.09392309432064495,
      "grad_norm": 0.06670556962490082,
      "learning_rate": 9.065863247214528e-05,
      "loss": 0.0036,
      "step": 1671500
    },
    {
      "epoch": 0.09395118977213184,
      "grad_norm": 0.12545372545719147,
      "learning_rate": 9.06558213474002e-05,
      "loss": 0.0036,
      "step": 1672000
    },
    {
      "epoch": 0.09397928522361872,
      "grad_norm": 0.21401701867580414,
      "learning_rate": 9.065301022265515e-05,
      "loss": 0.0038,
      "step": 1672500
    },
    {
      "epoch": 0.0940073806751056,
      "grad_norm": 0.014961475506424904,
      "learning_rate": 9.065019909791007e-05,
      "loss": 0.0038,
      "step": 1673000
    },
    {
      "epoch": 0.09403547612659248,
      "grad_norm": 0.2747545838356018,
      "learning_rate": 9.064738797316502e-05,
      "loss": 0.004,
      "step": 1673500
    },
    {
      "epoch": 0.09406357157807936,
      "grad_norm": 0.3102858066558838,
      "learning_rate": 9.064457684841994e-05,
      "loss": 0.0037,
      "step": 1674000
    },
    {
      "epoch": 0.09409166702956624,
      "grad_norm": 0.014659751206636429,
      "learning_rate": 9.064176572367487e-05,
      "loss": 0.0041,
      "step": 1674500
    },
    {
      "epoch": 0.09411976248105312,
      "grad_norm": 0.041198354214429855,
      "learning_rate": 9.06389545989298e-05,
      "loss": 0.0038,
      "step": 1675000
    },
    {
      "epoch": 0.09414785793254,
      "grad_norm": 0.06286726891994476,
      "learning_rate": 9.063614347418474e-05,
      "loss": 0.0037,
      "step": 1675500
    },
    {
      "epoch": 0.09417595338402689,
      "grad_norm": 0.11926185339689255,
      "learning_rate": 9.063333234943969e-05,
      "loss": 0.0039,
      "step": 1676000
    },
    {
      "epoch": 0.09420404883551377,
      "grad_norm": 0.21027269959449768,
      "learning_rate": 9.063052122469461e-05,
      "loss": 0.0038,
      "step": 1676500
    },
    {
      "epoch": 0.09423214428700065,
      "grad_norm": 0.5355750322341919,
      "learning_rate": 9.062771009994954e-05,
      "loss": 0.0035,
      "step": 1677000
    },
    {
      "epoch": 0.09426023973848753,
      "grad_norm": 0.08149431645870209,
      "learning_rate": 9.062489897520448e-05,
      "loss": 0.0036,
      "step": 1677500
    },
    {
      "epoch": 0.09428833518997443,
      "grad_norm": 0.47912994027137756,
      "learning_rate": 9.062208785045941e-05,
      "loss": 0.0039,
      "step": 1678000
    },
    {
      "epoch": 0.09431643064146131,
      "grad_norm": 0.04374375194311142,
      "learning_rate": 9.061927672571435e-05,
      "loss": 0.0042,
      "step": 1678500
    },
    {
      "epoch": 0.09434452609294819,
      "grad_norm": 0.059529103338718414,
      "learning_rate": 9.061646560096928e-05,
      "loss": 0.0037,
      "step": 1679000
    },
    {
      "epoch": 0.09437262154443507,
      "grad_norm": 0.05934026092290878,
      "learning_rate": 9.061365447622421e-05,
      "loss": 0.0036,
      "step": 1679500
    },
    {
      "epoch": 0.09440071699592195,
      "grad_norm": 0.17720487713813782,
      "learning_rate": 9.061084335147915e-05,
      "loss": 0.0039,
      "step": 1680000
    },
    {
      "epoch": 0.09440071699592195,
      "eval_loss": 0.0010851974366232753,
      "eval_runtime": 21.0829,
      "eval_samples_per_second": 4743.174,
      "eval_steps_per_second": 74.136,
      "step": 1680000
    },
    {
      "epoch": 0.09442881244740883,
      "grad_norm": 0.2353086918592453,
      "learning_rate": 9.060803222673408e-05,
      "loss": 0.0038,
      "step": 1680500
    },
    {
      "epoch": 0.09445690789889571,
      "grad_norm": 0.06655671447515488,
      "learning_rate": 9.060522110198902e-05,
      "loss": 0.004,
      "step": 1681000
    },
    {
      "epoch": 0.0944850033503826,
      "grad_norm": 0.012160133570432663,
      "learning_rate": 9.060240997724395e-05,
      "loss": 0.0038,
      "step": 1681500
    },
    {
      "epoch": 0.09451309880186948,
      "grad_norm": 0.30951499938964844,
      "learning_rate": 9.059959885249889e-05,
      "loss": 0.0036,
      "step": 1682000
    },
    {
      "epoch": 0.09454119425335636,
      "grad_norm": 0.06207214668393135,
      "learning_rate": 9.059678772775382e-05,
      "loss": 0.0037,
      "step": 1682500
    },
    {
      "epoch": 0.09456928970484324,
      "grad_norm": 0.5031428933143616,
      "learning_rate": 9.059397660300875e-05,
      "loss": 0.0039,
      "step": 1683000
    },
    {
      "epoch": 0.09459738515633012,
      "grad_norm": 0.1271180957555771,
      "learning_rate": 9.059116547826369e-05,
      "loss": 0.0039,
      "step": 1683500
    },
    {
      "epoch": 0.094625480607817,
      "grad_norm": 0.4332607686519623,
      "learning_rate": 9.058835435351862e-05,
      "loss": 0.0035,
      "step": 1684000
    },
    {
      "epoch": 0.09465357605930388,
      "grad_norm": 0.27462053298950195,
      "learning_rate": 9.058554322877356e-05,
      "loss": 0.0041,
      "step": 1684500
    },
    {
      "epoch": 0.09468167151079077,
      "grad_norm": 0.13431254029273987,
      "learning_rate": 9.058273210402849e-05,
      "loss": 0.0039,
      "step": 1685000
    },
    {
      "epoch": 0.09470976696227765,
      "grad_norm": 0.030169473960995674,
      "learning_rate": 9.057992097928341e-05,
      "loss": 0.0041,
      "step": 1685500
    },
    {
      "epoch": 0.09473786241376453,
      "grad_norm": 0.006047951523214579,
      "learning_rate": 9.057710985453836e-05,
      "loss": 0.0038,
      "step": 1686000
    },
    {
      "epoch": 0.09476595786525141,
      "grad_norm": 0.04722347483038902,
      "learning_rate": 9.057429872979328e-05,
      "loss": 0.0035,
      "step": 1686500
    },
    {
      "epoch": 0.09479405331673829,
      "grad_norm": 0.3195975720882416,
      "learning_rate": 9.057148760504823e-05,
      "loss": 0.0038,
      "step": 1687000
    },
    {
      "epoch": 0.09482214876822517,
      "grad_norm": 0.04599999263882637,
      "learning_rate": 9.056867648030316e-05,
      "loss": 0.0039,
      "step": 1687500
    },
    {
      "epoch": 0.09485024421971205,
      "grad_norm": 0.11807280033826828,
      "learning_rate": 9.056586535555808e-05,
      "loss": 0.0034,
      "step": 1688000
    },
    {
      "epoch": 0.09487833967119894,
      "grad_norm": 0.12876634299755096,
      "learning_rate": 9.056305423081303e-05,
      "loss": 0.0039,
      "step": 1688500
    },
    {
      "epoch": 0.09490643512268582,
      "grad_norm": 0.21091534197330475,
      "learning_rate": 9.056024310606795e-05,
      "loss": 0.0037,
      "step": 1689000
    },
    {
      "epoch": 0.0949345305741727,
      "grad_norm": 0.05654275789856911,
      "learning_rate": 9.05574319813229e-05,
      "loss": 0.0042,
      "step": 1689500
    },
    {
      "epoch": 0.09496262602565958,
      "grad_norm": 0.14987827837467194,
      "learning_rate": 9.055462085657782e-05,
      "loss": 0.0036,
      "step": 1690000
    },
    {
      "epoch": 0.09496262602565958,
      "eval_loss": 0.0010676528327167034,
      "eval_runtime": 20.4912,
      "eval_samples_per_second": 4880.136,
      "eval_steps_per_second": 76.277,
      "step": 1690000
    },
    {
      "epoch": 0.09499072147714646,
      "grad_norm": 0.05156060680747032,
      "learning_rate": 9.055180973183275e-05,
      "loss": 0.0036,
      "step": 1690500
    },
    {
      "epoch": 0.09501881692863334,
      "grad_norm": 0.25777730345726013,
      "learning_rate": 9.05489986070877e-05,
      "loss": 0.004,
      "step": 1691000
    },
    {
      "epoch": 0.09504691238012022,
      "grad_norm": 0.2536044418811798,
      "learning_rate": 9.054618748234262e-05,
      "loss": 0.0039,
      "step": 1691500
    },
    {
      "epoch": 0.0950750078316071,
      "grad_norm": 0.0073243482038378716,
      "learning_rate": 9.054337635759757e-05,
      "loss": 0.0041,
      "step": 1692000
    },
    {
      "epoch": 0.09510310328309399,
      "grad_norm": 0.06245224177837372,
      "learning_rate": 9.054056523285249e-05,
      "loss": 0.0038,
      "step": 1692500
    },
    {
      "epoch": 0.09513119873458087,
      "grad_norm": 0.29626139998435974,
      "learning_rate": 9.053775410810742e-05,
      "loss": 0.0035,
      "step": 1693000
    },
    {
      "epoch": 0.09515929418606775,
      "grad_norm": 0.13315682113170624,
      "learning_rate": 9.053494298336236e-05,
      "loss": 0.0038,
      "step": 1693500
    },
    {
      "epoch": 0.09518738963755463,
      "grad_norm": 0.21530123054981232,
      "learning_rate": 9.05321318586173e-05,
      "loss": 0.004,
      "step": 1694000
    },
    {
      "epoch": 0.09521548508904151,
      "grad_norm": 0.23705936968326569,
      "learning_rate": 9.052932073387223e-05,
      "loss": 0.0038,
      "step": 1694500
    },
    {
      "epoch": 0.0952435805405284,
      "grad_norm": 0.07795345038175583,
      "learning_rate": 9.052650960912716e-05,
      "loss": 0.0037,
      "step": 1695000
    },
    {
      "epoch": 0.09527167599201528,
      "grad_norm": 0.2729845643043518,
      "learning_rate": 9.05236984843821e-05,
      "loss": 0.0037,
      "step": 1695500
    },
    {
      "epoch": 0.09529977144350216,
      "grad_norm": 0.025170067325234413,
      "learning_rate": 9.052088735963703e-05,
      "loss": 0.0038,
      "step": 1696000
    },
    {
      "epoch": 0.09532786689498904,
      "grad_norm": 0.28268730640411377,
      "learning_rate": 9.051807623489196e-05,
      "loss": 0.0041,
      "step": 1696500
    },
    {
      "epoch": 0.09535596234647592,
      "grad_norm": 0.6229880452156067,
      "learning_rate": 9.05152651101469e-05,
      "loss": 0.0039,
      "step": 1697000
    },
    {
      "epoch": 0.0953840577979628,
      "grad_norm": 0.18185074627399445,
      "learning_rate": 9.051245398540183e-05,
      "loss": 0.0041,
      "step": 1697500
    },
    {
      "epoch": 0.09541215324944968,
      "grad_norm": 0.05852361395955086,
      "learning_rate": 9.050964286065677e-05,
      "loss": 0.004,
      "step": 1698000
    },
    {
      "epoch": 0.09544024870093656,
      "grad_norm": 0.027844125404953957,
      "learning_rate": 9.05068317359117e-05,
      "loss": 0.0038,
      "step": 1698500
    },
    {
      "epoch": 0.09546834415242345,
      "grad_norm": 0.10008593648672104,
      "learning_rate": 9.050402061116664e-05,
      "loss": 0.0037,
      "step": 1699000
    },
    {
      "epoch": 0.09549643960391033,
      "grad_norm": 0.5320420265197754,
      "learning_rate": 9.050120948642157e-05,
      "loss": 0.0033,
      "step": 1699500
    },
    {
      "epoch": 0.09552453505539721,
      "grad_norm": 0.03290066868066788,
      "learning_rate": 9.04983983616765e-05,
      "loss": 0.0039,
      "step": 1700000
    },
    {
      "epoch": 0.09552453505539721,
      "eval_loss": 0.0011868831934407353,
      "eval_runtime": 20.6044,
      "eval_samples_per_second": 4853.338,
      "eval_steps_per_second": 75.858,
      "step": 1700000
    },
    {
      "epoch": 0.09555263050688409,
      "grad_norm": 0.2259746491909027,
      "learning_rate": 9.049558723693144e-05,
      "loss": 0.004,
      "step": 1700500
    },
    {
      "epoch": 0.09558072595837097,
      "grad_norm": 0.5864883661270142,
      "learning_rate": 9.049277611218637e-05,
      "loss": 0.0038,
      "step": 1701000
    },
    {
      "epoch": 0.09560882140985785,
      "grad_norm": 0.36565962433815,
      "learning_rate": 9.048996498744131e-05,
      "loss": 0.0035,
      "step": 1701500
    },
    {
      "epoch": 0.09563691686134473,
      "grad_norm": 0.28503426909446716,
      "learning_rate": 9.048715386269624e-05,
      "loss": 0.0038,
      "step": 1702000
    },
    {
      "epoch": 0.09566501231283162,
      "grad_norm": 0.09494578093290329,
      "learning_rate": 9.048434273795118e-05,
      "loss": 0.0036,
      "step": 1702500
    },
    {
      "epoch": 0.0956931077643185,
      "grad_norm": 0.2752651274204254,
      "learning_rate": 9.048153161320611e-05,
      "loss": 0.0035,
      "step": 1703000
    },
    {
      "epoch": 0.09572120321580538,
      "grad_norm": 0.5037176609039307,
      "learning_rate": 9.047872048846104e-05,
      "loss": 0.0037,
      "step": 1703500
    },
    {
      "epoch": 0.09574929866729226,
      "grad_norm": 0.1431761384010315,
      "learning_rate": 9.047590936371598e-05,
      "loss": 0.0041,
      "step": 1704000
    },
    {
      "epoch": 0.09577739411877914,
      "grad_norm": 0.1340865045785904,
      "learning_rate": 9.047309823897091e-05,
      "loss": 0.0038,
      "step": 1704500
    },
    {
      "epoch": 0.09580548957026602,
      "grad_norm": 0.11248308420181274,
      "learning_rate": 9.047028711422583e-05,
      "loss": 0.0037,
      "step": 1705000
    },
    {
      "epoch": 0.0958335850217529,
      "grad_norm": 0.25079163908958435,
      "learning_rate": 9.046747598948078e-05,
      "loss": 0.0039,
      "step": 1705500
    },
    {
      "epoch": 0.09586168047323979,
      "grad_norm": 0.02515585534274578,
      "learning_rate": 9.04646648647357e-05,
      "loss": 0.0038,
      "step": 1706000
    },
    {
      "epoch": 0.09588977592472667,
      "grad_norm": 0.22882865369319916,
      "learning_rate": 9.046185373999065e-05,
      "loss": 0.0035,
      "step": 1706500
    },
    {
      "epoch": 0.09591787137621355,
      "grad_norm": 0.05898139625787735,
      "learning_rate": 9.045904261524558e-05,
      "loss": 0.0037,
      "step": 1707000
    },
    {
      "epoch": 0.09594596682770043,
      "grad_norm": 0.12253257632255554,
      "learning_rate": 9.04562314905005e-05,
      "loss": 0.0036,
      "step": 1707500
    },
    {
      "epoch": 0.09597406227918731,
      "grad_norm": 0.45007601380348206,
      "learning_rate": 9.045342036575545e-05,
      "loss": 0.0041,
      "step": 1708000
    },
    {
      "epoch": 0.09600215773067419,
      "grad_norm": 0.16373538970947266,
      "learning_rate": 9.045060924101037e-05,
      "loss": 0.0037,
      "step": 1708500
    },
    {
      "epoch": 0.09603025318216107,
      "grad_norm": 0.24029554426670074,
      "learning_rate": 9.044779811626532e-05,
      "loss": 0.0039,
      "step": 1709000
    },
    {
      "epoch": 0.09605834863364796,
      "grad_norm": 0.250747412443161,
      "learning_rate": 9.044498699152024e-05,
      "loss": 0.004,
      "step": 1709500
    },
    {
      "epoch": 0.09608644408513484,
      "grad_norm": 0.2647465169429779,
      "learning_rate": 9.044217586677518e-05,
      "loss": 0.0038,
      "step": 1710000
    },
    {
      "epoch": 0.09608644408513484,
      "eval_loss": 0.001179430866613984,
      "eval_runtime": 21.1406,
      "eval_samples_per_second": 4730.225,
      "eval_steps_per_second": 73.933,
      "step": 1710000
    },
    {
      "epoch": 0.09611453953662172,
      "grad_norm": 0.05698367580771446,
      "learning_rate": 9.043936474203012e-05,
      "loss": 0.0039,
      "step": 1710500
    },
    {
      "epoch": 0.0961426349881086,
      "grad_norm": 0.38743332028388977,
      "learning_rate": 9.043655361728504e-05,
      "loss": 0.0039,
      "step": 1711000
    },
    {
      "epoch": 0.09617073043959548,
      "grad_norm": 0.009205064736306667,
      "learning_rate": 9.043374249253999e-05,
      "loss": 0.0037,
      "step": 1711500
    },
    {
      "epoch": 0.09619882589108236,
      "grad_norm": 0.021021319553256035,
      "learning_rate": 9.043093136779491e-05,
      "loss": 0.0038,
      "step": 1712000
    },
    {
      "epoch": 0.09622692134256924,
      "grad_norm": 0.23709367215633392,
      "learning_rate": 9.042812024304985e-05,
      "loss": 0.0041,
      "step": 1712500
    },
    {
      "epoch": 0.09625501679405613,
      "grad_norm": 0.3579992949962616,
      "learning_rate": 9.042530911830478e-05,
      "loss": 0.004,
      "step": 1713000
    },
    {
      "epoch": 0.096283112245543,
      "grad_norm": 0.1081274151802063,
      "learning_rate": 9.042249799355972e-05,
      "loss": 0.0035,
      "step": 1713500
    },
    {
      "epoch": 0.09631120769702989,
      "grad_norm": 0.1900496929883957,
      "learning_rate": 9.041968686881465e-05,
      "loss": 0.0038,
      "step": 1714000
    },
    {
      "epoch": 0.09633930314851677,
      "grad_norm": 0.03740813583135605,
      "learning_rate": 9.041687574406958e-05,
      "loss": 0.0033,
      "step": 1714500
    },
    {
      "epoch": 0.09636739860000365,
      "grad_norm": 0.05010242387652397,
      "learning_rate": 9.041406461932452e-05,
      "loss": 0.0038,
      "step": 1715000
    },
    {
      "epoch": 0.09639549405149053,
      "grad_norm": 0.5372081398963928,
      "learning_rate": 9.041125349457945e-05,
      "loss": 0.0038,
      "step": 1715500
    },
    {
      "epoch": 0.09642358950297741,
      "grad_norm": 0.01124121155589819,
      "learning_rate": 9.040844236983439e-05,
      "loss": 0.0037,
      "step": 1716000
    },
    {
      "epoch": 0.0964516849544643,
      "grad_norm": 0.18227040767669678,
      "learning_rate": 9.040563124508932e-05,
      "loss": 0.0034,
      "step": 1716500
    },
    {
      "epoch": 0.09647978040595118,
      "grad_norm": 0.36592814326286316,
      "learning_rate": 9.040282012034426e-05,
      "loss": 0.0038,
      "step": 1717000
    },
    {
      "epoch": 0.09650787585743806,
      "grad_norm": 0.10606935620307922,
      "learning_rate": 9.040000899559919e-05,
      "loss": 0.004,
      "step": 1717500
    },
    {
      "epoch": 0.09653597130892494,
      "grad_norm": 0.35441651940345764,
      "learning_rate": 9.039719787085412e-05,
      "loss": 0.0034,
      "step": 1718000
    },
    {
      "epoch": 0.09656406676041182,
      "grad_norm": 0.01358159352093935,
      "learning_rate": 9.039438674610906e-05,
      "loss": 0.0036,
      "step": 1718500
    },
    {
      "epoch": 0.0965921622118987,
      "grad_norm": 0.016130002215504646,
      "learning_rate": 9.039157562136399e-05,
      "loss": 0.0037,
      "step": 1719000
    },
    {
      "epoch": 0.09662025766338558,
      "grad_norm": 0.16727320849895477,
      "learning_rate": 9.038876449661893e-05,
      "loss": 0.0042,
      "step": 1719500
    },
    {
      "epoch": 0.09664835311487247,
      "grad_norm": 0.02771255187690258,
      "learning_rate": 9.038595337187386e-05,
      "loss": 0.0039,
      "step": 1720000
    },
    {
      "epoch": 0.09664835311487247,
      "eval_loss": 0.001053039450198412,
      "eval_runtime": 20.0664,
      "eval_samples_per_second": 4983.447,
      "eval_steps_per_second": 77.891,
      "step": 1720000
    },
    {
      "epoch": 0.09667644856635935,
      "grad_norm": 0.19996362924575806,
      "learning_rate": 9.03831422471288e-05,
      "loss": 0.0039,
      "step": 1720500
    },
    {
      "epoch": 0.09670454401784623,
      "grad_norm": 0.03603646159172058,
      "learning_rate": 9.038033112238372e-05,
      "loss": 0.0035,
      "step": 1721000
    },
    {
      "epoch": 0.09673263946933311,
      "grad_norm": 0.030411193147301674,
      "learning_rate": 9.037751999763866e-05,
      "loss": 0.0035,
      "step": 1721500
    },
    {
      "epoch": 0.09676073492081999,
      "grad_norm": 0.37538212537765503,
      "learning_rate": 9.03747088728936e-05,
      "loss": 0.0037,
      "step": 1722000
    },
    {
      "epoch": 0.09678883037230687,
      "grad_norm": 0.16437673568725586,
      "learning_rate": 9.037189774814853e-05,
      "loss": 0.0036,
      "step": 1722500
    },
    {
      "epoch": 0.09681692582379375,
      "grad_norm": 0.023029115051031113,
      "learning_rate": 9.036908662340347e-05,
      "loss": 0.0038,
      "step": 1723000
    },
    {
      "epoch": 0.09684502127528063,
      "grad_norm": 0.09980501979589462,
      "learning_rate": 9.036627549865839e-05,
      "loss": 0.0035,
      "step": 1723500
    },
    {
      "epoch": 0.09687311672676752,
      "grad_norm": 0.038480259478092194,
      "learning_rate": 9.036346437391333e-05,
      "loss": 0.0034,
      "step": 1724000
    },
    {
      "epoch": 0.0969012121782544,
      "grad_norm": 0.13794279098510742,
      "learning_rate": 9.036065324916826e-05,
      "loss": 0.0041,
      "step": 1724500
    },
    {
      "epoch": 0.09692930762974128,
      "grad_norm": 0.17784206569194794,
      "learning_rate": 9.03578421244232e-05,
      "loss": 0.0036,
      "step": 1725000
    },
    {
      "epoch": 0.09695740308122816,
      "grad_norm": 0.0700945109128952,
      "learning_rate": 9.035503099967812e-05,
      "loss": 0.0038,
      "step": 1725500
    },
    {
      "epoch": 0.09698549853271504,
      "grad_norm": 0.012129506096243858,
      "learning_rate": 9.035221987493306e-05,
      "loss": 0.0039,
      "step": 1726000
    },
    {
      "epoch": 0.09701359398420192,
      "grad_norm": 0.026597965508699417,
      "learning_rate": 9.0349408750188e-05,
      "loss": 0.0035,
      "step": 1726500
    },
    {
      "epoch": 0.0970416894356888,
      "grad_norm": 0.1979774832725525,
      "learning_rate": 9.034659762544293e-05,
      "loss": 0.0038,
      "step": 1727000
    },
    {
      "epoch": 0.09706978488717569,
      "grad_norm": 0.23298326134681702,
      "learning_rate": 9.034378650069787e-05,
      "loss": 0.0039,
      "step": 1727500
    },
    {
      "epoch": 0.09709788033866257,
      "grad_norm": 0.7912974953651428,
      "learning_rate": 9.03409753759528e-05,
      "loss": 0.0035,
      "step": 1728000
    },
    {
      "epoch": 0.09712597579014945,
      "grad_norm": 0.06296484172344208,
      "learning_rate": 9.033816425120773e-05,
      "loss": 0.0035,
      "step": 1728500
    },
    {
      "epoch": 0.09715407124163633,
      "grad_norm": 0.038529254496097565,
      "learning_rate": 9.033535312646266e-05,
      "loss": 0.0036,
      "step": 1729000
    },
    {
      "epoch": 0.09718216669312321,
      "grad_norm": 0.13511034846305847,
      "learning_rate": 9.03325420017176e-05,
      "loss": 0.0038,
      "step": 1729500
    },
    {
      "epoch": 0.0972102621446101,
      "grad_norm": 0.1507483422756195,
      "learning_rate": 9.032973087697255e-05,
      "loss": 0.0037,
      "step": 1730000
    },
    {
      "epoch": 0.0972102621446101,
      "eval_loss": 0.0010616765357553959,
      "eval_runtime": 19.9231,
      "eval_samples_per_second": 5019.302,
      "eval_steps_per_second": 78.452,
      "step": 1730000
    },
    {
      "epoch": 0.09723835759609697,
      "grad_norm": 0.3233445882797241,
      "learning_rate": 9.032691975222747e-05,
      "loss": 0.004,
      "step": 1730500
    },
    {
      "epoch": 0.09726645304758386,
      "grad_norm": 0.1611568033695221,
      "learning_rate": 9.03241086274824e-05,
      "loss": 0.0038,
      "step": 1731000
    },
    {
      "epoch": 0.09729454849907074,
      "grad_norm": 0.14250963926315308,
      "learning_rate": 9.032129750273733e-05,
      "loss": 0.0036,
      "step": 1731500
    },
    {
      "epoch": 0.09732264395055762,
      "grad_norm": 0.30502748489379883,
      "learning_rate": 9.031848637799227e-05,
      "loss": 0.0034,
      "step": 1732000
    },
    {
      "epoch": 0.0973507394020445,
      "grad_norm": 0.22021013498306274,
      "learning_rate": 9.03156752532472e-05,
      "loss": 0.0038,
      "step": 1732500
    },
    {
      "epoch": 0.09737883485353138,
      "grad_norm": 0.17573308944702148,
      "learning_rate": 9.031286412850214e-05,
      "loss": 0.0035,
      "step": 1733000
    },
    {
      "epoch": 0.09740693030501826,
      "grad_norm": 0.4316196143627167,
      "learning_rate": 9.031005300375707e-05,
      "loss": 0.0035,
      "step": 1733500
    },
    {
      "epoch": 0.09743502575650514,
      "grad_norm": 0.02424430474638939,
      "learning_rate": 9.0307241879012e-05,
      "loss": 0.0035,
      "step": 1734000
    },
    {
      "epoch": 0.09746312120799203,
      "grad_norm": 0.03152885288000107,
      "learning_rate": 9.030443075426694e-05,
      "loss": 0.0035,
      "step": 1734500
    },
    {
      "epoch": 0.09749121665947891,
      "grad_norm": 0.09809008240699768,
      "learning_rate": 9.030161962952187e-05,
      "loss": 0.0038,
      "step": 1735000
    },
    {
      "epoch": 0.09751931211096579,
      "grad_norm": 0.009033935144543648,
      "learning_rate": 9.029880850477681e-05,
      "loss": 0.0035,
      "step": 1735500
    },
    {
      "epoch": 0.09754740756245267,
      "grad_norm": 0.09594579041004181,
      "learning_rate": 9.029599738003174e-05,
      "loss": 0.004,
      "step": 1736000
    },
    {
      "epoch": 0.09757550301393955,
      "grad_norm": 0.054335225373506546,
      "learning_rate": 9.029318625528668e-05,
      "loss": 0.0037,
      "step": 1736500
    },
    {
      "epoch": 0.09760359846542643,
      "grad_norm": 0.16313336789608002,
      "learning_rate": 9.029037513054161e-05,
      "loss": 0.0042,
      "step": 1737000
    },
    {
      "epoch": 0.09763169391691331,
      "grad_norm": 0.6757809519767761,
      "learning_rate": 9.028756400579655e-05,
      "loss": 0.004,
      "step": 1737500
    },
    {
      "epoch": 0.0976597893684002,
      "grad_norm": 0.15209026634693146,
      "learning_rate": 9.028475288105148e-05,
      "loss": 0.004,
      "step": 1738000
    },
    {
      "epoch": 0.09768788481988708,
      "grad_norm": 0.017756061628460884,
      "learning_rate": 9.028194175630641e-05,
      "loss": 0.0038,
      "step": 1738500
    },
    {
      "epoch": 0.09771598027137397,
      "grad_norm": 0.017447059974074364,
      "learning_rate": 9.027913063156135e-05,
      "loss": 0.0038,
      "step": 1739000
    },
    {
      "epoch": 0.09774407572286085,
      "grad_norm": 0.22944927215576172,
      "learning_rate": 9.027631950681628e-05,
      "loss": 0.0036,
      "step": 1739500
    },
    {
      "epoch": 0.09777217117434774,
      "grad_norm": 0.01851493865251541,
      "learning_rate": 9.027350838207122e-05,
      "loss": 0.0037,
      "step": 1740000
    },
    {
      "epoch": 0.09777217117434774,
      "eval_loss": 0.0011831497540697455,
      "eval_runtime": 20.4494,
      "eval_samples_per_second": 4890.124,
      "eval_steps_per_second": 76.433,
      "step": 1740000
    },
    {
      "epoch": 0.09780026662583462,
      "grad_norm": 0.009510939009487629,
      "learning_rate": 9.027069725732614e-05,
      "loss": 0.0035,
      "step": 1740500
    },
    {
      "epoch": 0.0978283620773215,
      "grad_norm": 0.030114345252513885,
      "learning_rate": 9.026788613258109e-05,
      "loss": 0.0034,
      "step": 1741000
    },
    {
      "epoch": 0.09785645752880838,
      "grad_norm": 0.13891367614269257,
      "learning_rate": 9.026507500783602e-05,
      "loss": 0.0034,
      "step": 1741500
    },
    {
      "epoch": 0.09788455298029526,
      "grad_norm": 0.04501444846391678,
      "learning_rate": 9.026226388309095e-05,
      "loss": 0.0033,
      "step": 1742000
    },
    {
      "epoch": 0.09791264843178214,
      "grad_norm": 0.3054334223270416,
      "learning_rate": 9.025945275834589e-05,
      "loss": 0.0037,
      "step": 1742500
    },
    {
      "epoch": 0.09794074388326902,
      "grad_norm": 0.9423303604125977,
      "learning_rate": 9.025664163360081e-05,
      "loss": 0.0034,
      "step": 1743000
    },
    {
      "epoch": 0.0979688393347559,
      "grad_norm": 0.29860156774520874,
      "learning_rate": 9.025383050885576e-05,
      "loss": 0.0036,
      "step": 1743500
    },
    {
      "epoch": 0.09799693478624279,
      "grad_norm": 0.22581708431243896,
      "learning_rate": 9.025101938411068e-05,
      "loss": 0.0037,
      "step": 1744000
    },
    {
      "epoch": 0.09802503023772967,
      "grad_norm": 0.34436655044555664,
      "learning_rate": 9.024820825936562e-05,
      "loss": 0.0038,
      "step": 1744500
    },
    {
      "epoch": 0.09805312568921655,
      "grad_norm": 0.4354114830493927,
      "learning_rate": 9.024539713462055e-05,
      "loss": 0.0041,
      "step": 1745000
    },
    {
      "epoch": 0.09808122114070343,
      "grad_norm": 0.17330627143383026,
      "learning_rate": 9.024258600987548e-05,
      "loss": 0.0039,
      "step": 1745500
    },
    {
      "epoch": 0.09810931659219031,
      "grad_norm": 0.18181316554546356,
      "learning_rate": 9.023977488513043e-05,
      "loss": 0.0037,
      "step": 1746000
    },
    {
      "epoch": 0.0981374120436772,
      "grad_norm": 0.26685631275177,
      "learning_rate": 9.023696376038535e-05,
      "loss": 0.0038,
      "step": 1746500
    },
    {
      "epoch": 0.09816550749516408,
      "grad_norm": 0.09998143464326859,
      "learning_rate": 9.02341526356403e-05,
      "loss": 0.0034,
      "step": 1747000
    },
    {
      "epoch": 0.09819360294665096,
      "grad_norm": 0.21607975661754608,
      "learning_rate": 9.023134151089522e-05,
      "loss": 0.004,
      "step": 1747500
    },
    {
      "epoch": 0.09822169839813784,
      "grad_norm": 0.1845114380121231,
      "learning_rate": 9.022853038615015e-05,
      "loss": 0.0038,
      "step": 1748000
    },
    {
      "epoch": 0.09824979384962472,
      "grad_norm": 2.779167413711548,
      "learning_rate": 9.022571926140509e-05,
      "loss": 0.0036,
      "step": 1748500
    },
    {
      "epoch": 0.0982778893011116,
      "grad_norm": 0.26734548807144165,
      "learning_rate": 9.022290813666002e-05,
      "loss": 0.0037,
      "step": 1749000
    },
    {
      "epoch": 0.09830598475259848,
      "grad_norm": 0.4453035891056061,
      "learning_rate": 9.022009701191497e-05,
      "loss": 0.0041,
      "step": 1749500
    },
    {
      "epoch": 0.09833408020408536,
      "grad_norm": 0.3543255627155304,
      "learning_rate": 9.021728588716989e-05,
      "loss": 0.0033,
      "step": 1750000
    },
    {
      "epoch": 0.09833408020408536,
      "eval_loss": 0.0010238038375973701,
      "eval_runtime": 21.2529,
      "eval_samples_per_second": 4705.25,
      "eval_steps_per_second": 73.543,
      "step": 1750000
    },
    {
      "epoch": 0.09836217565557225,
      "grad_norm": 0.1288807988166809,
      "learning_rate": 9.021447476242482e-05,
      "loss": 0.004,
      "step": 1750500
    },
    {
      "epoch": 0.09839027110705913,
      "grad_norm": 0.08851966261863708,
      "learning_rate": 9.021166363767976e-05,
      "loss": 0.0042,
      "step": 1751000
    },
    {
      "epoch": 0.09841836655854601,
      "grad_norm": 0.055573564022779465,
      "learning_rate": 9.020885251293469e-05,
      "loss": 0.004,
      "step": 1751500
    },
    {
      "epoch": 0.09844646201003289,
      "grad_norm": 0.3167805075645447,
      "learning_rate": 9.020604138818963e-05,
      "loss": 0.0035,
      "step": 1752000
    },
    {
      "epoch": 0.09847455746151977,
      "grad_norm": 0.38681986927986145,
      "learning_rate": 9.020323026344456e-05,
      "loss": 0.0042,
      "step": 1752500
    },
    {
      "epoch": 0.09850265291300665,
      "grad_norm": 0.13252128660678864,
      "learning_rate": 9.02004191386995e-05,
      "loss": 0.0033,
      "step": 1753000
    },
    {
      "epoch": 0.09853074836449353,
      "grad_norm": 0.1633508950471878,
      "learning_rate": 9.019760801395443e-05,
      "loss": 0.0037,
      "step": 1753500
    },
    {
      "epoch": 0.09855884381598042,
      "grad_norm": 0.005502280779182911,
      "learning_rate": 9.019479688920936e-05,
      "loss": 0.0035,
      "step": 1754000
    },
    {
      "epoch": 0.0985869392674673,
      "grad_norm": 0.026514511555433273,
      "learning_rate": 9.01919857644643e-05,
      "loss": 0.0038,
      "step": 1754500
    },
    {
      "epoch": 0.09861503471895418,
      "grad_norm": 0.02529745176434517,
      "learning_rate": 9.018917463971923e-05,
      "loss": 0.0036,
      "step": 1755000
    },
    {
      "epoch": 0.09864313017044106,
      "grad_norm": 0.3003075420856476,
      "learning_rate": 9.018636351497416e-05,
      "loss": 0.0034,
      "step": 1755500
    },
    {
      "epoch": 0.09867122562192794,
      "grad_norm": 0.22256438434123993,
      "learning_rate": 9.01835523902291e-05,
      "loss": 0.0034,
      "step": 1756000
    },
    {
      "epoch": 0.09869932107341482,
      "grad_norm": 0.1878322958946228,
      "learning_rate": 9.018074126548402e-05,
      "loss": 0.0041,
      "step": 1756500
    },
    {
      "epoch": 0.0987274165249017,
      "grad_norm": 0.10038375109434128,
      "learning_rate": 9.017793014073897e-05,
      "loss": 0.0037,
      "step": 1757000
    },
    {
      "epoch": 0.09875551197638859,
      "grad_norm": 0.1593119353055954,
      "learning_rate": 9.01751190159939e-05,
      "loss": 0.0034,
      "step": 1757500
    },
    {
      "epoch": 0.09878360742787547,
      "grad_norm": 0.1548091322183609,
      "learning_rate": 9.017230789124884e-05,
      "loss": 0.0037,
      "step": 1758000
    },
    {
      "epoch": 0.09881170287936235,
      "grad_norm": 0.043964091688394547,
      "learning_rate": 9.016949676650377e-05,
      "loss": 0.0037,
      "step": 1758500
    },
    {
      "epoch": 0.09883979833084923,
      "grad_norm": 0.831878662109375,
      "learning_rate": 9.016668564175869e-05,
      "loss": 0.004,
      "step": 1759000
    },
    {
      "epoch": 0.09886789378233611,
      "grad_norm": 0.1148514598608017,
      "learning_rate": 9.016387451701364e-05,
      "loss": 0.0038,
      "step": 1759500
    },
    {
      "epoch": 0.09889598923382299,
      "grad_norm": 0.14843454957008362,
      "learning_rate": 9.016106339226856e-05,
      "loss": 0.0035,
      "step": 1760000
    },
    {
      "epoch": 0.09889598923382299,
      "eval_loss": 0.0011304958024993539,
      "eval_runtime": 21.2975,
      "eval_samples_per_second": 4695.387,
      "eval_steps_per_second": 73.389,
      "step": 1760000
    },
    {
      "epoch": 0.09892408468530987,
      "grad_norm": 0.0166308656334877,
      "learning_rate": 9.015825226752351e-05,
      "loss": 0.0038,
      "step": 1760500
    },
    {
      "epoch": 0.09895218013679676,
      "grad_norm": 0.047273553907871246,
      "learning_rate": 9.015544114277844e-05,
      "loss": 0.0036,
      "step": 1761000
    },
    {
      "epoch": 0.09898027558828364,
      "grad_norm": 0.25857171416282654,
      "learning_rate": 9.015263001803336e-05,
      "loss": 0.0042,
      "step": 1761500
    },
    {
      "epoch": 0.09900837103977052,
      "grad_norm": 0.20474465191364288,
      "learning_rate": 9.014981889328831e-05,
      "loss": 0.0041,
      "step": 1762000
    },
    {
      "epoch": 0.0990364664912574,
      "grad_norm": 0.46014153957366943,
      "learning_rate": 9.014700776854323e-05,
      "loss": 0.0038,
      "step": 1762500
    },
    {
      "epoch": 0.09906456194274428,
      "grad_norm": 0.0057178339920938015,
      "learning_rate": 9.014419664379818e-05,
      "loss": 0.0032,
      "step": 1763000
    },
    {
      "epoch": 0.09909265739423116,
      "grad_norm": 0.31090760231018066,
      "learning_rate": 9.01413855190531e-05,
      "loss": 0.0037,
      "step": 1763500
    },
    {
      "epoch": 0.09912075284571804,
      "grad_norm": 0.1580929011106491,
      "learning_rate": 9.013857439430803e-05,
      "loss": 0.004,
      "step": 1764000
    },
    {
      "epoch": 0.09914884829720493,
      "grad_norm": 0.4197905361652374,
      "learning_rate": 9.013576326956298e-05,
      "loss": 0.0037,
      "step": 1764500
    },
    {
      "epoch": 0.0991769437486918,
      "grad_norm": 0.02376803196966648,
      "learning_rate": 9.01329521448179e-05,
      "loss": 0.0036,
      "step": 1765000
    },
    {
      "epoch": 0.09920503920017869,
      "grad_norm": 0.017554525285959244,
      "learning_rate": 9.013014102007285e-05,
      "loss": 0.0032,
      "step": 1765500
    },
    {
      "epoch": 0.09923313465166557,
      "grad_norm": 0.16355516016483307,
      "learning_rate": 9.012732989532777e-05,
      "loss": 0.004,
      "step": 1766000
    },
    {
      "epoch": 0.09926123010315245,
      "grad_norm": 0.2478390783071518,
      "learning_rate": 9.01245187705827e-05,
      "loss": 0.0035,
      "step": 1766500
    },
    {
      "epoch": 0.09928932555463933,
      "grad_norm": 0.09216161072254181,
      "learning_rate": 9.012170764583764e-05,
      "loss": 0.0032,
      "step": 1767000
    },
    {
      "epoch": 0.09931742100612621,
      "grad_norm": 0.013357479125261307,
      "learning_rate": 9.011889652109257e-05,
      "loss": 0.0036,
      "step": 1767500
    },
    {
      "epoch": 0.0993455164576131,
      "grad_norm": 0.41688501834869385,
      "learning_rate": 9.011608539634751e-05,
      "loss": 0.0036,
      "step": 1768000
    },
    {
      "epoch": 0.09937361190909998,
      "grad_norm": 0.2615896761417389,
      "learning_rate": 9.011327427160244e-05,
      "loss": 0.0039,
      "step": 1768500
    },
    {
      "epoch": 0.09940170736058686,
      "grad_norm": 0.15465086698532104,
      "learning_rate": 9.011046314685738e-05,
      "loss": 0.0037,
      "step": 1769000
    },
    {
      "epoch": 0.09942980281207374,
      "grad_norm": 0.039312463253736496,
      "learning_rate": 9.010765202211231e-05,
      "loss": 0.004,
      "step": 1769500
    },
    {
      "epoch": 0.09945789826356062,
      "grad_norm": 0.309386283159256,
      "learning_rate": 9.010484089736724e-05,
      "loss": 0.0041,
      "step": 1770000
    },
    {
      "epoch": 0.09945789826356062,
      "eval_loss": 0.0011056564981117845,
      "eval_runtime": 20.865,
      "eval_samples_per_second": 4792.723,
      "eval_steps_per_second": 74.91,
      "step": 1770000
    },
    {
      "epoch": 0.0994859937150475,
      "grad_norm": 0.12006338685750961,
      "learning_rate": 9.010202977262218e-05,
      "loss": 0.0035,
      "step": 1770500
    },
    {
      "epoch": 0.09951408916653438,
      "grad_norm": 0.01118430681526661,
      "learning_rate": 9.009921864787711e-05,
      "loss": 0.0035,
      "step": 1771000
    },
    {
      "epoch": 0.09954218461802126,
      "grad_norm": 0.4571743309497833,
      "learning_rate": 9.009640752313205e-05,
      "loss": 0.004,
      "step": 1771500
    },
    {
      "epoch": 0.09957028006950815,
      "grad_norm": 0.2319059520959854,
      "learning_rate": 9.009359639838698e-05,
      "loss": 0.0038,
      "step": 1772000
    },
    {
      "epoch": 0.09959837552099503,
      "grad_norm": 0.0866188257932663,
      "learning_rate": 9.009078527364192e-05,
      "loss": 0.0036,
      "step": 1772500
    },
    {
      "epoch": 0.09962647097248191,
      "grad_norm": 0.3270704448223114,
      "learning_rate": 9.008797414889685e-05,
      "loss": 0.0037,
      "step": 1773000
    },
    {
      "epoch": 0.09965456642396879,
      "grad_norm": 0.05084475874900818,
      "learning_rate": 9.008516302415178e-05,
      "loss": 0.0036,
      "step": 1773500
    },
    {
      "epoch": 0.09968266187545567,
      "grad_norm": 0.23136866092681885,
      "learning_rate": 9.008235189940672e-05,
      "loss": 0.0038,
      "step": 1774000
    },
    {
      "epoch": 0.09971075732694255,
      "grad_norm": 0.054314013570547104,
      "learning_rate": 9.007954077466165e-05,
      "loss": 0.0035,
      "step": 1774500
    },
    {
      "epoch": 0.09973885277842943,
      "grad_norm": 0.01691371388733387,
      "learning_rate": 9.007672964991659e-05,
      "loss": 0.0033,
      "step": 1775000
    },
    {
      "epoch": 0.09976694822991632,
      "grad_norm": 0.17047524452209473,
      "learning_rate": 9.007391852517152e-05,
      "loss": 0.0035,
      "step": 1775500
    },
    {
      "epoch": 0.0997950436814032,
      "grad_norm": 0.5309268832206726,
      "learning_rate": 9.007110740042644e-05,
      "loss": 0.0039,
      "step": 1776000
    },
    {
      "epoch": 0.09982313913289008,
      "grad_norm": 0.1353633552789688,
      "learning_rate": 9.006829627568139e-05,
      "loss": 0.0034,
      "step": 1776500
    },
    {
      "epoch": 0.09985123458437696,
      "grad_norm": 0.011818150989711285,
      "learning_rate": 9.006548515093632e-05,
      "loss": 0.0036,
      "step": 1777000
    },
    {
      "epoch": 0.09987933003586384,
      "grad_norm": 0.017661377787590027,
      "learning_rate": 9.006267402619126e-05,
      "loss": 0.0038,
      "step": 1777500
    },
    {
      "epoch": 0.09990742548735072,
      "grad_norm": 0.017122427001595497,
      "learning_rate": 9.005986290144619e-05,
      "loss": 0.0037,
      "step": 1778000
    },
    {
      "epoch": 0.0999355209388376,
      "grad_norm": 0.07249950617551804,
      "learning_rate": 9.005705177670111e-05,
      "loss": 0.0038,
      "step": 1778500
    },
    {
      "epoch": 0.09996361639032449,
      "grad_norm": 0.03177732974290848,
      "learning_rate": 9.005424065195606e-05,
      "loss": 0.0033,
      "step": 1779000
    },
    {
      "epoch": 0.09999171184181137,
      "grad_norm": 0.25536948442459106,
      "learning_rate": 9.005142952721098e-05,
      "loss": 0.0037,
      "step": 1779500
    },
    {
      "epoch": 0.10001980729329825,
      "grad_norm": 0.03238687291741371,
      "learning_rate": 9.004861840246593e-05,
      "loss": 0.0037,
      "step": 1780000
    },
    {
      "epoch": 0.10001980729329825,
      "eval_loss": 0.0010263487929478288,
      "eval_runtime": 21.2072,
      "eval_samples_per_second": 4715.385,
      "eval_steps_per_second": 73.701,
      "step": 1780000
    },
    {
      "epoch": 0.10004790274478513,
      "grad_norm": 0.4017139673233032,
      "learning_rate": 9.004580727772086e-05,
      "loss": 0.0037,
      "step": 1780500
    },
    {
      "epoch": 0.10007599819627201,
      "grad_norm": 0.5882335305213928,
      "learning_rate": 9.004299615297578e-05,
      "loss": 0.0034,
      "step": 1781000
    },
    {
      "epoch": 0.1001040936477589,
      "grad_norm": 0.007008026819676161,
      "learning_rate": 9.004018502823073e-05,
      "loss": 0.0034,
      "step": 1781500
    },
    {
      "epoch": 0.10013218909924577,
      "grad_norm": 0.1950787752866745,
      "learning_rate": 9.003737390348565e-05,
      "loss": 0.0038,
      "step": 1782000
    },
    {
      "epoch": 0.10016028455073266,
      "grad_norm": 0.20735932886600494,
      "learning_rate": 9.00345627787406e-05,
      "loss": 0.004,
      "step": 1782500
    },
    {
      "epoch": 0.10018838000221954,
      "grad_norm": 0.15861938893795013,
      "learning_rate": 9.003175165399552e-05,
      "loss": 0.0033,
      "step": 1783000
    },
    {
      "epoch": 0.10021647545370642,
      "grad_norm": 0.2252229005098343,
      "learning_rate": 9.002894052925046e-05,
      "loss": 0.0036,
      "step": 1783500
    },
    {
      "epoch": 0.1002445709051933,
      "grad_norm": 0.22814184427261353,
      "learning_rate": 9.00261294045054e-05,
      "loss": 0.0039,
      "step": 1784000
    },
    {
      "epoch": 0.10027266635668018,
      "grad_norm": 0.15793286263942719,
      "learning_rate": 9.002331827976032e-05,
      "loss": 0.0037,
      "step": 1784500
    },
    {
      "epoch": 0.10030076180816706,
      "grad_norm": 0.2870880365371704,
      "learning_rate": 9.002050715501527e-05,
      "loss": 0.0036,
      "step": 1785000
    },
    {
      "epoch": 0.10032885725965394,
      "grad_norm": 0.6633467674255371,
      "learning_rate": 9.001769603027019e-05,
      "loss": 0.0034,
      "step": 1785500
    },
    {
      "epoch": 0.10035695271114083,
      "grad_norm": 0.21866145730018616,
      "learning_rate": 9.001488490552513e-05,
      "loss": 0.004,
      "step": 1786000
    },
    {
      "epoch": 0.10038504816262771,
      "grad_norm": 0.17570732533931732,
      "learning_rate": 9.001207378078006e-05,
      "loss": 0.004,
      "step": 1786500
    },
    {
      "epoch": 0.10041314361411459,
      "grad_norm": 0.5771174430847168,
      "learning_rate": 9.0009262656035e-05,
      "loss": 0.0041,
      "step": 1787000
    },
    {
      "epoch": 0.10044123906560147,
      "grad_norm": 0.08770493417978287,
      "learning_rate": 9.000645153128993e-05,
      "loss": 0.0035,
      "step": 1787500
    },
    {
      "epoch": 0.10046933451708835,
      "grad_norm": 0.07530651241540909,
      "learning_rate": 9.000364040654486e-05,
      "loss": 0.0038,
      "step": 1788000
    },
    {
      "epoch": 0.10049742996857523,
      "grad_norm": 0.3193027973175049,
      "learning_rate": 9.00008292817998e-05,
      "loss": 0.0034,
      "step": 1788500
    },
    {
      "epoch": 0.10052552542006211,
      "grad_norm": 0.06060921028256416,
      "learning_rate": 8.999801815705473e-05,
      "loss": 0.0034,
      "step": 1789000
    },
    {
      "epoch": 0.100553620871549,
      "grad_norm": 0.10606202483177185,
      "learning_rate": 8.999520703230967e-05,
      "loss": 0.004,
      "step": 1789500
    },
    {
      "epoch": 0.10058171632303588,
      "grad_norm": 0.150042325258255,
      "learning_rate": 8.99923959075646e-05,
      "loss": 0.0038,
      "step": 1790000
    },
    {
      "epoch": 0.10058171632303588,
      "eval_loss": 0.0010057410690933466,
      "eval_runtime": 21.2709,
      "eval_samples_per_second": 4701.253,
      "eval_steps_per_second": 73.481,
      "step": 1790000
    },
    {
      "epoch": 0.10060981177452276,
      "grad_norm": 0.12001276016235352,
      "learning_rate": 8.998958478281953e-05,
      "loss": 0.0035,
      "step": 1790500
    },
    {
      "epoch": 0.10063790722600964,
      "grad_norm": 0.3144110441207886,
      "learning_rate": 8.998677365807447e-05,
      "loss": 0.0036,
      "step": 1791000
    },
    {
      "epoch": 0.10066600267749652,
      "grad_norm": 0.11776798963546753,
      "learning_rate": 8.99839625333294e-05,
      "loss": 0.0038,
      "step": 1791500
    },
    {
      "epoch": 0.1006940981289834,
      "grad_norm": 0.25451162457466125,
      "learning_rate": 8.998115140858434e-05,
      "loss": 0.0036,
      "step": 1792000
    },
    {
      "epoch": 0.10072219358047028,
      "grad_norm": 0.24892379343509674,
      "learning_rate": 8.997834028383927e-05,
      "loss": 0.0034,
      "step": 1792500
    },
    {
      "epoch": 0.10075028903195717,
      "grad_norm": 0.38910871744155884,
      "learning_rate": 8.99755291590942e-05,
      "loss": 0.0037,
      "step": 1793000
    },
    {
      "epoch": 0.10077838448344405,
      "grad_norm": 0.26501259207725525,
      "learning_rate": 8.997271803434914e-05,
      "loss": 0.0036,
      "step": 1793500
    },
    {
      "epoch": 0.10080647993493093,
      "grad_norm": 0.08320371061563492,
      "learning_rate": 8.996990690960407e-05,
      "loss": 0.0037,
      "step": 1794000
    },
    {
      "epoch": 0.10083457538641781,
      "grad_norm": 0.10417551547288895,
      "learning_rate": 8.9967095784859e-05,
      "loss": 0.0036,
      "step": 1794500
    },
    {
      "epoch": 0.10086267083790469,
      "grad_norm": 0.12538744509220123,
      "learning_rate": 8.996428466011394e-05,
      "loss": 0.0034,
      "step": 1795000
    },
    {
      "epoch": 0.10089076628939157,
      "grad_norm": 0.44357532262802124,
      "learning_rate": 8.996147353536886e-05,
      "loss": 0.0037,
      "step": 1795500
    },
    {
      "epoch": 0.10091886174087845,
      "grad_norm": 0.18069690465927124,
      "learning_rate": 8.995866241062381e-05,
      "loss": 0.0041,
      "step": 1796000
    },
    {
      "epoch": 0.10094695719236534,
      "grad_norm": 0.10957461595535278,
      "learning_rate": 8.995585128587875e-05,
      "loss": 0.0037,
      "step": 1796500
    },
    {
      "epoch": 0.10097505264385222,
      "grad_norm": 0.1134410947561264,
      "learning_rate": 8.995304016113367e-05,
      "loss": 0.0038,
      "step": 1797000
    },
    {
      "epoch": 0.1010031480953391,
      "grad_norm": 0.7883065342903137,
      "learning_rate": 8.995022903638861e-05,
      "loss": 0.0035,
      "step": 1797500
    },
    {
      "epoch": 0.10103124354682598,
      "grad_norm": 0.19966891407966614,
      "learning_rate": 8.994741791164353e-05,
      "loss": 0.0035,
      "step": 1798000
    },
    {
      "epoch": 0.10105933899831286,
      "grad_norm": 0.05456630513072014,
      "learning_rate": 8.994460678689848e-05,
      "loss": 0.0039,
      "step": 1798500
    },
    {
      "epoch": 0.10108743444979974,
      "grad_norm": 0.3279067575931549,
      "learning_rate": 8.99417956621534e-05,
      "loss": 0.0039,
      "step": 1799000
    },
    {
      "epoch": 0.10111552990128662,
      "grad_norm": 1.1903176307678223,
      "learning_rate": 8.993898453740834e-05,
      "loss": 0.0035,
      "step": 1799500
    },
    {
      "epoch": 0.10114362535277352,
      "grad_norm": 0.06674141436815262,
      "learning_rate": 8.993617341266329e-05,
      "loss": 0.0038,
      "step": 1800000
    },
    {
      "epoch": 0.10114362535277352,
      "eval_loss": 0.001049939775839448,
      "eval_runtime": 21.2499,
      "eval_samples_per_second": 4705.909,
      "eval_steps_per_second": 73.553,
      "step": 1800000
    },
    {
      "epoch": 0.1011717208042604,
      "grad_norm": 0.32348525524139404,
      "learning_rate": 8.99333622879182e-05,
      "loss": 0.004,
      "step": 1800500
    },
    {
      "epoch": 0.10119981625574728,
      "grad_norm": 0.012096893042325974,
      "learning_rate": 8.993055116317315e-05,
      "loss": 0.0039,
      "step": 1801000
    },
    {
      "epoch": 0.10122791170723416,
      "grad_norm": 0.14382313191890717,
      "learning_rate": 8.992774003842807e-05,
      "loss": 0.0034,
      "step": 1801500
    },
    {
      "epoch": 0.10125600715872105,
      "grad_norm": 0.09152617305517197,
      "learning_rate": 8.992492891368301e-05,
      "loss": 0.0034,
      "step": 1802000
    },
    {
      "epoch": 0.10128410261020793,
      "grad_norm": 0.2895829677581787,
      "learning_rate": 8.992211778893794e-05,
      "loss": 0.0035,
      "step": 1802500
    },
    {
      "epoch": 0.10131219806169481,
      "grad_norm": 0.2095119059085846,
      "learning_rate": 8.991930666419288e-05,
      "loss": 0.0038,
      "step": 1803000
    },
    {
      "epoch": 0.10134029351318169,
      "grad_norm": 0.06926735490560532,
      "learning_rate": 8.991649553944783e-05,
      "loss": 0.0035,
      "step": 1803500
    },
    {
      "epoch": 0.10136838896466857,
      "grad_norm": 0.49988406896591187,
      "learning_rate": 8.991368441470275e-05,
      "loss": 0.0038,
      "step": 1804000
    },
    {
      "epoch": 0.10139648441615545,
      "grad_norm": 0.13978898525238037,
      "learning_rate": 8.991087328995768e-05,
      "loss": 0.0038,
      "step": 1804500
    },
    {
      "epoch": 0.10142457986764233,
      "grad_norm": 0.05923159047961235,
      "learning_rate": 8.990806216521261e-05,
      "loss": 0.0038,
      "step": 1805000
    },
    {
      "epoch": 0.10145267531912922,
      "grad_norm": 0.1729961484670639,
      "learning_rate": 8.990525104046755e-05,
      "loss": 0.0035,
      "step": 1805500
    },
    {
      "epoch": 0.1014807707706161,
      "grad_norm": 0.07857293635606766,
      "learning_rate": 8.990243991572248e-05,
      "loss": 0.0038,
      "step": 1806000
    },
    {
      "epoch": 0.10150886622210298,
      "grad_norm": 0.33294227719306946,
      "learning_rate": 8.989962879097742e-05,
      "loss": 0.0038,
      "step": 1806500
    },
    {
      "epoch": 0.10153696167358986,
      "grad_norm": 0.037193577736616135,
      "learning_rate": 8.989681766623235e-05,
      "loss": 0.0038,
      "step": 1807000
    },
    {
      "epoch": 0.10156505712507674,
      "grad_norm": 0.19703422486782074,
      "learning_rate": 8.989400654148729e-05,
      "loss": 0.0035,
      "step": 1807500
    },
    {
      "epoch": 0.10159315257656362,
      "grad_norm": 0.016674840822815895,
      "learning_rate": 8.989119541674222e-05,
      "loss": 0.0038,
      "step": 1808000
    },
    {
      "epoch": 0.1016212480280505,
      "grad_norm": 0.2545909285545349,
      "learning_rate": 8.988838429199715e-05,
      "loss": 0.0034,
      "step": 1808500
    },
    {
      "epoch": 0.10164934347953739,
      "grad_norm": 0.10836143046617508,
      "learning_rate": 8.988557316725209e-05,
      "loss": 0.0036,
      "step": 1809000
    },
    {
      "epoch": 0.10167743893102427,
      "grad_norm": 0.12310092896223068,
      "learning_rate": 8.988276204250702e-05,
      "loss": 0.0039,
      "step": 1809500
    },
    {
      "epoch": 0.10170553438251115,
      "grad_norm": 0.19178184866905212,
      "learning_rate": 8.987995091776196e-05,
      "loss": 0.0035,
      "step": 1810000
    },
    {
      "epoch": 0.10170553438251115,
      "eval_loss": 0.0009616750758141279,
      "eval_runtime": 20.042,
      "eval_samples_per_second": 4989.51,
      "eval_steps_per_second": 77.986,
      "step": 1810000
    },
    {
      "epoch": 0.10173362983399803,
      "grad_norm": 0.04851434752345085,
      "learning_rate": 8.987713979301689e-05,
      "loss": 0.0034,
      "step": 1810500
    },
    {
      "epoch": 0.10176172528548491,
      "grad_norm": 0.25737977027893066,
      "learning_rate": 8.987432866827183e-05,
      "loss": 0.0036,
      "step": 1811000
    },
    {
      "epoch": 0.10178982073697179,
      "grad_norm": 0.1576848328113556,
      "learning_rate": 8.987151754352676e-05,
      "loss": 0.0042,
      "step": 1811500
    },
    {
      "epoch": 0.10181791618845867,
      "grad_norm": 0.3079156279563904,
      "learning_rate": 8.98687064187817e-05,
      "loss": 0.0036,
      "step": 1812000
    },
    {
      "epoch": 0.10184601163994556,
      "grad_norm": 0.043352965265512466,
      "learning_rate": 8.986589529403663e-05,
      "loss": 0.0036,
      "step": 1812500
    },
    {
      "epoch": 0.10187410709143244,
      "grad_norm": 0.059923719614744186,
      "learning_rate": 8.986308416929156e-05,
      "loss": 0.0038,
      "step": 1813000
    },
    {
      "epoch": 0.10190220254291932,
      "grad_norm": 0.2205529361963272,
      "learning_rate": 8.98602730445465e-05,
      "loss": 0.0038,
      "step": 1813500
    },
    {
      "epoch": 0.1019302979944062,
      "grad_norm": 0.03416968509554863,
      "learning_rate": 8.985746191980142e-05,
      "loss": 0.0034,
      "step": 1814000
    },
    {
      "epoch": 0.10195839344589308,
      "grad_norm": 0.2870223820209503,
      "learning_rate": 8.985465079505636e-05,
      "loss": 0.0035,
      "step": 1814500
    },
    {
      "epoch": 0.10198648889737996,
      "grad_norm": 0.2753540277481079,
      "learning_rate": 8.98518396703113e-05,
      "loss": 0.0035,
      "step": 1815000
    },
    {
      "epoch": 0.10201458434886684,
      "grad_norm": 0.26843586564064026,
      "learning_rate": 8.984902854556623e-05,
      "loss": 0.0036,
      "step": 1815500
    },
    {
      "epoch": 0.10204267980035372,
      "grad_norm": 0.10931497067213058,
      "learning_rate": 8.984621742082117e-05,
      "loss": 0.0043,
      "step": 1816000
    },
    {
      "epoch": 0.1020707752518406,
      "grad_norm": 0.9279570579528809,
      "learning_rate": 8.984340629607609e-05,
      "loss": 0.0037,
      "step": 1816500
    },
    {
      "epoch": 0.10209887070332749,
      "grad_norm": 0.1451379507780075,
      "learning_rate": 8.984059517133104e-05,
      "loss": 0.0034,
      "step": 1817000
    },
    {
      "epoch": 0.10212696615481437,
      "grad_norm": 0.007517084013670683,
      "learning_rate": 8.983778404658596e-05,
      "loss": 0.0037,
      "step": 1817500
    },
    {
      "epoch": 0.10215506160630125,
      "grad_norm": 0.4031040370464325,
      "learning_rate": 8.98349729218409e-05,
      "loss": 0.0033,
      "step": 1818000
    },
    {
      "epoch": 0.10218315705778813,
      "grad_norm": 0.03301075100898743,
      "learning_rate": 8.983216179709583e-05,
      "loss": 0.0037,
      "step": 1818500
    },
    {
      "epoch": 0.10221125250927501,
      "grad_norm": 0.007405804470181465,
      "learning_rate": 8.982935067235076e-05,
      "loss": 0.0035,
      "step": 1819000
    },
    {
      "epoch": 0.1022393479607619,
      "grad_norm": 0.12863948941230774,
      "learning_rate": 8.982653954760571e-05,
      "loss": 0.0036,
      "step": 1819500
    },
    {
      "epoch": 0.10226744341224878,
      "grad_norm": 0.06069844961166382,
      "learning_rate": 8.982372842286063e-05,
      "loss": 0.0035,
      "step": 1820000
    },
    {
      "epoch": 0.10226744341224878,
      "eval_loss": 0.0011033824412152171,
      "eval_runtime": 21.3594,
      "eval_samples_per_second": 4681.784,
      "eval_steps_per_second": 73.176,
      "step": 1820000
    },
    {
      "epoch": 0.10229553886373566,
      "grad_norm": 0.19095858931541443,
      "learning_rate": 8.982091729811558e-05,
      "loss": 0.0038,
      "step": 1820500
    },
    {
      "epoch": 0.10232363431522254,
      "grad_norm": 0.3299351632595062,
      "learning_rate": 8.98181061733705e-05,
      "loss": 0.0039,
      "step": 1821000
    },
    {
      "epoch": 0.10235172976670942,
      "grad_norm": 0.04521200433373451,
      "learning_rate": 8.981529504862543e-05,
      "loss": 0.0032,
      "step": 1821500
    },
    {
      "epoch": 0.1023798252181963,
      "grad_norm": 0.7145220041275024,
      "learning_rate": 8.981248392388037e-05,
      "loss": 0.004,
      "step": 1822000
    },
    {
      "epoch": 0.10240792066968318,
      "grad_norm": 0.07728198170661926,
      "learning_rate": 8.98096727991353e-05,
      "loss": 0.0034,
      "step": 1822500
    },
    {
      "epoch": 0.10243601612117006,
      "grad_norm": 0.4772721529006958,
      "learning_rate": 8.980686167439025e-05,
      "loss": 0.0036,
      "step": 1823000
    },
    {
      "epoch": 0.10246411157265695,
      "grad_norm": 0.2385581135749817,
      "learning_rate": 8.980405054964517e-05,
      "loss": 0.0033,
      "step": 1823500
    },
    {
      "epoch": 0.10249220702414383,
      "grad_norm": 0.17016355693340302,
      "learning_rate": 8.98012394249001e-05,
      "loss": 0.0041,
      "step": 1824000
    },
    {
      "epoch": 0.10252030247563071,
      "grad_norm": 0.17243388295173645,
      "learning_rate": 8.979842830015504e-05,
      "loss": 0.0044,
      "step": 1824500
    },
    {
      "epoch": 0.10254839792711759,
      "grad_norm": 0.13711316883563995,
      "learning_rate": 8.979561717540997e-05,
      "loss": 0.0034,
      "step": 1825000
    },
    {
      "epoch": 0.10257649337860447,
      "grad_norm": 0.040844060480594635,
      "learning_rate": 8.97928060506649e-05,
      "loss": 0.0033,
      "step": 1825500
    },
    {
      "epoch": 0.10260458883009135,
      "grad_norm": 0.38866791129112244,
      "learning_rate": 8.978999492591984e-05,
      "loss": 0.0035,
      "step": 1826000
    },
    {
      "epoch": 0.10263268428157823,
      "grad_norm": 0.5452684760093689,
      "learning_rate": 8.978718380117477e-05,
      "loss": 0.0035,
      "step": 1826500
    },
    {
      "epoch": 0.10266077973306512,
      "grad_norm": 0.14079608023166656,
      "learning_rate": 8.978437267642971e-05,
      "loss": 0.0034,
      "step": 1827000
    },
    {
      "epoch": 0.102688875184552,
      "grad_norm": 0.25920918583869934,
      "learning_rate": 8.978156155168464e-05,
      "loss": 0.0035,
      "step": 1827500
    },
    {
      "epoch": 0.10271697063603888,
      "grad_norm": 0.1784576028585434,
      "learning_rate": 8.977875042693958e-05,
      "loss": 0.0038,
      "step": 1828000
    },
    {
      "epoch": 0.10274506608752576,
      "grad_norm": 0.46126988530158997,
      "learning_rate": 8.977593930219451e-05,
      "loss": 0.0036,
      "step": 1828500
    },
    {
      "epoch": 0.10277316153901264,
      "grad_norm": 0.03018295206129551,
      "learning_rate": 8.977312817744944e-05,
      "loss": 0.0039,
      "step": 1829000
    },
    {
      "epoch": 0.10280125699049952,
      "grad_norm": 0.013495635241270065,
      "learning_rate": 8.977031705270438e-05,
      "loss": 0.0036,
      "step": 1829500
    },
    {
      "epoch": 0.1028293524419864,
      "grad_norm": 0.3208671510219574,
      "learning_rate": 8.97675059279593e-05,
      "loss": 0.0036,
      "step": 1830000
    },
    {
      "epoch": 0.1028293524419864,
      "eval_loss": 0.001071749720722437,
      "eval_runtime": 20.5864,
      "eval_samples_per_second": 4857.572,
      "eval_steps_per_second": 75.924,
      "step": 1830000
    },
    {
      "epoch": 0.10285744789347329,
      "grad_norm": 0.21666450798511505,
      "learning_rate": 8.976469480321425e-05,
      "loss": 0.0037,
      "step": 1830500
    },
    {
      "epoch": 0.10288554334496017,
      "grad_norm": 0.22611956298351288,
      "learning_rate": 8.976188367846918e-05,
      "loss": 0.0039,
      "step": 1831000
    },
    {
      "epoch": 0.10291363879644705,
      "grad_norm": 0.04832233861088753,
      "learning_rate": 8.975907255372412e-05,
      "loss": 0.0038,
      "step": 1831500
    },
    {
      "epoch": 0.10294173424793393,
      "grad_norm": 0.09441812336444855,
      "learning_rate": 8.975626142897905e-05,
      "loss": 0.0032,
      "step": 1832000
    },
    {
      "epoch": 0.10296982969942081,
      "grad_norm": 0.13744287192821503,
      "learning_rate": 8.975345030423397e-05,
      "loss": 0.0035,
      "step": 1832500
    },
    {
      "epoch": 0.1029979251509077,
      "grad_norm": 0.12936314940452576,
      "learning_rate": 8.975063917948892e-05,
      "loss": 0.0035,
      "step": 1833000
    },
    {
      "epoch": 0.10302602060239457,
      "grad_norm": 0.472878098487854,
      "learning_rate": 8.974782805474384e-05,
      "loss": 0.0035,
      "step": 1833500
    },
    {
      "epoch": 0.10305411605388146,
      "grad_norm": 0.05577974021434784,
      "learning_rate": 8.974501692999879e-05,
      "loss": 0.0042,
      "step": 1834000
    },
    {
      "epoch": 0.10308221150536834,
      "grad_norm": 0.3374248147010803,
      "learning_rate": 8.974220580525372e-05,
      "loss": 0.0039,
      "step": 1834500
    },
    {
      "epoch": 0.10311030695685522,
      "grad_norm": 0.2027401626110077,
      "learning_rate": 8.973939468050864e-05,
      "loss": 0.0036,
      "step": 1835000
    },
    {
      "epoch": 0.1031384024083421,
      "grad_norm": 0.13822123408317566,
      "learning_rate": 8.973658355576359e-05,
      "loss": 0.0033,
      "step": 1835500
    },
    {
      "epoch": 0.10316649785982898,
      "grad_norm": 0.19461283087730408,
      "learning_rate": 8.973377243101851e-05,
      "loss": 0.0036,
      "step": 1836000
    },
    {
      "epoch": 0.10319459331131586,
      "grad_norm": 0.3982580304145813,
      "learning_rate": 8.973096130627346e-05,
      "loss": 0.0039,
      "step": 1836500
    },
    {
      "epoch": 0.10322268876280274,
      "grad_norm": 0.08102861791849136,
      "learning_rate": 8.972815018152838e-05,
      "loss": 0.0037,
      "step": 1837000
    },
    {
      "epoch": 0.10325078421428963,
      "grad_norm": 0.0332663469016552,
      "learning_rate": 8.972533905678331e-05,
      "loss": 0.0041,
      "step": 1837500
    },
    {
      "epoch": 0.10327887966577651,
      "grad_norm": 0.022967960685491562,
      "learning_rate": 8.972252793203825e-05,
      "loss": 0.0038,
      "step": 1838000
    },
    {
      "epoch": 0.10330697511726339,
      "grad_norm": 0.2531149089336395,
      "learning_rate": 8.971971680729318e-05,
      "loss": 0.0038,
      "step": 1838500
    },
    {
      "epoch": 0.10333507056875027,
      "grad_norm": 0.046880435198545456,
      "learning_rate": 8.971690568254813e-05,
      "loss": 0.0033,
      "step": 1839000
    },
    {
      "epoch": 0.10336316602023715,
      "grad_norm": 0.3293026387691498,
      "learning_rate": 8.971409455780305e-05,
      "loss": 0.0031,
      "step": 1839500
    },
    {
      "epoch": 0.10339126147172403,
      "grad_norm": 0.21202370524406433,
      "learning_rate": 8.971128343305798e-05,
      "loss": 0.0039,
      "step": 1840000
    },
    {
      "epoch": 0.10339126147172403,
      "eval_loss": 0.001059332862496376,
      "eval_runtime": 20.7687,
      "eval_samples_per_second": 4814.927,
      "eval_steps_per_second": 75.257,
      "step": 1840000
    },
    {
      "epoch": 0.10341935692321091,
      "grad_norm": 0.437996506690979,
      "learning_rate": 8.970847230831292e-05,
      "loss": 0.0038,
      "step": 1840500
    },
    {
      "epoch": 0.1034474523746978,
      "grad_norm": 0.26026347279548645,
      "learning_rate": 8.970566118356785e-05,
      "loss": 0.0038,
      "step": 1841000
    },
    {
      "epoch": 0.10347554782618468,
      "grad_norm": 0.20228472352027893,
      "learning_rate": 8.970285005882279e-05,
      "loss": 0.0035,
      "step": 1841500
    },
    {
      "epoch": 0.10350364327767156,
      "grad_norm": 0.31847724318504333,
      "learning_rate": 8.970003893407772e-05,
      "loss": 0.0033,
      "step": 1842000
    },
    {
      "epoch": 0.10353173872915844,
      "grad_norm": 0.21906088292598724,
      "learning_rate": 8.969722780933267e-05,
      "loss": 0.0029,
      "step": 1842500
    },
    {
      "epoch": 0.10355983418064532,
      "grad_norm": 0.19295568764209747,
      "learning_rate": 8.969441668458759e-05,
      "loss": 0.0034,
      "step": 1843000
    },
    {
      "epoch": 0.1035879296321322,
      "grad_norm": 0.2892451882362366,
      "learning_rate": 8.969160555984252e-05,
      "loss": 0.0038,
      "step": 1843500
    },
    {
      "epoch": 0.10361602508361908,
      "grad_norm": 0.060988929122686386,
      "learning_rate": 8.968879443509746e-05,
      "loss": 0.0036,
      "step": 1844000
    },
    {
      "epoch": 0.10364412053510597,
      "grad_norm": 0.3320712447166443,
      "learning_rate": 8.968598331035239e-05,
      "loss": 0.0039,
      "step": 1844500
    },
    {
      "epoch": 0.10367221598659285,
      "grad_norm": 0.21983087062835693,
      "learning_rate": 8.968317218560733e-05,
      "loss": 0.0036,
      "step": 1845000
    },
    {
      "epoch": 0.10370031143807973,
      "grad_norm": 0.061211951076984406,
      "learning_rate": 8.968036106086226e-05,
      "loss": 0.0035,
      "step": 1845500
    },
    {
      "epoch": 0.10372840688956661,
      "grad_norm": 0.22681641578674316,
      "learning_rate": 8.96775499361172e-05,
      "loss": 0.0039,
      "step": 1846000
    },
    {
      "epoch": 0.10375650234105349,
      "grad_norm": 0.16643193364143372,
      "learning_rate": 8.967473881137213e-05,
      "loss": 0.0041,
      "step": 1846500
    },
    {
      "epoch": 0.10378459779254037,
      "grad_norm": 0.04589907079935074,
      "learning_rate": 8.967192768662706e-05,
      "loss": 0.0037,
      "step": 1847000
    },
    {
      "epoch": 0.10381269324402725,
      "grad_norm": 0.16526475548744202,
      "learning_rate": 8.9669116561882e-05,
      "loss": 0.0036,
      "step": 1847500
    },
    {
      "epoch": 0.10384078869551414,
      "grad_norm": 0.0675201565027237,
      "learning_rate": 8.966630543713693e-05,
      "loss": 0.0037,
      "step": 1848000
    },
    {
      "epoch": 0.10386888414700102,
      "grad_norm": 0.027465257793664932,
      "learning_rate": 8.966349431239187e-05,
      "loss": 0.0032,
      "step": 1848500
    },
    {
      "epoch": 0.1038969795984879,
      "grad_norm": 0.11448357999324799,
      "learning_rate": 8.96606831876468e-05,
      "loss": 0.0039,
      "step": 1849000
    },
    {
      "epoch": 0.10392507504997478,
      "grad_norm": 0.016032885760068893,
      "learning_rate": 8.965787206290172e-05,
      "loss": 0.0032,
      "step": 1849500
    },
    {
      "epoch": 0.10395317050146166,
      "grad_norm": 0.07465352863073349,
      "learning_rate": 8.965506093815667e-05,
      "loss": 0.0037,
      "step": 1850000
    },
    {
      "epoch": 0.10395317050146166,
      "eval_loss": 0.0011301926570013165,
      "eval_runtime": 21.0891,
      "eval_samples_per_second": 4741.776,
      "eval_steps_per_second": 74.114,
      "step": 1850000
    },
    {
      "epoch": 0.10398126595294854,
      "grad_norm": 0.0112705547362566,
      "learning_rate": 8.96522498134116e-05,
      "loss": 0.0038,
      "step": 1850500
    },
    {
      "epoch": 0.10400936140443542,
      "grad_norm": 0.2694491744041443,
      "learning_rate": 8.964943868866654e-05,
      "loss": 0.0035,
      "step": 1851000
    },
    {
      "epoch": 0.1040374568559223,
      "grad_norm": 0.06364738196134567,
      "learning_rate": 8.964662756392147e-05,
      "loss": 0.0037,
      "step": 1851500
    },
    {
      "epoch": 0.10406555230740919,
      "grad_norm": 0.11618582159280777,
      "learning_rate": 8.964381643917639e-05,
      "loss": 0.0036,
      "step": 1852000
    },
    {
      "epoch": 0.10409364775889607,
      "grad_norm": 0.1829931139945984,
      "learning_rate": 8.964100531443134e-05,
      "loss": 0.0035,
      "step": 1852500
    },
    {
      "epoch": 0.10412174321038295,
      "grad_norm": 0.2860136330127716,
      "learning_rate": 8.963819418968626e-05,
      "loss": 0.0034,
      "step": 1853000
    },
    {
      "epoch": 0.10414983866186983,
      "grad_norm": 0.010878216475248337,
      "learning_rate": 8.963538306494121e-05,
      "loss": 0.0036,
      "step": 1853500
    },
    {
      "epoch": 0.10417793411335671,
      "grad_norm": 0.0166919082403183,
      "learning_rate": 8.963257194019614e-05,
      "loss": 0.0035,
      "step": 1854000
    },
    {
      "epoch": 0.1042060295648436,
      "grad_norm": 0.14671899378299713,
      "learning_rate": 8.962976081545106e-05,
      "loss": 0.0034,
      "step": 1854500
    },
    {
      "epoch": 0.10423412501633048,
      "grad_norm": 0.03882969915866852,
      "learning_rate": 8.962694969070601e-05,
      "loss": 0.0034,
      "step": 1855000
    },
    {
      "epoch": 0.10426222046781736,
      "grad_norm": 0.38469818234443665,
      "learning_rate": 8.962413856596093e-05,
      "loss": 0.0035,
      "step": 1855500
    },
    {
      "epoch": 0.10429031591930424,
      "grad_norm": 0.0610668808221817,
      "learning_rate": 8.962132744121588e-05,
      "loss": 0.0037,
      "step": 1856000
    },
    {
      "epoch": 0.10431841137079112,
      "grad_norm": 0.04871132969856262,
      "learning_rate": 8.96185163164708e-05,
      "loss": 0.0035,
      "step": 1856500
    },
    {
      "epoch": 0.104346506822278,
      "grad_norm": 0.05182403326034546,
      "learning_rate": 8.961570519172574e-05,
      "loss": 0.0036,
      "step": 1857000
    },
    {
      "epoch": 0.10437460227376488,
      "grad_norm": 0.12608522176742554,
      "learning_rate": 8.961289406698067e-05,
      "loss": 0.0033,
      "step": 1857500
    },
    {
      "epoch": 0.10440269772525176,
      "grad_norm": 0.5429893732070923,
      "learning_rate": 8.96100829422356e-05,
      "loss": 0.004,
      "step": 1858000
    },
    {
      "epoch": 0.10443079317673865,
      "grad_norm": 0.2011408805847168,
      "learning_rate": 8.960727181749055e-05,
      "loss": 0.0035,
      "step": 1858500
    },
    {
      "epoch": 0.10445888862822553,
      "grad_norm": 0.02060970850288868,
      "learning_rate": 8.960446069274547e-05,
      "loss": 0.0033,
      "step": 1859000
    },
    {
      "epoch": 0.10448698407971241,
      "grad_norm": 0.10249344259500504,
      "learning_rate": 8.96016495680004e-05,
      "loss": 0.004,
      "step": 1859500
    },
    {
      "epoch": 0.10451507953119929,
      "grad_norm": 0.010506724007427692,
      "learning_rate": 8.959883844325534e-05,
      "loss": 0.0033,
      "step": 1860000
    },
    {
      "epoch": 0.10451507953119929,
      "eval_loss": 0.0010416334262117743,
      "eval_runtime": 19.8349,
      "eval_samples_per_second": 5041.631,
      "eval_steps_per_second": 78.801,
      "step": 1860000
    },
    {
      "epoch": 0.10454317498268617,
      "grad_norm": 0.13599075376987457,
      "learning_rate": 8.959602731851027e-05,
      "loss": 0.0034,
      "step": 1860500
    },
    {
      "epoch": 0.10457127043417307,
      "grad_norm": 0.3090760111808777,
      "learning_rate": 8.959321619376521e-05,
      "loss": 0.0036,
      "step": 1861000
    },
    {
      "epoch": 0.10459936588565995,
      "grad_norm": 0.005957944318652153,
      "learning_rate": 8.959040506902014e-05,
      "loss": 0.0038,
      "step": 1861500
    },
    {
      "epoch": 0.10462746133714683,
      "grad_norm": 0.1989685595035553,
      "learning_rate": 8.958759394427508e-05,
      "loss": 0.0037,
      "step": 1862000
    },
    {
      "epoch": 0.10465555678863371,
      "grad_norm": 0.030771788209676743,
      "learning_rate": 8.958478281953001e-05,
      "loss": 0.0036,
      "step": 1862500
    },
    {
      "epoch": 0.10468365224012059,
      "grad_norm": 0.2692487835884094,
      "learning_rate": 8.958197169478495e-05,
      "loss": 0.0035,
      "step": 1863000
    },
    {
      "epoch": 0.10471174769160747,
      "grad_norm": 0.28614163398742676,
      "learning_rate": 8.957916057003988e-05,
      "loss": 0.0036,
      "step": 1863500
    },
    {
      "epoch": 0.10473984314309435,
      "grad_norm": 0.24331122636795044,
      "learning_rate": 8.957634944529481e-05,
      "loss": 0.0037,
      "step": 1864000
    },
    {
      "epoch": 0.10476793859458124,
      "grad_norm": 0.06732198596000671,
      "learning_rate": 8.957353832054975e-05,
      "loss": 0.0035,
      "step": 1864500
    },
    {
      "epoch": 0.10479603404606812,
      "grad_norm": 0.49960407614707947,
      "learning_rate": 8.957072719580468e-05,
      "loss": 0.0035,
      "step": 1865000
    },
    {
      "epoch": 0.104824129497555,
      "grad_norm": 0.22794874012470245,
      "learning_rate": 8.956791607105962e-05,
      "loss": 0.0032,
      "step": 1865500
    },
    {
      "epoch": 0.10485222494904188,
      "grad_norm": 0.14818638563156128,
      "learning_rate": 8.956510494631455e-05,
      "loss": 0.0037,
      "step": 1866000
    },
    {
      "epoch": 0.10488032040052876,
      "grad_norm": 0.07804803550243378,
      "learning_rate": 8.956229382156949e-05,
      "loss": 0.0033,
      "step": 1866500
    },
    {
      "epoch": 0.10490841585201564,
      "grad_norm": 0.42942336201667786,
      "learning_rate": 8.955948269682442e-05,
      "loss": 0.0038,
      "step": 1867000
    },
    {
      "epoch": 0.10493651130350252,
      "grad_norm": 0.2124224603176117,
      "learning_rate": 8.955667157207935e-05,
      "loss": 0.0034,
      "step": 1867500
    },
    {
      "epoch": 0.1049646067549894,
      "grad_norm": 0.0177470576018095,
      "learning_rate": 8.955386044733427e-05,
      "loss": 0.004,
      "step": 1868000
    },
    {
      "epoch": 0.10499270220647629,
      "grad_norm": 0.5632030963897705,
      "learning_rate": 8.955104932258922e-05,
      "loss": 0.0039,
      "step": 1868500
    },
    {
      "epoch": 0.10502079765796317,
      "grad_norm": 0.27310922741889954,
      "learning_rate": 8.954823819784414e-05,
      "loss": 0.0034,
      "step": 1869000
    },
    {
      "epoch": 0.10504889310945005,
      "grad_norm": 0.4772487282752991,
      "learning_rate": 8.954542707309909e-05,
      "loss": 0.0035,
      "step": 1869500
    },
    {
      "epoch": 0.10507698856093693,
      "grad_norm": 0.36102724075317383,
      "learning_rate": 8.954261594835403e-05,
      "loss": 0.0036,
      "step": 1870000
    },
    {
      "epoch": 0.10507698856093693,
      "eval_loss": 0.0010927076218649745,
      "eval_runtime": 20.7836,
      "eval_samples_per_second": 4811.477,
      "eval_steps_per_second": 75.203,
      "step": 1870000
    },
    {
      "epoch": 0.10510508401242381,
      "grad_norm": 0.01939494162797928,
      "learning_rate": 8.953980482360895e-05,
      "loss": 0.0036,
      "step": 1870500
    },
    {
      "epoch": 0.1051331794639107,
      "grad_norm": 0.043913040310144424,
      "learning_rate": 8.95369936988639e-05,
      "loss": 0.0034,
      "step": 1871000
    },
    {
      "epoch": 0.10516127491539758,
      "grad_norm": 0.04896989092230797,
      "learning_rate": 8.953418257411881e-05,
      "loss": 0.0035,
      "step": 1871500
    },
    {
      "epoch": 0.10518937036688446,
      "grad_norm": 0.023966245353221893,
      "learning_rate": 8.953137144937376e-05,
      "loss": 0.0039,
      "step": 1872000
    },
    {
      "epoch": 0.10521746581837134,
      "grad_norm": 0.185037299990654,
      "learning_rate": 8.952856032462868e-05,
      "loss": 0.0033,
      "step": 1872500
    },
    {
      "epoch": 0.10524556126985822,
      "grad_norm": 0.40999898314476013,
      "learning_rate": 8.952574919988362e-05,
      "loss": 0.0034,
      "step": 1873000
    },
    {
      "epoch": 0.1052736567213451,
      "grad_norm": 0.0925159677863121,
      "learning_rate": 8.952293807513857e-05,
      "loss": 0.0035,
      "step": 1873500
    },
    {
      "epoch": 0.10530175217283198,
      "grad_norm": 0.21800900995731354,
      "learning_rate": 8.952012695039349e-05,
      "loss": 0.0036,
      "step": 1874000
    },
    {
      "epoch": 0.10532984762431886,
      "grad_norm": 0.21903951466083527,
      "learning_rate": 8.951731582564843e-05,
      "loss": 0.0033,
      "step": 1874500
    },
    {
      "epoch": 0.10535794307580575,
      "grad_norm": 0.5136993527412415,
      "learning_rate": 8.951450470090335e-05,
      "loss": 0.0034,
      "step": 1875000
    },
    {
      "epoch": 0.10538603852729263,
      "grad_norm": 0.027731461450457573,
      "learning_rate": 8.95116935761583e-05,
      "loss": 0.0034,
      "step": 1875500
    },
    {
      "epoch": 0.10541413397877951,
      "grad_norm": 0.366281121969223,
      "learning_rate": 8.950888245141322e-05,
      "loss": 0.0038,
      "step": 1876000
    },
    {
      "epoch": 0.10544222943026639,
      "grad_norm": 0.25741341710090637,
      "learning_rate": 8.950607132666816e-05,
      "loss": 0.0036,
      "step": 1876500
    },
    {
      "epoch": 0.10547032488175327,
      "grad_norm": 0.21381999552249908,
      "learning_rate": 8.950326020192309e-05,
      "loss": 0.0032,
      "step": 1877000
    },
    {
      "epoch": 0.10549842033324015,
      "grad_norm": 0.04047742113471031,
      "learning_rate": 8.950044907717803e-05,
      "loss": 0.003,
      "step": 1877500
    },
    {
      "epoch": 0.10552651578472703,
      "grad_norm": 0.08369942754507065,
      "learning_rate": 8.949763795243297e-05,
      "loss": 0.0036,
      "step": 1878000
    },
    {
      "epoch": 0.10555461123621392,
      "grad_norm": 0.6536921858787537,
      "learning_rate": 8.94948268276879e-05,
      "loss": 0.0039,
      "step": 1878500
    },
    {
      "epoch": 0.1055827066877008,
      "grad_norm": 0.01826905645430088,
      "learning_rate": 8.949201570294283e-05,
      "loss": 0.0034,
      "step": 1879000
    },
    {
      "epoch": 0.10561080213918768,
      "grad_norm": 0.44634056091308594,
      "learning_rate": 8.948920457819776e-05,
      "loss": 0.0036,
      "step": 1879500
    },
    {
      "epoch": 0.10563889759067456,
      "grad_norm": 0.22515925765037537,
      "learning_rate": 8.94863934534527e-05,
      "loss": 0.0037,
      "step": 1880000
    },
    {
      "epoch": 0.10563889759067456,
      "eval_loss": 0.0010303528979420662,
      "eval_runtime": 21.5574,
      "eval_samples_per_second": 4638.779,
      "eval_steps_per_second": 72.504,
      "step": 1880000
    },
    {
      "epoch": 0.10566699304216144,
      "grad_norm": 0.2224959135055542,
      "learning_rate": 8.948358232870763e-05,
      "loss": 0.0035,
      "step": 1880500
    },
    {
      "epoch": 0.10569508849364832,
      "grad_norm": 0.19630908966064453,
      "learning_rate": 8.948077120396257e-05,
      "loss": 0.0034,
      "step": 1881000
    },
    {
      "epoch": 0.1057231839451352,
      "grad_norm": 0.15543444454669952,
      "learning_rate": 8.94779600792175e-05,
      "loss": 0.004,
      "step": 1881500
    },
    {
      "epoch": 0.10575127939662209,
      "grad_norm": 0.21067343652248383,
      "learning_rate": 8.947514895447243e-05,
      "loss": 0.0037,
      "step": 1882000
    },
    {
      "epoch": 0.10577937484810897,
      "grad_norm": 0.6547477841377258,
      "learning_rate": 8.947233782972737e-05,
      "loss": 0.0037,
      "step": 1882500
    },
    {
      "epoch": 0.10580747029959585,
      "grad_norm": 0.11348346620798111,
      "learning_rate": 8.94695267049823e-05,
      "loss": 0.0038,
      "step": 1883000
    },
    {
      "epoch": 0.10583556575108273,
      "grad_norm": 0.02884378284215927,
      "learning_rate": 8.946671558023724e-05,
      "loss": 0.0035,
      "step": 1883500
    },
    {
      "epoch": 0.10586366120256961,
      "grad_norm": 0.10168496519327164,
      "learning_rate": 8.946390445549217e-05,
      "loss": 0.0038,
      "step": 1884000
    },
    {
      "epoch": 0.1058917566540565,
      "grad_norm": 0.16817209124565125,
      "learning_rate": 8.94610933307471e-05,
      "loss": 0.0034,
      "step": 1884500
    },
    {
      "epoch": 0.10591985210554337,
      "grad_norm": 0.04369745030999184,
      "learning_rate": 8.945828220600204e-05,
      "loss": 0.003,
      "step": 1885000
    },
    {
      "epoch": 0.10594794755703026,
      "grad_norm": 0.09415610879659653,
      "learning_rate": 8.945547108125697e-05,
      "loss": 0.0039,
      "step": 1885500
    },
    {
      "epoch": 0.10597604300851714,
      "grad_norm": 0.043582625687122345,
      "learning_rate": 8.945265995651191e-05,
      "loss": 0.0036,
      "step": 1886000
    },
    {
      "epoch": 0.10600413846000402,
      "grad_norm": 0.42021670937538147,
      "learning_rate": 8.944984883176684e-05,
      "loss": 0.0034,
      "step": 1886500
    },
    {
      "epoch": 0.1060322339114909,
      "grad_norm": 0.013503940775990486,
      "learning_rate": 8.944703770702178e-05,
      "loss": 0.0036,
      "step": 1887000
    },
    {
      "epoch": 0.10606032936297778,
      "grad_norm": 0.17955748736858368,
      "learning_rate": 8.94442265822767e-05,
      "loss": 0.0035,
      "step": 1887500
    },
    {
      "epoch": 0.10608842481446466,
      "grad_norm": 0.1950448453426361,
      "learning_rate": 8.944141545753164e-05,
      "loss": 0.0035,
      "step": 1888000
    },
    {
      "epoch": 0.10611652026595154,
      "grad_norm": 0.2290637344121933,
      "learning_rate": 8.943860433278657e-05,
      "loss": 0.0035,
      "step": 1888500
    },
    {
      "epoch": 0.10614461571743843,
      "grad_norm": 0.3803083896636963,
      "learning_rate": 8.943579320804151e-05,
      "loss": 0.0037,
      "step": 1889000
    },
    {
      "epoch": 0.10617271116892531,
      "grad_norm": 0.16210494935512543,
      "learning_rate": 8.943298208329645e-05,
      "loss": 0.0034,
      "step": 1889500
    },
    {
      "epoch": 0.10620080662041219,
      "grad_norm": 0.15835392475128174,
      "learning_rate": 8.943017095855137e-05,
      "loss": 0.0039,
      "step": 1890000
    },
    {
      "epoch": 0.10620080662041219,
      "eval_loss": 0.0011104666627943516,
      "eval_runtime": 20.821,
      "eval_samples_per_second": 4802.84,
      "eval_steps_per_second": 75.068,
      "step": 1890000
    },
    {
      "epoch": 0.10622890207189907,
      "grad_norm": 0.15269140899181366,
      "learning_rate": 8.942735983380632e-05,
      "loss": 0.0039,
      "step": 1890500
    },
    {
      "epoch": 0.10625699752338595,
      "grad_norm": 0.2755350172519684,
      "learning_rate": 8.942454870906124e-05,
      "loss": 0.0033,
      "step": 1891000
    },
    {
      "epoch": 0.10628509297487283,
      "grad_norm": 0.11083029210567474,
      "learning_rate": 8.942173758431618e-05,
      "loss": 0.0033,
      "step": 1891500
    },
    {
      "epoch": 0.10631318842635971,
      "grad_norm": 0.14099928736686707,
      "learning_rate": 8.94189264595711e-05,
      "loss": 0.0038,
      "step": 1892000
    },
    {
      "epoch": 0.1063412838778466,
      "grad_norm": 0.08998662233352661,
      "learning_rate": 8.941611533482604e-05,
      "loss": 0.0038,
      "step": 1892500
    },
    {
      "epoch": 0.10636937932933348,
      "grad_norm": 0.6053885221481323,
      "learning_rate": 8.941330421008099e-05,
      "loss": 0.0034,
      "step": 1893000
    },
    {
      "epoch": 0.10639747478082036,
      "grad_norm": 0.1476273089647293,
      "learning_rate": 8.941049308533591e-05,
      "loss": 0.0038,
      "step": 1893500
    },
    {
      "epoch": 0.10642557023230724,
      "grad_norm": 0.10829238593578339,
      "learning_rate": 8.940768196059086e-05,
      "loss": 0.0034,
      "step": 1894000
    },
    {
      "epoch": 0.10645366568379412,
      "grad_norm": 0.04622223600745201,
      "learning_rate": 8.940487083584578e-05,
      "loss": 0.0036,
      "step": 1894500
    },
    {
      "epoch": 0.106481761135281,
      "grad_norm": 0.08976573497056961,
      "learning_rate": 8.940205971110071e-05,
      "loss": 0.0036,
      "step": 1895000
    },
    {
      "epoch": 0.10650985658676788,
      "grad_norm": 0.045397721230983734,
      "learning_rate": 8.939924858635564e-05,
      "loss": 0.0039,
      "step": 1895500
    },
    {
      "epoch": 0.10653795203825477,
      "grad_norm": 0.0252035241574049,
      "learning_rate": 8.939643746161058e-05,
      "loss": 0.0039,
      "step": 1896000
    },
    {
      "epoch": 0.10656604748974165,
      "grad_norm": 0.2579740583896637,
      "learning_rate": 8.939362633686553e-05,
      "loss": 0.0035,
      "step": 1896500
    },
    {
      "epoch": 0.10659414294122853,
      "grad_norm": 0.39578545093536377,
      "learning_rate": 8.939081521212045e-05,
      "loss": 0.0031,
      "step": 1897000
    },
    {
      "epoch": 0.10662223839271541,
      "grad_norm": 0.2194099873304367,
      "learning_rate": 8.938800408737538e-05,
      "loss": 0.0036,
      "step": 1897500
    },
    {
      "epoch": 0.10665033384420229,
      "grad_norm": 0.02392362430691719,
      "learning_rate": 8.938519296263032e-05,
      "loss": 0.0038,
      "step": 1898000
    },
    {
      "epoch": 0.10667842929568917,
      "grad_norm": 0.14601726830005646,
      "learning_rate": 8.938238183788525e-05,
      "loss": 0.0035,
      "step": 1898500
    },
    {
      "epoch": 0.10670652474717605,
      "grad_norm": 0.10283427685499191,
      "learning_rate": 8.937957071314018e-05,
      "loss": 0.0034,
      "step": 1899000
    },
    {
      "epoch": 0.10673462019866294,
      "grad_norm": 0.06922376900911331,
      "learning_rate": 8.937675958839512e-05,
      "loss": 0.0034,
      "step": 1899500
    },
    {
      "epoch": 0.10676271565014982,
      "grad_norm": 0.1590214967727661,
      "learning_rate": 8.937394846365005e-05,
      "loss": 0.0037,
      "step": 1900000
    },
    {
      "epoch": 0.10676271565014982,
      "eval_loss": 0.0010456570889800787,
      "eval_runtime": 20.4937,
      "eval_samples_per_second": 4879.551,
      "eval_steps_per_second": 76.267,
      "step": 1900000
    },
    {
      "epoch": 0.1067908111016367,
      "grad_norm": 0.02314009889960289,
      "learning_rate": 8.937113733890499e-05,
      "loss": 0.0031,
      "step": 1900500
    },
    {
      "epoch": 0.10681890655312358,
      "grad_norm": 0.09055186808109283,
      "learning_rate": 8.936832621415992e-05,
      "loss": 0.0041,
      "step": 1901000
    },
    {
      "epoch": 0.10684700200461046,
      "grad_norm": 0.4548119008541107,
      "learning_rate": 8.936551508941486e-05,
      "loss": 0.0036,
      "step": 1901500
    },
    {
      "epoch": 0.10687509745609734,
      "grad_norm": 0.05715390667319298,
      "learning_rate": 8.936270396466979e-05,
      "loss": 0.0034,
      "step": 1902000
    },
    {
      "epoch": 0.10690319290758422,
      "grad_norm": 0.029932064935564995,
      "learning_rate": 8.935989283992472e-05,
      "loss": 0.0037,
      "step": 1902500
    },
    {
      "epoch": 0.1069312883590711,
      "grad_norm": 0.4651196002960205,
      "learning_rate": 8.935708171517966e-05,
      "loss": 0.0033,
      "step": 1903000
    },
    {
      "epoch": 0.10695938381055799,
      "grad_norm": 0.07123777270317078,
      "learning_rate": 8.935427059043458e-05,
      "loss": 0.0032,
      "step": 1903500
    },
    {
      "epoch": 0.10698747926204487,
      "grad_norm": 0.08635170757770538,
      "learning_rate": 8.935145946568953e-05,
      "loss": 0.0034,
      "step": 1904000
    },
    {
      "epoch": 0.10701557471353175,
      "grad_norm": 0.075421541929245,
      "learning_rate": 8.934864834094446e-05,
      "loss": 0.0037,
      "step": 1904500
    },
    {
      "epoch": 0.10704367016501863,
      "grad_norm": 0.39798644185066223,
      "learning_rate": 8.93458372161994e-05,
      "loss": 0.0038,
      "step": 1905000
    },
    {
      "epoch": 0.10707176561650551,
      "grad_norm": 0.019556161016225815,
      "learning_rate": 8.934302609145433e-05,
      "loss": 0.0033,
      "step": 1905500
    },
    {
      "epoch": 0.1070998610679924,
      "grad_norm": 0.05569138750433922,
      "learning_rate": 8.934021496670925e-05,
      "loss": 0.0035,
      "step": 1906000
    },
    {
      "epoch": 0.10712795651947928,
      "grad_norm": 0.13457028567790985,
      "learning_rate": 8.93374038419642e-05,
      "loss": 0.0038,
      "step": 1906500
    },
    {
      "epoch": 0.10715605197096616,
      "grad_norm": 0.16228531301021576,
      "learning_rate": 8.933459271721912e-05,
      "loss": 0.0035,
      "step": 1907000
    },
    {
      "epoch": 0.10718414742245304,
      "grad_norm": 0.27043482661247253,
      "learning_rate": 8.933178159247407e-05,
      "loss": 0.0039,
      "step": 1907500
    },
    {
      "epoch": 0.10721224287393992,
      "grad_norm": 0.09696745127439499,
      "learning_rate": 8.932897046772899e-05,
      "loss": 0.0035,
      "step": 1908000
    },
    {
      "epoch": 0.1072403383254268,
      "grad_norm": 0.3619145452976227,
      "learning_rate": 8.932615934298392e-05,
      "loss": 0.0034,
      "step": 1908500
    },
    {
      "epoch": 0.10726843377691368,
      "grad_norm": 0.012460851110517979,
      "learning_rate": 8.932334821823887e-05,
      "loss": 0.0035,
      "step": 1909000
    },
    {
      "epoch": 0.10729652922840056,
      "grad_norm": 0.052940815687179565,
      "learning_rate": 8.932053709349379e-05,
      "loss": 0.0039,
      "step": 1909500
    },
    {
      "epoch": 0.10732462467988745,
      "grad_norm": 0.17859382927417755,
      "learning_rate": 8.931772596874874e-05,
      "loss": 0.0036,
      "step": 1910000
    },
    {
      "epoch": 0.10732462467988745,
      "eval_loss": 0.0010880166664719582,
      "eval_runtime": 21.6226,
      "eval_samples_per_second": 4624.792,
      "eval_steps_per_second": 72.285,
      "step": 1910000
    },
    {
      "epoch": 0.10735272013137433,
      "grad_norm": 0.3462056517601013,
      "learning_rate": 8.931491484400366e-05,
      "loss": 0.0033,
      "step": 1910500
    },
    {
      "epoch": 0.10738081558286121,
      "grad_norm": 0.012449614703655243,
      "learning_rate": 8.93121037192586e-05,
      "loss": 0.0033,
      "step": 1911000
    },
    {
      "epoch": 0.10740891103434809,
      "grad_norm": 0.23391826450824738,
      "learning_rate": 8.930929259451353e-05,
      "loss": 0.0035,
      "step": 1911500
    },
    {
      "epoch": 0.10743700648583497,
      "grad_norm": 0.2775353789329529,
      "learning_rate": 8.930648146976846e-05,
      "loss": 0.0039,
      "step": 1912000
    },
    {
      "epoch": 0.10746510193732185,
      "grad_norm": 0.04689347743988037,
      "learning_rate": 8.930367034502341e-05,
      "loss": 0.0036,
      "step": 1912500
    },
    {
      "epoch": 0.10749319738880873,
      "grad_norm": 0.48390713334083557,
      "learning_rate": 8.930085922027833e-05,
      "loss": 0.0036,
      "step": 1913000
    },
    {
      "epoch": 0.10752129284029562,
      "grad_norm": 0.6071310639381409,
      "learning_rate": 8.929804809553328e-05,
      "loss": 0.0036,
      "step": 1913500
    },
    {
      "epoch": 0.1075493882917825,
      "grad_norm": 0.02087262086570263,
      "learning_rate": 8.92952369707882e-05,
      "loss": 0.0036,
      "step": 1914000
    },
    {
      "epoch": 0.10757748374326938,
      "grad_norm": 0.04144865646958351,
      "learning_rate": 8.929242584604313e-05,
      "loss": 0.0034,
      "step": 1914500
    },
    {
      "epoch": 0.10760557919475626,
      "grad_norm": 0.08724620938301086,
      "learning_rate": 8.928961472129807e-05,
      "loss": 0.0035,
      "step": 1915000
    },
    {
      "epoch": 0.10763367464624314,
      "grad_norm": 0.05949806421995163,
      "learning_rate": 8.9286803596553e-05,
      "loss": 0.0031,
      "step": 1915500
    },
    {
      "epoch": 0.10766177009773002,
      "grad_norm": 0.19783833622932434,
      "learning_rate": 8.928399247180795e-05,
      "loss": 0.0034,
      "step": 1916000
    },
    {
      "epoch": 0.1076898655492169,
      "grad_norm": 0.8447439074516296,
      "learning_rate": 8.928118134706287e-05,
      "loss": 0.0038,
      "step": 1916500
    },
    {
      "epoch": 0.10771796100070379,
      "grad_norm": 0.0027481396682560444,
      "learning_rate": 8.92783702223178e-05,
      "loss": 0.0035,
      "step": 1917000
    },
    {
      "epoch": 0.10774605645219067,
      "grad_norm": 0.13413451611995697,
      "learning_rate": 8.927555909757274e-05,
      "loss": 0.0038,
      "step": 1917500
    },
    {
      "epoch": 0.10777415190367755,
      "grad_norm": 0.033415913581848145,
      "learning_rate": 8.927274797282767e-05,
      "loss": 0.004,
      "step": 1918000
    },
    {
      "epoch": 0.10780224735516443,
      "grad_norm": 0.11847122758626938,
      "learning_rate": 8.92699368480826e-05,
      "loss": 0.0036,
      "step": 1918500
    },
    {
      "epoch": 0.10783034280665131,
      "grad_norm": 0.039997898042201996,
      "learning_rate": 8.926712572333754e-05,
      "loss": 0.0039,
      "step": 1919000
    },
    {
      "epoch": 0.10785843825813819,
      "grad_norm": 0.03600193187594414,
      "learning_rate": 8.926431459859247e-05,
      "loss": 0.0031,
      "step": 1919500
    },
    {
      "epoch": 0.10788653370962507,
      "grad_norm": 0.018136436119675636,
      "learning_rate": 8.926150347384741e-05,
      "loss": 0.0037,
      "step": 1920000
    },
    {
      "epoch": 0.10788653370962507,
      "eval_loss": 0.0010866436641663313,
      "eval_runtime": 21.4703,
      "eval_samples_per_second": 4657.587,
      "eval_steps_per_second": 72.798,
      "step": 1920000
    },
    {
      "epoch": 0.10791462916111196,
      "grad_norm": 0.11147164553403854,
      "learning_rate": 8.925869234910234e-05,
      "loss": 0.0038,
      "step": 1920500
    },
    {
      "epoch": 0.10794272461259884,
      "grad_norm": 0.15896692872047424,
      "learning_rate": 8.925588122435728e-05,
      "loss": 0.0035,
      "step": 1921000
    },
    {
      "epoch": 0.10797082006408572,
      "grad_norm": 0.20130674540996552,
      "learning_rate": 8.925307009961221e-05,
      "loss": 0.0036,
      "step": 1921500
    },
    {
      "epoch": 0.10799891551557261,
      "grad_norm": 0.5379828810691833,
      "learning_rate": 8.925025897486715e-05,
      "loss": 0.0033,
      "step": 1922000
    },
    {
      "epoch": 0.1080270109670595,
      "grad_norm": 0.21323837339878082,
      "learning_rate": 8.924744785012208e-05,
      "loss": 0.0036,
      "step": 1922500
    },
    {
      "epoch": 0.10805510641854638,
      "grad_norm": 0.09945690631866455,
      "learning_rate": 8.9244636725377e-05,
      "loss": 0.0037,
      "step": 1923000
    },
    {
      "epoch": 0.10808320187003326,
      "grad_norm": 0.5242556929588318,
      "learning_rate": 8.924182560063195e-05,
      "loss": 0.0037,
      "step": 1923500
    },
    {
      "epoch": 0.10811129732152014,
      "grad_norm": 0.8465277552604675,
      "learning_rate": 8.923901447588688e-05,
      "loss": 0.0038,
      "step": 1924000
    },
    {
      "epoch": 0.10813939277300702,
      "grad_norm": 0.16151881217956543,
      "learning_rate": 8.923620335114182e-05,
      "loss": 0.0035,
      "step": 1924500
    },
    {
      "epoch": 0.1081674882244939,
      "grad_norm": 0.26541727781295776,
      "learning_rate": 8.923339222639675e-05,
      "loss": 0.0038,
      "step": 1925000
    },
    {
      "epoch": 0.10819558367598078,
      "grad_norm": 0.014060776680707932,
      "learning_rate": 8.923058110165167e-05,
      "loss": 0.0038,
      "step": 1925500
    },
    {
      "epoch": 0.10822367912746766,
      "grad_norm": 0.22699755430221558,
      "learning_rate": 8.922776997690662e-05,
      "loss": 0.0035,
      "step": 1926000
    },
    {
      "epoch": 0.10825177457895455,
      "grad_norm": 0.5572399497032166,
      "learning_rate": 8.922495885216154e-05,
      "loss": 0.0031,
      "step": 1926500
    },
    {
      "epoch": 0.10827987003044143,
      "grad_norm": 0.21212641894817352,
      "learning_rate": 8.922214772741649e-05,
      "loss": 0.0036,
      "step": 1927000
    },
    {
      "epoch": 0.10830796548192831,
      "grad_norm": 0.10637366026639938,
      "learning_rate": 8.921933660267141e-05,
      "loss": 0.0036,
      "step": 1927500
    },
    {
      "epoch": 0.10833606093341519,
      "grad_norm": 0.6467658281326294,
      "learning_rate": 8.921652547792634e-05,
      "loss": 0.0034,
      "step": 1928000
    },
    {
      "epoch": 0.10836415638490207,
      "grad_norm": 0.016587624326348305,
      "learning_rate": 8.921371435318129e-05,
      "loss": 0.0033,
      "step": 1928500
    },
    {
      "epoch": 0.10839225183638895,
      "grad_norm": 0.08235786110162735,
      "learning_rate": 8.921090322843621e-05,
      "loss": 0.0036,
      "step": 1929000
    },
    {
      "epoch": 0.10842034728787583,
      "grad_norm": 0.050160154700279236,
      "learning_rate": 8.920809210369116e-05,
      "loss": 0.0034,
      "step": 1929500
    },
    {
      "epoch": 0.10844844273936272,
      "grad_norm": 0.31677114963531494,
      "learning_rate": 8.920528097894608e-05,
      "loss": 0.0038,
      "step": 1930000
    },
    {
      "epoch": 0.10844844273936272,
      "eval_loss": 0.00101854233071208,
      "eval_runtime": 20.8852,
      "eval_samples_per_second": 4788.09,
      "eval_steps_per_second": 74.838,
      "step": 1930000
    },
    {
      "epoch": 0.1084765381908496,
      "grad_norm": 0.0906958281993866,
      "learning_rate": 8.920246985420101e-05,
      "loss": 0.0032,
      "step": 1930500
    },
    {
      "epoch": 0.10850463364233648,
      "grad_norm": 0.004193918779492378,
      "learning_rate": 8.919965872945595e-05,
      "loss": 0.0033,
      "step": 1931000
    },
    {
      "epoch": 0.10853272909382336,
      "grad_norm": 0.05238037928938866,
      "learning_rate": 8.919684760471088e-05,
      "loss": 0.0036,
      "step": 1931500
    },
    {
      "epoch": 0.10856082454531024,
      "grad_norm": 0.7957500219345093,
      "learning_rate": 8.919403647996583e-05,
      "loss": 0.0031,
      "step": 1932000
    },
    {
      "epoch": 0.10858891999679712,
      "grad_norm": 0.22493526339530945,
      "learning_rate": 8.919122535522075e-05,
      "loss": 0.0038,
      "step": 1932500
    },
    {
      "epoch": 0.108617015448284,
      "grad_norm": 0.028094761073589325,
      "learning_rate": 8.918841423047569e-05,
      "loss": 0.004,
      "step": 1933000
    },
    {
      "epoch": 0.10864511089977089,
      "grad_norm": 0.4859025478363037,
      "learning_rate": 8.918560310573062e-05,
      "loss": 0.0037,
      "step": 1933500
    },
    {
      "epoch": 0.10867320635125777,
      "grad_norm": 0.26389163732528687,
      "learning_rate": 8.918279198098555e-05,
      "loss": 0.0036,
      "step": 1934000
    },
    {
      "epoch": 0.10870130180274465,
      "grad_norm": 0.14697761833667755,
      "learning_rate": 8.917998085624049e-05,
      "loss": 0.0035,
      "step": 1934500
    },
    {
      "epoch": 0.10872939725423153,
      "grad_norm": 0.3323575556278229,
      "learning_rate": 8.917716973149542e-05,
      "loss": 0.0034,
      "step": 1935000
    },
    {
      "epoch": 0.10875749270571841,
      "grad_norm": 0.3839832842350006,
      "learning_rate": 8.917435860675036e-05,
      "loss": 0.0035,
      "step": 1935500
    },
    {
      "epoch": 0.10878558815720529,
      "grad_norm": 0.05858621746301651,
      "learning_rate": 8.917154748200529e-05,
      "loss": 0.0034,
      "step": 1936000
    },
    {
      "epoch": 0.10881368360869217,
      "grad_norm": 0.09535638988018036,
      "learning_rate": 8.916873635726023e-05,
      "loss": 0.0036,
      "step": 1936500
    },
    {
      "epoch": 0.10884177906017906,
      "grad_norm": 0.04983556643128395,
      "learning_rate": 8.916592523251516e-05,
      "loss": 0.0038,
      "step": 1937000
    },
    {
      "epoch": 0.10886987451166594,
      "grad_norm": 0.06924628466367722,
      "learning_rate": 8.91631141077701e-05,
      "loss": 0.0035,
      "step": 1937500
    },
    {
      "epoch": 0.10889796996315282,
      "grad_norm": 0.4357367157936096,
      "learning_rate": 8.916030298302503e-05,
      "loss": 0.0034,
      "step": 1938000
    },
    {
      "epoch": 0.1089260654146397,
      "grad_norm": 0.21149897575378418,
      "learning_rate": 8.915749185827996e-05,
      "loss": 0.0039,
      "step": 1938500
    },
    {
      "epoch": 0.10895416086612658,
      "grad_norm": 0.019763220101594925,
      "learning_rate": 8.915468073353488e-05,
      "loss": 0.0035,
      "step": 1939000
    },
    {
      "epoch": 0.10898225631761346,
      "grad_norm": 0.09347216784954071,
      "learning_rate": 8.915186960878983e-05,
      "loss": 0.0039,
      "step": 1939500
    },
    {
      "epoch": 0.10901035176910034,
      "grad_norm": 0.22286184132099152,
      "learning_rate": 8.914905848404477e-05,
      "loss": 0.0039,
      "step": 1940000
    },
    {
      "epoch": 0.10901035176910034,
      "eval_loss": 0.0010988173307850957,
      "eval_runtime": 21.1789,
      "eval_samples_per_second": 4721.672,
      "eval_steps_per_second": 73.8,
      "step": 1940000
    },
    {
      "epoch": 0.10903844722058723,
      "grad_norm": 0.24255919456481934,
      "learning_rate": 8.91462473592997e-05,
      "loss": 0.0034,
      "step": 1940500
    },
    {
      "epoch": 0.10906654267207411,
      "grad_norm": 0.5553407073020935,
      "learning_rate": 8.914343623455463e-05,
      "loss": 0.0032,
      "step": 1941000
    },
    {
      "epoch": 0.10909463812356099,
      "grad_norm": 0.09169156849384308,
      "learning_rate": 8.914062510980955e-05,
      "loss": 0.0036,
      "step": 1941500
    },
    {
      "epoch": 0.10912273357504787,
      "grad_norm": 0.0024563418701291084,
      "learning_rate": 8.91378139850645e-05,
      "loss": 0.0038,
      "step": 1942000
    },
    {
      "epoch": 0.10915082902653475,
      "grad_norm": 0.008046782575547695,
      "learning_rate": 8.913500286031942e-05,
      "loss": 0.0036,
      "step": 1942500
    },
    {
      "epoch": 0.10917892447802163,
      "grad_norm": 0.3103855848312378,
      "learning_rate": 8.913219173557437e-05,
      "loss": 0.0039,
      "step": 1943000
    },
    {
      "epoch": 0.10920701992950851,
      "grad_norm": 0.24607549607753754,
      "learning_rate": 8.91293806108293e-05,
      "loss": 0.0038,
      "step": 1943500
    },
    {
      "epoch": 0.1092351153809954,
      "grad_norm": 0.286925733089447,
      "learning_rate": 8.912656948608424e-05,
      "loss": 0.0032,
      "step": 1944000
    },
    {
      "epoch": 0.10926321083248228,
      "grad_norm": 0.17988137900829315,
      "learning_rate": 8.912375836133917e-05,
      "loss": 0.0031,
      "step": 1944500
    },
    {
      "epoch": 0.10929130628396916,
      "grad_norm": 0.6219384670257568,
      "learning_rate": 8.91209472365941e-05,
      "loss": 0.0038,
      "step": 1945000
    },
    {
      "epoch": 0.10931940173545604,
      "grad_norm": 0.023000968620181084,
      "learning_rate": 8.911813611184904e-05,
      "loss": 0.0036,
      "step": 1945500
    },
    {
      "epoch": 0.10934749718694292,
      "grad_norm": 0.407747745513916,
      "learning_rate": 8.911532498710396e-05,
      "loss": 0.004,
      "step": 1946000
    },
    {
      "epoch": 0.1093755926384298,
      "grad_norm": 0.2929767370223999,
      "learning_rate": 8.911251386235891e-05,
      "loss": 0.0033,
      "step": 1946500
    },
    {
      "epoch": 0.10940368808991668,
      "grad_norm": 0.4651617407798767,
      "learning_rate": 8.910970273761384e-05,
      "loss": 0.0035,
      "step": 1947000
    },
    {
      "epoch": 0.10943178354140357,
      "grad_norm": 0.047656234353780746,
      "learning_rate": 8.910689161286877e-05,
      "loss": 0.0033,
      "step": 1947500
    },
    {
      "epoch": 0.10945987899289045,
      "grad_norm": 0.027453161776065826,
      "learning_rate": 8.910408048812371e-05,
      "loss": 0.0033,
      "step": 1948000
    },
    {
      "epoch": 0.10948797444437733,
      "grad_norm": 0.10182250291109085,
      "learning_rate": 8.910126936337863e-05,
      "loss": 0.0036,
      "step": 1948500
    },
    {
      "epoch": 0.10951606989586421,
      "grad_norm": 0.024727892130613327,
      "learning_rate": 8.909845823863358e-05,
      "loss": 0.0034,
      "step": 1949000
    },
    {
      "epoch": 0.10954416534735109,
      "grad_norm": 0.004073600750416517,
      "learning_rate": 8.90956471138885e-05,
      "loss": 0.0036,
      "step": 1949500
    },
    {
      "epoch": 0.10957226079883797,
      "grad_norm": 0.2160915583372116,
      "learning_rate": 8.909283598914344e-05,
      "loss": 0.0035,
      "step": 1950000
    },
    {
      "epoch": 0.10957226079883797,
      "eval_loss": 0.0009707002900540829,
      "eval_runtime": 21.0958,
      "eval_samples_per_second": 4740.28,
      "eval_steps_per_second": 74.091,
      "step": 1950000
    },
    {
      "epoch": 0.10960035625032485,
      "grad_norm": 0.4353334307670593,
      "learning_rate": 8.909002486439837e-05,
      "loss": 0.0038,
      "step": 1950500
    },
    {
      "epoch": 0.10962845170181174,
      "grad_norm": 0.019457634538412094,
      "learning_rate": 8.90872137396533e-05,
      "loss": 0.0036,
      "step": 1951000
    },
    {
      "epoch": 0.10965654715329862,
      "grad_norm": 0.5009468793869019,
      "learning_rate": 8.908440261490825e-05,
      "loss": 0.0035,
      "step": 1951500
    },
    {
      "epoch": 0.1096846426047855,
      "grad_norm": 0.13547994196414948,
      "learning_rate": 8.908159149016317e-05,
      "loss": 0.0036,
      "step": 1952000
    },
    {
      "epoch": 0.10971273805627238,
      "grad_norm": 0.019020365551114082,
      "learning_rate": 8.907878036541811e-05,
      "loss": 0.0036,
      "step": 1952500
    },
    {
      "epoch": 0.10974083350775926,
      "grad_norm": 0.13449299335479736,
      "learning_rate": 8.907596924067304e-05,
      "loss": 0.0035,
      "step": 1953000
    },
    {
      "epoch": 0.10976892895924614,
      "grad_norm": 0.1858680695295334,
      "learning_rate": 8.907315811592798e-05,
      "loss": 0.0037,
      "step": 1953500
    },
    {
      "epoch": 0.10979702441073302,
      "grad_norm": 0.267441987991333,
      "learning_rate": 8.907034699118291e-05,
      "loss": 0.0033,
      "step": 1954000
    },
    {
      "epoch": 0.1098251198622199,
      "grad_norm": 0.13671037554740906,
      "learning_rate": 8.906753586643784e-05,
      "loss": 0.0033,
      "step": 1954500
    },
    {
      "epoch": 0.10985321531370679,
      "grad_norm": 0.41939201951026917,
      "learning_rate": 8.906472474169278e-05,
      "loss": 0.0036,
      "step": 1955000
    },
    {
      "epoch": 0.10988131076519367,
      "grad_norm": 0.499761164188385,
      "learning_rate": 8.906191361694771e-05,
      "loss": 0.0034,
      "step": 1955500
    },
    {
      "epoch": 0.10990940621668055,
      "grad_norm": 0.004530653823167086,
      "learning_rate": 8.905910249220265e-05,
      "loss": 0.0037,
      "step": 1956000
    },
    {
      "epoch": 0.10993750166816743,
      "grad_norm": 0.04485579580068588,
      "learning_rate": 8.905629136745758e-05,
      "loss": 0.0038,
      "step": 1956500
    },
    {
      "epoch": 0.10996559711965431,
      "grad_norm": 0.6397731304168701,
      "learning_rate": 8.905348024271252e-05,
      "loss": 0.0037,
      "step": 1957000
    },
    {
      "epoch": 0.1099936925711412,
      "grad_norm": 0.35198312997817993,
      "learning_rate": 8.905066911796745e-05,
      "loss": 0.0031,
      "step": 1957500
    },
    {
      "epoch": 0.11002178802262808,
      "grad_norm": 0.32738879323005676,
      "learning_rate": 8.904785799322238e-05,
      "loss": 0.0036,
      "step": 1958000
    },
    {
      "epoch": 0.11004988347411496,
      "grad_norm": 0.12961293756961823,
      "learning_rate": 8.90450468684773e-05,
      "loss": 0.0035,
      "step": 1958500
    },
    {
      "epoch": 0.11007797892560184,
      "grad_norm": 0.08355088531970978,
      "learning_rate": 8.904223574373225e-05,
      "loss": 0.0039,
      "step": 1959000
    },
    {
      "epoch": 0.11010607437708872,
      "grad_norm": 0.05591559410095215,
      "learning_rate": 8.903942461898719e-05,
      "loss": 0.0034,
      "step": 1959500
    },
    {
      "epoch": 0.1101341698285756,
      "grad_norm": 0.8923861980438232,
      "learning_rate": 8.903661349424212e-05,
      "loss": 0.0036,
      "step": 1960000
    },
    {
      "epoch": 0.1101341698285756,
      "eval_loss": 0.0010160728124901652,
      "eval_runtime": 21.0895,
      "eval_samples_per_second": 4741.697,
      "eval_steps_per_second": 74.113,
      "step": 1960000
    },
    {
      "epoch": 0.11016226528006248,
      "grad_norm": 0.04634539410471916,
      "learning_rate": 8.903380236949706e-05,
      "loss": 0.0034,
      "step": 1960500
    },
    {
      "epoch": 0.11019036073154936,
      "grad_norm": 0.052169039845466614,
      "learning_rate": 8.903099124475198e-05,
      "loss": 0.0041,
      "step": 1961000
    },
    {
      "epoch": 0.11021845618303625,
      "grad_norm": 0.09679170697927475,
      "learning_rate": 8.902818012000692e-05,
      "loss": 0.0035,
      "step": 1961500
    },
    {
      "epoch": 0.11024655163452313,
      "grad_norm": 0.1450476497411728,
      "learning_rate": 8.902536899526185e-05,
      "loss": 0.003,
      "step": 1962000
    },
    {
      "epoch": 0.11027464708601001,
      "grad_norm": 0.052600812166929245,
      "learning_rate": 8.902255787051679e-05,
      "loss": 0.0036,
      "step": 1962500
    },
    {
      "epoch": 0.11030274253749689,
      "grad_norm": 0.01295449398458004,
      "learning_rate": 8.901974674577173e-05,
      "loss": 0.0034,
      "step": 1963000
    },
    {
      "epoch": 0.11033083798898377,
      "grad_norm": 0.07186666131019592,
      "learning_rate": 8.901693562102665e-05,
      "loss": 0.0036,
      "step": 1963500
    },
    {
      "epoch": 0.11035893344047065,
      "grad_norm": 0.0886726900935173,
      "learning_rate": 8.90141244962816e-05,
      "loss": 0.0037,
      "step": 1964000
    },
    {
      "epoch": 0.11038702889195753,
      "grad_norm": 0.03855216130614281,
      "learning_rate": 8.901131337153652e-05,
      "loss": 0.0036,
      "step": 1964500
    },
    {
      "epoch": 0.11041512434344442,
      "grad_norm": 0.054766807705163956,
      "learning_rate": 8.900850224679146e-05,
      "loss": 0.0032,
      "step": 1965000
    },
    {
      "epoch": 0.1104432197949313,
      "grad_norm": 0.27343636751174927,
      "learning_rate": 8.900569112204638e-05,
      "loss": 0.0033,
      "step": 1965500
    },
    {
      "epoch": 0.11047131524641818,
      "grad_norm": 0.3284555971622467,
      "learning_rate": 8.900287999730132e-05,
      "loss": 0.0034,
      "step": 1966000
    },
    {
      "epoch": 0.11049941069790506,
      "grad_norm": 0.0052039227448403835,
      "learning_rate": 8.900006887255627e-05,
      "loss": 0.003,
      "step": 1966500
    },
    {
      "epoch": 0.11052750614939194,
      "grad_norm": 0.5870387554168701,
      "learning_rate": 8.899725774781119e-05,
      "loss": 0.0036,
      "step": 1967000
    },
    {
      "epoch": 0.11055560160087882,
      "grad_norm": 0.022446492686867714,
      "learning_rate": 8.899444662306614e-05,
      "loss": 0.0039,
      "step": 1967500
    },
    {
      "epoch": 0.1105836970523657,
      "grad_norm": 0.0642019659280777,
      "learning_rate": 8.899163549832106e-05,
      "loss": 0.0034,
      "step": 1968000
    },
    {
      "epoch": 0.11061179250385259,
      "grad_norm": 0.3903399109840393,
      "learning_rate": 8.898882437357599e-05,
      "loss": 0.0037,
      "step": 1968500
    },
    {
      "epoch": 0.11063988795533947,
      "grad_norm": 0.012718300335109234,
      "learning_rate": 8.898601324883092e-05,
      "loss": 0.0041,
      "step": 1969000
    },
    {
      "epoch": 0.11066798340682635,
      "grad_norm": 0.07459641993045807,
      "learning_rate": 8.898320212408586e-05,
      "loss": 0.0033,
      "step": 1969500
    },
    {
      "epoch": 0.11069607885831323,
      "grad_norm": 0.33959683775901794,
      "learning_rate": 8.898039099934079e-05,
      "loss": 0.0036,
      "step": 1970000
    },
    {
      "epoch": 0.11069607885831323,
      "eval_loss": 0.0009351868066005409,
      "eval_runtime": 21.2909,
      "eval_samples_per_second": 4696.844,
      "eval_steps_per_second": 73.412,
      "step": 1970000
    },
    {
      "epoch": 0.11072417430980011,
      "grad_norm": 0.3096773326396942,
      "learning_rate": 8.897757987459573e-05,
      "loss": 0.0031,
      "step": 1970500
    },
    {
      "epoch": 0.11075226976128699,
      "grad_norm": 0.2660648822784424,
      "learning_rate": 8.897476874985066e-05,
      "loss": 0.0032,
      "step": 1971000
    },
    {
      "epoch": 0.11078036521277387,
      "grad_norm": 0.1621415764093399,
      "learning_rate": 8.89719576251056e-05,
      "loss": 0.0033,
      "step": 1971500
    },
    {
      "epoch": 0.11080846066426076,
      "grad_norm": 0.2852150499820709,
      "learning_rate": 8.896914650036053e-05,
      "loss": 0.0037,
      "step": 1972000
    },
    {
      "epoch": 0.11083655611574764,
      "grad_norm": 0.9801985621452332,
      "learning_rate": 8.896633537561546e-05,
      "loss": 0.0038,
      "step": 1972500
    },
    {
      "epoch": 0.11086465156723452,
      "grad_norm": 0.04264038801193237,
      "learning_rate": 8.89635242508704e-05,
      "loss": 0.0033,
      "step": 1973000
    },
    {
      "epoch": 0.1108927470187214,
      "grad_norm": 0.10145581513643265,
      "learning_rate": 8.896071312612533e-05,
      "loss": 0.0033,
      "step": 1973500
    },
    {
      "epoch": 0.11092084247020828,
      "grad_norm": 0.12909379601478577,
      "learning_rate": 8.895790200138027e-05,
      "loss": 0.0035,
      "step": 1974000
    },
    {
      "epoch": 0.11094893792169516,
      "grad_norm": 0.09438823163509369,
      "learning_rate": 8.89550908766352e-05,
      "loss": 0.0033,
      "step": 1974500
    },
    {
      "epoch": 0.11097703337318204,
      "grad_norm": 0.478042334318161,
      "learning_rate": 8.895227975189014e-05,
      "loss": 0.0038,
      "step": 1975000
    },
    {
      "epoch": 0.11100512882466892,
      "grad_norm": 0.07882014662027359,
      "learning_rate": 8.894946862714507e-05,
      "loss": 0.0036,
      "step": 1975500
    },
    {
      "epoch": 0.1110332242761558,
      "grad_norm": 0.008582033216953278,
      "learning_rate": 8.89466575024e-05,
      "loss": 0.0034,
      "step": 1976000
    },
    {
      "epoch": 0.11106131972764269,
      "grad_norm": 0.6503294706344604,
      "learning_rate": 8.894384637765494e-05,
      "loss": 0.0034,
      "step": 1976500
    },
    {
      "epoch": 0.11108941517912957,
      "grad_norm": 0.2460946887731552,
      "learning_rate": 8.894103525290986e-05,
      "loss": 0.0033,
      "step": 1977000
    },
    {
      "epoch": 0.11111751063061645,
      "grad_norm": 0.15805932879447937,
      "learning_rate": 8.89382241281648e-05,
      "loss": 0.0032,
      "step": 1977500
    },
    {
      "epoch": 0.11114560608210333,
      "grad_norm": 0.18588665127754211,
      "learning_rate": 8.893541300341974e-05,
      "loss": 0.0034,
      "step": 1978000
    },
    {
      "epoch": 0.11117370153359021,
      "grad_norm": 0.020531557500362396,
      "learning_rate": 8.893260187867468e-05,
      "loss": 0.0032,
      "step": 1978500
    },
    {
      "epoch": 0.1112017969850771,
      "grad_norm": 0.3457701504230499,
      "learning_rate": 8.892979075392961e-05,
      "loss": 0.0031,
      "step": 1979000
    },
    {
      "epoch": 0.11122989243656398,
      "grad_norm": 0.30409279465675354,
      "learning_rate": 8.892697962918454e-05,
      "loss": 0.0034,
      "step": 1979500
    },
    {
      "epoch": 0.11125798788805086,
      "grad_norm": 0.30001622438430786,
      "learning_rate": 8.892416850443948e-05,
      "loss": 0.0037,
      "step": 1980000
    },
    {
      "epoch": 0.11125798788805086,
      "eval_loss": 0.0011176305124536157,
      "eval_runtime": 20.498,
      "eval_samples_per_second": 4878.531,
      "eval_steps_per_second": 76.251,
      "step": 1980000
    },
    {
      "epoch": 0.11128608333953774,
      "grad_norm": 0.22852389514446259,
      "learning_rate": 8.89213573796944e-05,
      "loss": 0.0032,
      "step": 1980500
    },
    {
      "epoch": 0.11131417879102462,
      "grad_norm": 0.18306277692317963,
      "learning_rate": 8.891854625494935e-05,
      "loss": 0.0031,
      "step": 1981000
    },
    {
      "epoch": 0.1113422742425115,
      "grad_norm": 0.12831656634807587,
      "learning_rate": 8.891573513020427e-05,
      "loss": 0.0036,
      "step": 1981500
    },
    {
      "epoch": 0.11137036969399838,
      "grad_norm": 0.04501403123140335,
      "learning_rate": 8.891292400545921e-05,
      "loss": 0.0035,
      "step": 1982000
    },
    {
      "epoch": 0.11139846514548526,
      "grad_norm": 1.1274560689926147,
      "learning_rate": 8.891011288071415e-05,
      "loss": 0.0036,
      "step": 1982500
    },
    {
      "epoch": 0.11142656059697216,
      "grad_norm": 0.10185586661100388,
      "learning_rate": 8.890730175596907e-05,
      "loss": 0.0031,
      "step": 1983000
    },
    {
      "epoch": 0.11145465604845904,
      "grad_norm": 0.1378890573978424,
      "learning_rate": 8.890449063122402e-05,
      "loss": 0.0033,
      "step": 1983500
    },
    {
      "epoch": 0.11148275149994592,
      "grad_norm": 0.015967847779393196,
      "learning_rate": 8.890167950647894e-05,
      "loss": 0.003,
      "step": 1984000
    },
    {
      "epoch": 0.1115108469514328,
      "grad_norm": 0.2720855176448822,
      "learning_rate": 8.889886838173389e-05,
      "loss": 0.0039,
      "step": 1984500
    },
    {
      "epoch": 0.11153894240291969,
      "grad_norm": 0.08666975051164627,
      "learning_rate": 8.88960572569888e-05,
      "loss": 0.0038,
      "step": 1985000
    },
    {
      "epoch": 0.11156703785440657,
      "grad_norm": 0.18525956571102142,
      "learning_rate": 8.889324613224374e-05,
      "loss": 0.0037,
      "step": 1985500
    },
    {
      "epoch": 0.11159513330589345,
      "grad_norm": 0.4377421438694,
      "learning_rate": 8.889043500749869e-05,
      "loss": 0.0037,
      "step": 1986000
    },
    {
      "epoch": 0.11162322875738033,
      "grad_norm": 0.015368866734206676,
      "learning_rate": 8.888762388275361e-05,
      "loss": 0.0035,
      "step": 1986500
    },
    {
      "epoch": 0.11165132420886721,
      "grad_norm": 0.09868405759334564,
      "learning_rate": 8.888481275800856e-05,
      "loss": 0.0031,
      "step": 1987000
    },
    {
      "epoch": 0.11167941966035409,
      "grad_norm": 0.11267565935850143,
      "learning_rate": 8.888200163326348e-05,
      "loss": 0.0035,
      "step": 1987500
    },
    {
      "epoch": 0.11170751511184097,
      "grad_norm": 0.21201056241989136,
      "learning_rate": 8.887919050851841e-05,
      "loss": 0.0036,
      "step": 1988000
    },
    {
      "epoch": 0.11173561056332786,
      "grad_norm": 0.5139074325561523,
      "learning_rate": 8.887637938377335e-05,
      "loss": 0.0033,
      "step": 1988500
    },
    {
      "epoch": 0.11176370601481474,
      "grad_norm": 0.12604691088199615,
      "learning_rate": 8.887356825902828e-05,
      "loss": 0.0039,
      "step": 1989000
    },
    {
      "epoch": 0.11179180146630162,
      "grad_norm": 0.07353223860263824,
      "learning_rate": 8.887075713428321e-05,
      "loss": 0.0036,
      "step": 1989500
    },
    {
      "epoch": 0.1118198969177885,
      "grad_norm": 0.09601051360368729,
      "learning_rate": 8.886794600953815e-05,
      "loss": 0.0035,
      "step": 1990000
    },
    {
      "epoch": 0.1118198969177885,
      "eval_loss": 0.0009686924167908728,
      "eval_runtime": 21.3405,
      "eval_samples_per_second": 4685.931,
      "eval_steps_per_second": 73.241,
      "step": 1990000
    },
    {
      "epoch": 0.11184799236927538,
      "grad_norm": 0.03197005018591881,
      "learning_rate": 8.886513488479308e-05,
      "loss": 0.0032,
      "step": 1990500
    },
    {
      "epoch": 0.11187608782076226,
      "grad_norm": 0.2379349023103714,
      "learning_rate": 8.886232376004802e-05,
      "loss": 0.003,
      "step": 1991000
    },
    {
      "epoch": 0.11190418327224914,
      "grad_norm": 0.04218382388353348,
      "learning_rate": 8.885951263530295e-05,
      "loss": 0.0036,
      "step": 1991500
    },
    {
      "epoch": 0.11193227872373603,
      "grad_norm": 0.20208323001861572,
      "learning_rate": 8.885670151055789e-05,
      "loss": 0.0035,
      "step": 1992000
    },
    {
      "epoch": 0.11196037417522291,
      "grad_norm": 0.2645913362503052,
      "learning_rate": 8.885389038581282e-05,
      "loss": 0.0035,
      "step": 1992500
    },
    {
      "epoch": 0.11198846962670979,
      "grad_norm": 0.20774993300437927,
      "learning_rate": 8.885107926106775e-05,
      "loss": 0.0035,
      "step": 1993000
    },
    {
      "epoch": 0.11201656507819667,
      "grad_norm": 0.4513762593269348,
      "learning_rate": 8.884826813632269e-05,
      "loss": 0.0037,
      "step": 1993500
    },
    {
      "epoch": 0.11204466052968355,
      "grad_norm": 0.28829294443130493,
      "learning_rate": 8.884545701157762e-05,
      "loss": 0.0035,
      "step": 1994000
    },
    {
      "epoch": 0.11207275598117043,
      "grad_norm": 0.26622605323791504,
      "learning_rate": 8.884264588683256e-05,
      "loss": 0.0036,
      "step": 1994500
    },
    {
      "epoch": 0.11210085143265731,
      "grad_norm": 0.5080221891403198,
      "learning_rate": 8.883983476208749e-05,
      "loss": 0.0033,
      "step": 1995000
    },
    {
      "epoch": 0.1121289468841442,
      "grad_norm": 0.36771681904792786,
      "learning_rate": 8.883702363734243e-05,
      "loss": 0.0033,
      "step": 1995500
    },
    {
      "epoch": 0.11215704233563108,
      "grad_norm": 0.021964797750115395,
      "learning_rate": 8.883421251259736e-05,
      "loss": 0.0034,
      "step": 1996000
    },
    {
      "epoch": 0.11218513778711796,
      "grad_norm": 0.04810341075062752,
      "learning_rate": 8.883140138785228e-05,
      "loss": 0.0038,
      "step": 1996500
    },
    {
      "epoch": 0.11221323323860484,
      "grad_norm": 0.1414511799812317,
      "learning_rate": 8.882859026310723e-05,
      "loss": 0.0037,
      "step": 1997000
    },
    {
      "epoch": 0.11224132869009172,
      "grad_norm": 0.045663729310035706,
      "learning_rate": 8.882577913836216e-05,
      "loss": 0.0034,
      "step": 1997500
    },
    {
      "epoch": 0.1122694241415786,
      "grad_norm": 0.17962580919265747,
      "learning_rate": 8.88229680136171e-05,
      "loss": 0.0034,
      "step": 1998000
    },
    {
      "epoch": 0.11229751959306548,
      "grad_norm": 0.1602739691734314,
      "learning_rate": 8.882015688887203e-05,
      "loss": 0.0034,
      "step": 1998500
    },
    {
      "epoch": 0.11232561504455237,
      "grad_norm": 0.12581636011600494,
      "learning_rate": 8.881734576412695e-05,
      "loss": 0.0037,
      "step": 1999000
    },
    {
      "epoch": 0.11235371049603925,
      "grad_norm": 0.06575322151184082,
      "learning_rate": 8.88145346393819e-05,
      "loss": 0.0033,
      "step": 1999500
    },
    {
      "epoch": 0.11238180594752613,
      "grad_norm": 0.07624582201242447,
      "learning_rate": 8.881172351463682e-05,
      "loss": 0.0036,
      "step": 2000000
    },
    {
      "epoch": 0.11238180594752613,
      "eval_loss": 0.0009573550196364522,
      "eval_runtime": 20.8494,
      "eval_samples_per_second": 4796.298,
      "eval_steps_per_second": 74.966,
      "step": 2000000
    },
    {
      "epoch": 0.11240990139901301,
      "grad_norm": 0.1984766125679016,
      "learning_rate": 8.880891238989177e-05,
      "loss": 0.0031,
      "step": 2000500
    },
    {
      "epoch": 0.11243799685049989,
      "grad_norm": 0.030303392559289932,
      "learning_rate": 8.880610126514669e-05,
      "loss": 0.0032,
      "step": 2001000
    },
    {
      "epoch": 0.11246609230198677,
      "grad_norm": 0.07780413329601288,
      "learning_rate": 8.880329014040162e-05,
      "loss": 0.0035,
      "step": 2001500
    },
    {
      "epoch": 0.11249418775347365,
      "grad_norm": 0.06867330521345139,
      "learning_rate": 8.880047901565657e-05,
      "loss": 0.0033,
      "step": 2002000
    },
    {
      "epoch": 0.11252228320496054,
      "grad_norm": 0.12742647528648376,
      "learning_rate": 8.879766789091149e-05,
      "loss": 0.0034,
      "step": 2002500
    },
    {
      "epoch": 0.11255037865644742,
      "grad_norm": 0.12136323750019073,
      "learning_rate": 8.879485676616644e-05,
      "loss": 0.0036,
      "step": 2003000
    },
    {
      "epoch": 0.1125784741079343,
      "grad_norm": 0.09162833541631699,
      "learning_rate": 8.879204564142136e-05,
      "loss": 0.0033,
      "step": 2003500
    },
    {
      "epoch": 0.11260656955942118,
      "grad_norm": 0.11725050956010818,
      "learning_rate": 8.87892345166763e-05,
      "loss": 0.0034,
      "step": 2004000
    },
    {
      "epoch": 0.11263466501090806,
      "grad_norm": 0.2526611387729645,
      "learning_rate": 8.878642339193123e-05,
      "loss": 0.0034,
      "step": 2004500
    },
    {
      "epoch": 0.11266276046239494,
      "grad_norm": 0.02469324879348278,
      "learning_rate": 8.878361226718616e-05,
      "loss": 0.0032,
      "step": 2005000
    },
    {
      "epoch": 0.11269085591388182,
      "grad_norm": 0.12171825021505356,
      "learning_rate": 8.878080114244111e-05,
      "loss": 0.0038,
      "step": 2005500
    },
    {
      "epoch": 0.1127189513653687,
      "grad_norm": 0.13790464401245117,
      "learning_rate": 8.877799001769603e-05,
      "loss": 0.004,
      "step": 2006000
    },
    {
      "epoch": 0.11274704681685559,
      "grad_norm": 0.34346872568130493,
      "learning_rate": 8.877517889295097e-05,
      "loss": 0.0039,
      "step": 2006500
    },
    {
      "epoch": 0.11277514226834247,
      "grad_norm": 0.1928027868270874,
      "learning_rate": 8.87723677682059e-05,
      "loss": 0.0032,
      "step": 2007000
    },
    {
      "epoch": 0.11280323771982935,
      "grad_norm": 0.4542957544326782,
      "learning_rate": 8.876955664346083e-05,
      "loss": 0.0035,
      "step": 2007500
    },
    {
      "epoch": 0.11283133317131623,
      "grad_norm": 0.14381492137908936,
      "learning_rate": 8.876674551871577e-05,
      "loss": 0.0036,
      "step": 2008000
    },
    {
      "epoch": 0.11285942862280311,
      "grad_norm": 0.3393492102622986,
      "learning_rate": 8.87639343939707e-05,
      "loss": 0.0036,
      "step": 2008500
    },
    {
      "epoch": 0.11288752407429,
      "grad_norm": 0.23797206580638885,
      "learning_rate": 8.876112326922564e-05,
      "loss": 0.0033,
      "step": 2009000
    },
    {
      "epoch": 0.11291561952577688,
      "grad_norm": 0.1436556577682495,
      "learning_rate": 8.875831214448057e-05,
      "loss": 0.0038,
      "step": 2009500
    },
    {
      "epoch": 0.11294371497726376,
      "grad_norm": 0.15631040930747986,
      "learning_rate": 8.87555010197355e-05,
      "loss": 0.0039,
      "step": 2010000
    },
    {
      "epoch": 0.11294371497726376,
      "eval_loss": 0.0010686377063393593,
      "eval_runtime": 21.0146,
      "eval_samples_per_second": 4758.606,
      "eval_steps_per_second": 74.377,
      "step": 2010000
    },
    {
      "epoch": 0.11297181042875064,
      "grad_norm": 0.13979491591453552,
      "learning_rate": 8.875268989499044e-05,
      "loss": 0.0037,
      "step": 2010500
    },
    {
      "epoch": 0.11299990588023752,
      "grad_norm": 0.2896650433540344,
      "learning_rate": 8.874987877024537e-05,
      "loss": 0.0032,
      "step": 2011000
    },
    {
      "epoch": 0.1130280013317244,
      "grad_norm": 0.05351383239030838,
      "learning_rate": 8.874706764550031e-05,
      "loss": 0.0032,
      "step": 2011500
    },
    {
      "epoch": 0.11305609678321128,
      "grad_norm": 0.011447306722402573,
      "learning_rate": 8.874425652075524e-05,
      "loss": 0.0031,
      "step": 2012000
    },
    {
      "epoch": 0.11308419223469816,
      "grad_norm": 0.24691610038280487,
      "learning_rate": 8.874144539601018e-05,
      "loss": 0.0034,
      "step": 2012500
    },
    {
      "epoch": 0.11311228768618505,
      "grad_norm": 0.12549658119678497,
      "learning_rate": 8.873863427126511e-05,
      "loss": 0.0034,
      "step": 2013000
    },
    {
      "epoch": 0.11314038313767193,
      "grad_norm": 0.22595283389091492,
      "learning_rate": 8.873582314652005e-05,
      "loss": 0.0034,
      "step": 2013500
    },
    {
      "epoch": 0.11316847858915881,
      "grad_norm": 0.26143738627433777,
      "learning_rate": 8.873301202177498e-05,
      "loss": 0.0035,
      "step": 2014000
    },
    {
      "epoch": 0.11319657404064569,
      "grad_norm": 0.09855612367391586,
      "learning_rate": 8.873020089702991e-05,
      "loss": 0.0034,
      "step": 2014500
    },
    {
      "epoch": 0.11322466949213257,
      "grad_norm": 0.09458869695663452,
      "learning_rate": 8.872738977228485e-05,
      "loss": 0.0032,
      "step": 2015000
    },
    {
      "epoch": 0.11325276494361945,
      "grad_norm": 0.4445010721683502,
      "learning_rate": 8.872457864753978e-05,
      "loss": 0.0041,
      "step": 2015500
    },
    {
      "epoch": 0.11328086039510633,
      "grad_norm": 0.09287916123867035,
      "learning_rate": 8.87217675227947e-05,
      "loss": 0.0043,
      "step": 2016000
    },
    {
      "epoch": 0.11330895584659322,
      "grad_norm": 0.08768012374639511,
      "learning_rate": 8.871895639804965e-05,
      "loss": 0.0033,
      "step": 2016500
    },
    {
      "epoch": 0.1133370512980801,
      "grad_norm": 0.024052614346146584,
      "learning_rate": 8.871614527330458e-05,
      "loss": 0.0032,
      "step": 2017000
    },
    {
      "epoch": 0.11336514674956698,
      "grad_norm": 0.04406220093369484,
      "learning_rate": 8.871333414855952e-05,
      "loss": 0.0031,
      "step": 2017500
    },
    {
      "epoch": 0.11339324220105386,
      "grad_norm": 0.17439095675945282,
      "learning_rate": 8.871052302381445e-05,
      "loss": 0.0033,
      "step": 2018000
    },
    {
      "epoch": 0.11342133765254074,
      "grad_norm": 0.36895230412483215,
      "learning_rate": 8.870771189906937e-05,
      "loss": 0.004,
      "step": 2018500
    },
    {
      "epoch": 0.11344943310402762,
      "grad_norm": 0.16915768384933472,
      "learning_rate": 8.870490077432432e-05,
      "loss": 0.0035,
      "step": 2019000
    },
    {
      "epoch": 0.1134775285555145,
      "grad_norm": 0.02588050067424774,
      "learning_rate": 8.870208964957924e-05,
      "loss": 0.0036,
      "step": 2019500
    },
    {
      "epoch": 0.11350562400700138,
      "grad_norm": 0.03309859707951546,
      "learning_rate": 8.869927852483419e-05,
      "loss": 0.0032,
      "step": 2020000
    },
    {
      "epoch": 0.11350562400700138,
      "eval_loss": 0.0009140180191025138,
      "eval_runtime": 21.3651,
      "eval_samples_per_second": 4680.522,
      "eval_steps_per_second": 73.157,
      "step": 2020000
    },
    {
      "epoch": 0.11353371945848827,
      "grad_norm": 0.04195785894989967,
      "learning_rate": 8.869646740008911e-05,
      "loss": 0.0036,
      "step": 2020500
    },
    {
      "epoch": 0.11356181490997515,
      "grad_norm": 0.18672722578048706,
      "learning_rate": 8.869365627534405e-05,
      "loss": 0.0033,
      "step": 2021000
    },
    {
      "epoch": 0.11358991036146203,
      "grad_norm": 0.21580193936824799,
      "learning_rate": 8.869084515059899e-05,
      "loss": 0.0036,
      "step": 2021500
    },
    {
      "epoch": 0.11361800581294891,
      "grad_norm": 0.3745381236076355,
      "learning_rate": 8.868803402585391e-05,
      "loss": 0.0034,
      "step": 2022000
    },
    {
      "epoch": 0.11364610126443579,
      "grad_norm": 0.942057728767395,
      "learning_rate": 8.868522290110886e-05,
      "loss": 0.0037,
      "step": 2022500
    },
    {
      "epoch": 0.11367419671592267,
      "grad_norm": 0.2211517095565796,
      "learning_rate": 8.868241177636378e-05,
      "loss": 0.0035,
      "step": 2023000
    },
    {
      "epoch": 0.11370229216740955,
      "grad_norm": 0.09028757363557816,
      "learning_rate": 8.867960065161872e-05,
      "loss": 0.0037,
      "step": 2023500
    },
    {
      "epoch": 0.11373038761889644,
      "grad_norm": 0.009037063457071781,
      "learning_rate": 8.867678952687365e-05,
      "loss": 0.0034,
      "step": 2024000
    },
    {
      "epoch": 0.11375848307038332,
      "grad_norm": 0.21865014731884003,
      "learning_rate": 8.867397840212858e-05,
      "loss": 0.0032,
      "step": 2024500
    },
    {
      "epoch": 0.1137865785218702,
      "grad_norm": 0.12529250979423523,
      "learning_rate": 8.867116727738353e-05,
      "loss": 0.0037,
      "step": 2025000
    },
    {
      "epoch": 0.11381467397335708,
      "grad_norm": 0.526752233505249,
      "learning_rate": 8.866835615263845e-05,
      "loss": 0.0032,
      "step": 2025500
    },
    {
      "epoch": 0.11384276942484396,
      "grad_norm": 0.16500836610794067,
      "learning_rate": 8.866554502789339e-05,
      "loss": 0.0034,
      "step": 2026000
    },
    {
      "epoch": 0.11387086487633084,
      "grad_norm": 0.1320427656173706,
      "learning_rate": 8.866273390314832e-05,
      "loss": 0.0037,
      "step": 2026500
    },
    {
      "epoch": 0.11389896032781772,
      "grad_norm": 0.29928264021873474,
      "learning_rate": 8.865992277840326e-05,
      "loss": 0.0037,
      "step": 2027000
    },
    {
      "epoch": 0.1139270557793046,
      "grad_norm": 0.1300007402896881,
      "learning_rate": 8.865711165365819e-05,
      "loss": 0.0038,
      "step": 2027500
    },
    {
      "epoch": 0.11395515123079149,
      "grad_norm": 0.1438903659582138,
      "learning_rate": 8.865430052891312e-05,
      "loss": 0.0031,
      "step": 2028000
    },
    {
      "epoch": 0.11398324668227837,
      "grad_norm": 0.2127365916967392,
      "learning_rate": 8.865148940416806e-05,
      "loss": 0.0035,
      "step": 2028500
    },
    {
      "epoch": 0.11401134213376525,
      "grad_norm": 0.24760612845420837,
      "learning_rate": 8.864867827942299e-05,
      "loss": 0.0031,
      "step": 2029000
    },
    {
      "epoch": 0.11403943758525213,
      "grad_norm": 0.05509030073881149,
      "learning_rate": 8.864586715467793e-05,
      "loss": 0.0033,
      "step": 2029500
    },
    {
      "epoch": 0.11406753303673901,
      "grad_norm": 0.09522388130426407,
      "learning_rate": 8.864305602993286e-05,
      "loss": 0.0035,
      "step": 2030000
    },
    {
      "epoch": 0.11406753303673901,
      "eval_loss": 0.0010058473562821746,
      "eval_runtime": 21.5699,
      "eval_samples_per_second": 4636.093,
      "eval_steps_per_second": 72.462,
      "step": 2030000
    },
    {
      "epoch": 0.1140956284882259,
      "grad_norm": 0.10671861469745636,
      "learning_rate": 8.86402449051878e-05,
      "loss": 0.0033,
      "step": 2030500
    },
    {
      "epoch": 0.11412372393971278,
      "grad_norm": 0.09003587812185287,
      "learning_rate": 8.863743378044273e-05,
      "loss": 0.0037,
      "step": 2031000
    },
    {
      "epoch": 0.11415181939119966,
      "grad_norm": 0.022479252889752388,
      "learning_rate": 8.863462265569766e-05,
      "loss": 0.0039,
      "step": 2031500
    },
    {
      "epoch": 0.11417991484268654,
      "grad_norm": 0.006614909507334232,
      "learning_rate": 8.863181153095259e-05,
      "loss": 0.0032,
      "step": 2032000
    },
    {
      "epoch": 0.11420801029417342,
      "grad_norm": 0.007570501882582903,
      "learning_rate": 8.862900040620753e-05,
      "loss": 0.0035,
      "step": 2032500
    },
    {
      "epoch": 0.1142361057456603,
      "grad_norm": 0.31181764602661133,
      "learning_rate": 8.862618928146247e-05,
      "loss": 0.0036,
      "step": 2033000
    },
    {
      "epoch": 0.11426420119714718,
      "grad_norm": 0.11055704951286316,
      "learning_rate": 8.86233781567174e-05,
      "loss": 0.0036,
      "step": 2033500
    },
    {
      "epoch": 0.11429229664863406,
      "grad_norm": 0.1619977504014969,
      "learning_rate": 8.862056703197234e-05,
      "loss": 0.0036,
      "step": 2034000
    },
    {
      "epoch": 0.11432039210012095,
      "grad_norm": 0.13194969296455383,
      "learning_rate": 8.861775590722726e-05,
      "loss": 0.0034,
      "step": 2034500
    },
    {
      "epoch": 0.11434848755160783,
      "grad_norm": 0.020682532340288162,
      "learning_rate": 8.86149447824822e-05,
      "loss": 0.0033,
      "step": 2035000
    },
    {
      "epoch": 0.11437658300309471,
      "grad_norm": 0.012436321936547756,
      "learning_rate": 8.861213365773712e-05,
      "loss": 0.0033,
      "step": 2035500
    },
    {
      "epoch": 0.11440467845458159,
      "grad_norm": 0.00644836388528347,
      "learning_rate": 8.860932253299207e-05,
      "loss": 0.0036,
      "step": 2036000
    },
    {
      "epoch": 0.11443277390606847,
      "grad_norm": 0.32172656059265137,
      "learning_rate": 8.860651140824701e-05,
      "loss": 0.0031,
      "step": 2036500
    },
    {
      "epoch": 0.11446086935755535,
      "grad_norm": 0.0341893769800663,
      "learning_rate": 8.860370028350193e-05,
      "loss": 0.0032,
      "step": 2037000
    },
    {
      "epoch": 0.11448896480904223,
      "grad_norm": 0.24907436966896057,
      "learning_rate": 8.860088915875688e-05,
      "loss": 0.0033,
      "step": 2037500
    },
    {
      "epoch": 0.11451706026052912,
      "grad_norm": 0.02366035431623459,
      "learning_rate": 8.85980780340118e-05,
      "loss": 0.0035,
      "step": 2038000
    },
    {
      "epoch": 0.114545155712016,
      "grad_norm": 0.07230642437934875,
      "learning_rate": 8.859526690926674e-05,
      "loss": 0.0034,
      "step": 2038500
    },
    {
      "epoch": 0.11457325116350288,
      "grad_norm": 0.057147443294525146,
      "learning_rate": 8.859245578452166e-05,
      "loss": 0.0035,
      "step": 2039000
    },
    {
      "epoch": 0.11460134661498976,
      "grad_norm": 0.020804135128855705,
      "learning_rate": 8.85896446597766e-05,
      "loss": 0.0035,
      "step": 2039500
    },
    {
      "epoch": 0.11462944206647664,
      "grad_norm": 0.18895606696605682,
      "learning_rate": 8.858683353503153e-05,
      "loss": 0.0034,
      "step": 2040000
    },
    {
      "epoch": 0.11462944206647664,
      "eval_loss": 0.0009520776802673936,
      "eval_runtime": 21.2083,
      "eval_samples_per_second": 4715.144,
      "eval_steps_per_second": 73.698,
      "step": 2040000
    },
    {
      "epoch": 0.11465753751796352,
      "grad_norm": 0.11276011168956757,
      "learning_rate": 8.858402241028647e-05,
      "loss": 0.0033,
      "step": 2040500
    },
    {
      "epoch": 0.1146856329694504,
      "grad_norm": 0.06699661165475845,
      "learning_rate": 8.858121128554142e-05,
      "loss": 0.0037,
      "step": 2041000
    },
    {
      "epoch": 0.11471372842093729,
      "grad_norm": 0.24235881865024567,
      "learning_rate": 8.857840016079634e-05,
      "loss": 0.0034,
      "step": 2041500
    },
    {
      "epoch": 0.11474182387242417,
      "grad_norm": 0.08628302067518234,
      "learning_rate": 8.857558903605127e-05,
      "loss": 0.003,
      "step": 2042000
    },
    {
      "epoch": 0.11476991932391105,
      "grad_norm": 0.1085679680109024,
      "learning_rate": 8.85727779113062e-05,
      "loss": 0.0033,
      "step": 2042500
    },
    {
      "epoch": 0.11479801477539793,
      "grad_norm": 0.20214250683784485,
      "learning_rate": 8.856996678656114e-05,
      "loss": 0.0034,
      "step": 2043000
    },
    {
      "epoch": 0.11482611022688481,
      "grad_norm": 0.29452839493751526,
      "learning_rate": 8.856715566181607e-05,
      "loss": 0.0036,
      "step": 2043500
    },
    {
      "epoch": 0.1148542056783717,
      "grad_norm": 1.1739393472671509,
      "learning_rate": 8.856434453707101e-05,
      "loss": 0.0036,
      "step": 2044000
    },
    {
      "epoch": 0.11488230112985859,
      "grad_norm": 0.02883232571184635,
      "learning_rate": 8.856153341232594e-05,
      "loss": 0.003,
      "step": 2044500
    },
    {
      "epoch": 0.11491039658134547,
      "grad_norm": 0.28272292017936707,
      "learning_rate": 8.855872228758088e-05,
      "loss": 0.003,
      "step": 2045000
    },
    {
      "epoch": 0.11493849203283235,
      "grad_norm": 0.19343119859695435,
      "learning_rate": 8.855591116283581e-05,
      "loss": 0.0035,
      "step": 2045500
    },
    {
      "epoch": 0.11496658748431923,
      "grad_norm": 0.23017920553684235,
      "learning_rate": 8.855310003809074e-05,
      "loss": 0.0031,
      "step": 2046000
    },
    {
      "epoch": 0.11499468293580611,
      "grad_norm": 0.16965626180171967,
      "learning_rate": 8.855028891334568e-05,
      "loss": 0.0034,
      "step": 2046500
    },
    {
      "epoch": 0.115022778387293,
      "grad_norm": 0.412509024143219,
      "learning_rate": 8.854747778860061e-05,
      "loss": 0.0034,
      "step": 2047000
    },
    {
      "epoch": 0.11505087383877988,
      "grad_norm": 0.17939473688602448,
      "learning_rate": 8.854466666385555e-05,
      "loss": 0.0033,
      "step": 2047500
    },
    {
      "epoch": 0.11507896929026676,
      "grad_norm": 0.2843863070011139,
      "learning_rate": 8.854185553911048e-05,
      "loss": 0.0036,
      "step": 2048000
    },
    {
      "epoch": 0.11510706474175364,
      "grad_norm": 0.1407933235168457,
      "learning_rate": 8.853904441436542e-05,
      "loss": 0.0037,
      "step": 2048500
    },
    {
      "epoch": 0.11513516019324052,
      "grad_norm": 0.07419268786907196,
      "learning_rate": 8.853623328962035e-05,
      "loss": 0.003,
      "step": 2049000
    },
    {
      "epoch": 0.1151632556447274,
      "grad_norm": 0.8977330923080444,
      "learning_rate": 8.853342216487528e-05,
      "loss": 0.0036,
      "step": 2049500
    },
    {
      "epoch": 0.11519135109621428,
      "grad_norm": 0.060343313962221146,
      "learning_rate": 8.853061104013022e-05,
      "loss": 0.0035,
      "step": 2050000
    },
    {
      "epoch": 0.11519135109621428,
      "eval_loss": 0.0009185041999444366,
      "eval_runtime": 21.198,
      "eval_samples_per_second": 4717.436,
      "eval_steps_per_second": 73.734,
      "step": 2050000
    },
    {
      "epoch": 0.11521944654770117,
      "grad_norm": 0.29479196667671204,
      "learning_rate": 8.852779991538515e-05,
      "loss": 0.0031,
      "step": 2050500
    },
    {
      "epoch": 0.11524754199918805,
      "grad_norm": 0.31556662917137146,
      "learning_rate": 8.852498879064009e-05,
      "loss": 0.0036,
      "step": 2051000
    },
    {
      "epoch": 0.11527563745067493,
      "grad_norm": 0.07352384179830551,
      "learning_rate": 8.852217766589501e-05,
      "loss": 0.0037,
      "step": 2051500
    },
    {
      "epoch": 0.11530373290216181,
      "grad_norm": 0.38281628489494324,
      "learning_rate": 8.851936654114995e-05,
      "loss": 0.0033,
      "step": 2052000
    },
    {
      "epoch": 0.11533182835364869,
      "grad_norm": 0.2761682868003845,
      "learning_rate": 8.851655541640489e-05,
      "loss": 0.0036,
      "step": 2052500
    },
    {
      "epoch": 0.11535992380513557,
      "grad_norm": 0.32999560236930847,
      "learning_rate": 8.851374429165982e-05,
      "loss": 0.0035,
      "step": 2053000
    },
    {
      "epoch": 0.11538801925662245,
      "grad_norm": 0.06934799253940582,
      "learning_rate": 8.851093316691476e-05,
      "loss": 0.0032,
      "step": 2053500
    },
    {
      "epoch": 0.11541611470810934,
      "grad_norm": 0.0015590874245390296,
      "learning_rate": 8.850812204216968e-05,
      "loss": 0.0039,
      "step": 2054000
    },
    {
      "epoch": 0.11544421015959622,
      "grad_norm": 0.12612146139144897,
      "learning_rate": 8.850531091742463e-05,
      "loss": 0.0034,
      "step": 2054500
    },
    {
      "epoch": 0.1154723056110831,
      "grad_norm": 0.2275298833847046,
      "learning_rate": 8.850249979267955e-05,
      "loss": 0.0036,
      "step": 2055000
    },
    {
      "epoch": 0.11550040106256998,
      "grad_norm": 2.466493606567383,
      "learning_rate": 8.84996886679345e-05,
      "loss": 0.0034,
      "step": 2055500
    },
    {
      "epoch": 0.11552849651405686,
      "grad_norm": 0.3368181586265564,
      "learning_rate": 8.849687754318943e-05,
      "loss": 0.0037,
      "step": 2056000
    },
    {
      "epoch": 0.11555659196554374,
      "grad_norm": 0.10436995327472687,
      "learning_rate": 8.849406641844435e-05,
      "loss": 0.0035,
      "step": 2056500
    },
    {
      "epoch": 0.11558468741703062,
      "grad_norm": 0.1122901439666748,
      "learning_rate": 8.84912552936993e-05,
      "loss": 0.0029,
      "step": 2057000
    },
    {
      "epoch": 0.1156127828685175,
      "grad_norm": 0.01626911200582981,
      "learning_rate": 8.848844416895422e-05,
      "loss": 0.0037,
      "step": 2057500
    },
    {
      "epoch": 0.11564087832000439,
      "grad_norm": 0.07723339647054672,
      "learning_rate": 8.848563304420917e-05,
      "loss": 0.0039,
      "step": 2058000
    },
    {
      "epoch": 0.11566897377149127,
      "grad_norm": 0.30068734288215637,
      "learning_rate": 8.848282191946409e-05,
      "loss": 0.0032,
      "step": 2058500
    },
    {
      "epoch": 0.11569706922297815,
      "grad_norm": 0.14972840249538422,
      "learning_rate": 8.848001079471902e-05,
      "loss": 0.0032,
      "step": 2059000
    },
    {
      "epoch": 0.11572516467446503,
      "grad_norm": 0.31999456882476807,
      "learning_rate": 8.847719966997397e-05,
      "loss": 0.0034,
      "step": 2059500
    },
    {
      "epoch": 0.11575326012595191,
      "grad_norm": 0.1329042762517929,
      "learning_rate": 8.847438854522889e-05,
      "loss": 0.0033,
      "step": 2060000
    },
    {
      "epoch": 0.11575326012595191,
      "eval_loss": 0.0011008490109816194,
      "eval_runtime": 21.4042,
      "eval_samples_per_second": 4671.978,
      "eval_steps_per_second": 73.023,
      "step": 2060000
    },
    {
      "epoch": 0.1157813555774388,
      "grad_norm": 0.31856435537338257,
      "learning_rate": 8.847157742048384e-05,
      "loss": 0.0035,
      "step": 2060500
    },
    {
      "epoch": 0.11580945102892568,
      "grad_norm": 0.04703819379210472,
      "learning_rate": 8.846876629573876e-05,
      "loss": 0.0032,
      "step": 2061000
    },
    {
      "epoch": 0.11583754648041256,
      "grad_norm": 0.16204619407653809,
      "learning_rate": 8.846595517099369e-05,
      "loss": 0.0037,
      "step": 2061500
    },
    {
      "epoch": 0.11586564193189944,
      "grad_norm": 0.5784881114959717,
      "learning_rate": 8.846314404624863e-05,
      "loss": 0.0034,
      "step": 2062000
    },
    {
      "epoch": 0.11589373738338632,
      "grad_norm": 0.3188836872577667,
      "learning_rate": 8.846033292150356e-05,
      "loss": 0.0033,
      "step": 2062500
    },
    {
      "epoch": 0.1159218328348732,
      "grad_norm": 0.5541816353797913,
      "learning_rate": 8.84575217967585e-05,
      "loss": 0.0035,
      "step": 2063000
    },
    {
      "epoch": 0.11594992828636008,
      "grad_norm": 0.237843856215477,
      "learning_rate": 8.845471067201343e-05,
      "loss": 0.0034,
      "step": 2063500
    },
    {
      "epoch": 0.11597802373784696,
      "grad_norm": 0.39492350816726685,
      "learning_rate": 8.845189954726836e-05,
      "loss": 0.0031,
      "step": 2064000
    },
    {
      "epoch": 0.11600611918933385,
      "grad_norm": 0.26928406953811646,
      "learning_rate": 8.84490884225233e-05,
      "loss": 0.0031,
      "step": 2064500
    },
    {
      "epoch": 0.11603421464082073,
      "grad_norm": 0.10857639461755753,
      "learning_rate": 8.844627729777823e-05,
      "loss": 0.0034,
      "step": 2065000
    },
    {
      "epoch": 0.11606231009230761,
      "grad_norm": 0.31078723073005676,
      "learning_rate": 8.844346617303317e-05,
      "loss": 0.0037,
      "step": 2065500
    },
    {
      "epoch": 0.11609040554379449,
      "grad_norm": 0.012858640402555466,
      "learning_rate": 8.84406550482881e-05,
      "loss": 0.0029,
      "step": 2066000
    },
    {
      "epoch": 0.11611850099528137,
      "grad_norm": 0.3739479184150696,
      "learning_rate": 8.843784392354303e-05,
      "loss": 0.0039,
      "step": 2066500
    },
    {
      "epoch": 0.11614659644676825,
      "grad_norm": 0.34293681383132935,
      "learning_rate": 8.843503279879797e-05,
      "loss": 0.0037,
      "step": 2067000
    },
    {
      "epoch": 0.11617469189825513,
      "grad_norm": 0.11198814958333969,
      "learning_rate": 8.84322216740529e-05,
      "loss": 0.0037,
      "step": 2067500
    },
    {
      "epoch": 0.11620278734974201,
      "grad_norm": 0.266759991645813,
      "learning_rate": 8.842941054930784e-05,
      "loss": 0.0035,
      "step": 2068000
    },
    {
      "epoch": 0.1162308828012289,
      "grad_norm": 0.20282705128192902,
      "learning_rate": 8.842659942456277e-05,
      "loss": 0.0036,
      "step": 2068500
    },
    {
      "epoch": 0.11625897825271578,
      "grad_norm": 0.45684361457824707,
      "learning_rate": 8.84237882998177e-05,
      "loss": 0.0036,
      "step": 2069000
    },
    {
      "epoch": 0.11628707370420266,
      "grad_norm": 0.039820872247219086,
      "learning_rate": 8.842097717507264e-05,
      "loss": 0.003,
      "step": 2069500
    },
    {
      "epoch": 0.11631516915568954,
      "grad_norm": 0.16388577222824097,
      "learning_rate": 8.841816605032756e-05,
      "loss": 0.0037,
      "step": 2070000
    },
    {
      "epoch": 0.11631516915568954,
      "eval_loss": 0.0010890185367316008,
      "eval_runtime": 20.8052,
      "eval_samples_per_second": 4806.493,
      "eval_steps_per_second": 75.125,
      "step": 2070000
    },
    {
      "epoch": 0.11634326460717642,
      "grad_norm": 0.08570024371147156,
      "learning_rate": 8.841535492558251e-05,
      "loss": 0.0033,
      "step": 2070500
    },
    {
      "epoch": 0.1163713600586633,
      "grad_norm": 0.11683829873800278,
      "learning_rate": 8.841254380083743e-05,
      "loss": 0.0039,
      "step": 2071000
    },
    {
      "epoch": 0.11639945551015018,
      "grad_norm": 0.1209435760974884,
      "learning_rate": 8.840973267609238e-05,
      "loss": 0.0036,
      "step": 2071500
    },
    {
      "epoch": 0.11642755096163707,
      "grad_norm": 0.03184112161397934,
      "learning_rate": 8.840692155134731e-05,
      "loss": 0.0035,
      "step": 2072000
    },
    {
      "epoch": 0.11645564641312395,
      "grad_norm": 0.2284742146730423,
      "learning_rate": 8.840411042660223e-05,
      "loss": 0.0035,
      "step": 2072500
    },
    {
      "epoch": 0.11648374186461083,
      "grad_norm": 0.6838604807853699,
      "learning_rate": 8.840129930185718e-05,
      "loss": 0.0036,
      "step": 2073000
    },
    {
      "epoch": 0.11651183731609771,
      "grad_norm": 0.1951485276222229,
      "learning_rate": 8.83984881771121e-05,
      "loss": 0.0034,
      "step": 2073500
    },
    {
      "epoch": 0.11653993276758459,
      "grad_norm": 0.13264967501163483,
      "learning_rate": 8.839567705236705e-05,
      "loss": 0.0032,
      "step": 2074000
    },
    {
      "epoch": 0.11656802821907147,
      "grad_norm": 0.26691552996635437,
      "learning_rate": 8.839286592762197e-05,
      "loss": 0.0044,
      "step": 2074500
    },
    {
      "epoch": 0.11659612367055835,
      "grad_norm": 0.03371751680970192,
      "learning_rate": 8.83900548028769e-05,
      "loss": 0.0035,
      "step": 2075000
    },
    {
      "epoch": 0.11662421912204524,
      "grad_norm": 0.08038131892681122,
      "learning_rate": 8.838724367813185e-05,
      "loss": 0.0035,
      "step": 2075500
    },
    {
      "epoch": 0.11665231457353212,
      "grad_norm": 0.01410088874399662,
      "learning_rate": 8.838443255338677e-05,
      "loss": 0.0034,
      "step": 2076000
    },
    {
      "epoch": 0.116680410025019,
      "grad_norm": 0.1705130785703659,
      "learning_rate": 8.838162142864172e-05,
      "loss": 0.0034,
      "step": 2076500
    },
    {
      "epoch": 0.11670850547650588,
      "grad_norm": 0.04325655847787857,
      "learning_rate": 8.837881030389664e-05,
      "loss": 0.0032,
      "step": 2077000
    },
    {
      "epoch": 0.11673660092799276,
      "grad_norm": 0.1133064478635788,
      "learning_rate": 8.837599917915157e-05,
      "loss": 0.0032,
      "step": 2077500
    },
    {
      "epoch": 0.11676469637947964,
      "grad_norm": 0.7130228281021118,
      "learning_rate": 8.837318805440651e-05,
      "loss": 0.0038,
      "step": 2078000
    },
    {
      "epoch": 0.11679279183096652,
      "grad_norm": 0.31087782979011536,
      "learning_rate": 8.837037692966144e-05,
      "loss": 0.0033,
      "step": 2078500
    },
    {
      "epoch": 0.1168208872824534,
      "grad_norm": 0.0696057379245758,
      "learning_rate": 8.836756580491639e-05,
      "loss": 0.0037,
      "step": 2079000
    },
    {
      "epoch": 0.11684898273394029,
      "grad_norm": 0.06058643385767937,
      "learning_rate": 8.836475468017131e-05,
      "loss": 0.003,
      "step": 2079500
    },
    {
      "epoch": 0.11687707818542717,
      "grad_norm": 0.06922844797372818,
      "learning_rate": 8.836194355542625e-05,
      "loss": 0.0032,
      "step": 2080000
    },
    {
      "epoch": 0.11687707818542717,
      "eval_loss": 0.0010371992830187082,
      "eval_runtime": 21.4361,
      "eval_samples_per_second": 4665.017,
      "eval_steps_per_second": 72.914,
      "step": 2080000
    },
    {
      "epoch": 0.11690517363691405,
      "grad_norm": 0.4799737334251404,
      "learning_rate": 8.835913243068118e-05,
      "loss": 0.0036,
      "step": 2080500
    },
    {
      "epoch": 0.11693326908840093,
      "grad_norm": 0.46592196822166443,
      "learning_rate": 8.835632130593611e-05,
      "loss": 0.0034,
      "step": 2081000
    },
    {
      "epoch": 0.11696136453988781,
      "grad_norm": 0.3615148663520813,
      "learning_rate": 8.835351018119105e-05,
      "loss": 0.0039,
      "step": 2081500
    },
    {
      "epoch": 0.1169894599913747,
      "grad_norm": 0.09727933257818222,
      "learning_rate": 8.835069905644598e-05,
      "loss": 0.0033,
      "step": 2082000
    },
    {
      "epoch": 0.11701755544286158,
      "grad_norm": 0.05615749582648277,
      "learning_rate": 8.834788793170092e-05,
      "loss": 0.0034,
      "step": 2082500
    },
    {
      "epoch": 0.11704565089434846,
      "grad_norm": 0.044777967035770416,
      "learning_rate": 8.834507680695585e-05,
      "loss": 0.0033,
      "step": 2083000
    },
    {
      "epoch": 0.11707374634583534,
      "grad_norm": 0.046710673719644547,
      "learning_rate": 8.834226568221079e-05,
      "loss": 0.0034,
      "step": 2083500
    },
    {
      "epoch": 0.11710184179732222,
      "grad_norm": 0.010143487714231014,
      "learning_rate": 8.833945455746572e-05,
      "loss": 0.0036,
      "step": 2084000
    },
    {
      "epoch": 0.1171299372488091,
      "grad_norm": 0.04070751741528511,
      "learning_rate": 8.833664343272065e-05,
      "loss": 0.0035,
      "step": 2084500
    },
    {
      "epoch": 0.11715803270029598,
      "grad_norm": 0.32201939821243286,
      "learning_rate": 8.833383230797559e-05,
      "loss": 0.0036,
      "step": 2085000
    },
    {
      "epoch": 0.11718612815178286,
      "grad_norm": 0.6592568159103394,
      "learning_rate": 8.833102118323052e-05,
      "loss": 0.0033,
      "step": 2085500
    },
    {
      "epoch": 0.11721422360326975,
      "grad_norm": 0.3065859377384186,
      "learning_rate": 8.832821005848546e-05,
      "loss": 0.0037,
      "step": 2086000
    },
    {
      "epoch": 0.11724231905475663,
      "grad_norm": 0.28870218992233276,
      "learning_rate": 8.832539893374039e-05,
      "loss": 0.0035,
      "step": 2086500
    },
    {
      "epoch": 0.11727041450624351,
      "grad_norm": 0.020488955080509186,
      "learning_rate": 8.832258780899532e-05,
      "loss": 0.0032,
      "step": 2087000
    },
    {
      "epoch": 0.11729850995773039,
      "grad_norm": 0.023965073749423027,
      "learning_rate": 8.831977668425026e-05,
      "loss": 0.0033,
      "step": 2087500
    },
    {
      "epoch": 0.11732660540921727,
      "grad_norm": 0.6059281229972839,
      "learning_rate": 8.83169655595052e-05,
      "loss": 0.0037,
      "step": 2088000
    },
    {
      "epoch": 0.11735470086070415,
      "grad_norm": 0.18878744542598724,
      "learning_rate": 8.831415443476013e-05,
      "loss": 0.0037,
      "step": 2088500
    },
    {
      "epoch": 0.11738279631219103,
      "grad_norm": 0.07157760858535767,
      "learning_rate": 8.831134331001506e-05,
      "loss": 0.0029,
      "step": 2089000
    },
    {
      "epoch": 0.11741089176367792,
      "grad_norm": 0.5572594404220581,
      "learning_rate": 8.830853218526998e-05,
      "loss": 0.0033,
      "step": 2089500
    },
    {
      "epoch": 0.1174389872151648,
      "grad_norm": 0.03606130927801132,
      "learning_rate": 8.830572106052493e-05,
      "loss": 0.0036,
      "step": 2090000
    },
    {
      "epoch": 0.1174389872151648,
      "eval_loss": 0.0009573614806868136,
      "eval_runtime": 21.0537,
      "eval_samples_per_second": 4749.764,
      "eval_steps_per_second": 74.239,
      "step": 2090000
    },
    {
      "epoch": 0.11746708266665168,
      "grad_norm": 0.006238874047994614,
      "learning_rate": 8.830290993577985e-05,
      "loss": 0.0034,
      "step": 2090500
    },
    {
      "epoch": 0.11749517811813856,
      "grad_norm": 0.4211447834968567,
      "learning_rate": 8.83000988110348e-05,
      "loss": 0.0034,
      "step": 2091000
    },
    {
      "epoch": 0.11752327356962544,
      "grad_norm": 0.15046995878219604,
      "learning_rate": 8.829728768628973e-05,
      "loss": 0.0035,
      "step": 2091500
    },
    {
      "epoch": 0.11755136902111232,
      "grad_norm": 0.12838776409626007,
      "learning_rate": 8.829447656154465e-05,
      "loss": 0.0037,
      "step": 2092000
    },
    {
      "epoch": 0.1175794644725992,
      "grad_norm": 0.21827693283557892,
      "learning_rate": 8.82916654367996e-05,
      "loss": 0.0033,
      "step": 2092500
    },
    {
      "epoch": 0.11760755992408609,
      "grad_norm": 0.07833577692508698,
      "learning_rate": 8.828885431205452e-05,
      "loss": 0.003,
      "step": 2093000
    },
    {
      "epoch": 0.11763565537557297,
      "grad_norm": 0.06977199763059616,
      "learning_rate": 8.828604318730947e-05,
      "loss": 0.0031,
      "step": 2093500
    },
    {
      "epoch": 0.11766375082705985,
      "grad_norm": 0.007098248694092035,
      "learning_rate": 8.828323206256439e-05,
      "loss": 0.0035,
      "step": 2094000
    },
    {
      "epoch": 0.11769184627854673,
      "grad_norm": 0.084495410323143,
      "learning_rate": 8.828042093781932e-05,
      "loss": 0.0031,
      "step": 2094500
    },
    {
      "epoch": 0.11771994173003361,
      "grad_norm": 0.022701947018504143,
      "learning_rate": 8.827760981307427e-05,
      "loss": 0.0038,
      "step": 2095000
    },
    {
      "epoch": 0.11774803718152049,
      "grad_norm": 0.24482755362987518,
      "learning_rate": 8.82747986883292e-05,
      "loss": 0.0032,
      "step": 2095500
    },
    {
      "epoch": 0.11777613263300737,
      "grad_norm": 0.1907288134098053,
      "learning_rate": 8.827198756358414e-05,
      "loss": 0.0035,
      "step": 2096000
    },
    {
      "epoch": 0.11780422808449426,
      "grad_norm": 0.40336328744888306,
      "learning_rate": 8.826917643883906e-05,
      "loss": 0.0035,
      "step": 2096500
    },
    {
      "epoch": 0.11783232353598114,
      "grad_norm": 0.06036648154258728,
      "learning_rate": 8.8266365314094e-05,
      "loss": 0.0033,
      "step": 2097000
    },
    {
      "epoch": 0.11786041898746802,
      "grad_norm": 0.12179279327392578,
      "learning_rate": 8.826355418934893e-05,
      "loss": 0.0031,
      "step": 2097500
    },
    {
      "epoch": 0.1178885144389549,
      "grad_norm": 0.2584671378135681,
      "learning_rate": 8.826074306460386e-05,
      "loss": 0.0034,
      "step": 2098000
    },
    {
      "epoch": 0.11791660989044178,
      "grad_norm": 0.043458241969347,
      "learning_rate": 8.825793193985881e-05,
      "loss": 0.0043,
      "step": 2098500
    },
    {
      "epoch": 0.11794470534192866,
      "grad_norm": 0.1946551352739334,
      "learning_rate": 8.825512081511373e-05,
      "loss": 0.0035,
      "step": 2099000
    },
    {
      "epoch": 0.11797280079341554,
      "grad_norm": 0.03716660663485527,
      "learning_rate": 8.825230969036867e-05,
      "loss": 0.0038,
      "step": 2099500
    },
    {
      "epoch": 0.11800089624490243,
      "grad_norm": 0.13105052709579468,
      "learning_rate": 8.82494985656236e-05,
      "loss": 0.0033,
      "step": 2100000
    },
    {
      "epoch": 0.11800089624490243,
      "eval_loss": 0.0009389984770677984,
      "eval_runtime": 21.0747,
      "eval_samples_per_second": 4745.024,
      "eval_steps_per_second": 74.165,
      "step": 2100000
    },
    {
      "epoch": 0.11802899169638931,
      "grad_norm": 0.016745569184422493,
      "learning_rate": 8.824668744087854e-05,
      "loss": 0.0032,
      "step": 2100500
    },
    {
      "epoch": 0.11805708714787619,
      "grad_norm": 0.12199407070875168,
      "learning_rate": 8.824387631613347e-05,
      "loss": 0.0033,
      "step": 2101000
    },
    {
      "epoch": 0.11808518259936307,
      "grad_norm": 0.0112282894551754,
      "learning_rate": 8.82410651913884e-05,
      "loss": 0.0037,
      "step": 2101500
    },
    {
      "epoch": 0.11811327805084995,
      "grad_norm": 0.11003360897302628,
      "learning_rate": 8.823825406664334e-05,
      "loss": 0.0034,
      "step": 2102000
    },
    {
      "epoch": 0.11814137350233683,
      "grad_norm": 0.023492300882935524,
      "learning_rate": 8.823544294189827e-05,
      "loss": 0.0034,
      "step": 2102500
    },
    {
      "epoch": 0.11816946895382371,
      "grad_norm": 0.15065357089042664,
      "learning_rate": 8.823263181715321e-05,
      "loss": 0.0034,
      "step": 2103000
    },
    {
      "epoch": 0.1181975644053106,
      "grad_norm": 0.02629978582262993,
      "learning_rate": 8.822982069240814e-05,
      "loss": 0.0034,
      "step": 2103500
    },
    {
      "epoch": 0.11822565985679748,
      "grad_norm": 0.22366513311862946,
      "learning_rate": 8.822700956766308e-05,
      "loss": 0.0033,
      "step": 2104000
    },
    {
      "epoch": 0.11825375530828436,
      "grad_norm": 0.012149770744144917,
      "learning_rate": 8.822419844291801e-05,
      "loss": 0.003,
      "step": 2104500
    },
    {
      "epoch": 0.11828185075977125,
      "grad_norm": 0.08580254763364792,
      "learning_rate": 8.822138731817294e-05,
      "loss": 0.0034,
      "step": 2105000
    },
    {
      "epoch": 0.11830994621125814,
      "grad_norm": 0.2628576159477234,
      "learning_rate": 8.821857619342786e-05,
      "loss": 0.0031,
      "step": 2105500
    },
    {
      "epoch": 0.11833804166274502,
      "grad_norm": 0.3288927376270294,
      "learning_rate": 8.821576506868281e-05,
      "loss": 0.0033,
      "step": 2106000
    },
    {
      "epoch": 0.1183661371142319,
      "grad_norm": 0.03003854677081108,
      "learning_rate": 8.821295394393775e-05,
      "loss": 0.0037,
      "step": 2106500
    },
    {
      "epoch": 0.11839423256571878,
      "grad_norm": 0.5947257876396179,
      "learning_rate": 8.821014281919268e-05,
      "loss": 0.0035,
      "step": 2107000
    },
    {
      "epoch": 0.11842232801720566,
      "grad_norm": 0.06050731614232063,
      "learning_rate": 8.820733169444762e-05,
      "loss": 0.0034,
      "step": 2107500
    },
    {
      "epoch": 0.11845042346869254,
      "grad_norm": 0.1326678842306137,
      "learning_rate": 8.820452056970254e-05,
      "loss": 0.0037,
      "step": 2108000
    },
    {
      "epoch": 0.11847851892017942,
      "grad_norm": 0.079000324010849,
      "learning_rate": 8.820170944495748e-05,
      "loss": 0.0033,
      "step": 2108500
    },
    {
      "epoch": 0.1185066143716663,
      "grad_norm": 0.25076377391815186,
      "learning_rate": 8.81988983202124e-05,
      "loss": 0.0038,
      "step": 2109000
    },
    {
      "epoch": 0.11853470982315319,
      "grad_norm": 0.09657255560159683,
      "learning_rate": 8.819608719546735e-05,
      "loss": 0.0032,
      "step": 2109500
    },
    {
      "epoch": 0.11856280527464007,
      "grad_norm": 0.28360939025878906,
      "learning_rate": 8.819327607072229e-05,
      "loss": 0.0033,
      "step": 2110000
    },
    {
      "epoch": 0.11856280527464007,
      "eval_loss": 0.000925231259316206,
      "eval_runtime": 20.6529,
      "eval_samples_per_second": 4841.928,
      "eval_steps_per_second": 75.679,
      "step": 2110000
    },
    {
      "epoch": 0.11859090072612695,
      "grad_norm": 0.2553918659687042,
      "learning_rate": 8.819046494597721e-05,
      "loss": 0.0033,
      "step": 2110500
    },
    {
      "epoch": 0.11861899617761383,
      "grad_norm": 1.3483963012695312,
      "learning_rate": 8.818765382123216e-05,
      "loss": 0.0036,
      "step": 2111000
    },
    {
      "epoch": 0.11864709162910071,
      "grad_norm": 0.6885415315628052,
      "learning_rate": 8.818484269648708e-05,
      "loss": 0.0032,
      "step": 2111500
    },
    {
      "epoch": 0.1186751870805876,
      "grad_norm": 0.0312873013317585,
      "learning_rate": 8.818203157174202e-05,
      "loss": 0.0031,
      "step": 2112000
    },
    {
      "epoch": 0.11870328253207447,
      "grad_norm": 0.01450409460812807,
      "learning_rate": 8.817922044699694e-05,
      "loss": 0.0035,
      "step": 2112500
    },
    {
      "epoch": 0.11873137798356136,
      "grad_norm": 0.21570944786071777,
      "learning_rate": 8.817640932225188e-05,
      "loss": 0.0034,
      "step": 2113000
    },
    {
      "epoch": 0.11875947343504824,
      "grad_norm": 0.6607440710067749,
      "learning_rate": 8.817359819750681e-05,
      "loss": 0.0034,
      "step": 2113500
    },
    {
      "epoch": 0.11878756888653512,
      "grad_norm": 0.045542944222688675,
      "learning_rate": 8.817078707276175e-05,
      "loss": 0.0028,
      "step": 2114000
    },
    {
      "epoch": 0.118815664338022,
      "grad_norm": 0.34035879373550415,
      "learning_rate": 8.81679759480167e-05,
      "loss": 0.0043,
      "step": 2114500
    },
    {
      "epoch": 0.11884375978950888,
      "grad_norm": 0.1753203421831131,
      "learning_rate": 8.816516482327162e-05,
      "loss": 0.0037,
      "step": 2115000
    },
    {
      "epoch": 0.11887185524099576,
      "grad_norm": 0.3410065770149231,
      "learning_rate": 8.816235369852655e-05,
      "loss": 0.0034,
      "step": 2115500
    },
    {
      "epoch": 0.11889995069248264,
      "grad_norm": 0.09454028308391571,
      "learning_rate": 8.815954257378148e-05,
      "loss": 0.0035,
      "step": 2116000
    },
    {
      "epoch": 0.11892804614396953,
      "grad_norm": 0.10110834240913391,
      "learning_rate": 8.815673144903642e-05,
      "loss": 0.0032,
      "step": 2116500
    },
    {
      "epoch": 0.11895614159545641,
      "grad_norm": 0.055232174694538116,
      "learning_rate": 8.815392032429135e-05,
      "loss": 0.0033,
      "step": 2117000
    },
    {
      "epoch": 0.11898423704694329,
      "grad_norm": 0.29838132858276367,
      "learning_rate": 8.815110919954629e-05,
      "loss": 0.0035,
      "step": 2117500
    },
    {
      "epoch": 0.11901233249843017,
      "grad_norm": 0.04507848247885704,
      "learning_rate": 8.814829807480123e-05,
      "loss": 0.0033,
      "step": 2118000
    },
    {
      "epoch": 0.11904042794991705,
      "grad_norm": 0.2995174527168274,
      "learning_rate": 8.814548695005616e-05,
      "loss": 0.003,
      "step": 2118500
    },
    {
      "epoch": 0.11906852340140393,
      "grad_norm": 0.02856316603720188,
      "learning_rate": 8.814267582531109e-05,
      "loss": 0.0035,
      "step": 2119000
    },
    {
      "epoch": 0.11909661885289081,
      "grad_norm": 0.22700466215610504,
      "learning_rate": 8.813986470056602e-05,
      "loss": 0.0031,
      "step": 2119500
    },
    {
      "epoch": 0.1191247143043777,
      "grad_norm": 0.03339420631527901,
      "learning_rate": 8.813705357582096e-05,
      "loss": 0.0033,
      "step": 2120000
    },
    {
      "epoch": 0.1191247143043777,
      "eval_loss": 0.0009376262896694243,
      "eval_runtime": 21.3409,
      "eval_samples_per_second": 4685.835,
      "eval_steps_per_second": 73.24,
      "step": 2120000
    },
    {
      "epoch": 0.11915280975586458,
      "grad_norm": 0.05749626085162163,
      "learning_rate": 8.813424245107589e-05,
      "loss": 0.0035,
      "step": 2120500
    },
    {
      "epoch": 0.11918090520735146,
      "grad_norm": 0.5664114356040955,
      "learning_rate": 8.813143132633083e-05,
      "loss": 0.0043,
      "step": 2121000
    },
    {
      "epoch": 0.11920900065883834,
      "grad_norm": 0.04093622416257858,
      "learning_rate": 8.812862020158576e-05,
      "loss": 0.0033,
      "step": 2121500
    },
    {
      "epoch": 0.11923709611032522,
      "grad_norm": 0.12090705335140228,
      "learning_rate": 8.81258090768407e-05,
      "loss": 0.0038,
      "step": 2122000
    },
    {
      "epoch": 0.1192651915618121,
      "grad_norm": 0.07069465517997742,
      "learning_rate": 8.812299795209563e-05,
      "loss": 0.0033,
      "step": 2122500
    },
    {
      "epoch": 0.11929328701329898,
      "grad_norm": 0.22788511216640472,
      "learning_rate": 8.812018682735056e-05,
      "loss": 0.0034,
      "step": 2123000
    },
    {
      "epoch": 0.11932138246478587,
      "grad_norm": 0.020009608939290047,
      "learning_rate": 8.81173757026055e-05,
      "loss": 0.003,
      "step": 2123500
    },
    {
      "epoch": 0.11934947791627275,
      "grad_norm": 0.05477311089634895,
      "learning_rate": 8.811456457786043e-05,
      "loss": 0.0035,
      "step": 2124000
    },
    {
      "epoch": 0.11937757336775963,
      "grad_norm": 0.32556039094924927,
      "learning_rate": 8.811175345311537e-05,
      "loss": 0.0031,
      "step": 2124500
    },
    {
      "epoch": 0.11940566881924651,
      "grad_norm": 0.017256977036595345,
      "learning_rate": 8.810894232837029e-05,
      "loss": 0.003,
      "step": 2125000
    },
    {
      "epoch": 0.11943376427073339,
      "grad_norm": 0.15460792183876038,
      "learning_rate": 8.810613120362523e-05,
      "loss": 0.0034,
      "step": 2125500
    },
    {
      "epoch": 0.11946185972222027,
      "grad_norm": 0.41101765632629395,
      "learning_rate": 8.810332007888017e-05,
      "loss": 0.0033,
      "step": 2126000
    },
    {
      "epoch": 0.11948995517370715,
      "grad_norm": 0.07662639021873474,
      "learning_rate": 8.81005089541351e-05,
      "loss": 0.0036,
      "step": 2126500
    },
    {
      "epoch": 0.11951805062519404,
      "grad_norm": 0.0029676579870283604,
      "learning_rate": 8.809769782939004e-05,
      "loss": 0.0032,
      "step": 2127000
    },
    {
      "epoch": 0.11954614607668092,
      "grad_norm": 0.03394806757569313,
      "learning_rate": 8.809488670464496e-05,
      "loss": 0.0035,
      "step": 2127500
    },
    {
      "epoch": 0.1195742415281678,
      "grad_norm": 0.03920350968837738,
      "learning_rate": 8.80920755798999e-05,
      "loss": 0.0031,
      "step": 2128000
    },
    {
      "epoch": 0.11960233697965468,
      "grad_norm": 0.12882545590400696,
      "learning_rate": 8.808926445515483e-05,
      "loss": 0.0036,
      "step": 2128500
    },
    {
      "epoch": 0.11963043243114156,
      "grad_norm": 0.02992190420627594,
      "learning_rate": 8.808645333040977e-05,
      "loss": 0.0032,
      "step": 2129000
    },
    {
      "epoch": 0.11965852788262844,
      "grad_norm": 0.045391540974378586,
      "learning_rate": 8.808364220566471e-05,
      "loss": 0.0033,
      "step": 2129500
    },
    {
      "epoch": 0.11968662333411532,
      "grad_norm": 0.04615369439125061,
      "learning_rate": 8.808083108091963e-05,
      "loss": 0.0031,
      "step": 2130000
    },
    {
      "epoch": 0.11968662333411532,
      "eval_loss": 0.0009867220651358366,
      "eval_runtime": 21.4553,
      "eval_samples_per_second": 4660.842,
      "eval_steps_per_second": 72.849,
      "step": 2130000
    },
    {
      "epoch": 0.1197147187856022,
      "grad_norm": 0.012099516578018665,
      "learning_rate": 8.807801995617458e-05,
      "loss": 0.0035,
      "step": 2130500
    },
    {
      "epoch": 0.11974281423708909,
      "grad_norm": 0.1518895924091339,
      "learning_rate": 8.80752088314295e-05,
      "loss": 0.0034,
      "step": 2131000
    },
    {
      "epoch": 0.11977090968857597,
      "grad_norm": 0.05839917063713074,
      "learning_rate": 8.807239770668445e-05,
      "loss": 0.0035,
      "step": 2131500
    },
    {
      "epoch": 0.11979900514006285,
      "grad_norm": 0.0593687929213047,
      "learning_rate": 8.806958658193937e-05,
      "loss": 0.0032,
      "step": 2132000
    },
    {
      "epoch": 0.11982710059154973,
      "grad_norm": 0.4970300495624542,
      "learning_rate": 8.80667754571943e-05,
      "loss": 0.0035,
      "step": 2132500
    },
    {
      "epoch": 0.11985519604303661,
      "grad_norm": 0.04236412048339844,
      "learning_rate": 8.806396433244923e-05,
      "loss": 0.0036,
      "step": 2133000
    },
    {
      "epoch": 0.1198832914945235,
      "grad_norm": 0.07222803682088852,
      "learning_rate": 8.806115320770417e-05,
      "loss": 0.0033,
      "step": 2133500
    },
    {
      "epoch": 0.11991138694601038,
      "grad_norm": 0.6081197261810303,
      "learning_rate": 8.805834208295912e-05,
      "loss": 0.0035,
      "step": 2134000
    },
    {
      "epoch": 0.11993948239749726,
      "grad_norm": 0.21618057787418365,
      "learning_rate": 8.805553095821404e-05,
      "loss": 0.0032,
      "step": 2134500
    },
    {
      "epoch": 0.11996757784898414,
      "grad_norm": 0.2822238504886627,
      "learning_rate": 8.805271983346897e-05,
      "loss": 0.0035,
      "step": 2135000
    },
    {
      "epoch": 0.11999567330047102,
      "grad_norm": 0.2508888244628906,
      "learning_rate": 8.80499087087239e-05,
      "loss": 0.0034,
      "step": 2135500
    },
    {
      "epoch": 0.1200237687519579,
      "grad_norm": 0.3378598392009735,
      "learning_rate": 8.804709758397884e-05,
      "loss": 0.0039,
      "step": 2136000
    },
    {
      "epoch": 0.12005186420344478,
      "grad_norm": 0.44139331579208374,
      "learning_rate": 8.804428645923377e-05,
      "loss": 0.0033,
      "step": 2136500
    },
    {
      "epoch": 0.12007995965493166,
      "grad_norm": 0.3413311839103699,
      "learning_rate": 8.804147533448871e-05,
      "loss": 0.0036,
      "step": 2137000
    },
    {
      "epoch": 0.12010805510641855,
      "grad_norm": 0.35550880432128906,
      "learning_rate": 8.803866420974364e-05,
      "loss": 0.0033,
      "step": 2137500
    },
    {
      "epoch": 0.12013615055790543,
      "grad_norm": 0.07517466694116592,
      "learning_rate": 8.803585308499858e-05,
      "loss": 0.0035,
      "step": 2138000
    },
    {
      "epoch": 0.12016424600939231,
      "grad_norm": 0.6302868127822876,
      "learning_rate": 8.803304196025351e-05,
      "loss": 0.0035,
      "step": 2138500
    },
    {
      "epoch": 0.12019234146087919,
      "grad_norm": 0.8117706775665283,
      "learning_rate": 8.803023083550845e-05,
      "loss": 0.0035,
      "step": 2139000
    },
    {
      "epoch": 0.12022043691236607,
      "grad_norm": 0.416963666677475,
      "learning_rate": 8.802741971076338e-05,
      "loss": 0.0038,
      "step": 2139500
    },
    {
      "epoch": 0.12024853236385295,
      "grad_norm": 0.22956009209156036,
      "learning_rate": 8.802460858601831e-05,
      "loss": 0.0031,
      "step": 2140000
    },
    {
      "epoch": 0.12024853236385295,
      "eval_loss": 0.0009576224256306887,
      "eval_runtime": 20.8723,
      "eval_samples_per_second": 4791.03,
      "eval_steps_per_second": 74.884,
      "step": 2140000
    },
    {
      "epoch": 0.12027662781533983,
      "grad_norm": 0.2199954092502594,
      "learning_rate": 8.802179746127325e-05,
      "loss": 0.0034,
      "step": 2140500
    },
    {
      "epoch": 0.12030472326682672,
      "grad_norm": 0.3204999566078186,
      "learning_rate": 8.801898633652817e-05,
      "loss": 0.0035,
      "step": 2141000
    },
    {
      "epoch": 0.1203328187183136,
      "grad_norm": 0.02746294066309929,
      "learning_rate": 8.801617521178312e-05,
      "loss": 0.0031,
      "step": 2141500
    },
    {
      "epoch": 0.12036091416980048,
      "grad_norm": 0.02619127370417118,
      "learning_rate": 8.801336408703805e-05,
      "loss": 0.0033,
      "step": 2142000
    },
    {
      "epoch": 0.12038900962128736,
      "grad_norm": 0.014007612131536007,
      "learning_rate": 8.801055296229299e-05,
      "loss": 0.0033,
      "step": 2142500
    },
    {
      "epoch": 0.12041710507277424,
      "grad_norm": 0.019986478611826897,
      "learning_rate": 8.800774183754792e-05,
      "loss": 0.0033,
      "step": 2143000
    },
    {
      "epoch": 0.12044520052426112,
      "grad_norm": 0.06478609889745712,
      "learning_rate": 8.800493071280284e-05,
      "loss": 0.0032,
      "step": 2143500
    },
    {
      "epoch": 0.120473295975748,
      "grad_norm": 0.11693380773067474,
      "learning_rate": 8.800211958805779e-05,
      "loss": 0.0035,
      "step": 2144000
    },
    {
      "epoch": 0.12050139142723489,
      "grad_norm": 0.004282612353563309,
      "learning_rate": 8.799930846331271e-05,
      "loss": 0.0031,
      "step": 2144500
    },
    {
      "epoch": 0.12052948687872177,
      "grad_norm": 0.10538338869810104,
      "learning_rate": 8.799649733856766e-05,
      "loss": 0.0035,
      "step": 2145000
    },
    {
      "epoch": 0.12055758233020865,
      "grad_norm": 0.42704686522483826,
      "learning_rate": 8.799368621382259e-05,
      "loss": 0.0034,
      "step": 2145500
    },
    {
      "epoch": 0.12058567778169553,
      "grad_norm": 0.2306007593870163,
      "learning_rate": 8.799087508907751e-05,
      "loss": 0.0034,
      "step": 2146000
    },
    {
      "epoch": 0.12061377323318241,
      "grad_norm": 0.15828390419483185,
      "learning_rate": 8.798806396433246e-05,
      "loss": 0.0032,
      "step": 2146500
    },
    {
      "epoch": 0.12064186868466929,
      "grad_norm": 0.028905430808663368,
      "learning_rate": 8.798525283958738e-05,
      "loss": 0.0032,
      "step": 2147000
    },
    {
      "epoch": 0.12066996413615617,
      "grad_norm": 0.07871949672698975,
      "learning_rate": 8.798244171484233e-05,
      "loss": 0.0033,
      "step": 2147500
    },
    {
      "epoch": 0.12069805958764306,
      "grad_norm": 0.15106883645057678,
      "learning_rate": 8.797963059009725e-05,
      "loss": 0.0031,
      "step": 2148000
    },
    {
      "epoch": 0.12072615503912994,
      "grad_norm": 0.10909616947174072,
      "learning_rate": 8.797681946535218e-05,
      "loss": 0.0037,
      "step": 2148500
    },
    {
      "epoch": 0.12075425049061682,
      "grad_norm": 0.23947273194789886,
      "learning_rate": 8.797400834060713e-05,
      "loss": 0.0029,
      "step": 2149000
    },
    {
      "epoch": 0.1207823459421037,
      "grad_norm": 0.06837966293096542,
      "learning_rate": 8.797119721586205e-05,
      "loss": 0.0034,
      "step": 2149500
    },
    {
      "epoch": 0.12081044139359058,
      "grad_norm": 0.11615414172410965,
      "learning_rate": 8.7968386091117e-05,
      "loss": 0.0035,
      "step": 2150000
    },
    {
      "epoch": 0.12081044139359058,
      "eval_loss": 0.0009179599583148956,
      "eval_runtime": 22.7505,
      "eval_samples_per_second": 4395.509,
      "eval_steps_per_second": 68.702,
      "step": 2150000
    },
    {
      "epoch": 0.12083853684507746,
      "grad_norm": 0.12239506095647812,
      "learning_rate": 8.796557496637192e-05,
      "loss": 0.003,
      "step": 2150500
    },
    {
      "epoch": 0.12086663229656434,
      "grad_norm": 0.1413443237543106,
      "learning_rate": 8.796276384162685e-05,
      "loss": 0.0034,
      "step": 2151000
    },
    {
      "epoch": 0.12089472774805123,
      "grad_norm": 0.36325132846832275,
      "learning_rate": 8.795995271688179e-05,
      "loss": 0.004,
      "step": 2151500
    },
    {
      "epoch": 0.12092282319953811,
      "grad_norm": 0.3149436116218567,
      "learning_rate": 8.795714159213672e-05,
      "loss": 0.0034,
      "step": 2152000
    },
    {
      "epoch": 0.12095091865102499,
      "grad_norm": 0.10558515787124634,
      "learning_rate": 8.795433046739166e-05,
      "loss": 0.0032,
      "step": 2152500
    },
    {
      "epoch": 0.12097901410251187,
      "grad_norm": 0.08696296811103821,
      "learning_rate": 8.795151934264659e-05,
      "loss": 0.0034,
      "step": 2153000
    },
    {
      "epoch": 0.12100710955399875,
      "grad_norm": 0.1681995987892151,
      "learning_rate": 8.794870821790154e-05,
      "loss": 0.0036,
      "step": 2153500
    },
    {
      "epoch": 0.12103520500548563,
      "grad_norm": 0.08608263731002808,
      "learning_rate": 8.794589709315646e-05,
      "loss": 0.0035,
      "step": 2154000
    },
    {
      "epoch": 0.12106330045697251,
      "grad_norm": 0.21881575882434845,
      "learning_rate": 8.79430859684114e-05,
      "loss": 0.0034,
      "step": 2154500
    },
    {
      "epoch": 0.1210913959084594,
      "grad_norm": 0.047741346061229706,
      "learning_rate": 8.794027484366633e-05,
      "loss": 0.0039,
      "step": 2155000
    },
    {
      "epoch": 0.12111949135994628,
      "grad_norm": 0.060262322425842285,
      "learning_rate": 8.793746371892126e-05,
      "loss": 0.0038,
      "step": 2155500
    },
    {
      "epoch": 0.12114758681143316,
      "grad_norm": 0.0586262047290802,
      "learning_rate": 8.79346525941762e-05,
      "loss": 0.0031,
      "step": 2156000
    },
    {
      "epoch": 0.12117568226292004,
      "grad_norm": 0.3583146035671234,
      "learning_rate": 8.793184146943113e-05,
      "loss": 0.003,
      "step": 2156500
    },
    {
      "epoch": 0.12120377771440692,
      "grad_norm": 0.1961340755224228,
      "learning_rate": 8.792903034468606e-05,
      "loss": 0.0032,
      "step": 2157000
    },
    {
      "epoch": 0.1212318731658938,
      "grad_norm": 0.09214869141578674,
      "learning_rate": 8.7926219219941e-05,
      "loss": 0.0035,
      "step": 2157500
    },
    {
      "epoch": 0.12125996861738068,
      "grad_norm": 0.19349394738674164,
      "learning_rate": 8.792340809519593e-05,
      "loss": 0.0032,
      "step": 2158000
    },
    {
      "epoch": 0.12128806406886757,
      "grad_norm": 0.142136812210083,
      "learning_rate": 8.792059697045087e-05,
      "loss": 0.0034,
      "step": 2158500
    },
    {
      "epoch": 0.12131615952035445,
      "grad_norm": 0.12191025912761688,
      "learning_rate": 8.79177858457058e-05,
      "loss": 0.003,
      "step": 2159000
    },
    {
      "epoch": 0.12134425497184133,
      "grad_norm": 0.1295662522315979,
      "learning_rate": 8.791497472096074e-05,
      "loss": 0.0033,
      "step": 2159500
    },
    {
      "epoch": 0.12137235042332821,
      "grad_norm": 0.18052832782268524,
      "learning_rate": 8.791216359621567e-05,
      "loss": 0.0032,
      "step": 2160000
    },
    {
      "epoch": 0.12137235042332821,
      "eval_loss": 0.0011437282664701343,
      "eval_runtime": 21.5235,
      "eval_samples_per_second": 4646.093,
      "eval_steps_per_second": 72.618,
      "step": 2160000
    },
    {
      "epoch": 0.12140044587481509,
      "grad_norm": 0.008054355159401894,
      "learning_rate": 8.79093524714706e-05,
      "loss": 0.0033,
      "step": 2160500
    },
    {
      "epoch": 0.12142854132630197,
      "grad_norm": 0.09266544878482819,
      "learning_rate": 8.790654134672554e-05,
      "loss": 0.0034,
      "step": 2161000
    },
    {
      "epoch": 0.12145663677778885,
      "grad_norm": 0.02629527635872364,
      "learning_rate": 8.790373022198047e-05,
      "loss": 0.0033,
      "step": 2161500
    },
    {
      "epoch": 0.12148473222927574,
      "grad_norm": 0.24918004870414734,
      "learning_rate": 8.790091909723541e-05,
      "loss": 0.0034,
      "step": 2162000
    },
    {
      "epoch": 0.12151282768076262,
      "grad_norm": 0.062283676117658615,
      "learning_rate": 8.789810797249034e-05,
      "loss": 0.0038,
      "step": 2162500
    },
    {
      "epoch": 0.1215409231322495,
      "grad_norm": 0.2535631060600281,
      "learning_rate": 8.789529684774526e-05,
      "loss": 0.0031,
      "step": 2163000
    },
    {
      "epoch": 0.12156901858373638,
      "grad_norm": 0.3588554859161377,
      "learning_rate": 8.789248572300021e-05,
      "loss": 0.0034,
      "step": 2163500
    },
    {
      "epoch": 0.12159711403522326,
      "grad_norm": 0.26641082763671875,
      "learning_rate": 8.788967459825513e-05,
      "loss": 0.0036,
      "step": 2164000
    },
    {
      "epoch": 0.12162520948671014,
      "grad_norm": 0.17007941007614136,
      "learning_rate": 8.788686347351008e-05,
      "loss": 0.0034,
      "step": 2164500
    },
    {
      "epoch": 0.12165330493819702,
      "grad_norm": 0.5927696228027344,
      "learning_rate": 8.788405234876501e-05,
      "loss": 0.003,
      "step": 2165000
    },
    {
      "epoch": 0.1216814003896839,
      "grad_norm": 0.5462448000907898,
      "learning_rate": 8.788124122401993e-05,
      "loss": 0.0029,
      "step": 2165500
    },
    {
      "epoch": 0.1217094958411708,
      "grad_norm": 0.06656444817781448,
      "learning_rate": 8.787843009927488e-05,
      "loss": 0.0034,
      "step": 2166000
    },
    {
      "epoch": 0.12173759129265768,
      "grad_norm": 0.24438348412513733,
      "learning_rate": 8.78756189745298e-05,
      "loss": 0.0035,
      "step": 2166500
    },
    {
      "epoch": 0.12176568674414456,
      "grad_norm": 0.05193296819925308,
      "learning_rate": 8.787280784978475e-05,
      "loss": 0.0034,
      "step": 2167000
    },
    {
      "epoch": 0.12179378219563144,
      "grad_norm": 0.18902412056922913,
      "learning_rate": 8.786999672503967e-05,
      "loss": 0.0032,
      "step": 2167500
    },
    {
      "epoch": 0.12182187764711833,
      "grad_norm": 0.08583325147628784,
      "learning_rate": 8.78671856002946e-05,
      "loss": 0.0035,
      "step": 2168000
    },
    {
      "epoch": 0.12184997309860521,
      "grad_norm": 0.01825862191617489,
      "learning_rate": 8.786437447554955e-05,
      "loss": 0.0034,
      "step": 2168500
    },
    {
      "epoch": 0.12187806855009209,
      "grad_norm": 0.17283041775226593,
      "learning_rate": 8.786156335080447e-05,
      "loss": 0.0033,
      "step": 2169000
    },
    {
      "epoch": 0.12190616400157897,
      "grad_norm": 0.05378873273730278,
      "learning_rate": 8.785875222605942e-05,
      "loss": 0.0035,
      "step": 2169500
    },
    {
      "epoch": 0.12193425945306585,
      "grad_norm": 0.08710167557001114,
      "learning_rate": 8.785594110131434e-05,
      "loss": 0.0033,
      "step": 2170000
    },
    {
      "epoch": 0.12193425945306585,
      "eval_loss": 0.0009027324267663062,
      "eval_runtime": 20.7005,
      "eval_samples_per_second": 4830.791,
      "eval_steps_per_second": 75.505,
      "step": 2170000
    },
    {
      "epoch": 0.12196235490455273,
      "grad_norm": 0.0071140676736831665,
      "learning_rate": 8.785312997656928e-05,
      "loss": 0.0034,
      "step": 2170500
    },
    {
      "epoch": 0.12199045035603961,
      "grad_norm": 0.2369423657655716,
      "learning_rate": 8.785031885182421e-05,
      "loss": 0.0031,
      "step": 2171000
    },
    {
      "epoch": 0.1220185458075265,
      "grad_norm": 0.20237374305725098,
      "learning_rate": 8.784750772707914e-05,
      "loss": 0.0035,
      "step": 2171500
    },
    {
      "epoch": 0.12204664125901338,
      "grad_norm": 0.053732313215732574,
      "learning_rate": 8.784469660233408e-05,
      "loss": 0.0032,
      "step": 2172000
    },
    {
      "epoch": 0.12207473671050026,
      "grad_norm": 0.0414520762860775,
      "learning_rate": 8.784188547758901e-05,
      "loss": 0.0032,
      "step": 2172500
    },
    {
      "epoch": 0.12210283216198714,
      "grad_norm": 0.07675611972808838,
      "learning_rate": 8.783907435284395e-05,
      "loss": 0.0035,
      "step": 2173000
    },
    {
      "epoch": 0.12213092761347402,
      "grad_norm": 0.03801066055893898,
      "learning_rate": 8.783626322809888e-05,
      "loss": 0.0032,
      "step": 2173500
    },
    {
      "epoch": 0.1221590230649609,
      "grad_norm": 0.15508735179901123,
      "learning_rate": 8.783345210335382e-05,
      "loss": 0.003,
      "step": 2174000
    },
    {
      "epoch": 0.12218711851644778,
      "grad_norm": 0.011789385229349136,
      "learning_rate": 8.783064097860875e-05,
      "loss": 0.0033,
      "step": 2174500
    },
    {
      "epoch": 0.12221521396793467,
      "grad_norm": 0.13849785923957825,
      "learning_rate": 8.782782985386368e-05,
      "loss": 0.0035,
      "step": 2175000
    },
    {
      "epoch": 0.12224330941942155,
      "grad_norm": 0.04606989026069641,
      "learning_rate": 8.782501872911862e-05,
      "loss": 0.0032,
      "step": 2175500
    },
    {
      "epoch": 0.12227140487090843,
      "grad_norm": 0.24876569211483002,
      "learning_rate": 8.782220760437355e-05,
      "loss": 0.0035,
      "step": 2176000
    },
    {
      "epoch": 0.12229950032239531,
      "grad_norm": 0.05645715072751045,
      "learning_rate": 8.781939647962849e-05,
      "loss": 0.0032,
      "step": 2176500
    },
    {
      "epoch": 0.12232759577388219,
      "grad_norm": 0.02955523505806923,
      "learning_rate": 8.781658535488342e-05,
      "loss": 0.0033,
      "step": 2177000
    },
    {
      "epoch": 0.12235569122536907,
      "grad_norm": 0.19832848012447357,
      "learning_rate": 8.781377423013836e-05,
      "loss": 0.0036,
      "step": 2177500
    },
    {
      "epoch": 0.12238378667685595,
      "grad_norm": 0.0921875387430191,
      "learning_rate": 8.781096310539329e-05,
      "loss": 0.0034,
      "step": 2178000
    },
    {
      "epoch": 0.12241188212834284,
      "grad_norm": 0.12057602405548096,
      "learning_rate": 8.780815198064822e-05,
      "loss": 0.0032,
      "step": 2178500
    },
    {
      "epoch": 0.12243997757982972,
      "grad_norm": 0.17982062697410583,
      "learning_rate": 8.780534085590314e-05,
      "loss": 0.0033,
      "step": 2179000
    },
    {
      "epoch": 0.1224680730313166,
      "grad_norm": 0.23055577278137207,
      "learning_rate": 8.780252973115809e-05,
      "loss": 0.0037,
      "step": 2179500
    },
    {
      "epoch": 0.12249616848280348,
      "grad_norm": 0.07762419432401657,
      "learning_rate": 8.779971860641303e-05,
      "loss": 0.0033,
      "step": 2180000
    },
    {
      "epoch": 0.12249616848280348,
      "eval_loss": 0.0010246356250718236,
      "eval_runtime": 21.3895,
      "eval_samples_per_second": 4675.201,
      "eval_steps_per_second": 73.073,
      "step": 2180000
    },
    {
      "epoch": 0.12252426393429036,
      "grad_norm": 0.05221297964453697,
      "learning_rate": 8.779690748166796e-05,
      "loss": 0.0033,
      "step": 2180500
    },
    {
      "epoch": 0.12255235938577724,
      "grad_norm": 0.38445475697517395,
      "learning_rate": 8.77940963569229e-05,
      "loss": 0.0032,
      "step": 2181000
    },
    {
      "epoch": 0.12258045483726412,
      "grad_norm": 0.2694986164569855,
      "learning_rate": 8.779128523217782e-05,
      "loss": 0.003,
      "step": 2181500
    },
    {
      "epoch": 0.122608550288751,
      "grad_norm": 0.14278855919837952,
      "learning_rate": 8.778847410743276e-05,
      "loss": 0.0035,
      "step": 2182000
    },
    {
      "epoch": 0.12263664574023789,
      "grad_norm": 0.016396844759583473,
      "learning_rate": 8.778566298268768e-05,
      "loss": 0.0033,
      "step": 2182500
    },
    {
      "epoch": 0.12266474119172477,
      "grad_norm": 0.061096206307411194,
      "learning_rate": 8.778285185794263e-05,
      "loss": 0.0032,
      "step": 2183000
    },
    {
      "epoch": 0.12269283664321165,
      "grad_norm": 0.07272664457559586,
      "learning_rate": 8.778004073319755e-05,
      "loss": 0.0031,
      "step": 2183500
    },
    {
      "epoch": 0.12272093209469853,
      "grad_norm": 0.14946463704109192,
      "learning_rate": 8.777722960845249e-05,
      "loss": 0.0031,
      "step": 2184000
    },
    {
      "epoch": 0.12274902754618541,
      "grad_norm": 0.09179151058197021,
      "learning_rate": 8.777441848370743e-05,
      "loss": 0.0034,
      "step": 2184500
    },
    {
      "epoch": 0.1227771229976723,
      "grad_norm": 0.007493549957871437,
      "learning_rate": 8.777160735896236e-05,
      "loss": 0.0036,
      "step": 2185000
    },
    {
      "epoch": 0.12280521844915918,
      "grad_norm": 0.13610462844371796,
      "learning_rate": 8.77687962342173e-05,
      "loss": 0.0035,
      "step": 2185500
    },
    {
      "epoch": 0.12283331390064606,
      "grad_norm": 0.0075225792825222015,
      "learning_rate": 8.776598510947222e-05,
      "loss": 0.0031,
      "step": 2186000
    },
    {
      "epoch": 0.12286140935213294,
      "grad_norm": 0.15210223197937012,
      "learning_rate": 8.776317398472717e-05,
      "loss": 0.0035,
      "step": 2186500
    },
    {
      "epoch": 0.12288950480361982,
      "grad_norm": 0.08057691156864166,
      "learning_rate": 8.776036285998209e-05,
      "loss": 0.0028,
      "step": 2187000
    },
    {
      "epoch": 0.1229176002551067,
      "grad_norm": 0.2662033438682556,
      "learning_rate": 8.775755173523703e-05,
      "loss": 0.003,
      "step": 2187500
    },
    {
      "epoch": 0.12294569570659358,
      "grad_norm": 0.3532576262950897,
      "learning_rate": 8.775474061049197e-05,
      "loss": 0.0034,
      "step": 2188000
    },
    {
      "epoch": 0.12297379115808046,
      "grad_norm": 0.0440080352127552,
      "learning_rate": 8.77519294857469e-05,
      "loss": 0.0035,
      "step": 2188500
    },
    {
      "epoch": 0.12300188660956735,
      "grad_norm": 0.03793169930577278,
      "learning_rate": 8.774911836100184e-05,
      "loss": 0.0033,
      "step": 2189000
    },
    {
      "epoch": 0.12302998206105423,
      "grad_norm": 0.06380082666873932,
      "learning_rate": 8.774630723625676e-05,
      "loss": 0.0033,
      "step": 2189500
    },
    {
      "epoch": 0.12305807751254111,
      "grad_norm": 0.18035192787647247,
      "learning_rate": 8.77434961115117e-05,
      "loss": 0.0034,
      "step": 2190000
    },
    {
      "epoch": 0.12305807751254111,
      "eval_loss": 0.0009258292848244309,
      "eval_runtime": 20.3158,
      "eval_samples_per_second": 4922.285,
      "eval_steps_per_second": 76.935,
      "step": 2190000
    },
    {
      "epoch": 0.12308617296402799,
      "grad_norm": 0.06760106980800629,
      "learning_rate": 8.774068498676663e-05,
      "loss": 0.0036,
      "step": 2190500
    },
    {
      "epoch": 0.12311426841551487,
      "grad_norm": 0.4011680781841278,
      "learning_rate": 8.773787386202157e-05,
      "loss": 0.003,
      "step": 2191000
    },
    {
      "epoch": 0.12314236386700175,
      "grad_norm": 0.029123324900865555,
      "learning_rate": 8.773506273727651e-05,
      "loss": 0.0033,
      "step": 2191500
    },
    {
      "epoch": 0.12317045931848863,
      "grad_norm": 0.004385882057249546,
      "learning_rate": 8.773225161253143e-05,
      "loss": 0.0028,
      "step": 2192000
    },
    {
      "epoch": 0.12319855476997552,
      "grad_norm": 0.12044834345579147,
      "learning_rate": 8.772944048778637e-05,
      "loss": 0.0037,
      "step": 2192500
    },
    {
      "epoch": 0.1232266502214624,
      "grad_norm": 0.2530531585216522,
      "learning_rate": 8.77266293630413e-05,
      "loss": 0.0034,
      "step": 2193000
    },
    {
      "epoch": 0.12325474567294928,
      "grad_norm": 0.12713980674743652,
      "learning_rate": 8.772381823829624e-05,
      "loss": 0.0035,
      "step": 2193500
    },
    {
      "epoch": 0.12328284112443616,
      "grad_norm": 0.1667780876159668,
      "learning_rate": 8.772100711355117e-05,
      "loss": 0.0032,
      "step": 2194000
    },
    {
      "epoch": 0.12331093657592304,
      "grad_norm": 0.38912731409072876,
      "learning_rate": 8.77181959888061e-05,
      "loss": 0.0031,
      "step": 2194500
    },
    {
      "epoch": 0.12333903202740992,
      "grad_norm": 0.611954927444458,
      "learning_rate": 8.771538486406104e-05,
      "loss": 0.0031,
      "step": 2195000
    },
    {
      "epoch": 0.1233671274788968,
      "grad_norm": 0.04023931175470352,
      "learning_rate": 8.771257373931597e-05,
      "loss": 0.0033,
      "step": 2195500
    },
    {
      "epoch": 0.12339522293038369,
      "grad_norm": 2.350386619567871,
      "learning_rate": 8.770976261457091e-05,
      "loss": 0.0035,
      "step": 2196000
    },
    {
      "epoch": 0.12342331838187057,
      "grad_norm": 0.20476752519607544,
      "learning_rate": 8.770695148982584e-05,
      "loss": 0.0036,
      "step": 2196500
    },
    {
      "epoch": 0.12345141383335745,
      "grad_norm": 0.016095679253339767,
      "learning_rate": 8.770414036508078e-05,
      "loss": 0.0034,
      "step": 2197000
    },
    {
      "epoch": 0.12347950928484433,
      "grad_norm": 0.5129429697990417,
      "learning_rate": 8.770132924033571e-05,
      "loss": 0.0032,
      "step": 2197500
    },
    {
      "epoch": 0.12350760473633121,
      "grad_norm": 0.07915324717760086,
      "learning_rate": 8.769851811559065e-05,
      "loss": 0.0031,
      "step": 2198000
    },
    {
      "epoch": 0.12353570018781809,
      "grad_norm": 0.0946221873164177,
      "learning_rate": 8.769570699084557e-05,
      "loss": 0.0033,
      "step": 2198500
    },
    {
      "epoch": 0.12356379563930497,
      "grad_norm": 0.07450170069932938,
      "learning_rate": 8.769289586610051e-05,
      "loss": 0.0035,
      "step": 2199000
    },
    {
      "epoch": 0.12359189109079186,
      "grad_norm": 0.26606711745262146,
      "learning_rate": 8.769008474135545e-05,
      "loss": 0.0033,
      "step": 2199500
    },
    {
      "epoch": 0.12361998654227874,
      "grad_norm": 0.02058521844446659,
      "learning_rate": 8.768727361661038e-05,
      "loss": 0.0033,
      "step": 2200000
    },
    {
      "epoch": 0.12361998654227874,
      "eval_loss": 0.0008769869455136359,
      "eval_runtime": 20.8757,
      "eval_samples_per_second": 4790.25,
      "eval_steps_per_second": 74.872,
      "step": 2200000
    },
    {
      "epoch": 0.12364808199376562,
      "grad_norm": 0.07469994574785233,
      "learning_rate": 8.768446249186532e-05,
      "loss": 0.0035,
      "step": 2200500
    },
    {
      "epoch": 0.1236761774452525,
      "grad_norm": 0.33589819073677063,
      "learning_rate": 8.768165136712024e-05,
      "loss": 0.0031,
      "step": 2201000
    },
    {
      "epoch": 0.12370427289673938,
      "grad_norm": 0.029902232810854912,
      "learning_rate": 8.767884024237519e-05,
      "loss": 0.0034,
      "step": 2201500
    },
    {
      "epoch": 0.12373236834822626,
      "grad_norm": 0.24413257837295532,
      "learning_rate": 8.76760291176301e-05,
      "loss": 0.0029,
      "step": 2202000
    },
    {
      "epoch": 0.12376046379971314,
      "grad_norm": 0.14931513369083405,
      "learning_rate": 8.767321799288505e-05,
      "loss": 0.0032,
      "step": 2202500
    },
    {
      "epoch": 0.12378855925120003,
      "grad_norm": 0.02547093853354454,
      "learning_rate": 8.767040686813997e-05,
      "loss": 0.0032,
      "step": 2203000
    },
    {
      "epoch": 0.1238166547026869,
      "grad_norm": 0.046757977455854416,
      "learning_rate": 8.766759574339491e-05,
      "loss": 0.0033,
      "step": 2203500
    },
    {
      "epoch": 0.12384475015417379,
      "grad_norm": 0.04063960164785385,
      "learning_rate": 8.766478461864986e-05,
      "loss": 0.0034,
      "step": 2204000
    },
    {
      "epoch": 0.12387284560566067,
      "grad_norm": 0.25593093037605286,
      "learning_rate": 8.766197349390478e-05,
      "loss": 0.0031,
      "step": 2204500
    },
    {
      "epoch": 0.12390094105714755,
      "grad_norm": 0.17337873578071594,
      "learning_rate": 8.765916236915973e-05,
      "loss": 0.0036,
      "step": 2205000
    },
    {
      "epoch": 0.12392903650863443,
      "grad_norm": 0.010168155655264854,
      "learning_rate": 8.765635124441465e-05,
      "loss": 0.0032,
      "step": 2205500
    },
    {
      "epoch": 0.12395713196012131,
      "grad_norm": 0.28379860520362854,
      "learning_rate": 8.765354011966958e-05,
      "loss": 0.0032,
      "step": 2206000
    },
    {
      "epoch": 0.1239852274116082,
      "grad_norm": 0.1540098786354065,
      "learning_rate": 8.765072899492451e-05,
      "loss": 0.003,
      "step": 2206500
    },
    {
      "epoch": 0.12401332286309508,
      "grad_norm": 0.1537041813135147,
      "learning_rate": 8.764791787017945e-05,
      "loss": 0.0033,
      "step": 2207000
    },
    {
      "epoch": 0.12404141831458196,
      "grad_norm": 0.041850097477436066,
      "learning_rate": 8.76451067454344e-05,
      "loss": 0.003,
      "step": 2207500
    },
    {
      "epoch": 0.12406951376606884,
      "grad_norm": 0.1118449866771698,
      "learning_rate": 8.764229562068932e-05,
      "loss": 0.0032,
      "step": 2208000
    },
    {
      "epoch": 0.12409760921755572,
      "grad_norm": 0.3935372829437256,
      "learning_rate": 8.763948449594425e-05,
      "loss": 0.0034,
      "step": 2208500
    },
    {
      "epoch": 0.1241257046690426,
      "grad_norm": 0.15742990374565125,
      "learning_rate": 8.763667337119919e-05,
      "loss": 0.0031,
      "step": 2209000
    },
    {
      "epoch": 0.12415380012052948,
      "grad_norm": 0.2258852869272232,
      "learning_rate": 8.763386224645412e-05,
      "loss": 0.0036,
      "step": 2209500
    },
    {
      "epoch": 0.12418189557201637,
      "grad_norm": 0.03303273022174835,
      "learning_rate": 8.763105112170905e-05,
      "loss": 0.0032,
      "step": 2210000
    },
    {
      "epoch": 0.12418189557201637,
      "eval_loss": 0.0010839072056114674,
      "eval_runtime": 20.4186,
      "eval_samples_per_second": 4897.497,
      "eval_steps_per_second": 76.548,
      "step": 2210000
    },
    {
      "epoch": 0.12420999102350325,
      "grad_norm": 0.029762540012598038,
      "learning_rate": 8.762823999696399e-05,
      "loss": 0.004,
      "step": 2210500
    },
    {
      "epoch": 0.12423808647499013,
      "grad_norm": 0.2763008773326874,
      "learning_rate": 8.762542887221892e-05,
      "loss": 0.0036,
      "step": 2211000
    },
    {
      "epoch": 0.12426618192647701,
      "grad_norm": 0.16648265719413757,
      "learning_rate": 8.762261774747386e-05,
      "loss": 0.0034,
      "step": 2211500
    },
    {
      "epoch": 0.12429427737796389,
      "grad_norm": 0.1617298573255539,
      "learning_rate": 8.761980662272879e-05,
      "loss": 0.0032,
      "step": 2212000
    },
    {
      "epoch": 0.12432237282945077,
      "grad_norm": 0.00700047891587019,
      "learning_rate": 8.761699549798373e-05,
      "loss": 0.0039,
      "step": 2212500
    },
    {
      "epoch": 0.12435046828093765,
      "grad_norm": 0.045782338827848434,
      "learning_rate": 8.761418437323866e-05,
      "loss": 0.0032,
      "step": 2213000
    },
    {
      "epoch": 0.12437856373242454,
      "grad_norm": 0.02077990025281906,
      "learning_rate": 8.76113732484936e-05,
      "loss": 0.0035,
      "step": 2213500
    },
    {
      "epoch": 0.12440665918391142,
      "grad_norm": 0.12479683756828308,
      "learning_rate": 8.760856212374853e-05,
      "loss": 0.0028,
      "step": 2214000
    },
    {
      "epoch": 0.1244347546353983,
      "grad_norm": 0.07503530383110046,
      "learning_rate": 8.760575099900345e-05,
      "loss": 0.0035,
      "step": 2214500
    },
    {
      "epoch": 0.12446285008688518,
      "grad_norm": 0.03350229933857918,
      "learning_rate": 8.76029398742584e-05,
      "loss": 0.0035,
      "step": 2215000
    },
    {
      "epoch": 0.12449094553837206,
      "grad_norm": 0.288156121969223,
      "learning_rate": 8.760012874951333e-05,
      "loss": 0.003,
      "step": 2215500
    },
    {
      "epoch": 0.12451904098985894,
      "grad_norm": 0.12346626073122025,
      "learning_rate": 8.759731762476827e-05,
      "loss": 0.0033,
      "step": 2216000
    },
    {
      "epoch": 0.12454713644134582,
      "grad_norm": 0.07033105939626694,
      "learning_rate": 8.75945065000232e-05,
      "loss": 0.0031,
      "step": 2216500
    },
    {
      "epoch": 0.1245752318928327,
      "grad_norm": 0.2992044985294342,
      "learning_rate": 8.759169537527812e-05,
      "loss": 0.0032,
      "step": 2217000
    },
    {
      "epoch": 0.12460332734431959,
      "grad_norm": 0.011424686759710312,
      "learning_rate": 8.758888425053307e-05,
      "loss": 0.003,
      "step": 2217500
    },
    {
      "epoch": 0.12463142279580647,
      "grad_norm": 0.05912477523088455,
      "learning_rate": 8.758607312578799e-05,
      "loss": 0.0036,
      "step": 2218000
    },
    {
      "epoch": 0.12465951824729335,
      "grad_norm": 0.03409493714570999,
      "learning_rate": 8.758326200104294e-05,
      "loss": 0.0033,
      "step": 2218500
    },
    {
      "epoch": 0.12468761369878023,
      "grad_norm": 0.07927458733320236,
      "learning_rate": 8.758045087629787e-05,
      "loss": 0.0032,
      "step": 2219000
    },
    {
      "epoch": 0.12471570915026711,
      "grad_norm": 0.04742063581943512,
      "learning_rate": 8.757763975155279e-05,
      "loss": 0.0033,
      "step": 2219500
    },
    {
      "epoch": 0.124743804601754,
      "grad_norm": 0.055291157215833664,
      "learning_rate": 8.757482862680774e-05,
      "loss": 0.0031,
      "step": 2220000
    },
    {
      "epoch": 0.124743804601754,
      "eval_loss": 0.0008793058223091066,
      "eval_runtime": 22.0717,
      "eval_samples_per_second": 4530.693,
      "eval_steps_per_second": 70.815,
      "step": 2220000
    },
    {
      "epoch": 0.12477190005324088,
      "grad_norm": 0.22137413918972015,
      "learning_rate": 8.757201750206266e-05,
      "loss": 0.003,
      "step": 2220500
    },
    {
      "epoch": 0.12479999550472776,
      "grad_norm": 0.36838096380233765,
      "learning_rate": 8.756920637731761e-05,
      "loss": 0.0036,
      "step": 2221000
    },
    {
      "epoch": 0.12482809095621464,
      "grad_norm": 0.1706075370311737,
      "learning_rate": 8.756639525257253e-05,
      "loss": 0.0032,
      "step": 2221500
    },
    {
      "epoch": 0.12485618640770152,
      "grad_norm": 0.3901354670524597,
      "learning_rate": 8.756358412782748e-05,
      "loss": 0.0035,
      "step": 2222000
    },
    {
      "epoch": 0.1248842818591884,
      "grad_norm": 0.05789580196142197,
      "learning_rate": 8.75607730030824e-05,
      "loss": 0.0032,
      "step": 2222500
    },
    {
      "epoch": 0.12491237731067528,
      "grad_norm": 0.17806994915008545,
      "learning_rate": 8.755796187833733e-05,
      "loss": 0.0035,
      "step": 2223000
    },
    {
      "epoch": 0.12494047276216216,
      "grad_norm": 0.17897017300128937,
      "learning_rate": 8.755515075359228e-05,
      "loss": 0.0032,
      "step": 2223500
    },
    {
      "epoch": 0.12496856821364904,
      "grad_norm": 0.06841370463371277,
      "learning_rate": 8.75523396288472e-05,
      "loss": 0.003,
      "step": 2224000
    },
    {
      "epoch": 0.12499666366513593,
      "grad_norm": 0.0381578654050827,
      "learning_rate": 8.754952850410215e-05,
      "loss": 0.0033,
      "step": 2224500
    },
    {
      "epoch": 0.1250247591166228,
      "grad_norm": 0.07270258665084839,
      "learning_rate": 8.754671737935707e-05,
      "loss": 0.0031,
      "step": 2225000
    },
    {
      "epoch": 0.1250528545681097,
      "grad_norm": 0.18147927522659302,
      "learning_rate": 8.7543906254612e-05,
      "loss": 0.0034,
      "step": 2225500
    },
    {
      "epoch": 0.12508095001959657,
      "grad_norm": 0.07606278359889984,
      "learning_rate": 8.754109512986694e-05,
      "loss": 0.0034,
      "step": 2226000
    },
    {
      "epoch": 0.12510904547108345,
      "grad_norm": 0.37121161818504333,
      "learning_rate": 8.753828400512187e-05,
      "loss": 0.0033,
      "step": 2226500
    },
    {
      "epoch": 0.12513714092257033,
      "grad_norm": 0.05924626439809799,
      "learning_rate": 8.753547288037682e-05,
      "loss": 0.0034,
      "step": 2227000
    },
    {
      "epoch": 0.12516523637405721,
      "grad_norm": 0.1793297678232193,
      "learning_rate": 8.753266175563174e-05,
      "loss": 0.0029,
      "step": 2227500
    },
    {
      "epoch": 0.1251933318255441,
      "grad_norm": 0.015566447749733925,
      "learning_rate": 8.752985063088667e-05,
      "loss": 0.003,
      "step": 2228000
    },
    {
      "epoch": 0.12522142727703098,
      "grad_norm": 0.06133547052741051,
      "learning_rate": 8.752703950614161e-05,
      "loss": 0.0031,
      "step": 2228500
    },
    {
      "epoch": 0.12524952272851786,
      "grad_norm": 0.5235915780067444,
      "learning_rate": 8.752422838139654e-05,
      "loss": 0.0032,
      "step": 2229000
    },
    {
      "epoch": 0.12527761818000474,
      "grad_norm": 0.2540911138057709,
      "learning_rate": 8.752141725665148e-05,
      "loss": 0.0036,
      "step": 2229500
    },
    {
      "epoch": 0.12530571363149162,
      "grad_norm": 0.196343332529068,
      "learning_rate": 8.751860613190641e-05,
      "loss": 0.0033,
      "step": 2230000
    },
    {
      "epoch": 0.12530571363149162,
      "eval_loss": 0.0009113756823353469,
      "eval_runtime": 21.345,
      "eval_samples_per_second": 4684.947,
      "eval_steps_per_second": 73.226,
      "step": 2230000
    },
    {
      "epoch": 0.1253338090829785,
      "grad_norm": 0.1254461258649826,
      "learning_rate": 8.751579500716134e-05,
      "loss": 0.0028,
      "step": 2230500
    },
    {
      "epoch": 0.12536190453446538,
      "grad_norm": 0.215071439743042,
      "learning_rate": 8.751298388241628e-05,
      "loss": 0.0033,
      "step": 2231000
    },
    {
      "epoch": 0.12538999998595227,
      "grad_norm": 0.004193076863884926,
      "learning_rate": 8.751017275767121e-05,
      "loss": 0.003,
      "step": 2231500
    },
    {
      "epoch": 0.12541809543743915,
      "grad_norm": 0.4389505386352539,
      "learning_rate": 8.750736163292615e-05,
      "loss": 0.0029,
      "step": 2232000
    },
    {
      "epoch": 0.12544619088892603,
      "grad_norm": 0.1415526121854782,
      "learning_rate": 8.750455050818108e-05,
      "loss": 0.0033,
      "step": 2232500
    },
    {
      "epoch": 0.1254742863404129,
      "grad_norm": 0.109725721180439,
      "learning_rate": 8.750173938343602e-05,
      "loss": 0.0037,
      "step": 2233000
    },
    {
      "epoch": 0.1255023817918998,
      "grad_norm": 0.2314571887254715,
      "learning_rate": 8.749892825869095e-05,
      "loss": 0.003,
      "step": 2233500
    },
    {
      "epoch": 0.12553047724338667,
      "grad_norm": 0.03220493718981743,
      "learning_rate": 8.749611713394587e-05,
      "loss": 0.0037,
      "step": 2234000
    },
    {
      "epoch": 0.12555857269487355,
      "grad_norm": 0.06504803895950317,
      "learning_rate": 8.749330600920082e-05,
      "loss": 0.0036,
      "step": 2234500
    },
    {
      "epoch": 0.12558666814636044,
      "grad_norm": 0.19462326169013977,
      "learning_rate": 8.749049488445575e-05,
      "loss": 0.003,
      "step": 2235000
    },
    {
      "epoch": 0.12561476359784732,
      "grad_norm": 1.2389832735061646,
      "learning_rate": 8.748768375971069e-05,
      "loss": 0.0035,
      "step": 2235500
    },
    {
      "epoch": 0.1256428590493342,
      "grad_norm": 0.09509094059467316,
      "learning_rate": 8.748487263496562e-05,
      "loss": 0.0032,
      "step": 2236000
    },
    {
      "epoch": 0.12567095450082108,
      "grad_norm": 0.1669352948665619,
      "learning_rate": 8.748206151022054e-05,
      "loss": 0.003,
      "step": 2236500
    },
    {
      "epoch": 0.12569904995230796,
      "grad_norm": 0.3369818925857544,
      "learning_rate": 8.747925038547549e-05,
      "loss": 0.0032,
      "step": 2237000
    },
    {
      "epoch": 0.12572714540379484,
      "grad_norm": 0.009052306413650513,
      "learning_rate": 8.747643926073041e-05,
      "loss": 0.0034,
      "step": 2237500
    },
    {
      "epoch": 0.12575524085528172,
      "grad_norm": 0.23279234766960144,
      "learning_rate": 8.747362813598536e-05,
      "loss": 0.0033,
      "step": 2238000
    },
    {
      "epoch": 0.1257833363067686,
      "grad_norm": 0.6109939217567444,
      "learning_rate": 8.747081701124029e-05,
      "loss": 0.0034,
      "step": 2238500
    },
    {
      "epoch": 0.1258114317582555,
      "grad_norm": 0.4639173746109009,
      "learning_rate": 8.746800588649521e-05,
      "loss": 0.0033,
      "step": 2239000
    },
    {
      "epoch": 0.12583952720974237,
      "grad_norm": 0.515522837638855,
      "learning_rate": 8.746519476175016e-05,
      "loss": 0.0034,
      "step": 2239500
    },
    {
      "epoch": 0.12586762266122925,
      "grad_norm": 0.14059415459632874,
      "learning_rate": 8.746238363700508e-05,
      "loss": 0.0029,
      "step": 2240000
    },
    {
      "epoch": 0.12586762266122925,
      "eval_loss": 0.0009689727448858321,
      "eval_runtime": 21.7432,
      "eval_samples_per_second": 4599.149,
      "eval_steps_per_second": 71.885,
      "step": 2240000
    },
    {
      "epoch": 0.12589571811271613,
      "grad_norm": 0.093004509806633,
      "learning_rate": 8.745957251226003e-05,
      "loss": 0.0033,
      "step": 2240500
    },
    {
      "epoch": 0.125923813564203,
      "grad_norm": 0.07415077090263367,
      "learning_rate": 8.745676138751495e-05,
      "loss": 0.0034,
      "step": 2241000
    },
    {
      "epoch": 0.1259519090156899,
      "grad_norm": 0.02663518860936165,
      "learning_rate": 8.745395026276988e-05,
      "loss": 0.0035,
      "step": 2241500
    },
    {
      "epoch": 0.12598000446717678,
      "grad_norm": 0.33422768115997314,
      "learning_rate": 8.745113913802483e-05,
      "loss": 0.0033,
      "step": 2242000
    },
    {
      "epoch": 0.12600809991866366,
      "grad_norm": 0.10463952273130417,
      "learning_rate": 8.744832801327975e-05,
      "loss": 0.003,
      "step": 2242500
    },
    {
      "epoch": 0.12603619537015054,
      "grad_norm": 0.04125693440437317,
      "learning_rate": 8.74455168885347e-05,
      "loss": 0.0028,
      "step": 2243000
    },
    {
      "epoch": 0.12606429082163742,
      "grad_norm": 0.06672526150941849,
      "learning_rate": 8.744270576378962e-05,
      "loss": 0.0031,
      "step": 2243500
    },
    {
      "epoch": 0.1260923862731243,
      "grad_norm": 0.2798943817615509,
      "learning_rate": 8.743989463904456e-05,
      "loss": 0.0033,
      "step": 2244000
    },
    {
      "epoch": 0.12612048172461118,
      "grad_norm": 0.28213268518447876,
      "learning_rate": 8.743708351429949e-05,
      "loss": 0.0034,
      "step": 2244500
    },
    {
      "epoch": 0.12614857717609806,
      "grad_norm": 0.062414269894361496,
      "learning_rate": 8.743427238955442e-05,
      "loss": 0.0035,
      "step": 2245000
    },
    {
      "epoch": 0.12617667262758495,
      "grad_norm": 0.030865071341395378,
      "learning_rate": 8.743146126480936e-05,
      "loss": 0.0035,
      "step": 2245500
    },
    {
      "epoch": 0.12620476807907183,
      "grad_norm": 0.30232879519462585,
      "learning_rate": 8.742865014006429e-05,
      "loss": 0.0035,
      "step": 2246000
    },
    {
      "epoch": 0.1262328635305587,
      "grad_norm": 0.09209495037794113,
      "learning_rate": 8.742583901531923e-05,
      "loss": 0.0036,
      "step": 2246500
    },
    {
      "epoch": 0.1262609589820456,
      "grad_norm": 0.14815537631511688,
      "learning_rate": 8.742302789057416e-05,
      "loss": 0.003,
      "step": 2247000
    },
    {
      "epoch": 0.12628905443353247,
      "grad_norm": 0.05568363517522812,
      "learning_rate": 8.74202167658291e-05,
      "loss": 0.0032,
      "step": 2247500
    },
    {
      "epoch": 0.12631714988501935,
      "grad_norm": 0.41729772090911865,
      "learning_rate": 8.741740564108403e-05,
      "loss": 0.0031,
      "step": 2248000
    },
    {
      "epoch": 0.12634524533650623,
      "grad_norm": 0.34574049711227417,
      "learning_rate": 8.741459451633896e-05,
      "loss": 0.0032,
      "step": 2248500
    },
    {
      "epoch": 0.12637334078799312,
      "grad_norm": 0.47962862253189087,
      "learning_rate": 8.74117833915939e-05,
      "loss": 0.0037,
      "step": 2249000
    },
    {
      "epoch": 0.12640143623948,
      "grad_norm": 0.09413591027259827,
      "learning_rate": 8.740897226684883e-05,
      "loss": 0.0033,
      "step": 2249500
    },
    {
      "epoch": 0.12642953169096688,
      "grad_norm": 0.20696914196014404,
      "learning_rate": 8.740616114210377e-05,
      "loss": 0.0035,
      "step": 2250000
    },
    {
      "epoch": 0.12642953169096688,
      "eval_loss": 0.0009399843984283507,
      "eval_runtime": 21.1341,
      "eval_samples_per_second": 4731.685,
      "eval_steps_per_second": 73.956,
      "step": 2250000
    },
    {
      "epoch": 0.12645762714245376,
      "grad_norm": 0.18760612607002258,
      "learning_rate": 8.74033500173587e-05,
      "loss": 0.0032,
      "step": 2250500
    },
    {
      "epoch": 0.12648572259394064,
      "grad_norm": 0.24592849612236023,
      "learning_rate": 8.740053889261364e-05,
      "loss": 0.0038,
      "step": 2251000
    },
    {
      "epoch": 0.12651381804542752,
      "grad_norm": 0.11269158124923706,
      "learning_rate": 8.739772776786857e-05,
      "loss": 0.0034,
      "step": 2251500
    },
    {
      "epoch": 0.1265419134969144,
      "grad_norm": 0.03251815214753151,
      "learning_rate": 8.73949166431235e-05,
      "loss": 0.0034,
      "step": 2252000
    },
    {
      "epoch": 0.12657000894840129,
      "grad_norm": 0.42488235235214233,
      "learning_rate": 8.739210551837842e-05,
      "loss": 0.0031,
      "step": 2252500
    },
    {
      "epoch": 0.12659810439988817,
      "grad_norm": 0.061894625425338745,
      "learning_rate": 8.738929439363337e-05,
      "loss": 0.0037,
      "step": 2253000
    },
    {
      "epoch": 0.12662619985137505,
      "grad_norm": 0.24790121614933014,
      "learning_rate": 8.738648326888829e-05,
      "loss": 0.0032,
      "step": 2253500
    },
    {
      "epoch": 0.12665429530286193,
      "grad_norm": 0.0675799697637558,
      "learning_rate": 8.738367214414324e-05,
      "loss": 0.0035,
      "step": 2254000
    },
    {
      "epoch": 0.1266823907543488,
      "grad_norm": 0.4844650626182556,
      "learning_rate": 8.738086101939817e-05,
      "loss": 0.003,
      "step": 2254500
    },
    {
      "epoch": 0.1267104862058357,
      "grad_norm": 0.058062467724084854,
      "learning_rate": 8.737804989465311e-05,
      "loss": 0.0029,
      "step": 2255000
    },
    {
      "epoch": 0.12673858165732257,
      "grad_norm": 0.06153354421257973,
      "learning_rate": 8.737523876990804e-05,
      "loss": 0.0035,
      "step": 2255500
    },
    {
      "epoch": 0.12676667710880946,
      "grad_norm": 0.3844359815120697,
      "learning_rate": 8.737242764516296e-05,
      "loss": 0.0036,
      "step": 2256000
    },
    {
      "epoch": 0.12679477256029634,
      "grad_norm": 0.03937630355358124,
      "learning_rate": 8.736961652041791e-05,
      "loss": 0.0033,
      "step": 2256500
    },
    {
      "epoch": 0.12682286801178322,
      "grad_norm": 0.44954293966293335,
      "learning_rate": 8.736680539567283e-05,
      "loss": 0.0034,
      "step": 2257000
    },
    {
      "epoch": 0.12685096346327013,
      "grad_norm": 0.4723307192325592,
      "learning_rate": 8.736399427092778e-05,
      "loss": 0.0031,
      "step": 2257500
    },
    {
      "epoch": 0.126879058914757,
      "grad_norm": 0.010916091501712799,
      "learning_rate": 8.736118314618271e-05,
      "loss": 0.0033,
      "step": 2258000
    },
    {
      "epoch": 0.1269071543662439,
      "grad_norm": 0.07388461381196976,
      "learning_rate": 8.735837202143764e-05,
      "loss": 0.0034,
      "step": 2258500
    },
    {
      "epoch": 0.12693524981773077,
      "grad_norm": 0.24818149209022522,
      "learning_rate": 8.735556089669258e-05,
      "loss": 0.0032,
      "step": 2259000
    },
    {
      "epoch": 0.12696334526921765,
      "grad_norm": 0.16739307343959808,
      "learning_rate": 8.73527497719475e-05,
      "loss": 0.0034,
      "step": 2259500
    },
    {
      "epoch": 0.12699144072070453,
      "grad_norm": 0.04051772505044937,
      "learning_rate": 8.734993864720245e-05,
      "loss": 0.0031,
      "step": 2260000
    },
    {
      "epoch": 0.12699144072070453,
      "eval_loss": 0.0009187624673359096,
      "eval_runtime": 21.3652,
      "eval_samples_per_second": 4680.513,
      "eval_steps_per_second": 73.156,
      "step": 2260000
    },
    {
      "epoch": 0.12701953617219142,
      "grad_norm": 0.07952333241701126,
      "learning_rate": 8.734712752245737e-05,
      "loss": 0.0026,
      "step": 2260500
    },
    {
      "epoch": 0.1270476316236783,
      "grad_norm": 0.30219775438308716,
      "learning_rate": 8.73443163977123e-05,
      "loss": 0.0033,
      "step": 2261000
    },
    {
      "epoch": 0.12707572707516518,
      "grad_norm": 0.16032543778419495,
      "learning_rate": 8.734150527296725e-05,
      "loss": 0.0036,
      "step": 2261500
    },
    {
      "epoch": 0.12710382252665206,
      "grad_norm": 0.022567909210920334,
      "learning_rate": 8.733869414822217e-05,
      "loss": 0.0035,
      "step": 2262000
    },
    {
      "epoch": 0.12713191797813894,
      "grad_norm": 0.06557442247867584,
      "learning_rate": 8.733588302347712e-05,
      "loss": 0.0034,
      "step": 2262500
    },
    {
      "epoch": 0.12716001342962582,
      "grad_norm": 0.3129238486289978,
      "learning_rate": 8.733307189873204e-05,
      "loss": 0.0032,
      "step": 2263000
    },
    {
      "epoch": 0.1271881088811127,
      "grad_norm": 0.025555355474352837,
      "learning_rate": 8.733026077398698e-05,
      "loss": 0.0034,
      "step": 2263500
    },
    {
      "epoch": 0.1272162043325996,
      "grad_norm": 0.11003687977790833,
      "learning_rate": 8.732744964924191e-05,
      "loss": 0.0029,
      "step": 2264000
    },
    {
      "epoch": 0.12724429978408647,
      "grad_norm": 0.09662497788667679,
      "learning_rate": 8.732463852449685e-05,
      "loss": 0.0029,
      "step": 2264500
    },
    {
      "epoch": 0.12727239523557335,
      "grad_norm": 0.012932457961142063,
      "learning_rate": 8.732182739975178e-05,
      "loss": 0.0032,
      "step": 2265000
    },
    {
      "epoch": 0.12730049068706023,
      "grad_norm": 0.31209149956703186,
      "learning_rate": 8.731901627500671e-05,
      "loss": 0.0033,
      "step": 2265500
    },
    {
      "epoch": 0.1273285861385471,
      "grad_norm": 0.1738048493862152,
      "learning_rate": 8.731620515026165e-05,
      "loss": 0.003,
      "step": 2266000
    },
    {
      "epoch": 0.127356681590034,
      "grad_norm": 0.2429886907339096,
      "learning_rate": 8.731339402551658e-05,
      "loss": 0.0035,
      "step": 2266500
    },
    {
      "epoch": 0.12738477704152087,
      "grad_norm": 0.024616794660687447,
      "learning_rate": 8.731058290077152e-05,
      "loss": 0.0034,
      "step": 2267000
    },
    {
      "epoch": 0.12741287249300776,
      "grad_norm": 0.10808227956295013,
      "learning_rate": 8.730777177602645e-05,
      "loss": 0.0035,
      "step": 2267500
    },
    {
      "epoch": 0.12744096794449464,
      "grad_norm": 0.12278886139392853,
      "learning_rate": 8.730496065128139e-05,
      "loss": 0.0034,
      "step": 2268000
    },
    {
      "epoch": 0.12746906339598152,
      "grad_norm": 0.08211809396743774,
      "learning_rate": 8.730214952653632e-05,
      "loss": 0.0033,
      "step": 2268500
    },
    {
      "epoch": 0.1274971588474684,
      "grad_norm": 0.2738075256347656,
      "learning_rate": 8.729933840179125e-05,
      "loss": 0.0034,
      "step": 2269000
    },
    {
      "epoch": 0.12752525429895528,
      "grad_norm": 0.24838487803936005,
      "learning_rate": 8.729652727704619e-05,
      "loss": 0.0031,
      "step": 2269500
    },
    {
      "epoch": 0.12755334975044216,
      "grad_norm": 0.03918525204062462,
      "learning_rate": 8.729371615230112e-05,
      "loss": 0.0032,
      "step": 2270000
    },
    {
      "epoch": 0.12755334975044216,
      "eval_loss": 0.0009381092968396842,
      "eval_runtime": 21.4413,
      "eval_samples_per_second": 4663.894,
      "eval_steps_per_second": 72.897,
      "step": 2270000
    },
    {
      "epoch": 0.12758144520192904,
      "grad_norm": 0.05452878028154373,
      "learning_rate": 8.729090502755606e-05,
      "loss": 0.0031,
      "step": 2270500
    },
    {
      "epoch": 0.12760954065341593,
      "grad_norm": 0.20485220849514008,
      "learning_rate": 8.728809390281099e-05,
      "loss": 0.0037,
      "step": 2271000
    },
    {
      "epoch": 0.1276376361049028,
      "grad_norm": 0.01727023907005787,
      "learning_rate": 8.728528277806593e-05,
      "loss": 0.003,
      "step": 2271500
    },
    {
      "epoch": 0.1276657315563897,
      "grad_norm": 0.1696368157863617,
      "learning_rate": 8.728247165332085e-05,
      "loss": 0.0034,
      "step": 2272000
    },
    {
      "epoch": 0.12769382700787657,
      "grad_norm": 0.0340394601225853,
      "learning_rate": 8.72796605285758e-05,
      "loss": 0.003,
      "step": 2272500
    },
    {
      "epoch": 0.12772192245936345,
      "grad_norm": 0.09823792427778244,
      "learning_rate": 8.727684940383073e-05,
      "loss": 0.0031,
      "step": 2273000
    },
    {
      "epoch": 0.12775001791085033,
      "grad_norm": 0.2136528193950653,
      "learning_rate": 8.727403827908566e-05,
      "loss": 0.0029,
      "step": 2273500
    },
    {
      "epoch": 0.12777811336233721,
      "grad_norm": 0.015351462177932262,
      "learning_rate": 8.72712271543406e-05,
      "loss": 0.0037,
      "step": 2274000
    },
    {
      "epoch": 0.1278062088138241,
      "grad_norm": 0.11143738776445389,
      "learning_rate": 8.726841602959552e-05,
      "loss": 0.0035,
      "step": 2274500
    },
    {
      "epoch": 0.12783430426531098,
      "grad_norm": 0.11728966981172562,
      "learning_rate": 8.726560490485047e-05,
      "loss": 0.0036,
      "step": 2275000
    },
    {
      "epoch": 0.12786239971679786,
      "grad_norm": 0.16822001338005066,
      "learning_rate": 8.726279378010539e-05,
      "loss": 0.003,
      "step": 2275500
    },
    {
      "epoch": 0.12789049516828474,
      "grad_norm": 0.018881114199757576,
      "learning_rate": 8.725998265536033e-05,
      "loss": 0.0028,
      "step": 2276000
    },
    {
      "epoch": 0.12791859061977162,
      "grad_norm": 0.06077355891466141,
      "learning_rate": 8.725717153061525e-05,
      "loss": 0.0033,
      "step": 2276500
    },
    {
      "epoch": 0.1279466860712585,
      "grad_norm": 0.23527328670024872,
      "learning_rate": 8.725436040587019e-05,
      "loss": 0.003,
      "step": 2277000
    },
    {
      "epoch": 0.12797478152274538,
      "grad_norm": 0.015803545713424683,
      "learning_rate": 8.725154928112514e-05,
      "loss": 0.0032,
      "step": 2277500
    },
    {
      "epoch": 0.12800287697423227,
      "grad_norm": 0.43480604887008667,
      "learning_rate": 8.724873815638006e-05,
      "loss": 0.0033,
      "step": 2278000
    },
    {
      "epoch": 0.12803097242571915,
      "grad_norm": 0.2174009084701538,
      "learning_rate": 8.7245927031635e-05,
      "loss": 0.0036,
      "step": 2278500
    },
    {
      "epoch": 0.12805906787720603,
      "grad_norm": 0.09792391955852509,
      "learning_rate": 8.724311590688993e-05,
      "loss": 0.0028,
      "step": 2279000
    },
    {
      "epoch": 0.1280871633286929,
      "grad_norm": 0.05848565697669983,
      "learning_rate": 8.724030478214486e-05,
      "loss": 0.003,
      "step": 2279500
    },
    {
      "epoch": 0.1281152587801798,
      "grad_norm": 0.013477032072842121,
      "learning_rate": 8.72374936573998e-05,
      "loss": 0.0033,
      "step": 2280000
    },
    {
      "epoch": 0.1281152587801798,
      "eval_loss": 0.0010076594771817327,
      "eval_runtime": 22.0187,
      "eval_samples_per_second": 4541.603,
      "eval_steps_per_second": 70.985,
      "step": 2280000
    },
    {
      "epoch": 0.12814335423166667,
      "grad_norm": 0.1482432633638382,
      "learning_rate": 8.723468253265473e-05,
      "loss": 0.0034,
      "step": 2280500
    },
    {
      "epoch": 0.12817144968315355,
      "grad_norm": 0.023282591253519058,
      "learning_rate": 8.723187140790968e-05,
      "loss": 0.0033,
      "step": 2281000
    },
    {
      "epoch": 0.12819954513464044,
      "grad_norm": 0.03783091902732849,
      "learning_rate": 8.72290602831646e-05,
      "loss": 0.0032,
      "step": 2281500
    },
    {
      "epoch": 0.12822764058612732,
      "grad_norm": 0.05382690578699112,
      "learning_rate": 8.722624915841953e-05,
      "loss": 0.003,
      "step": 2282000
    },
    {
      "epoch": 0.1282557360376142,
      "grad_norm": 0.22857968509197235,
      "learning_rate": 8.722343803367447e-05,
      "loss": 0.0034,
      "step": 2282500
    },
    {
      "epoch": 0.12828383148910108,
      "grad_norm": 0.6713717579841614,
      "learning_rate": 8.72206269089294e-05,
      "loss": 0.0035,
      "step": 2283000
    },
    {
      "epoch": 0.12831192694058796,
      "grad_norm": 0.23562169075012207,
      "learning_rate": 8.721781578418433e-05,
      "loss": 0.0033,
      "step": 2283500
    },
    {
      "epoch": 0.12834002239207484,
      "grad_norm": 0.25128722190856934,
      "learning_rate": 8.721500465943927e-05,
      "loss": 0.0033,
      "step": 2284000
    },
    {
      "epoch": 0.12836811784356172,
      "grad_norm": 0.07070224732160568,
      "learning_rate": 8.72121935346942e-05,
      "loss": 0.0032,
      "step": 2284500
    },
    {
      "epoch": 0.1283962132950486,
      "grad_norm": 0.38225439190864563,
      "learning_rate": 8.720938240994914e-05,
      "loss": 0.0034,
      "step": 2285000
    },
    {
      "epoch": 0.1284243087465355,
      "grad_norm": 0.22779147326946259,
      "learning_rate": 8.720657128520407e-05,
      "loss": 0.0036,
      "step": 2285500
    },
    {
      "epoch": 0.12845240419802237,
      "grad_norm": 0.0038753277622163296,
      "learning_rate": 8.7203760160459e-05,
      "loss": 0.0033,
      "step": 2286000
    },
    {
      "epoch": 0.12848049964950925,
      "grad_norm": 0.02706863358616829,
      "learning_rate": 8.720094903571394e-05,
      "loss": 0.0035,
      "step": 2286500
    },
    {
      "epoch": 0.12850859510099613,
      "grad_norm": 0.272554486989975,
      "learning_rate": 8.719813791096887e-05,
      "loss": 0.0032,
      "step": 2287000
    },
    {
      "epoch": 0.128536690552483,
      "grad_norm": 0.008169117383658886,
      "learning_rate": 8.719532678622381e-05,
      "loss": 0.0034,
      "step": 2287500
    },
    {
      "epoch": 0.1285647860039699,
      "grad_norm": 0.007285816129297018,
      "learning_rate": 8.719251566147874e-05,
      "loss": 0.0032,
      "step": 2288000
    },
    {
      "epoch": 0.12859288145545678,
      "grad_norm": 0.36173415184020996,
      "learning_rate": 8.718970453673368e-05,
      "loss": 0.0028,
      "step": 2288500
    },
    {
      "epoch": 0.12862097690694366,
      "grad_norm": 0.45031192898750305,
      "learning_rate": 8.718689341198861e-05,
      "loss": 0.0029,
      "step": 2289000
    },
    {
      "epoch": 0.12864907235843054,
      "grad_norm": 0.15703505277633667,
      "learning_rate": 8.718408228724354e-05,
      "loss": 0.0035,
      "step": 2289500
    },
    {
      "epoch": 0.12867716780991742,
      "grad_norm": 0.765093207359314,
      "learning_rate": 8.718127116249848e-05,
      "loss": 0.0031,
      "step": 2290000
    },
    {
      "epoch": 0.12867716780991742,
      "eval_loss": 0.0010532314190641046,
      "eval_runtime": 22.0739,
      "eval_samples_per_second": 4530.236,
      "eval_steps_per_second": 70.808,
      "step": 2290000
    },
    {
      "epoch": 0.1287052632614043,
      "grad_norm": 0.14932942390441895,
      "learning_rate": 8.717846003775341e-05,
      "loss": 0.0035,
      "step": 2290500
    },
    {
      "epoch": 0.12873335871289118,
      "grad_norm": 0.20995697379112244,
      "learning_rate": 8.717564891300835e-05,
      "loss": 0.0032,
      "step": 2291000
    },
    {
      "epoch": 0.12876145416437806,
      "grad_norm": 0.08948595821857452,
      "learning_rate": 8.717283778826327e-05,
      "loss": 0.0029,
      "step": 2291500
    },
    {
      "epoch": 0.12878954961586495,
      "grad_norm": 0.3151197135448456,
      "learning_rate": 8.717002666351822e-05,
      "loss": 0.003,
      "step": 2292000
    },
    {
      "epoch": 0.12881764506735183,
      "grad_norm": 0.09182391315698624,
      "learning_rate": 8.716721553877315e-05,
      "loss": 0.0034,
      "step": 2292500
    },
    {
      "epoch": 0.1288457405188387,
      "grad_norm": 0.2739611268043518,
      "learning_rate": 8.716440441402808e-05,
      "loss": 0.0034,
      "step": 2293000
    },
    {
      "epoch": 0.1288738359703256,
      "grad_norm": 0.055448200553655624,
      "learning_rate": 8.716159328928302e-05,
      "loss": 0.0035,
      "step": 2293500
    },
    {
      "epoch": 0.12890193142181247,
      "grad_norm": 0.02384144626557827,
      "learning_rate": 8.715878216453794e-05,
      "loss": 0.0036,
      "step": 2294000
    },
    {
      "epoch": 0.12893002687329935,
      "grad_norm": 0.09538160264492035,
      "learning_rate": 8.715597103979289e-05,
      "loss": 0.0033,
      "step": 2294500
    },
    {
      "epoch": 0.12895812232478623,
      "grad_norm": 0.050050750374794006,
      "learning_rate": 8.715315991504781e-05,
      "loss": 0.003,
      "step": 2295000
    },
    {
      "epoch": 0.12898621777627312,
      "grad_norm": 0.23324613273143768,
      "learning_rate": 8.715034879030276e-05,
      "loss": 0.0035,
      "step": 2295500
    },
    {
      "epoch": 0.12901431322776,
      "grad_norm": 0.3318881392478943,
      "learning_rate": 8.714753766555768e-05,
      "loss": 0.0032,
      "step": 2296000
    },
    {
      "epoch": 0.12904240867924688,
      "grad_norm": 0.0043735625222325325,
      "learning_rate": 8.714472654081261e-05,
      "loss": 0.0034,
      "step": 2296500
    },
    {
      "epoch": 0.12907050413073376,
      "grad_norm": 0.6975714564323425,
      "learning_rate": 8.714191541606756e-05,
      "loss": 0.0033,
      "step": 2297000
    },
    {
      "epoch": 0.12909859958222064,
      "grad_norm": 0.026886682957410812,
      "learning_rate": 8.713910429132248e-05,
      "loss": 0.0033,
      "step": 2297500
    },
    {
      "epoch": 0.12912669503370752,
      "grad_norm": 1.0875130891799927,
      "learning_rate": 8.713629316657743e-05,
      "loss": 0.0033,
      "step": 2298000
    },
    {
      "epoch": 0.1291547904851944,
      "grad_norm": 0.2736487090587616,
      "learning_rate": 8.713348204183235e-05,
      "loss": 0.0029,
      "step": 2298500
    },
    {
      "epoch": 0.12918288593668129,
      "grad_norm": 0.015357300639152527,
      "learning_rate": 8.713067091708728e-05,
      "loss": 0.0031,
      "step": 2299000
    },
    {
      "epoch": 0.12921098138816817,
      "grad_norm": 0.039237573742866516,
      "learning_rate": 8.712785979234222e-05,
      "loss": 0.0028,
      "step": 2299500
    },
    {
      "epoch": 0.12923907683965505,
      "grad_norm": 0.35434794425964355,
      "learning_rate": 8.712504866759715e-05,
      "loss": 0.0034,
      "step": 2300000
    },
    {
      "epoch": 0.12923907683965505,
      "eval_loss": 0.0009381390991620719,
      "eval_runtime": 23.5387,
      "eval_samples_per_second": 4248.321,
      "eval_steps_per_second": 66.401,
      "step": 2300000
    },
    {
      "epoch": 0.12926717229114193,
      "grad_norm": 0.07891759276390076,
      "learning_rate": 8.71222375428521e-05,
      "loss": 0.0035,
      "step": 2300500
    },
    {
      "epoch": 0.1292952677426288,
      "grad_norm": 0.03437865898013115,
      "learning_rate": 8.711942641810702e-05,
      "loss": 0.003,
      "step": 2301000
    },
    {
      "epoch": 0.1293233631941157,
      "grad_norm": 0.03998472914099693,
      "learning_rate": 8.711661529336195e-05,
      "loss": 0.0031,
      "step": 2301500
    },
    {
      "epoch": 0.12935145864560257,
      "grad_norm": 0.34789401292800903,
      "learning_rate": 8.711380416861689e-05,
      "loss": 0.0034,
      "step": 2302000
    },
    {
      "epoch": 0.12937955409708946,
      "grad_norm": 0.07659707218408585,
      "learning_rate": 8.711099304387182e-05,
      "loss": 0.0029,
      "step": 2302500
    },
    {
      "epoch": 0.12940764954857634,
      "grad_norm": 0.5255523920059204,
      "learning_rate": 8.710818191912676e-05,
      "loss": 0.0032,
      "step": 2303000
    },
    {
      "epoch": 0.12943574500006322,
      "grad_norm": 0.036543965339660645,
      "learning_rate": 8.710537079438169e-05,
      "loss": 0.0031,
      "step": 2303500
    },
    {
      "epoch": 0.1294638404515501,
      "grad_norm": 0.044800661504268646,
      "learning_rate": 8.710255966963662e-05,
      "loss": 0.0035,
      "step": 2304000
    },
    {
      "epoch": 0.12949193590303698,
      "grad_norm": 0.09447060525417328,
      "learning_rate": 8.709974854489156e-05,
      "loss": 0.0033,
      "step": 2304500
    },
    {
      "epoch": 0.12952003135452386,
      "grad_norm": 0.12453793734312057,
      "learning_rate": 8.709693742014649e-05,
      "loss": 0.0033,
      "step": 2305000
    },
    {
      "epoch": 0.12954812680601074,
      "grad_norm": 0.4792734384536743,
      "learning_rate": 8.709412629540143e-05,
      "loss": 0.0034,
      "step": 2305500
    },
    {
      "epoch": 0.12957622225749763,
      "grad_norm": 0.20397105813026428,
      "learning_rate": 8.709131517065636e-05,
      "loss": 0.0031,
      "step": 2306000
    },
    {
      "epoch": 0.1296043177089845,
      "grad_norm": 0.021636052057147026,
      "learning_rate": 8.70885040459113e-05,
      "loss": 0.0035,
      "step": 2306500
    },
    {
      "epoch": 0.1296324131604714,
      "grad_norm": 0.30539435148239136,
      "learning_rate": 8.708569292116623e-05,
      "loss": 0.0035,
      "step": 2307000
    },
    {
      "epoch": 0.12966050861195827,
      "grad_norm": 0.04625521972775459,
      "learning_rate": 8.708288179642115e-05,
      "loss": 0.0032,
      "step": 2307500
    },
    {
      "epoch": 0.12968860406344515,
      "grad_norm": 0.1813434362411499,
      "learning_rate": 8.70800706716761e-05,
      "loss": 0.0031,
      "step": 2308000
    },
    {
      "epoch": 0.12971669951493203,
      "grad_norm": 0.0256199948489666,
      "learning_rate": 8.707725954693103e-05,
      "loss": 0.0032,
      "step": 2308500
    },
    {
      "epoch": 0.1297447949664189,
      "grad_norm": 0.07807358354330063,
      "learning_rate": 8.707444842218597e-05,
      "loss": 0.0032,
      "step": 2309000
    },
    {
      "epoch": 0.1297728904179058,
      "grad_norm": 0.19613660871982574,
      "learning_rate": 8.70716372974409e-05,
      "loss": 0.0035,
      "step": 2309500
    },
    {
      "epoch": 0.12980098586939268,
      "grad_norm": 0.17265991866588593,
      "learning_rate": 8.706882617269582e-05,
      "loss": 0.0033,
      "step": 2310000
    },
    {
      "epoch": 0.12980098586939268,
      "eval_loss": 0.0010009693214669824,
      "eval_runtime": 20.8743,
      "eval_samples_per_second": 4790.588,
      "eval_steps_per_second": 74.877,
      "step": 2310000
    },
    {
      "epoch": 0.12982908132087956,
      "grad_norm": 0.054193634539842606,
      "learning_rate": 8.706601504795077e-05,
      "loss": 0.003,
      "step": 2310500
    },
    {
      "epoch": 0.12985717677236644,
      "grad_norm": 0.13586834073066711,
      "learning_rate": 8.706320392320569e-05,
      "loss": 0.0034,
      "step": 2311000
    },
    {
      "epoch": 0.12988527222385332,
      "grad_norm": 0.05599553883075714,
      "learning_rate": 8.706039279846064e-05,
      "loss": 0.0033,
      "step": 2311500
    },
    {
      "epoch": 0.1299133676753402,
      "grad_norm": 0.1823965162038803,
      "learning_rate": 8.705758167371557e-05,
      "loss": 0.0032,
      "step": 2312000
    },
    {
      "epoch": 0.12994146312682708,
      "grad_norm": 0.007247969973832369,
      "learning_rate": 8.705477054897049e-05,
      "loss": 0.0032,
      "step": 2312500
    },
    {
      "epoch": 0.12996955857831397,
      "grad_norm": 0.10111196339130402,
      "learning_rate": 8.705195942422544e-05,
      "loss": 0.003,
      "step": 2313000
    },
    {
      "epoch": 0.12999765402980085,
      "grad_norm": 0.00792770180851221,
      "learning_rate": 8.704914829948036e-05,
      "loss": 0.003,
      "step": 2313500
    },
    {
      "epoch": 0.13002574948128773,
      "grad_norm": 0.46104133129119873,
      "learning_rate": 8.704633717473531e-05,
      "loss": 0.0032,
      "step": 2314000
    },
    {
      "epoch": 0.1300538449327746,
      "grad_norm": 0.7091958522796631,
      "learning_rate": 8.704352604999023e-05,
      "loss": 0.0034,
      "step": 2314500
    },
    {
      "epoch": 0.1300819403842615,
      "grad_norm": 0.044681575149297714,
      "learning_rate": 8.704071492524516e-05,
      "loss": 0.0034,
      "step": 2315000
    },
    {
      "epoch": 0.13011003583574837,
      "grad_norm": 0.10276102274656296,
      "learning_rate": 8.70379038005001e-05,
      "loss": 0.003,
      "step": 2315500
    },
    {
      "epoch": 0.13013813128723525,
      "grad_norm": 0.16568058729171753,
      "learning_rate": 8.703509267575503e-05,
      "loss": 0.0031,
      "step": 2316000
    },
    {
      "epoch": 0.13016622673872214,
      "grad_norm": 0.29582107067108154,
      "learning_rate": 8.703228155100998e-05,
      "loss": 0.0032,
      "step": 2316500
    },
    {
      "epoch": 0.13019432219020902,
      "grad_norm": 0.2117563635110855,
      "learning_rate": 8.70294704262649e-05,
      "loss": 0.0029,
      "step": 2317000
    },
    {
      "epoch": 0.1302224176416959,
      "grad_norm": 0.01844138652086258,
      "learning_rate": 8.702665930151984e-05,
      "loss": 0.0033,
      "step": 2317500
    },
    {
      "epoch": 0.13025051309318278,
      "grad_norm": 0.019786490127444267,
      "learning_rate": 8.702384817677477e-05,
      "loss": 0.0031,
      "step": 2318000
    },
    {
      "epoch": 0.13027860854466966,
      "grad_norm": 0.180935338139534,
      "learning_rate": 8.70210370520297e-05,
      "loss": 0.003,
      "step": 2318500
    },
    {
      "epoch": 0.13030670399615654,
      "grad_norm": 0.008897069841623306,
      "learning_rate": 8.701822592728464e-05,
      "loss": 0.003,
      "step": 2319000
    },
    {
      "epoch": 0.13033479944764342,
      "grad_norm": 0.038673777133226395,
      "learning_rate": 8.701541480253957e-05,
      "loss": 0.003,
      "step": 2319500
    },
    {
      "epoch": 0.1303628948991303,
      "grad_norm": 0.09060835838317871,
      "learning_rate": 8.70126036777945e-05,
      "loss": 0.0033,
      "step": 2320000
    },
    {
      "epoch": 0.1303628948991303,
      "eval_loss": 0.000880204257555306,
      "eval_runtime": 21.0155,
      "eval_samples_per_second": 4758.383,
      "eval_steps_per_second": 74.374,
      "step": 2320000
    },
    {
      "epoch": 0.1303909903506172,
      "grad_norm": 0.12188246846199036,
      "learning_rate": 8.700979255304944e-05,
      "loss": 0.0032,
      "step": 2320500
    },
    {
      "epoch": 0.13041908580210407,
      "grad_norm": 0.13433222472667694,
      "learning_rate": 8.700698142830438e-05,
      "loss": 0.0036,
      "step": 2321000
    },
    {
      "epoch": 0.13044718125359095,
      "grad_norm": 0.06356354802846909,
      "learning_rate": 8.700417030355931e-05,
      "loss": 0.0027,
      "step": 2321500
    },
    {
      "epoch": 0.13047527670507783,
      "grad_norm": 0.3193577826023102,
      "learning_rate": 8.700135917881424e-05,
      "loss": 0.0029,
      "step": 2322000
    },
    {
      "epoch": 0.1305033721565647,
      "grad_norm": 0.0776451975107193,
      "learning_rate": 8.699854805406918e-05,
      "loss": 0.0031,
      "step": 2322500
    },
    {
      "epoch": 0.1305314676080516,
      "grad_norm": 0.047142207622528076,
      "learning_rate": 8.699573692932411e-05,
      "loss": 0.0031,
      "step": 2323000
    },
    {
      "epoch": 0.13055956305953847,
      "grad_norm": 0.43043917417526245,
      "learning_rate": 8.699292580457905e-05,
      "loss": 0.0035,
      "step": 2323500
    },
    {
      "epoch": 0.13058765851102536,
      "grad_norm": 0.06478359550237656,
      "learning_rate": 8.699011467983398e-05,
      "loss": 0.0035,
      "step": 2324000
    },
    {
      "epoch": 0.13061575396251224,
      "grad_norm": 0.07960785925388336,
      "learning_rate": 8.698730355508891e-05,
      "loss": 0.003,
      "step": 2324500
    },
    {
      "epoch": 0.13064384941399912,
      "grad_norm": 0.04688958078622818,
      "learning_rate": 8.698449243034385e-05,
      "loss": 0.0028,
      "step": 2325000
    },
    {
      "epoch": 0.130671944865486,
      "grad_norm": 0.01014631986618042,
      "learning_rate": 8.698168130559878e-05,
      "loss": 0.0031,
      "step": 2325500
    },
    {
      "epoch": 0.13070004031697288,
      "grad_norm": 0.0346858873963356,
      "learning_rate": 8.697887018085372e-05,
      "loss": 0.0031,
      "step": 2326000
    },
    {
      "epoch": 0.13072813576845976,
      "grad_norm": 0.1579107642173767,
      "learning_rate": 8.697605905610865e-05,
      "loss": 0.0037,
      "step": 2326500
    },
    {
      "epoch": 0.13075623121994664,
      "grad_norm": 0.5280841588973999,
      "learning_rate": 8.697324793136357e-05,
      "loss": 0.003,
      "step": 2327000
    },
    {
      "epoch": 0.13078432667143353,
      "grad_norm": 0.3585899770259857,
      "learning_rate": 8.697043680661852e-05,
      "loss": 0.0031,
      "step": 2327500
    },
    {
      "epoch": 0.1308124221229204,
      "grad_norm": 0.42021551728248596,
      "learning_rate": 8.696762568187345e-05,
      "loss": 0.0028,
      "step": 2328000
    },
    {
      "epoch": 0.1308405175744073,
      "grad_norm": 0.04730016365647316,
      "learning_rate": 8.696481455712839e-05,
      "loss": 0.0031,
      "step": 2328500
    },
    {
      "epoch": 0.13086861302589417,
      "grad_norm": 0.11284168064594269,
      "learning_rate": 8.696200343238332e-05,
      "loss": 0.0033,
      "step": 2329000
    },
    {
      "epoch": 0.13089670847738105,
      "grad_norm": 0.008887456730008125,
      "learning_rate": 8.695919230763824e-05,
      "loss": 0.0031,
      "step": 2329500
    },
    {
      "epoch": 0.13092480392886793,
      "grad_norm": 0.31793713569641113,
      "learning_rate": 8.695638118289319e-05,
      "loss": 0.0038,
      "step": 2330000
    },
    {
      "epoch": 0.13092480392886793,
      "eval_loss": 0.0011588168563321233,
      "eval_runtime": 21.3447,
      "eval_samples_per_second": 4684.996,
      "eval_steps_per_second": 73.226,
      "step": 2330000
    },
    {
      "epoch": 0.13095289938035481,
      "grad_norm": 0.12173574417829514,
      "learning_rate": 8.695357005814811e-05,
      "loss": 0.0031,
      "step": 2330500
    },
    {
      "epoch": 0.1309809948318417,
      "grad_norm": 0.05779516324400902,
      "learning_rate": 8.695075893340306e-05,
      "loss": 0.0033,
      "step": 2331000
    },
    {
      "epoch": 0.13100909028332858,
      "grad_norm": 0.23573613166809082,
      "learning_rate": 8.6947947808658e-05,
      "loss": 0.0032,
      "step": 2331500
    },
    {
      "epoch": 0.13103718573481546,
      "grad_norm": 0.1471417248249054,
      "learning_rate": 8.694513668391291e-05,
      "loss": 0.0035,
      "step": 2332000
    },
    {
      "epoch": 0.13106528118630234,
      "grad_norm": 0.1336989551782608,
      "learning_rate": 8.694232555916786e-05,
      "loss": 0.0032,
      "step": 2332500
    },
    {
      "epoch": 0.13109337663778922,
      "grad_norm": 0.2935961186885834,
      "learning_rate": 8.693951443442278e-05,
      "loss": 0.003,
      "step": 2333000
    },
    {
      "epoch": 0.1311214720892761,
      "grad_norm": 0.03097989596426487,
      "learning_rate": 8.693670330967773e-05,
      "loss": 0.003,
      "step": 2333500
    },
    {
      "epoch": 0.13114956754076298,
      "grad_norm": 0.06371722370386124,
      "learning_rate": 8.693389218493265e-05,
      "loss": 0.0032,
      "step": 2334000
    },
    {
      "epoch": 0.13117766299224987,
      "grad_norm": 0.00700262701138854,
      "learning_rate": 8.693108106018759e-05,
      "loss": 0.0033,
      "step": 2334500
    },
    {
      "epoch": 0.13120575844373675,
      "grad_norm": 0.03147423639893532,
      "learning_rate": 8.692826993544252e-05,
      "loss": 0.0032,
      "step": 2335000
    },
    {
      "epoch": 0.13123385389522363,
      "grad_norm": 0.031114904209971428,
      "learning_rate": 8.692545881069745e-05,
      "loss": 0.0033,
      "step": 2335500
    },
    {
      "epoch": 0.1312619493467105,
      "grad_norm": 0.08324511349201202,
      "learning_rate": 8.69226476859524e-05,
      "loss": 0.0033,
      "step": 2336000
    },
    {
      "epoch": 0.1312900447981974,
      "grad_norm": 0.0025332202203571796,
      "learning_rate": 8.691983656120732e-05,
      "loss": 0.0034,
      "step": 2336500
    },
    {
      "epoch": 0.13131814024968427,
      "grad_norm": 0.20790602266788483,
      "learning_rate": 8.691702543646226e-05,
      "loss": 0.0028,
      "step": 2337000
    },
    {
      "epoch": 0.13134623570117115,
      "grad_norm": 0.32701271772384644,
      "learning_rate": 8.691421431171719e-05,
      "loss": 0.0036,
      "step": 2337500
    },
    {
      "epoch": 0.13137433115265804,
      "grad_norm": 0.03560295328497887,
      "learning_rate": 8.691140318697213e-05,
      "loss": 0.003,
      "step": 2338000
    },
    {
      "epoch": 0.13140242660414492,
      "grad_norm": 0.21828140318393707,
      "learning_rate": 8.690859206222706e-05,
      "loss": 0.0035,
      "step": 2338500
    },
    {
      "epoch": 0.1314305220556318,
      "grad_norm": 0.01559557393193245,
      "learning_rate": 8.6905780937482e-05,
      "loss": 0.0031,
      "step": 2339000
    },
    {
      "epoch": 0.13145861750711868,
      "grad_norm": 0.19663654267787933,
      "learning_rate": 8.690296981273693e-05,
      "loss": 0.0032,
      "step": 2339500
    },
    {
      "epoch": 0.13148671295860556,
      "grad_norm": 0.15551365911960602,
      "learning_rate": 8.690015868799186e-05,
      "loss": 0.0032,
      "step": 2340000
    },
    {
      "epoch": 0.13148671295860556,
      "eval_loss": 0.0011127815814688802,
      "eval_runtime": 21.1525,
      "eval_samples_per_second": 4727.572,
      "eval_steps_per_second": 73.892,
      "step": 2340000
    },
    {
      "epoch": 0.13151480841009244,
      "grad_norm": 0.15656426548957825,
      "learning_rate": 8.68973475632468e-05,
      "loss": 0.0033,
      "step": 2340500
    },
    {
      "epoch": 0.13154290386157932,
      "grad_norm": 0.3016814589500427,
      "learning_rate": 8.689453643850173e-05,
      "loss": 0.0033,
      "step": 2341000
    },
    {
      "epoch": 0.1315709993130662,
      "grad_norm": 0.3437385857105255,
      "learning_rate": 8.689172531375667e-05,
      "loss": 0.0031,
      "step": 2341500
    },
    {
      "epoch": 0.1315990947645531,
      "grad_norm": 0.139424130320549,
      "learning_rate": 8.68889141890116e-05,
      "loss": 0.0034,
      "step": 2342000
    },
    {
      "epoch": 0.13162719021603997,
      "grad_norm": 0.32954710721969604,
      "learning_rate": 8.688610306426653e-05,
      "loss": 0.0033,
      "step": 2342500
    },
    {
      "epoch": 0.13165528566752685,
      "grad_norm": 0.08425068855285645,
      "learning_rate": 8.688329193952147e-05,
      "loss": 0.0031,
      "step": 2343000
    },
    {
      "epoch": 0.13168338111901373,
      "grad_norm": 0.06937738507986069,
      "learning_rate": 8.68804808147764e-05,
      "loss": 0.0035,
      "step": 2343500
    },
    {
      "epoch": 0.1317114765705006,
      "grad_norm": 0.15668481588363647,
      "learning_rate": 8.687766969003134e-05,
      "loss": 0.0032,
      "step": 2344000
    },
    {
      "epoch": 0.1317395720219875,
      "grad_norm": 0.09955492615699768,
      "learning_rate": 8.687485856528627e-05,
      "loss": 0.0034,
      "step": 2344500
    },
    {
      "epoch": 0.13176766747347438,
      "grad_norm": 0.13856583833694458,
      "learning_rate": 8.68720474405412e-05,
      "loss": 0.0035,
      "step": 2345000
    },
    {
      "epoch": 0.13179576292496126,
      "grad_norm": 0.07295780628919601,
      "learning_rate": 8.686923631579613e-05,
      "loss": 0.0035,
      "step": 2345500
    },
    {
      "epoch": 0.13182385837644814,
      "grad_norm": 0.20824050903320312,
      "learning_rate": 8.686642519105107e-05,
      "loss": 0.0032,
      "step": 2346000
    },
    {
      "epoch": 0.13185195382793502,
      "grad_norm": 0.024830928072333336,
      "learning_rate": 8.6863614066306e-05,
      "loss": 0.003,
      "step": 2346500
    },
    {
      "epoch": 0.1318800492794219,
      "grad_norm": 0.011496895924210548,
      "learning_rate": 8.686080294156094e-05,
      "loss": 0.0034,
      "step": 2347000
    },
    {
      "epoch": 0.13190814473090878,
      "grad_norm": 0.06156516820192337,
      "learning_rate": 8.685799181681588e-05,
      "loss": 0.0032,
      "step": 2347500
    },
    {
      "epoch": 0.13193624018239566,
      "grad_norm": 0.3395572900772095,
      "learning_rate": 8.68551806920708e-05,
      "loss": 0.0029,
      "step": 2348000
    },
    {
      "epoch": 0.13196433563388255,
      "grad_norm": 0.07962331175804138,
      "learning_rate": 8.685236956732574e-05,
      "loss": 0.0032,
      "step": 2348500
    },
    {
      "epoch": 0.13199243108536943,
      "grad_norm": 0.19166894257068634,
      "learning_rate": 8.684955844258067e-05,
      "loss": 0.0031,
      "step": 2349000
    },
    {
      "epoch": 0.1320205265368563,
      "grad_norm": 0.09983449429273605,
      "learning_rate": 8.684674731783561e-05,
      "loss": 0.0033,
      "step": 2349500
    },
    {
      "epoch": 0.1320486219883432,
      "grad_norm": 0.13079524040222168,
      "learning_rate": 8.684393619309053e-05,
      "loss": 0.0032,
      "step": 2350000
    },
    {
      "epoch": 0.1320486219883432,
      "eval_loss": 0.0009802401764318347,
      "eval_runtime": 21.3326,
      "eval_samples_per_second": 4687.66,
      "eval_steps_per_second": 73.268,
      "step": 2350000
    },
    {
      "epoch": 0.13207671743983007,
      "grad_norm": 0.6341605186462402,
      "learning_rate": 8.684112506834547e-05,
      "loss": 0.003,
      "step": 2350500
    },
    {
      "epoch": 0.13210481289131695,
      "grad_norm": 0.14120182394981384,
      "learning_rate": 8.683831394360042e-05,
      "loss": 0.0031,
      "step": 2351000
    },
    {
      "epoch": 0.13213290834280383,
      "grad_norm": 0.17755228281021118,
      "learning_rate": 8.683550281885534e-05,
      "loss": 0.0032,
      "step": 2351500
    },
    {
      "epoch": 0.13216100379429072,
      "grad_norm": 0.18908526003360748,
      "learning_rate": 8.683269169411028e-05,
      "loss": 0.0029,
      "step": 2352000
    },
    {
      "epoch": 0.1321890992457776,
      "grad_norm": 0.18858271837234497,
      "learning_rate": 8.68298805693652e-05,
      "loss": 0.0034,
      "step": 2352500
    },
    {
      "epoch": 0.13221719469726448,
      "grad_norm": 0.15175937116146088,
      "learning_rate": 8.682706944462014e-05,
      "loss": 0.0029,
      "step": 2353000
    },
    {
      "epoch": 0.13224529014875136,
      "grad_norm": 0.10121076554059982,
      "learning_rate": 8.682425831987507e-05,
      "loss": 0.0034,
      "step": 2353500
    },
    {
      "epoch": 0.13227338560023824,
      "grad_norm": 0.011528481729328632,
      "learning_rate": 8.682144719513001e-05,
      "loss": 0.0033,
      "step": 2354000
    },
    {
      "epoch": 0.13230148105172512,
      "grad_norm": 0.9695717096328735,
      "learning_rate": 8.681863607038496e-05,
      "loss": 0.0029,
      "step": 2354500
    },
    {
      "epoch": 0.132329576503212,
      "grad_norm": 0.20655624568462372,
      "learning_rate": 8.681582494563988e-05,
      "loss": 0.0028,
      "step": 2355000
    },
    {
      "epoch": 0.13235767195469889,
      "grad_norm": 0.24879667162895203,
      "learning_rate": 8.681301382089481e-05,
      "loss": 0.0035,
      "step": 2355500
    },
    {
      "epoch": 0.13238576740618577,
      "grad_norm": 0.12968499958515167,
      "learning_rate": 8.681020269614975e-05,
      "loss": 0.003,
      "step": 2356000
    },
    {
      "epoch": 0.13241386285767265,
      "grad_norm": 0.10832477360963821,
      "learning_rate": 8.680739157140468e-05,
      "loss": 0.003,
      "step": 2356500
    },
    {
      "epoch": 0.13244195830915953,
      "grad_norm": 0.3254179060459137,
      "learning_rate": 8.680458044665961e-05,
      "loss": 0.0032,
      "step": 2357000
    },
    {
      "epoch": 0.1324700537606464,
      "grad_norm": 0.3437732458114624,
      "learning_rate": 8.680176932191455e-05,
      "loss": 0.0033,
      "step": 2357500
    },
    {
      "epoch": 0.1324981492121333,
      "grad_norm": 0.07308788597583771,
      "learning_rate": 8.679895819716948e-05,
      "loss": 0.0034,
      "step": 2358000
    },
    {
      "epoch": 0.13252624466362017,
      "grad_norm": 0.5503115653991699,
      "learning_rate": 8.679614707242442e-05,
      "loss": 0.0031,
      "step": 2358500
    },
    {
      "epoch": 0.13255434011510706,
      "grad_norm": 0.012402304448187351,
      "learning_rate": 8.679333594767935e-05,
      "loss": 0.0029,
      "step": 2359000
    },
    {
      "epoch": 0.13258243556659394,
      "grad_norm": 0.011599610559642315,
      "learning_rate": 8.679052482293428e-05,
      "loss": 0.0028,
      "step": 2359500
    },
    {
      "epoch": 0.13261053101808082,
      "grad_norm": 0.03540010005235672,
      "learning_rate": 8.678771369818922e-05,
      "loss": 0.0029,
      "step": 2360000
    },
    {
      "epoch": 0.13261053101808082,
      "eval_loss": 0.000981673365458846,
      "eval_runtime": 21.317,
      "eval_samples_per_second": 4691.083,
      "eval_steps_per_second": 73.322,
      "step": 2360000
    },
    {
      "epoch": 0.1326386264695677,
      "grad_norm": 0.04254437983036041,
      "learning_rate": 8.678490257344415e-05,
      "loss": 0.0035,
      "step": 2360500
    },
    {
      "epoch": 0.13266672192105458,
      "grad_norm": 0.0827493742108345,
      "learning_rate": 8.678209144869909e-05,
      "loss": 0.0035,
      "step": 2361000
    },
    {
      "epoch": 0.13269481737254146,
      "grad_norm": 0.018044553697109222,
      "learning_rate": 8.677928032395402e-05,
      "loss": 0.0033,
      "step": 2361500
    },
    {
      "epoch": 0.13272291282402834,
      "grad_norm": 0.8187684416770935,
      "learning_rate": 8.677646919920896e-05,
      "loss": 0.0032,
      "step": 2362000
    },
    {
      "epoch": 0.13275100827551523,
      "grad_norm": 0.1893647313117981,
      "learning_rate": 8.677365807446389e-05,
      "loss": 0.0035,
      "step": 2362500
    },
    {
      "epoch": 0.1327791037270021,
      "grad_norm": 0.08881170302629471,
      "learning_rate": 8.677084694971882e-05,
      "loss": 0.0035,
      "step": 2363000
    },
    {
      "epoch": 0.132807199178489,
      "grad_norm": 0.18563778698444366,
      "learning_rate": 8.676803582497376e-05,
      "loss": 0.0031,
      "step": 2363500
    },
    {
      "epoch": 0.13283529462997587,
      "grad_norm": 0.11246151477098465,
      "learning_rate": 8.676522470022869e-05,
      "loss": 0.0036,
      "step": 2364000
    },
    {
      "epoch": 0.13286339008146275,
      "grad_norm": 0.05170727148652077,
      "learning_rate": 8.676241357548363e-05,
      "loss": 0.0033,
      "step": 2364500
    },
    {
      "epoch": 0.13289148553294963,
      "grad_norm": 0.14111663401126862,
      "learning_rate": 8.675960245073855e-05,
      "loss": 0.0036,
      "step": 2365000
    },
    {
      "epoch": 0.13291958098443651,
      "grad_norm": 0.10395776480436325,
      "learning_rate": 8.67567913259935e-05,
      "loss": 0.0031,
      "step": 2365500
    },
    {
      "epoch": 0.1329476764359234,
      "grad_norm": 0.060685642063617706,
      "learning_rate": 8.675398020124842e-05,
      "loss": 0.0032,
      "step": 2366000
    },
    {
      "epoch": 0.13297577188741028,
      "grad_norm": 0.2661735415458679,
      "learning_rate": 8.675116907650336e-05,
      "loss": 0.0029,
      "step": 2366500
    },
    {
      "epoch": 0.13300386733889716,
      "grad_norm": 0.5879401564598083,
      "learning_rate": 8.67483579517583e-05,
      "loss": 0.0031,
      "step": 2367000
    },
    {
      "epoch": 0.13303196279038404,
      "grad_norm": 0.06517988443374634,
      "learning_rate": 8.674554682701322e-05,
      "loss": 0.0031,
      "step": 2367500
    },
    {
      "epoch": 0.13306005824187092,
      "grad_norm": 0.02418726310133934,
      "learning_rate": 8.674273570226817e-05,
      "loss": 0.0032,
      "step": 2368000
    },
    {
      "epoch": 0.1330881536933578,
      "grad_norm": 0.08369223028421402,
      "learning_rate": 8.673992457752309e-05,
      "loss": 0.0032,
      "step": 2368500
    },
    {
      "epoch": 0.13311624914484468,
      "grad_norm": 0.14659008383750916,
      "learning_rate": 8.673711345277804e-05,
      "loss": 0.0035,
      "step": 2369000
    },
    {
      "epoch": 0.13314434459633157,
      "grad_norm": 0.2517109215259552,
      "learning_rate": 8.673430232803296e-05,
      "loss": 0.0033,
      "step": 2369500
    },
    {
      "epoch": 0.13317244004781845,
      "grad_norm": 0.07999755442142487,
      "learning_rate": 8.673149120328789e-05,
      "loss": 0.0028,
      "step": 2370000
    },
    {
      "epoch": 0.13317244004781845,
      "eval_loss": 0.0008886096766218543,
      "eval_runtime": 21.053,
      "eval_samples_per_second": 4749.927,
      "eval_steps_per_second": 74.241,
      "step": 2370000
    },
    {
      "epoch": 0.13320053549930533,
      "grad_norm": 0.0031957426108419895,
      "learning_rate": 8.672868007854284e-05,
      "loss": 0.0029,
      "step": 2370500
    },
    {
      "epoch": 0.1332286309507922,
      "grad_norm": 0.08311416208744049,
      "learning_rate": 8.672586895379776e-05,
      "loss": 0.0029,
      "step": 2371000
    },
    {
      "epoch": 0.1332567264022791,
      "grad_norm": 0.017397567629814148,
      "learning_rate": 8.67230578290527e-05,
      "loss": 0.0033,
      "step": 2371500
    },
    {
      "epoch": 0.13328482185376597,
      "grad_norm": 0.14379912614822388,
      "learning_rate": 8.672024670430763e-05,
      "loss": 0.0035,
      "step": 2372000
    },
    {
      "epoch": 0.13331291730525285,
      "grad_norm": 0.2793435752391815,
      "learning_rate": 8.671743557956256e-05,
      "loss": 0.0031,
      "step": 2372500
    },
    {
      "epoch": 0.13334101275673974,
      "grad_norm": 0.024337682873010635,
      "learning_rate": 8.67146244548175e-05,
      "loss": 0.0033,
      "step": 2373000
    },
    {
      "epoch": 0.13336910820822662,
      "grad_norm": 0.2102748602628708,
      "learning_rate": 8.671181333007243e-05,
      "loss": 0.0028,
      "step": 2373500
    },
    {
      "epoch": 0.1333972036597135,
      "grad_norm": 0.07472541183233261,
      "learning_rate": 8.670900220532738e-05,
      "loss": 0.0032,
      "step": 2374000
    },
    {
      "epoch": 0.13342529911120038,
      "grad_norm": 0.26765576004981995,
      "learning_rate": 8.67061910805823e-05,
      "loss": 0.0035,
      "step": 2374500
    },
    {
      "epoch": 0.13345339456268726,
      "grad_norm": 0.22451473772525787,
      "learning_rate": 8.670337995583723e-05,
      "loss": 0.0033,
      "step": 2375000
    },
    {
      "epoch": 0.13348149001417414,
      "grad_norm": 0.027187135070562363,
      "learning_rate": 8.670056883109217e-05,
      "loss": 0.0032,
      "step": 2375500
    },
    {
      "epoch": 0.13350958546566102,
      "grad_norm": 0.048889949917793274,
      "learning_rate": 8.66977577063471e-05,
      "loss": 0.0028,
      "step": 2376000
    },
    {
      "epoch": 0.1335376809171479,
      "grad_norm": 0.028212159872055054,
      "learning_rate": 8.669494658160204e-05,
      "loss": 0.0032,
      "step": 2376500
    },
    {
      "epoch": 0.1335657763686348,
      "grad_norm": 0.6054853796958923,
      "learning_rate": 8.669213545685697e-05,
      "loss": 0.0034,
      "step": 2377000
    },
    {
      "epoch": 0.13359387182012167,
      "grad_norm": 0.12566885352134705,
      "learning_rate": 8.66893243321119e-05,
      "loss": 0.0033,
      "step": 2377500
    },
    {
      "epoch": 0.13362196727160855,
      "grad_norm": 0.4412215054035187,
      "learning_rate": 8.668651320736684e-05,
      "loss": 0.0032,
      "step": 2378000
    },
    {
      "epoch": 0.13365006272309543,
      "grad_norm": 0.283652663230896,
      "learning_rate": 8.668370208262177e-05,
      "loss": 0.0032,
      "step": 2378500
    },
    {
      "epoch": 0.1336781581745823,
      "grad_norm": 0.08748628199100494,
      "learning_rate": 8.668089095787671e-05,
      "loss": 0.0028,
      "step": 2379000
    },
    {
      "epoch": 0.13370625362606922,
      "grad_norm": 0.39209797978401184,
      "learning_rate": 8.667807983313164e-05,
      "loss": 0.0031,
      "step": 2379500
    },
    {
      "epoch": 0.1337343490775561,
      "grad_norm": 0.43003126978874207,
      "learning_rate": 8.667526870838658e-05,
      "loss": 0.0034,
      "step": 2380000
    },
    {
      "epoch": 0.1337343490775561,
      "eval_loss": 0.0010247485479339957,
      "eval_runtime": 22.2292,
      "eval_samples_per_second": 4498.583,
      "eval_steps_per_second": 70.313,
      "step": 2380000
    },
    {
      "epoch": 0.13376244452904298,
      "grad_norm": 0.10830489546060562,
      "learning_rate": 8.667245758364151e-05,
      "loss": 0.0031,
      "step": 2380500
    },
    {
      "epoch": 0.13379053998052987,
      "grad_norm": 0.28350430727005005,
      "learning_rate": 8.666964645889643e-05,
      "loss": 0.0031,
      "step": 2381000
    },
    {
      "epoch": 0.13381863543201675,
      "grad_norm": 0.16874755918979645,
      "learning_rate": 8.666683533415138e-05,
      "loss": 0.0033,
      "step": 2381500
    },
    {
      "epoch": 0.13384673088350363,
      "grad_norm": 0.029282215982675552,
      "learning_rate": 8.666402420940631e-05,
      "loss": 0.003,
      "step": 2382000
    },
    {
      "epoch": 0.1338748263349905,
      "grad_norm": 0.24035395681858063,
      "learning_rate": 8.666121308466125e-05,
      "loss": 0.0031,
      "step": 2382500
    },
    {
      "epoch": 0.1339029217864774,
      "grad_norm": 0.24511367082595825,
      "learning_rate": 8.665840195991618e-05,
      "loss": 0.0029,
      "step": 2383000
    },
    {
      "epoch": 0.13393101723796427,
      "grad_norm": 0.018791867420077324,
      "learning_rate": 8.66555908351711e-05,
      "loss": 0.0031,
      "step": 2383500
    },
    {
      "epoch": 0.13395911268945115,
      "grad_norm": 0.1018337532877922,
      "learning_rate": 8.665277971042605e-05,
      "loss": 0.003,
      "step": 2384000
    },
    {
      "epoch": 0.13398720814093804,
      "grad_norm": 0.7171599864959717,
      "learning_rate": 8.664996858568097e-05,
      "loss": 0.0031,
      "step": 2384500
    },
    {
      "epoch": 0.13401530359242492,
      "grad_norm": 0.11129719018936157,
      "learning_rate": 8.664715746093592e-05,
      "loss": 0.0035,
      "step": 2385000
    },
    {
      "epoch": 0.1340433990439118,
      "grad_norm": 0.019837724044919014,
      "learning_rate": 8.664434633619084e-05,
      "loss": 0.0035,
      "step": 2385500
    },
    {
      "epoch": 0.13407149449539868,
      "grad_norm": 0.0500805601477623,
      "learning_rate": 8.664153521144577e-05,
      "loss": 0.003,
      "step": 2386000
    },
    {
      "epoch": 0.13409958994688556,
      "grad_norm": 0.031720224767923355,
      "learning_rate": 8.663872408670072e-05,
      "loss": 0.0033,
      "step": 2386500
    },
    {
      "epoch": 0.13412768539837244,
      "grad_norm": 0.2039293795824051,
      "learning_rate": 8.663591296195564e-05,
      "loss": 0.0031,
      "step": 2387000
    },
    {
      "epoch": 0.13415578084985932,
      "grad_norm": 0.41292864084243774,
      "learning_rate": 8.663310183721059e-05,
      "loss": 0.0029,
      "step": 2387500
    },
    {
      "epoch": 0.1341838763013462,
      "grad_norm": 0.014075344428420067,
      "learning_rate": 8.663029071246551e-05,
      "loss": 0.0034,
      "step": 2388000
    },
    {
      "epoch": 0.1342119717528331,
      "grad_norm": 0.02172701433300972,
      "learning_rate": 8.662747958772044e-05,
      "loss": 0.0034,
      "step": 2388500
    },
    {
      "epoch": 0.13424006720431997,
      "grad_norm": 0.18567147850990295,
      "learning_rate": 8.662466846297538e-05,
      "loss": 0.0031,
      "step": 2389000
    },
    {
      "epoch": 0.13426816265580685,
      "grad_norm": 0.4039323329925537,
      "learning_rate": 8.662185733823031e-05,
      "loss": 0.0031,
      "step": 2389500
    },
    {
      "epoch": 0.13429625810729373,
      "grad_norm": 0.00871939305216074,
      "learning_rate": 8.661904621348526e-05,
      "loss": 0.0032,
      "step": 2390000
    },
    {
      "epoch": 0.13429625810729373,
      "eval_loss": 0.0008729873807169497,
      "eval_runtime": 21.8986,
      "eval_samples_per_second": 4566.511,
      "eval_steps_per_second": 71.375,
      "step": 2390000
    },
    {
      "epoch": 0.1343243535587806,
      "grad_norm": 0.27237918972969055,
      "learning_rate": 8.661623508874018e-05,
      "loss": 0.0035,
      "step": 2390500
    },
    {
      "epoch": 0.1343524490102675,
      "grad_norm": 0.048708539456129074,
      "learning_rate": 8.661342396399512e-05,
      "loss": 0.0031,
      "step": 2391000
    },
    {
      "epoch": 0.13438054446175438,
      "grad_norm": 0.1995737999677658,
      "learning_rate": 8.661061283925005e-05,
      "loss": 0.0033,
      "step": 2391500
    },
    {
      "epoch": 0.13440863991324126,
      "grad_norm": 0.051344119012355804,
      "learning_rate": 8.660780171450498e-05,
      "loss": 0.0037,
      "step": 2392000
    },
    {
      "epoch": 0.13443673536472814,
      "grad_norm": 0.38933974504470825,
      "learning_rate": 8.660499058975992e-05,
      "loss": 0.0032,
      "step": 2392500
    },
    {
      "epoch": 0.13446483081621502,
      "grad_norm": 0.02812064066529274,
      "learning_rate": 8.660217946501485e-05,
      "loss": 0.0033,
      "step": 2393000
    },
    {
      "epoch": 0.1344929262677019,
      "grad_norm": 0.10515672713518143,
      "learning_rate": 8.659936834026979e-05,
      "loss": 0.003,
      "step": 2393500
    },
    {
      "epoch": 0.13452102171918878,
      "grad_norm": 0.10079319030046463,
      "learning_rate": 8.659655721552472e-05,
      "loss": 0.0029,
      "step": 2394000
    },
    {
      "epoch": 0.13454911717067566,
      "grad_norm": 0.16677150130271912,
      "learning_rate": 8.659374609077965e-05,
      "loss": 0.0032,
      "step": 2394500
    },
    {
      "epoch": 0.13457721262216255,
      "grad_norm": 0.044090382754802704,
      "learning_rate": 8.659093496603459e-05,
      "loss": 0.0035,
      "step": 2395000
    },
    {
      "epoch": 0.13460530807364943,
      "grad_norm": 0.2439500242471695,
      "learning_rate": 8.658812384128952e-05,
      "loss": 0.0036,
      "step": 2395500
    },
    {
      "epoch": 0.1346334035251363,
      "grad_norm": 0.23297882080078125,
      "learning_rate": 8.658531271654446e-05,
      "loss": 0.003,
      "step": 2396000
    },
    {
      "epoch": 0.1346614989766232,
      "grad_norm": 0.04846111312508583,
      "learning_rate": 8.658250159179939e-05,
      "loss": 0.0035,
      "step": 2396500
    },
    {
      "epoch": 0.13468959442811007,
      "grad_norm": 0.18401440978050232,
      "learning_rate": 8.657969046705433e-05,
      "loss": 0.0034,
      "step": 2397000
    },
    {
      "epoch": 0.13471768987959695,
      "grad_norm": 0.004340721759945154,
      "learning_rate": 8.657687934230926e-05,
      "loss": 0.0031,
      "step": 2397500
    },
    {
      "epoch": 0.13474578533108383,
      "grad_norm": 0.014955898746848106,
      "learning_rate": 8.65740682175642e-05,
      "loss": 0.0034,
      "step": 2398000
    },
    {
      "epoch": 0.13477388078257072,
      "grad_norm": 0.003914449829608202,
      "learning_rate": 8.657125709281913e-05,
      "loss": 0.0032,
      "step": 2398500
    },
    {
      "epoch": 0.1348019762340576,
      "grad_norm": 0.014763002283871174,
      "learning_rate": 8.656844596807406e-05,
      "loss": 0.0034,
      "step": 2399000
    },
    {
      "epoch": 0.13483007168554448,
      "grad_norm": 0.04991929605603218,
      "learning_rate": 8.6565634843329e-05,
      "loss": 0.0032,
      "step": 2399500
    },
    {
      "epoch": 0.13485816713703136,
      "grad_norm": 0.045372143387794495,
      "learning_rate": 8.656282371858393e-05,
      "loss": 0.0032,
      "step": 2400000
    },
    {
      "epoch": 0.13485816713703136,
      "eval_loss": 0.000885033281520009,
      "eval_runtime": 22.4363,
      "eval_samples_per_second": 4457.066,
      "eval_steps_per_second": 69.664,
      "step": 2400000
    },
    {
      "epoch": 0.13488626258851824,
      "grad_norm": 0.1419217586517334,
      "learning_rate": 8.656001259383885e-05,
      "loss": 0.0032,
      "step": 2400500
    },
    {
      "epoch": 0.13491435804000512,
      "grad_norm": 0.10107864439487457,
      "learning_rate": 8.65572014690938e-05,
      "loss": 0.0029,
      "step": 2401000
    },
    {
      "epoch": 0.134942453491492,
      "grad_norm": 0.0130121149122715,
      "learning_rate": 8.655439034434873e-05,
      "loss": 0.0037,
      "step": 2401500
    },
    {
      "epoch": 0.13497054894297889,
      "grad_norm": 0.19722798466682434,
      "learning_rate": 8.655157921960367e-05,
      "loss": 0.0032,
      "step": 2402000
    },
    {
      "epoch": 0.13499864439446577,
      "grad_norm": 0.04285535216331482,
      "learning_rate": 8.65487680948586e-05,
      "loss": 0.0028,
      "step": 2402500
    },
    {
      "epoch": 0.13502673984595265,
      "grad_norm": 0.13264815509319305,
      "learning_rate": 8.654595697011352e-05,
      "loss": 0.0031,
      "step": 2403000
    },
    {
      "epoch": 0.13505483529743953,
      "grad_norm": 0.008971774950623512,
      "learning_rate": 8.654314584536847e-05,
      "loss": 0.0028,
      "step": 2403500
    },
    {
      "epoch": 0.1350829307489264,
      "grad_norm": 0.08788402378559113,
      "learning_rate": 8.654033472062339e-05,
      "loss": 0.0031,
      "step": 2404000
    },
    {
      "epoch": 0.1351110262004133,
      "grad_norm": 0.20038414001464844,
      "learning_rate": 8.653752359587834e-05,
      "loss": 0.0032,
      "step": 2404500
    },
    {
      "epoch": 0.13513912165190017,
      "grad_norm": 0.0737476572394371,
      "learning_rate": 8.653471247113327e-05,
      "loss": 0.0031,
      "step": 2405000
    },
    {
      "epoch": 0.13516721710338706,
      "grad_norm": 0.0750235989689827,
      "learning_rate": 8.65319013463882e-05,
      "loss": 0.003,
      "step": 2405500
    },
    {
      "epoch": 0.13519531255487394,
      "grad_norm": 0.2972174286842346,
      "learning_rate": 8.652909022164314e-05,
      "loss": 0.0028,
      "step": 2406000
    },
    {
      "epoch": 0.13522340800636082,
      "grad_norm": 0.06028284505009651,
      "learning_rate": 8.652627909689806e-05,
      "loss": 0.0031,
      "step": 2406500
    },
    {
      "epoch": 0.1352515034578477,
      "grad_norm": 0.06563638150691986,
      "learning_rate": 8.652346797215301e-05,
      "loss": 0.0031,
      "step": 2407000
    },
    {
      "epoch": 0.13527959890933458,
      "grad_norm": 0.1934349536895752,
      "learning_rate": 8.652065684740793e-05,
      "loss": 0.0032,
      "step": 2407500
    },
    {
      "epoch": 0.13530769436082146,
      "grad_norm": 0.05000908672809601,
      "learning_rate": 8.651784572266287e-05,
      "loss": 0.0036,
      "step": 2408000
    },
    {
      "epoch": 0.13533578981230834,
      "grad_norm": 0.18842341005802155,
      "learning_rate": 8.65150345979178e-05,
      "loss": 0.0029,
      "step": 2408500
    },
    {
      "epoch": 0.13536388526379523,
      "grad_norm": 0.02797185443341732,
      "learning_rate": 8.651222347317273e-05,
      "loss": 0.003,
      "step": 2409000
    },
    {
      "epoch": 0.1353919807152821,
      "grad_norm": 0.08752512186765671,
      "learning_rate": 8.650941234842768e-05,
      "loss": 0.0034,
      "step": 2409500
    },
    {
      "epoch": 0.135420076166769,
      "grad_norm": 0.009308494627475739,
      "learning_rate": 8.65066012236826e-05,
      "loss": 0.0032,
      "step": 2410000
    },
    {
      "epoch": 0.135420076166769,
      "eval_loss": 0.0009794705547392368,
      "eval_runtime": 22.1865,
      "eval_samples_per_second": 4507.249,
      "eval_steps_per_second": 70.448,
      "step": 2410000
    },
    {
      "epoch": 0.13544817161825587,
      "grad_norm": 0.4052557647228241,
      "learning_rate": 8.650379009893754e-05,
      "loss": 0.0032,
      "step": 2410500
    },
    {
      "epoch": 0.13547626706974275,
      "grad_norm": 0.13159440457820892,
      "learning_rate": 8.650097897419247e-05,
      "loss": 0.0031,
      "step": 2411000
    },
    {
      "epoch": 0.13550436252122963,
      "grad_norm": 0.09445720165967941,
      "learning_rate": 8.64981678494474e-05,
      "loss": 0.0032,
      "step": 2411500
    },
    {
      "epoch": 0.1355324579727165,
      "grad_norm": 0.03408282622694969,
      "learning_rate": 8.649535672470234e-05,
      "loss": 0.0033,
      "step": 2412000
    },
    {
      "epoch": 0.1355605534242034,
      "grad_norm": 0.08574739843606949,
      "learning_rate": 8.649254559995727e-05,
      "loss": 0.0036,
      "step": 2412500
    },
    {
      "epoch": 0.13558864887569028,
      "grad_norm": 0.06834728270769119,
      "learning_rate": 8.648973447521221e-05,
      "loss": 0.0032,
      "step": 2413000
    },
    {
      "epoch": 0.13561674432717716,
      "grad_norm": 0.013790789060294628,
      "learning_rate": 8.648692335046714e-05,
      "loss": 0.0031,
      "step": 2413500
    },
    {
      "epoch": 0.13564483977866404,
      "grad_norm": 0.10175278037786484,
      "learning_rate": 8.648411222572208e-05,
      "loss": 0.003,
      "step": 2414000
    },
    {
      "epoch": 0.13567293523015092,
      "grad_norm": 0.04025917500257492,
      "learning_rate": 8.648130110097701e-05,
      "loss": 0.003,
      "step": 2414500
    },
    {
      "epoch": 0.1357010306816378,
      "grad_norm": 0.18242916464805603,
      "learning_rate": 8.647848997623195e-05,
      "loss": 0.0031,
      "step": 2415000
    },
    {
      "epoch": 0.13572912613312468,
      "grad_norm": 0.08520840853452682,
      "learning_rate": 8.647567885148688e-05,
      "loss": 0.003,
      "step": 2415500
    },
    {
      "epoch": 0.13575722158461156,
      "grad_norm": 0.14878065884113312,
      "learning_rate": 8.647286772674181e-05,
      "loss": 0.003,
      "step": 2416000
    },
    {
      "epoch": 0.13578531703609845,
      "grad_norm": 0.20641164481639862,
      "learning_rate": 8.647005660199673e-05,
      "loss": 0.0031,
      "step": 2416500
    },
    {
      "epoch": 0.13581341248758533,
      "grad_norm": 0.09053301811218262,
      "learning_rate": 8.646724547725168e-05,
      "loss": 0.003,
      "step": 2417000
    },
    {
      "epoch": 0.1358415079390722,
      "grad_norm": 0.15174949169158936,
      "learning_rate": 8.646443435250662e-05,
      "loss": 0.0032,
      "step": 2417500
    },
    {
      "epoch": 0.1358696033905591,
      "grad_norm": 0.34409579634666443,
      "learning_rate": 8.646162322776155e-05,
      "loss": 0.0033,
      "step": 2418000
    },
    {
      "epoch": 0.13589769884204597,
      "grad_norm": 0.18182417750358582,
      "learning_rate": 8.645881210301649e-05,
      "loss": 0.0034,
      "step": 2418500
    },
    {
      "epoch": 0.13592579429353285,
      "grad_norm": 0.21033069491386414,
      "learning_rate": 8.64560009782714e-05,
      "loss": 0.003,
      "step": 2419000
    },
    {
      "epoch": 0.13595388974501973,
      "grad_norm": 0.11570735275745392,
      "learning_rate": 8.645318985352635e-05,
      "loss": 0.0033,
      "step": 2419500
    },
    {
      "epoch": 0.13598198519650662,
      "grad_norm": 0.13430899381637573,
      "learning_rate": 8.645037872878127e-05,
      "loss": 0.0032,
      "step": 2420000
    },
    {
      "epoch": 0.13598198519650662,
      "eval_loss": 0.0008444083505310118,
      "eval_runtime": 21.1874,
      "eval_samples_per_second": 4719.779,
      "eval_steps_per_second": 73.77,
      "step": 2420000
    },
    {
      "epoch": 0.1360100806479935,
      "grad_norm": 0.10285529494285583,
      "learning_rate": 8.644756760403622e-05,
      "loss": 0.0032,
      "step": 2420500
    },
    {
      "epoch": 0.13603817609948038,
      "grad_norm": 0.06280775368213654,
      "learning_rate": 8.644475647929116e-05,
      "loss": 0.0033,
      "step": 2421000
    },
    {
      "epoch": 0.13606627155096726,
      "grad_norm": 0.10909795761108398,
      "learning_rate": 8.644194535454608e-05,
      "loss": 0.0028,
      "step": 2421500
    },
    {
      "epoch": 0.13609436700245414,
      "grad_norm": 0.06866857409477234,
      "learning_rate": 8.643913422980102e-05,
      "loss": 0.0028,
      "step": 2422000
    },
    {
      "epoch": 0.13612246245394102,
      "grad_norm": 0.2184986174106598,
      "learning_rate": 8.643632310505595e-05,
      "loss": 0.003,
      "step": 2422500
    },
    {
      "epoch": 0.1361505579054279,
      "grad_norm": 0.22805693745613098,
      "learning_rate": 8.643351198031089e-05,
      "loss": 0.0036,
      "step": 2423000
    },
    {
      "epoch": 0.13617865335691479,
      "grad_norm": 0.2305198609828949,
      "learning_rate": 8.643070085556581e-05,
      "loss": 0.0034,
      "step": 2423500
    },
    {
      "epoch": 0.13620674880840167,
      "grad_norm": 0.3349462151527405,
      "learning_rate": 8.642788973082075e-05,
      "loss": 0.0029,
      "step": 2424000
    },
    {
      "epoch": 0.13623484425988855,
      "grad_norm": 0.019817015156149864,
      "learning_rate": 8.64250786060757e-05,
      "loss": 0.0027,
      "step": 2424500
    },
    {
      "epoch": 0.13626293971137543,
      "grad_norm": 0.11840354651212692,
      "learning_rate": 8.642226748133062e-05,
      "loss": 0.0034,
      "step": 2425000
    },
    {
      "epoch": 0.1362910351628623,
      "grad_norm": 0.16881074011325836,
      "learning_rate": 8.641945635658556e-05,
      "loss": 0.0036,
      "step": 2425500
    },
    {
      "epoch": 0.1363191306143492,
      "grad_norm": 0.13443902134895325,
      "learning_rate": 8.641664523184049e-05,
      "loss": 0.003,
      "step": 2426000
    },
    {
      "epoch": 0.13634722606583607,
      "grad_norm": 0.19266019761562347,
      "learning_rate": 8.641383410709542e-05,
      "loss": 0.0034,
      "step": 2426500
    },
    {
      "epoch": 0.13637532151732296,
      "grad_norm": 0.13026241958141327,
      "learning_rate": 8.641102298235035e-05,
      "loss": 0.0033,
      "step": 2427000
    },
    {
      "epoch": 0.13640341696880984,
      "grad_norm": 0.03615282103419304,
      "learning_rate": 8.640821185760529e-05,
      "loss": 0.0031,
      "step": 2427500
    },
    {
      "epoch": 0.13643151242029672,
      "grad_norm": 0.32313820719718933,
      "learning_rate": 8.640540073286022e-05,
      "loss": 0.0035,
      "step": 2428000
    },
    {
      "epoch": 0.1364596078717836,
      "grad_norm": 0.11947086453437805,
      "learning_rate": 8.640258960811516e-05,
      "loss": 0.0033,
      "step": 2428500
    },
    {
      "epoch": 0.13648770332327048,
      "grad_norm": 0.2245829999446869,
      "learning_rate": 8.63997784833701e-05,
      "loss": 0.0035,
      "step": 2429000
    },
    {
      "epoch": 0.13651579877475736,
      "grad_norm": 0.23345573246479034,
      "learning_rate": 8.639696735862502e-05,
      "loss": 0.0036,
      "step": 2429500
    },
    {
      "epoch": 0.13654389422624424,
      "grad_norm": 0.4933567941188812,
      "learning_rate": 8.639415623387996e-05,
      "loss": 0.0033,
      "step": 2430000
    },
    {
      "epoch": 0.13654389422624424,
      "eval_loss": 0.0008495800429955125,
      "eval_runtime": 21.1624,
      "eval_samples_per_second": 4725.367,
      "eval_steps_per_second": 73.857,
      "step": 2430000
    },
    {
      "epoch": 0.13657198967773113,
      "grad_norm": 0.16076526045799255,
      "learning_rate": 8.63913451091349e-05,
      "loss": 0.003,
      "step": 2430500
    },
    {
      "epoch": 0.136600085129218,
      "grad_norm": 0.2799464762210846,
      "learning_rate": 8.638853398438983e-05,
      "loss": 0.0031,
      "step": 2431000
    },
    {
      "epoch": 0.1366281805807049,
      "grad_norm": 0.05205449089407921,
      "learning_rate": 8.638572285964476e-05,
      "loss": 0.0033,
      "step": 2431500
    },
    {
      "epoch": 0.13665627603219177,
      "grad_norm": 0.059429146349430084,
      "learning_rate": 8.63829117348997e-05,
      "loss": 0.0026,
      "step": 2432000
    },
    {
      "epoch": 0.13668437148367865,
      "grad_norm": 0.14912213385105133,
      "learning_rate": 8.638010061015463e-05,
      "loss": 0.0032,
      "step": 2432500
    },
    {
      "epoch": 0.13671246693516553,
      "grad_norm": 0.2628222703933716,
      "learning_rate": 8.637728948540956e-05,
      "loss": 0.0034,
      "step": 2433000
    },
    {
      "epoch": 0.13674056238665241,
      "grad_norm": 0.39464670419692993,
      "learning_rate": 8.63744783606645e-05,
      "loss": 0.0035,
      "step": 2433500
    },
    {
      "epoch": 0.1367686578381393,
      "grad_norm": 0.020822802558541298,
      "learning_rate": 8.637166723591943e-05,
      "loss": 0.0036,
      "step": 2434000
    },
    {
      "epoch": 0.13679675328962618,
      "grad_norm": 0.15633589029312134,
      "learning_rate": 8.636885611117437e-05,
      "loss": 0.0032,
      "step": 2434500
    },
    {
      "epoch": 0.13682484874111306,
      "grad_norm": 0.04454781860113144,
      "learning_rate": 8.63660449864293e-05,
      "loss": 0.003,
      "step": 2435000
    },
    {
      "epoch": 0.13685294419259994,
      "grad_norm": 0.10034733265638351,
      "learning_rate": 8.636323386168424e-05,
      "loss": 0.0029,
      "step": 2435500
    },
    {
      "epoch": 0.13688103964408682,
      "grad_norm": 0.38889721035957336,
      "learning_rate": 8.636042273693916e-05,
      "loss": 0.0033,
      "step": 2436000
    },
    {
      "epoch": 0.1369091350955737,
      "grad_norm": 0.210001602768898,
      "learning_rate": 8.63576116121941e-05,
      "loss": 0.0029,
      "step": 2436500
    },
    {
      "epoch": 0.13693723054706058,
      "grad_norm": 0.05517188459634781,
      "learning_rate": 8.635480048744904e-05,
      "loss": 0.0032,
      "step": 2437000
    },
    {
      "epoch": 0.13696532599854747,
      "grad_norm": 0.3853147327899933,
      "learning_rate": 8.635198936270397e-05,
      "loss": 0.0027,
      "step": 2437500
    },
    {
      "epoch": 0.13699342145003435,
      "grad_norm": 0.026504039764404297,
      "learning_rate": 8.634917823795891e-05,
      "loss": 0.0032,
      "step": 2438000
    },
    {
      "epoch": 0.13702151690152123,
      "grad_norm": 0.011620399542152882,
      "learning_rate": 8.634636711321383e-05,
      "loss": 0.0034,
      "step": 2438500
    },
    {
      "epoch": 0.1370496123530081,
      "grad_norm": 0.030216488987207413,
      "learning_rate": 8.634355598846878e-05,
      "loss": 0.0037,
      "step": 2439000
    },
    {
      "epoch": 0.137077707804495,
      "grad_norm": 0.3102664351463318,
      "learning_rate": 8.63407448637237e-05,
      "loss": 0.0032,
      "step": 2439500
    },
    {
      "epoch": 0.13710580325598187,
      "grad_norm": 0.15539871156215668,
      "learning_rate": 8.633793373897864e-05,
      "loss": 0.0033,
      "step": 2440000
    },
    {
      "epoch": 0.13710580325598187,
      "eval_loss": 0.0009170537232421339,
      "eval_runtime": 21.1942,
      "eval_samples_per_second": 4718.275,
      "eval_steps_per_second": 73.747,
      "step": 2440000
    },
    {
      "epoch": 0.13713389870746875,
      "grad_norm": 0.3916097581386566,
      "learning_rate": 8.633512261423358e-05,
      "loss": 0.0033,
      "step": 2440500
    },
    {
      "epoch": 0.13716199415895564,
      "grad_norm": 0.10009920597076416,
      "learning_rate": 8.63323114894885e-05,
      "loss": 0.003,
      "step": 2441000
    },
    {
      "epoch": 0.13719008961044252,
      "grad_norm": 0.024396106600761414,
      "learning_rate": 8.632950036474345e-05,
      "loss": 0.0034,
      "step": 2441500
    },
    {
      "epoch": 0.1372181850619294,
      "grad_norm": 0.3430376350879669,
      "learning_rate": 8.632668923999837e-05,
      "loss": 0.0032,
      "step": 2442000
    },
    {
      "epoch": 0.13724628051341628,
      "grad_norm": 0.007883713580667973,
      "learning_rate": 8.632387811525332e-05,
      "loss": 0.0032,
      "step": 2442500
    },
    {
      "epoch": 0.13727437596490316,
      "grad_norm": 0.33874601125717163,
      "learning_rate": 8.632106699050824e-05,
      "loss": 0.0028,
      "step": 2443000
    },
    {
      "epoch": 0.13730247141639004,
      "grad_norm": 0.047703586518764496,
      "learning_rate": 8.631825586576317e-05,
      "loss": 0.003,
      "step": 2443500
    },
    {
      "epoch": 0.13733056686787692,
      "grad_norm": 0.17721034586429596,
      "learning_rate": 8.631544474101812e-05,
      "loss": 0.0027,
      "step": 2444000
    },
    {
      "epoch": 0.1373586623193638,
      "grad_norm": 0.28705090284347534,
      "learning_rate": 8.631263361627304e-05,
      "loss": 0.0034,
      "step": 2444500
    },
    {
      "epoch": 0.1373867577708507,
      "grad_norm": 0.27625879645347595,
      "learning_rate": 8.630982249152799e-05,
      "loss": 0.0033,
      "step": 2445000
    },
    {
      "epoch": 0.13741485322233757,
      "grad_norm": 0.23979006707668304,
      "learning_rate": 8.630701136678291e-05,
      "loss": 0.0032,
      "step": 2445500
    },
    {
      "epoch": 0.13744294867382445,
      "grad_norm": 0.1542624831199646,
      "learning_rate": 8.630420024203784e-05,
      "loss": 0.0035,
      "step": 2446000
    },
    {
      "epoch": 0.13747104412531133,
      "grad_norm": 0.10780354589223862,
      "learning_rate": 8.630138911729278e-05,
      "loss": 0.0031,
      "step": 2446500
    },
    {
      "epoch": 0.1374991395767982,
      "grad_norm": 0.13248340785503387,
      "learning_rate": 8.629857799254771e-05,
      "loss": 0.0031,
      "step": 2447000
    },
    {
      "epoch": 0.1375272350282851,
      "grad_norm": 0.09567040950059891,
      "learning_rate": 8.629576686780264e-05,
      "loss": 0.0026,
      "step": 2447500
    },
    {
      "epoch": 0.13755533047977198,
      "grad_norm": 0.2829807698726654,
      "learning_rate": 8.629295574305758e-05,
      "loss": 0.0029,
      "step": 2448000
    },
    {
      "epoch": 0.13758342593125886,
      "grad_norm": 0.12037664651870728,
      "learning_rate": 8.629014461831251e-05,
      "loss": 0.0034,
      "step": 2448500
    },
    {
      "epoch": 0.13761152138274574,
      "grad_norm": 0.08170917630195618,
      "learning_rate": 8.628733349356745e-05,
      "loss": 0.003,
      "step": 2449000
    },
    {
      "epoch": 0.13763961683423262,
      "grad_norm": 0.029336566105484962,
      "learning_rate": 8.628452236882238e-05,
      "loss": 0.0029,
      "step": 2449500
    },
    {
      "epoch": 0.1376677122857195,
      "grad_norm": 0.011905718594789505,
      "learning_rate": 8.628171124407732e-05,
      "loss": 0.0032,
      "step": 2450000
    },
    {
      "epoch": 0.1376677122857195,
      "eval_loss": 0.0009006258915178478,
      "eval_runtime": 21.0347,
      "eval_samples_per_second": 4754.057,
      "eval_steps_per_second": 74.306,
      "step": 2450000
    },
    {
      "epoch": 0.13769580773720638,
      "grad_norm": 0.056340981274843216,
      "learning_rate": 8.627890011933225e-05,
      "loss": 0.0032,
      "step": 2450500
    },
    {
      "epoch": 0.13772390318869326,
      "grad_norm": 0.006955718621611595,
      "learning_rate": 8.627608899458718e-05,
      "loss": 0.0032,
      "step": 2451000
    },
    {
      "epoch": 0.13775199864018015,
      "grad_norm": 0.29519355297088623,
      "learning_rate": 8.627327786984212e-05,
      "loss": 0.0033,
      "step": 2451500
    },
    {
      "epoch": 0.13778009409166703,
      "grad_norm": 0.44728031754493713,
      "learning_rate": 8.627046674509705e-05,
      "loss": 0.0031,
      "step": 2452000
    },
    {
      "epoch": 0.1378081895431539,
      "grad_norm": 0.052978385239839554,
      "learning_rate": 8.626765562035199e-05,
      "loss": 0.0032,
      "step": 2452500
    },
    {
      "epoch": 0.1378362849946408,
      "grad_norm": 0.20823544263839722,
      "learning_rate": 8.626484449560692e-05,
      "loss": 0.0031,
      "step": 2453000
    },
    {
      "epoch": 0.13786438044612767,
      "grad_norm": 0.19451899826526642,
      "learning_rate": 8.626203337086186e-05,
      "loss": 0.0033,
      "step": 2453500
    },
    {
      "epoch": 0.13789247589761455,
      "grad_norm": 0.5107397437095642,
      "learning_rate": 8.625922224611679e-05,
      "loss": 0.0032,
      "step": 2454000
    },
    {
      "epoch": 0.13792057134910143,
      "grad_norm": 0.24166445434093475,
      "learning_rate": 8.625641112137171e-05,
      "loss": 0.0028,
      "step": 2454500
    },
    {
      "epoch": 0.13794866680058832,
      "grad_norm": 0.03156990930438042,
      "learning_rate": 8.625359999662666e-05,
      "loss": 0.0032,
      "step": 2455000
    },
    {
      "epoch": 0.1379767622520752,
      "grad_norm": 0.14860546588897705,
      "learning_rate": 8.625078887188159e-05,
      "loss": 0.0035,
      "step": 2455500
    },
    {
      "epoch": 0.13800485770356208,
      "grad_norm": 0.31846898794174194,
      "learning_rate": 8.624797774713653e-05,
      "loss": 0.0034,
      "step": 2456000
    },
    {
      "epoch": 0.13803295315504896,
      "grad_norm": 0.28991344571113586,
      "learning_rate": 8.624516662239146e-05,
      "loss": 0.0031,
      "step": 2456500
    },
    {
      "epoch": 0.13806104860653584,
      "grad_norm": 0.452849417924881,
      "learning_rate": 8.624235549764638e-05,
      "loss": 0.0032,
      "step": 2457000
    },
    {
      "epoch": 0.13808914405802272,
      "grad_norm": 0.6213051676750183,
      "learning_rate": 8.623954437290133e-05,
      "loss": 0.0036,
      "step": 2457500
    },
    {
      "epoch": 0.1381172395095096,
      "grad_norm": 0.04221858084201813,
      "learning_rate": 8.623673324815625e-05,
      "loss": 0.0031,
      "step": 2458000
    },
    {
      "epoch": 0.13814533496099649,
      "grad_norm": 0.16664955019950867,
      "learning_rate": 8.62339221234112e-05,
      "loss": 0.0032,
      "step": 2458500
    },
    {
      "epoch": 0.13817343041248337,
      "grad_norm": 0.01840175688266754,
      "learning_rate": 8.623111099866612e-05,
      "loss": 0.003,
      "step": 2459000
    },
    {
      "epoch": 0.13820152586397025,
      "grad_norm": 0.04597383365035057,
      "learning_rate": 8.622829987392105e-05,
      "loss": 0.0031,
      "step": 2459500
    },
    {
      "epoch": 0.13822962131545713,
      "grad_norm": 0.4854367673397064,
      "learning_rate": 8.6225488749176e-05,
      "loss": 0.0033,
      "step": 2460000
    },
    {
      "epoch": 0.13822962131545713,
      "eval_loss": 0.0009084802004508674,
      "eval_runtime": 21.8526,
      "eval_samples_per_second": 4576.105,
      "eval_steps_per_second": 71.525,
      "step": 2460000
    },
    {
      "epoch": 0.138257716766944,
      "grad_norm": 0.16269372403621674,
      "learning_rate": 8.622267762443092e-05,
      "loss": 0.0034,
      "step": 2460500
    },
    {
      "epoch": 0.1382858122184309,
      "grad_norm": 0.04507942125201225,
      "learning_rate": 8.621986649968587e-05,
      "loss": 0.0036,
      "step": 2461000
    },
    {
      "epoch": 0.13831390766991777,
      "grad_norm": 0.20501209795475006,
      "learning_rate": 8.621705537494079e-05,
      "loss": 0.0031,
      "step": 2461500
    },
    {
      "epoch": 0.13834200312140466,
      "grad_norm": 0.06878155469894409,
      "learning_rate": 8.621424425019572e-05,
      "loss": 0.0032,
      "step": 2462000
    },
    {
      "epoch": 0.13837009857289154,
      "grad_norm": 0.13801723718643188,
      "learning_rate": 8.621143312545066e-05,
      "loss": 0.0029,
      "step": 2462500
    },
    {
      "epoch": 0.13839819402437842,
      "grad_norm": 0.05971916764974594,
      "learning_rate": 8.620862200070559e-05,
      "loss": 0.0031,
      "step": 2463000
    },
    {
      "epoch": 0.1384262894758653,
      "grad_norm": 0.3672217130661011,
      "learning_rate": 8.620581087596054e-05,
      "loss": 0.0031,
      "step": 2463500
    },
    {
      "epoch": 0.13845438492735218,
      "grad_norm": 0.18584512174129486,
      "learning_rate": 8.620299975121546e-05,
      "loss": 0.0032,
      "step": 2464000
    },
    {
      "epoch": 0.13848248037883906,
      "grad_norm": 0.8997350335121155,
      "learning_rate": 8.620018862647041e-05,
      "loss": 0.0031,
      "step": 2464500
    },
    {
      "epoch": 0.13851057583032594,
      "grad_norm": 0.03388001769781113,
      "learning_rate": 8.619737750172533e-05,
      "loss": 0.0033,
      "step": 2465000
    },
    {
      "epoch": 0.13853867128181283,
      "grad_norm": 0.0332951545715332,
      "learning_rate": 8.619456637698026e-05,
      "loss": 0.0029,
      "step": 2465500
    },
    {
      "epoch": 0.1385667667332997,
      "grad_norm": 0.010113608092069626,
      "learning_rate": 8.61917552522352e-05,
      "loss": 0.0033,
      "step": 2466000
    },
    {
      "epoch": 0.1385948621847866,
      "grad_norm": 0.04622742161154747,
      "learning_rate": 8.618894412749013e-05,
      "loss": 0.0028,
      "step": 2466500
    },
    {
      "epoch": 0.13862295763627347,
      "grad_norm": 0.5046655535697937,
      "learning_rate": 8.618613300274507e-05,
      "loss": 0.0028,
      "step": 2467000
    },
    {
      "epoch": 0.13865105308776035,
      "grad_norm": 0.019616402685642242,
      "learning_rate": 8.6183321878e-05,
      "loss": 0.0032,
      "step": 2467500
    },
    {
      "epoch": 0.13867914853924723,
      "grad_norm": 0.034295063465833664,
      "learning_rate": 8.618051075325493e-05,
      "loss": 0.0034,
      "step": 2468000
    },
    {
      "epoch": 0.1387072439907341,
      "grad_norm": 0.24334459006786346,
      "learning_rate": 8.617769962850987e-05,
      "loss": 0.0033,
      "step": 2468500
    },
    {
      "epoch": 0.138735339442221,
      "grad_norm": 0.2409389764070511,
      "learning_rate": 8.61748885037648e-05,
      "loss": 0.0034,
      "step": 2469000
    },
    {
      "epoch": 0.13876343489370788,
      "grad_norm": 0.058246809989213943,
      "learning_rate": 8.617207737901974e-05,
      "loss": 0.0031,
      "step": 2469500
    },
    {
      "epoch": 0.13879153034519476,
      "grad_norm": 0.19529002904891968,
      "learning_rate": 8.616926625427467e-05,
      "loss": 0.0029,
      "step": 2470000
    },
    {
      "epoch": 0.13879153034519476,
      "eval_loss": 0.0009863260202109814,
      "eval_runtime": 21.4807,
      "eval_samples_per_second": 4655.339,
      "eval_steps_per_second": 72.763,
      "step": 2470000
    },
    {
      "epoch": 0.13881962579668164,
      "grad_norm": 0.0922175720334053,
      "learning_rate": 8.61664551295296e-05,
      "loss": 0.0031,
      "step": 2470500
    },
    {
      "epoch": 0.13884772124816852,
      "grad_norm": 0.022740783169865608,
      "learning_rate": 8.616364400478454e-05,
      "loss": 0.0029,
      "step": 2471000
    },
    {
      "epoch": 0.1388758166996554,
      "grad_norm": 0.030328912660479546,
      "learning_rate": 8.616083288003947e-05,
      "loss": 0.0029,
      "step": 2471500
    },
    {
      "epoch": 0.13890391215114228,
      "grad_norm": 0.12525366246700287,
      "learning_rate": 8.615802175529441e-05,
      "loss": 0.0034,
      "step": 2472000
    },
    {
      "epoch": 0.13893200760262917,
      "grad_norm": 0.1970830112695694,
      "learning_rate": 8.615521063054934e-05,
      "loss": 0.0031,
      "step": 2472500
    },
    {
      "epoch": 0.13896010305411605,
      "grad_norm": 0.524986982345581,
      "learning_rate": 8.615239950580428e-05,
      "loss": 0.0035,
      "step": 2473000
    },
    {
      "epoch": 0.13898819850560293,
      "grad_norm": 0.10534903407096863,
      "learning_rate": 8.614958838105921e-05,
      "loss": 0.0032,
      "step": 2473500
    },
    {
      "epoch": 0.1390162939570898,
      "grad_norm": 0.25166916847229004,
      "learning_rate": 8.614677725631413e-05,
      "loss": 0.003,
      "step": 2474000
    },
    {
      "epoch": 0.1390443894085767,
      "grad_norm": 0.1458248496055603,
      "learning_rate": 8.614396613156908e-05,
      "loss": 0.0034,
      "step": 2474500
    },
    {
      "epoch": 0.13907248486006357,
      "grad_norm": 0.23561818897724152,
      "learning_rate": 8.614115500682401e-05,
      "loss": 0.0028,
      "step": 2475000
    },
    {
      "epoch": 0.13910058031155045,
      "grad_norm": 0.07587124407291412,
      "learning_rate": 8.613834388207895e-05,
      "loss": 0.0035,
      "step": 2475500
    },
    {
      "epoch": 0.13912867576303733,
      "grad_norm": 0.08799761533737183,
      "learning_rate": 8.613553275733388e-05,
      "loss": 0.0034,
      "step": 2476000
    },
    {
      "epoch": 0.13915677121452422,
      "grad_norm": 0.09866459667682648,
      "learning_rate": 8.61327216325888e-05,
      "loss": 0.0034,
      "step": 2476500
    },
    {
      "epoch": 0.1391848666660111,
      "grad_norm": 0.14940805733203888,
      "learning_rate": 8.612991050784375e-05,
      "loss": 0.003,
      "step": 2477000
    },
    {
      "epoch": 0.13921296211749798,
      "grad_norm": 0.45184004306793213,
      "learning_rate": 8.612709938309867e-05,
      "loss": 0.003,
      "step": 2477500
    },
    {
      "epoch": 0.13924105756898486,
      "grad_norm": 0.28806883096694946,
      "learning_rate": 8.612428825835362e-05,
      "loss": 0.003,
      "step": 2478000
    },
    {
      "epoch": 0.13926915302047174,
      "grad_norm": 0.3055581748485565,
      "learning_rate": 8.612147713360854e-05,
      "loss": 0.0029,
      "step": 2478500
    },
    {
      "epoch": 0.13929724847195862,
      "grad_norm": 0.016204068437218666,
      "learning_rate": 8.611866600886347e-05,
      "loss": 0.0027,
      "step": 2479000
    },
    {
      "epoch": 0.1393253439234455,
      "grad_norm": 0.31247758865356445,
      "learning_rate": 8.611585488411842e-05,
      "loss": 0.0033,
      "step": 2479500
    },
    {
      "epoch": 0.1393534393749324,
      "grad_norm": 0.2419605255126953,
      "learning_rate": 8.611304375937334e-05,
      "loss": 0.0031,
      "step": 2480000
    },
    {
      "epoch": 0.1393534393749324,
      "eval_loss": 0.0009257805068045855,
      "eval_runtime": 20.6457,
      "eval_samples_per_second": 4843.628,
      "eval_steps_per_second": 75.706,
      "step": 2480000
    },
    {
      "epoch": 0.13938153482641927,
      "grad_norm": 0.04863845929503441,
      "learning_rate": 8.611023263462829e-05,
      "loss": 0.0034,
      "step": 2480500
    },
    {
      "epoch": 0.13940963027790615,
      "grad_norm": 0.14821447432041168,
      "learning_rate": 8.610742150988321e-05,
      "loss": 0.0031,
      "step": 2481000
    },
    {
      "epoch": 0.13943772572939303,
      "grad_norm": 0.014280799776315689,
      "learning_rate": 8.610461038513815e-05,
      "loss": 0.0033,
      "step": 2481500
    },
    {
      "epoch": 0.1394658211808799,
      "grad_norm": 0.08231925219297409,
      "learning_rate": 8.610179926039308e-05,
      "loss": 0.0033,
      "step": 2482000
    },
    {
      "epoch": 0.1394939166323668,
      "grad_norm": 0.06581336259841919,
      "learning_rate": 8.609898813564801e-05,
      "loss": 0.003,
      "step": 2482500
    },
    {
      "epoch": 0.13952201208385367,
      "grad_norm": 0.20049773156642914,
      "learning_rate": 8.609617701090296e-05,
      "loss": 0.0032,
      "step": 2483000
    },
    {
      "epoch": 0.13955010753534056,
      "grad_norm": 0.00678613968193531,
      "learning_rate": 8.609336588615788e-05,
      "loss": 0.0034,
      "step": 2483500
    },
    {
      "epoch": 0.13957820298682744,
      "grad_norm": 0.09311876446008682,
      "learning_rate": 8.609055476141282e-05,
      "loss": 0.0032,
      "step": 2484000
    },
    {
      "epoch": 0.13960629843831432,
      "grad_norm": 0.13310232758522034,
      "learning_rate": 8.608774363666775e-05,
      "loss": 0.0028,
      "step": 2484500
    },
    {
      "epoch": 0.1396343938898012,
      "grad_norm": 0.03668701648712158,
      "learning_rate": 8.608493251192269e-05,
      "loss": 0.0034,
      "step": 2485000
    },
    {
      "epoch": 0.13966248934128808,
      "grad_norm": 0.16647931933403015,
      "learning_rate": 8.608212138717762e-05,
      "loss": 0.0027,
      "step": 2485500
    },
    {
      "epoch": 0.13969058479277496,
      "grad_norm": 0.3420109748840332,
      "learning_rate": 8.607931026243255e-05,
      "loss": 0.0033,
      "step": 2486000
    },
    {
      "epoch": 0.13971868024426184,
      "grad_norm": 0.09619796276092529,
      "learning_rate": 8.607649913768749e-05,
      "loss": 0.0033,
      "step": 2486500
    },
    {
      "epoch": 0.13974677569574873,
      "grad_norm": 0.03303459286689758,
      "learning_rate": 8.607368801294242e-05,
      "loss": 0.0028,
      "step": 2487000
    },
    {
      "epoch": 0.1397748711472356,
      "grad_norm": 0.012745531275868416,
      "learning_rate": 8.607087688819736e-05,
      "loss": 0.0034,
      "step": 2487500
    },
    {
      "epoch": 0.1398029665987225,
      "grad_norm": 0.07419634610414505,
      "learning_rate": 8.606806576345229e-05,
      "loss": 0.003,
      "step": 2488000
    },
    {
      "epoch": 0.13983106205020937,
      "grad_norm": 0.3854198455810547,
      "learning_rate": 8.606525463870723e-05,
      "loss": 0.0028,
      "step": 2488500
    },
    {
      "epoch": 0.13985915750169625,
      "grad_norm": 0.12040600925683975,
      "learning_rate": 8.606244351396216e-05,
      "loss": 0.0032,
      "step": 2489000
    },
    {
      "epoch": 0.13988725295318313,
      "grad_norm": 0.38129106163978577,
      "learning_rate": 8.60596323892171e-05,
      "loss": 0.0031,
      "step": 2489500
    },
    {
      "epoch": 0.13991534840467001,
      "grad_norm": 0.5022072196006775,
      "learning_rate": 8.605682126447201e-05,
      "loss": 0.0029,
      "step": 2490000
    },
    {
      "epoch": 0.13991534840467001,
      "eval_loss": 0.0009238669881597161,
      "eval_runtime": 21.5202,
      "eval_samples_per_second": 4646.789,
      "eval_steps_per_second": 72.629,
      "step": 2490000
    },
    {
      "epoch": 0.1399434438561569,
      "grad_norm": 0.1459672898054123,
      "learning_rate": 8.605401013972696e-05,
      "loss": 0.003,
      "step": 2490500
    },
    {
      "epoch": 0.13997153930764378,
      "grad_norm": 0.09515421837568283,
      "learning_rate": 8.60511990149819e-05,
      "loss": 0.0032,
      "step": 2491000
    },
    {
      "epoch": 0.13999963475913066,
      "grad_norm": 0.07712067663669586,
      "learning_rate": 8.604838789023683e-05,
      "loss": 0.0031,
      "step": 2491500
    },
    {
      "epoch": 0.14002773021061754,
      "grad_norm": 0.5120638012886047,
      "learning_rate": 8.604557676549176e-05,
      "loss": 0.003,
      "step": 2492000
    },
    {
      "epoch": 0.14005582566210442,
      "grad_norm": 0.024926964193582535,
      "learning_rate": 8.604276564074669e-05,
      "loss": 0.0037,
      "step": 2492500
    },
    {
      "epoch": 0.1400839211135913,
      "grad_norm": 0.040747325867414474,
      "learning_rate": 8.603995451600163e-05,
      "loss": 0.003,
      "step": 2493000
    },
    {
      "epoch": 0.14011201656507818,
      "grad_norm": 0.0066085075959563255,
      "learning_rate": 8.603714339125655e-05,
      "loss": 0.0031,
      "step": 2493500
    },
    {
      "epoch": 0.14014011201656507,
      "grad_norm": 0.5669000148773193,
      "learning_rate": 8.60343322665115e-05,
      "loss": 0.003,
      "step": 2494000
    },
    {
      "epoch": 0.14016820746805195,
      "grad_norm": 0.1473742574453354,
      "learning_rate": 8.603152114176644e-05,
      "loss": 0.0031,
      "step": 2494500
    },
    {
      "epoch": 0.14019630291953883,
      "grad_norm": 0.2671333849430084,
      "learning_rate": 8.602871001702136e-05,
      "loss": 0.0032,
      "step": 2495000
    },
    {
      "epoch": 0.1402243983710257,
      "grad_norm": 0.023992370814085007,
      "learning_rate": 8.60258988922763e-05,
      "loss": 0.0031,
      "step": 2495500
    },
    {
      "epoch": 0.1402524938225126,
      "grad_norm": 0.2671101987361908,
      "learning_rate": 8.602308776753123e-05,
      "loss": 0.003,
      "step": 2496000
    },
    {
      "epoch": 0.14028058927399947,
      "grad_norm": 0.021232934668660164,
      "learning_rate": 8.602027664278617e-05,
      "loss": 0.0031,
      "step": 2496500
    },
    {
      "epoch": 0.14030868472548635,
      "grad_norm": 0.02267903834581375,
      "learning_rate": 8.60174655180411e-05,
      "loss": 0.0034,
      "step": 2497000
    },
    {
      "epoch": 0.14033678017697324,
      "grad_norm": 0.11983169615268707,
      "learning_rate": 8.601465439329604e-05,
      "loss": 0.0027,
      "step": 2497500
    },
    {
      "epoch": 0.14036487562846012,
      "grad_norm": 0.004267022013664246,
      "learning_rate": 8.601184326855096e-05,
      "loss": 0.0031,
      "step": 2498000
    },
    {
      "epoch": 0.140392971079947,
      "grad_norm": 0.09896083921194077,
      "learning_rate": 8.60090321438059e-05,
      "loss": 0.0032,
      "step": 2498500
    },
    {
      "epoch": 0.14042106653143388,
      "grad_norm": 0.20103411376476288,
      "learning_rate": 8.600622101906084e-05,
      "loss": 0.0036,
      "step": 2499000
    },
    {
      "epoch": 0.14044916198292076,
      "grad_norm": 0.02743367664515972,
      "learning_rate": 8.600340989431576e-05,
      "loss": 0.0032,
      "step": 2499500
    },
    {
      "epoch": 0.14047725743440764,
      "grad_norm": 0.1786024421453476,
      "learning_rate": 8.600059876957071e-05,
      "loss": 0.003,
      "step": 2500000
    },
    {
      "epoch": 0.14047725743440764,
      "eval_loss": 0.00085383903933689,
      "eval_runtime": 20.578,
      "eval_samples_per_second": 4859.555,
      "eval_steps_per_second": 75.955,
      "step": 2500000
    }
  ],
  "logging_steps": 500,
  "max_steps": 17796475,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 500000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 500,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 8
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.2121226510218035e+18,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
